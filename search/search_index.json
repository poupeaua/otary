{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Index","text":"<p> Otary library, shape your images, image your shapes. </p> <p> </p>"},{"location":"#welcome-to-otary","title":"Welcome to Otary","text":"<p>Otary \u2014 elegant, readable, and powerful image and 2D geometry Python library.</p>"},{"location":"#features","title":"Features","text":"<p>The main features of Otary are:</p> <ul> <li> <p>Unification: Otary offers a cohesive solution for image and geometry manipulation, letting you work seamlessly without switching tools.</p> </li> <li> <p>Readability: Self-explanatory by design. Otary\u2019s clean, readable code eliminates the need for comments, making it easy for beginners to learn and for experts to build efficiently.</p> </li> <li> <p>Performance: optimized for speed and efficiency, making it suitable for high-performance applications. It is built on top of NumPy and OpenCV, which are known for their speed and performance.</p> </li> <li> <p>Interactivity: designed to be Interactive and user-friendly, ideal for Jupyter notebooks and live exploration.</p> </li> <li> <p>Flexibility: provides a flexible and extensible architecture, allowing developers to customize and extend its functionality as needed.</p> </li> </ul>"},{"location":"#example","title":"Example","text":"<p>Let me illustrate the usage of Otary with a simple example. Imagine you need to:</p> <ol> <li>read an image from a pdf file</li> <li>draw an rectangle on it, shift and rotate the rectangle</li> <li>crop a part of the image</li> <li>rotate the cropped image</li> <li>apply a threshold</li> <li>show the image</li> </ol> <p>In order to compare the use of Otary versus other libraries, I will use the same example but with different libraries. Try it yourself on your favorite LLM (like ChatGPT) by copying the query:</p> <pre><code>Generate a python code to read an image from a pdf, draw a rectangle on it, shift and rotate the rectangle, crop a part of the image, rotate the cropped image, apply a threshold on the image.\n</code></pre> <p>Using Otary you can do it with few lines of code:</p> OtaryChatGPT using other libraries <pre><code>import otary as ot\n\nim = ot.Image.from_pdf(\"path/to/you/file.pdf\", page_nb=0)\n\nrectangle = ot.Rectangle([[1, 1], [4, 1], [4, 4], [1, 4]]) * 100\nrectangle.shift([50, 50]).rotate(angle=30, is_degree=True)\n\nim = (\n    im.draw_polygons([rectangle])\n    .crop(x0=50, y0=50, x1=450, y1=450)\n    .rotate(angle=90, is_degree=True)\n    .threshold_simple(thresh=200)\n)\n\nim.show()\n</code></pre> <pre><code>#!/usr/bin/env python3\n\"\"\"\nSteps:\n- Load first page of a PDF as an image\n- Draw a rectangle\n- Shift &amp; rotate that rectangle (visualized as a rotated box)\n- Crop a region of the image\n- Rotate the cropped image\n- Threshold the (rotated) crop\n\nDependencies:\n    pip install pdf2image Pillow opencv-python\n    # If pdf2image isn't available, install: pip install PyMuPDF\n    # Note: pdf2image requires Poppler on your system.\n\nEdit the CONFIG section below to suit your needs.\n\"\"\"\n\nfrom pathlib import Path\nimport math\n\n# Pillow &amp; OpenCV\nfrom PIL import Image, ImageDraw\nimport numpy as np\nimport cv2\n\n# Try to import a PDF rasterizer\n_loader = None\ntry:\n    from pdf2image import convert_from_path\n    _loader = \"pdf2image\"\nexcept Exception:\n    try:\n        import fitz  # PyMuPDF\n        _loader = \"pymupdf\"\n    except Exception:\n        _loader = None\n\n\n# --------------------------- CONFIG --------------------------- #\nPDF_PATH = \"example.pdf\"        # &lt;- put your PDF path here\nOUTPUT_DIR = Path(\"out_steps\")\nOUTPUT_DIR.mkdir(exist_ok=True)\n\n# Rectangle (axis-aligned) you want to draw first:\nrect_x, rect_y, rect_w, rect_h = 200, 150, 400, 250  # pixels\n\n# Shift to apply to the rectangle center (dx, dy):\nshift_dx, shift_dy = 120, -40  # pixels\n\n# Rotation to apply to the rectangle (degrees, positive=CCW):\nrotate_deg = 25.0\n\n# Crop region from the original image (x, y, w, h):\ncrop_x, crop_y, crop_w, crop_h = 100, 100, 600, 400\n\n# Rotation to apply to the cropped image (degrees):\ncrop_rotate_deg = -15.0\n\n# Threshold (use None to use Otsu automatically)\nfixed_threshold_value = None  # e.g., set to 128 to force a fixed threshold\n# -------------------------------------------------------------- #\n\n\ndef load_pdf_first_page_as_image(pdf_path: str, dpi: int = 300) -&gt; Image.Image:\n    \"\"\"Return the first page of a PDF as a Pillow RGB image.\"\"\"\n    if _loader == \"pdf2image\":\n        pil_pages = convert_from_path(pdf_path, dpi=dpi, first_page=1, last_page=1)\n        if not pil_pages:\n            raise RuntimeError(\"No pages found in PDF.\")\n        return pil_pages[0].convert(\"RGB\")\n    elif _loader == \"pymupdf\":\n        doc = fitz.open(pdf_path)\n        if doc.page_count == 0:\n            raise RuntimeError(\"No pages found in PDF.\")\n        page = doc.load_page(0)\n        # 300 dpi equivalent scaling\n        zoom = dpi / 72.0\n        mat = fitz.Matrix(zoom, zoom)\n        pix = page.get_pixmap(matrix=mat, alpha=False)\n        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n        return img\n    else:\n        raise ImportError(\n            \"No PDF rasterizer available. Install either `pdf2image` (plus Poppler) or `PyMuPDF`.\"\n        )\n\n\ndef pil_to_cv(img_pil: Image.Image) -&gt; np.ndarray:\n    \"\"\"Pillow RGB -&gt; OpenCV BGR\"\"\"\n    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n\n\ndef cv_to_pil(img_cv: np.ndarray) -&gt; Image.Image:\n    \"\"\"OpenCV BGR -&gt; Pillow RGB\"\"\"\n    return Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))\n\n\ndef draw_axis_aligned_rectangle_pil(img_pil: Image.Image, x, y, w, h, width=4):\n    \"\"\"Draw axis-aligned rectangle on a PIL image.\"\"\"\n    draw = ImageDraw.Draw(img_pil)\n    draw.rectangle([x, y, x + w, y + h], outline=(255, 0, 0), width=width)\n    return img_pil\n\n\ndef draw_rotated_rectangle_cv(img_cv: np.ndarray, center, size, angle_deg: float, thickness=3, color=(0, 255, 0)):\n    \"\"\"\n    Draw a rotated rectangle using OpenCV. center=(cx,cy), size=(w,h), angle in degrees CCW.\n    \"\"\"\n    rect = (center, size, angle_deg)\n    box = cv2.boxPoints(rect)  # 4x2 float32 array of vertices\n    box = np.int32(box)\n    cv2.polylines(img_cv, [box], isClosed=True, color=color, thickness=thickness)\n    return img_cv\n\n\ndef rotate_image_keep_bounds(img_cv: np.ndarray, angle_deg: float) -&gt; np.ndarray:\n    \"\"\"\n    Rotate an image about its center, expanding bounds so nothing is cropped.\n    \"\"\"\n    (h, w) = img_cv.shape[:2]\n    c = (w // 2, h // 2)\n    M = cv2.getRotationMatrix2D(c, angle_deg, 1.0)\n    # compute new bounds\n    cos = abs(M[0, 0])\n    sin = abs(M[0, 1])\n    new_w = int((h * sin) + (w * cos))\n    new_h = int((h * cos) + (w * sin))\n    # adjust rotation matrix to account for translation\n    M[0, 2] += (new_w / 2) - c[0]\n    M[1, 2] += (new_h / 2) - c[1]\n    rotated = cv2.warpAffine(img_cv, M, (new_w, new_h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n    return rotated\n\n\ndef threshold_image(img_cv_gray: np.ndarray, fixed_thresh: int | None = None) -&gt; np.ndarray:\n    \"\"\"\n    Apply binary threshold. If fixed_thresh is None, use Otsu.\n    \"\"\"\n    if fixed_thresh is None:\n        _, th = cv2.threshold(img_cv_gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n    else:\n        _, th = cv2.threshold(img_cv_gray, int(fixed_thresh), 255, cv2.THRESH_BINARY)\n    return th\n\n\ndef main():\n    # 1) Load first page\n    pil_img = load_pdf_first_page_as_image(PDF_PATH, dpi=300)\n    pil_img.save(OUTPUT_DIR / \"01_loaded_page.png\")\n\n    # 2) Draw axis-aligned rectangle (Pillow)\n    pil_with_rect = pil_img.copy()\n    pil_with_rect = draw_axis_aligned_rectangle_pil(pil_with_rect, rect_x, rect_y, rect_w, rect_h, width=4)\n    pil_with_rect.save(OUTPUT_DIR / \"02_axis_aligned_rect.png\")\n\n    # Convert to OpenCV for further operations\n    cv_img = pil_to_cv(pil_with_rect)\n\n    # 3) Shift &amp; rotate rectangle (OpenCV rotated box)\n    #    Start from the original rectangle center:\n    cx = rect_x + rect_w / 2.0\n    cy = rect_y + rect_h / 2.0\n    #    Apply shift\n    cx_shifted = cx + shift_dx\n    cy_shifted = cy + shift_dy\n    #    Draw rotated rectangle (in green)\n    cv_img_rotrect = cv_img.copy()\n    cv_img_rotrect = draw_rotated_rectangle_cv(\n        cv_img_rotrect,\n        center=(cx_shifted, cy_shifted),\n        size=(rect_w, rect_h),\n        angle_deg=rotate_deg,\n        thickness=3,\n        color=(0, 255, 0),\n    )\n    cv2.imwrite(str(OUTPUT_DIR / \"03_shifted_rotated_rect.png\"), cv_img_rotrect)\n\n    # 4) Crop a region (axis-aligned box on the original image)\n    x1, y1 = int(crop_x), int(crop_y)\n    x2, y2 = int(crop_x + crop_w), int(crop_y + crop_h)\n    h, w = cv_img.shape[:2]\n    # clamp to image\n    x1 = max(0, min(w - 1, x1))\n    y1 = max(0, min(h - 1, y1))\n    x2 = max(0, min(w, x2))\n    y2 = max(0, min(h, y2))\n    crop = cv_img[y1:y2, x1:x2].copy()\n    cv2.imwrite(str(OUTPUT_DIR / \"04_crop.png\"), crop)\n\n    # 5) Rotate the cropped image (keeping bounds)\n    crop_rot = rotate_image_keep_bounds(crop, crop_rotate_deg)\n    cv2.imwrite(str(OUTPUT_DIR / \"05_crop_rotated.png\"), crop_rot)\n\n    # 6) Threshold the (rotated) crop\n    crop_gray = cv2.cvtColor(crop_rot, cv2.COLOR_BGR2GRAY)\n    crop_th = threshold_image(crop_gray, fixed_threshold_value)\n    cv2.imwrite(str(OUTPUT_DIR / \"06_crop_threshold.png\"), crop_th)\n\n    print(\"Done. See outputs in:\", OUTPUT_DIR.resolve())\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>ChatGPT proposes to re-invent the wheel and over-complicates everything.</p> <p>Using Otary makes the code:</p> <ul> <li>Much more readable and hence maintainable</li> <li>Much more interactive</li> <li>Much simpler, simplifying libraries management by only using one library and not manipulating multiple libraries like Pillow, OpenCV, Scikit-Image, PyMuPDF etc.</li> </ul>"},{"location":"#enhanced-interactivity","title":"Enhanced Interactivity","text":"<p>Enhanced Interactivity</p> <p>In a Jupyter notebook, you can easily test and iterate on transformations by simply commenting part of the code as you need it.</p> <pre><code>im = (\n    im.draw_polygons([rectangle])\n    # .crop(x0=50, y0=50, x1=450, y1=450)\n    # .rotate(angle=90, is_degree=True)\n    .threshold_simple(thresh=200)\n)\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>Otary is available on PyPI.</p> <p>Always make sure you are in a virtual environment before installing.</p> <pre><code>pip install otary\n</code></pre> <p>You can also install it using poetry</p> <pre><code>poetry add otary\n</code></pre> <p>If you use uv:</p> <pre><code>uv add otary\n</code></pre>"},{"location":"quickstart/","title":"Getting Started","text":""},{"location":"quickstart/#installation","title":"Installation","text":"<p>To start using Otary, simply install it via pip:</p> <pre><code>pip install otary\n</code></pre> <p>For more information on how to install Otary, please refer to the Installation page.</p>"},{"location":"quickstart/#basic-example","title":"Basic example","text":"<p>Here is a very basic usage of the Otary library that you can use as a starting point by simply copying and pasting the code below:</p> <pre><code>import otary as ot\n\n# instantiate an image\nim = ot.Image.from_fillvalue(shape=(1000, 1000, 3))\n\n# instantiate a polygon\npolygon = ot.Polygon(points=[[1, 7], [3, 3], [3, 2], [5, 2], [6, 3], [7, 2], [8, 4], [7, 5], [5, 8], [4, 7]])\n\n# scale the polygon\npolygon *= 100\n\n# rotate the polygon (pivot point is by default the centroid of the geometry entity)\npolygon.rotate(angle=15, is_clockwise=True, is_degree=True)\n\n# draw the polygon on the image\nim.draw_polygons(\n    polygons=[polygon],\n    render=ot.PolygonsRender(\n        is_filled=True,\n        default_color=\"blue\"\n    )\n)\n\nim.show()\n</code></pre> <p></p> <p>You can play around with this code in a script or a Jupyter notebook to explore to the full power of Otary.</p>"},{"location":"quickstart/#going-further","title":"Going further","text":"<p>You can explore more examples, tutorials and advanced functionalities in the Learn section.</p> <p>You can also jump to the API Reference to look for specific methods and classes or to get a deeper understanding of the library.</p>"},{"location":"why/","title":"Why Otary ?","text":""},{"location":"why/#unification","title":"Unification","text":"<p>\u201cOne library. Images and geometry together.\u201d</p> <p>Otary is a unified library for image and geometry processing, enabling easy manipulation and interaction between images and geometric objects without the need to use multiple libraries.</p> <p>If you\u2019ve ever found yourself juggling tools like Numpy, OpenCV, Shapely, PyMuPDF or fitz, Matplotlib, Pillow, Scikit-Image, Sympy, pdf2image, etc... you are not alone.</p> <p>You can always use the specific libraries if you need a more low-level control over your image processing pipeline.</p>"},{"location":"why/#readability","title":"Readability","text":"<p>\u201cNo comment.\u201d</p> <p>Otary is designed so the API speaks for itself. Otary\u2019s ultimate goal is to make you never need to write comments at all.</p> <p>Like Uncle Bob says in his book Clean Code, if you need to write a comment you have failed to express yourself through your code.</p> <p>Thus one of the main focus of Otary is to make your code as readable and easy to understand as possible.</p>"},{"location":"why/#performance","title":"Performance","text":"<p>Otary\u2019s image module uses OpenCV for fast, efficient image processing, while its geometry module relies on NumPy to deliver high-performance numerical and geometric operations.</p> <p>Otary is optimized for speed and efficiency, making it suitable for high-performance applications.</p>"},{"location":"why/#interactivity","title":"Interactivity","text":"<p>Otary is designed to be Interactive and user-friendly, ideal for Jupyter notebooks and live exploration.</p> <p>Enhanced Interactivity</p> <p>In a Jupyter notebook, you can easily test and iterate on transformations by simply commenting part of the code as you need it.</p> <pre><code>im = (\n    im.draw_polygons([rectangle])\n    # .crop(x0=50, y0=50, x1=450, y1=450)\n    # .rotate(angle=90, is_degree=True)\n    .threshold_simple(thresh=200)\n)\n</code></pre>"},{"location":"why/#flexibility","title":"Flexibility","text":"<p>Otary provides a flexible and extensible architecture, allowing developers to customize and extend its functionality as needed.</p> <p>If you are a Python developer, interested by Otary and want to contribute, feel free to bring your ideas to life! Check the Contributing section for more details.</p>"},{"location":"about/contributing/","title":"Contributing","text":"<p>If you are new to contributing to open-source projects, please check out this guide.</p> <p>This section assumes you have some familiarity with Git, GitHub, and Python virtualenvs.</p>"},{"location":"about/contributing/#set-up-the-repository","title":"Set Up the Repository","text":"<p>Here are the 3 steps you need to follow to set up the repository:</p> <ol> <li> <p>Fork the repository</p> <p>Go to this page and click the <code>Fork</code> button. This will create a copy of the repository in your GitHub account.</p> <p></p> </li> <li> <p>Clone the forked repository locally</p> <p>Go to your GitHub dashboard, click on the forked repository, and then click the <code>Code</code> button. Use the clone method you prefer.</p> <p></p> </li> <li> <p>Create a new branch</p> <p>Once the repository is cloned on your local device, you need to create a new branch.</p> <p>Otary follows the Gitflow workflow. You are therefore encourage to create a feature branch from the dev branch.</p> <p>Once on the dev branch, create a new branch like this:</p> <pre><code>git checkout -b feature/any-name-you-like\n</code></pre> </li> </ol>"},{"location":"about/contributing/#install-dependencies","title":"Install Dependencies","text":"<ol> <li> <p>Create a virtual environment</p> <p>You first need to set up a Python Virtual Environment. You can create it the way you like.</p> <p>I would recomment the use of pyenv + pyenv-virtualenv. This makes you coding experience smoother when it comes to manage multiple Python versions and multiple virtual environments.</p> <p>Activate your virtual environment.</p> </li> <li> <p>Install project dependencies</p> <p>This project currently uses Poetry as its dependency manager. If you do not have it installed, you first need to install Poetry.</p> <p>Poetry environment check</p> <p>You may want to check that Poetry understood you virtual environment correctly and will indeed install all your dependencies in it. You can do a quick check by running:</p> <pre><code>poetry env info\n</code></pre> <p>It should give you information about the virtual environment used by Poetry.</p> <p>Once Poetry is installed, run at the root of the project:</p> <pre><code>poetry sync\n</code></pre> <p>For more information about what this command does, please refer to the Poetry documentation.</p> </li> </ol>"},{"location":"about/contributing/#contribute-to-codebase","title":"Contribute to codebase","text":"<p>You are all done ! You can now start contributing to Otary ! Any idea or suggestion is welcome.</p> <p>If you do not have any idea, you can start with the \"Good first issue\" issues.</p>"},{"location":"about/contributing/#run-tests","title":"Run tests","text":"<p>Any change you propose should be tested before submitting a pull request.</p> <p>The CI/CD pipeline already includes tests and checks but controlling code before pushing is always a good idea. Run the following command:</p> <pre><code>make full-check\n</code></pre> <p>This will run all the code quality checks and the tests. Tools used for Otary development are:</p> <ul> <li>pytest: the Python testing framework</li> <li>pylint: the basic Python linter</li> <li>ruff: a fast Python linter</li> <li>mypy: a static type checker</li> <li>black: a code formatter</li> <li>pre-commit: a tool to manage git hooks before commiting</li> </ul> <p>For a fine-grained control on checks and tests, you can take a look at the <code>Makefile</code> at the root of the repository.</p>"},{"location":"about/contributing/#interactive-jupyter-notebook-development","title":"Interactive Jupyter Notebook development","text":"<p>Since Otary is a image and geometry processing library, having a visual interface to play with is a must.</p> <p>If you need to iterate quickly on the code and see the results right away, you can use a Jupyter notebook.</p> <p>For this you can put the two following cells at the top of your notebook:</p> <pre><code># automatically reload otary after a code change\n% load_ext autoreload\n% autoreload 2\n</code></pre> <pre><code>import otary as ot\n</code></pre> <p>You can put your Jupyter notebooks in the <code>notebooks/</code> directory at the root of the repository.</p>"},{"location":"about/contributing/#principles","title":"Principles","text":"<p>Thank you for respecting the following principles when contributing:</p> <ul> <li>Code tries to reach excellence and follows code best practices. Read the book \"Clean Code\" by Robert C. Martin if you are interested.</li> <li>Keep It Simple, Stupid (KISS principle). Do not overcomplicate things.</li> <li>Use type hints</li> <li>Function docstrings are written in Google style</li> <li>Try not to add new dependencies</li> </ul> <p>About tests: - Tests are written using pytest and are grouped within classes when possible when they are related - Try to respect TDD (Test Driven Development) if possible</p>"},{"location":"about/contributing/#contribute-to-documentation","title":"Contribute to documentation","text":"<p>The documentation is built using mkdocs and mkdocs-material.</p> <p>Start by running the following command:</p> <pre><code>make docs-serve\n</code></pre> <p>The documentation website will be available at <code>http://127.0.0.1:8000/</code></p> <p>It will be automatically be updated when you make any change to files in the <code>docs/</code> directory or the <code>mkdocs.yml</code> file at the root of the repository. You do not need to re-run the command over and over again after each change.</p>"},{"location":"about/contributing/#submit-a-pull-request","title":"Submit a Pull Request","text":"<p>Once you are done with your contribution, you can commit, push and submit a pull request by clicking on the <code>Compare &amp; pull request</code> button on the GitHub page on your forked repository.</p> <p>Thank you for your contribution !</p>"},{"location":"about/fair_advice/","title":"A Fair Advice","text":"<p>I, the author of the Otary library, want to be really fair about the use of this framework.</p> <p>Robert C. Martin in the book <code>Clean Architecture</code> at page 292</p> <p>Most frameworks authors offer their work for free because they want to be helpful to the community. They want to give back. This is laudable. However, regardless of their high-minded motives, those authors do not have your best interests at heart. They can't because they don't know you, and they don't know your problems.</p> <p>Framework authors know their own problems, and the problems of their coworkers and friends. And they write their frameworks to solve those problems \u2014 not yours.</p> <p>Of course, your problems will likely overlap with those other problems quite a bit. If this were not the case, frameworks would not be so popular. To the extent that such overlap exists, frameworks can be very useful indeed.</p> <p>I totally agree with this. In fact, this corresponds exactly to the history of Otary. Otary was born to solve my personal problems for my personal project. Otary exists because I needed something that did not exist. And I was not satisfied with what existed.</p> <p>Otary was born from real-world experience: the recurring problems I faced in previous projects and the pain points my colleagues often shared.</p> <p>Otary isn\u2019t perfect, and it probably never will be, just like any real-world tool. But it was built to solve genuine problems, and it might solve some of yours too. I hope you enjoy using it as much as I enjoyed creating it. Happy coding!</p>"},{"location":"about/history/","title":"History","text":"<p>Otary was at the beginning only a part of a larger project in a private repository in 2024. I decided to make it public and open source in July 2025.</p> <p>At the start, I was just tired of needing all the python image libraries to perform both basic and specific image processing tasks. I just wanted something that was simple to use and easy to understand.</p> <p>I needed a tool that combines image processing and geometry processing, this is where the journey started.</p> <p>This is how Otary was born.</p>"},{"location":"about/license/","title":"License","text":"<p>Otary is released under the BSD 3-Clause License.</p> <p>George E. P. Box</p> <p>\u201cAll models are wrong, but some are useful.\u201d</p> <pre><code>BSD 3-Clause License\n\nCopyright (c) 2025, Alexandre Poupeau\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n</code></pre>"},{"location":"api/","title":"API","text":"<p>Otary is built upon two core modules Image and Geometry, each designed with a distinct architectural pattern to provide flexibility and power.</p>"},{"location":"api/#image-a-composition-based-approach","title":"Image: A Composition-Based Approach","text":"<p>The <code>image</code> module is designed following a composition over inheritance principle. This allows you to build complex image processing pipelines by combining smaller, independent, and reusable components. Instead of inheriting properties from a monolithic class, you can dynamically assemble functionality, leading to a more flexible and maintainable codebase.</p> <p>The image object is composed of a <code>Reader</code> to load data, <code>Writer</code> to save data, a <code>Transformer</code> to apply modifications and a <code>Drawer</code> to add overlays, all working together seamlessly.</p>"},{"location":"api/#geometry-an-inheritance-based-structure","title":"Geometry: An Inheritance-Based Structure","text":"<p>The <code>geometry</code> module uses a more traditional inheritance model. It provides a clear and hierarchical structure for geometric entities. Base classes define common behaviors, and specialized subclasses inherit and extend this functionality. This approach is ideal for creating a well-defined and logical classification of shapes and geometric objects.</p>"},{"location":"api/geometry/","title":"Geometry","text":"<p>The <code>geometry</code> module provides a comprehensive set of tools for working with geometric shapes and entities.</p>"},{"location":"api/geometry/#geometric-objects","title":"Geometric Objects","text":"<p>The <code>geometry</code> module is organized into two main categories <code>discrete</code> and <code>continuous</code>. Each category contains other sub-categories like shape, linear, etc.</p> <ul> <li> <p>Discrete: Represents geometric entities that are defined by a finite set of points:</p> <ul> <li>Point</li> <li>Segment</li> <li>Linear Spline</li> <li>Vector</li> <li>Vectorized Linear Spline</li> <li>Polygon</li> <li>Rectangle</li> <li>Triangle</li> </ul> </li> <li> <p>Continuous: Represents geometric entities that are defined by continuous mathematical functions:</p> <ul> <li>Circle</li> <li>Ellipse</li> </ul> </li> </ul>"},{"location":"api/geometry/#available-modules","title":"Available Modules","text":"<p>Below is a list of available modules and their functionalities:</p>"},{"location":"api/geometry/#base-geometry","title":"Base Geometry","text":"<p>GeometryEntity module which allows to define transformation and property shared by all type of geometry objects</p>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity","title":"<code>GeometryEntity</code>","text":"<p>               Bases: <code>ABC</code></p> <p>GeometryEntity class which is the abstract base class for all geometry classes</p> Source code in <code>otary/geometry/entity.py</code> <pre><code>class GeometryEntity(ABC):\n    \"\"\"GeometryEntity class which is the abstract base class for all geometry classes\"\"\"\n\n    # --------------------------------- PROPERTIES ------------------------------------\n\n    @property\n    @abstractmethod\n    def shapely_edges(self) -&gt; GeometryCollection:\n        \"\"\"Representation of the geometric object in the shapely library\n        as a geometrical object defined only as a curve with no area. Particularly\n        useful to look for points intersections\n        \"\"\"\n\n    @property\n    @abstractmethod\n    def shapely_surface(self) -&gt; GeometryCollection:\n        \"\"\"Representation of the geometric object in the shapely library\n        as a geometrical object with an area and a border. Particularly useful\n        to check if two geometrical objects are contained within each other or not.\n        \"\"\"\n\n    @property\n    @abstractmethod\n    def area(self) -&gt; float:\n        \"\"\"Compute the area of the geometry entity\n\n        Returns:\n            float: area value\n        \"\"\"\n\n    @property\n    @abstractmethod\n    def perimeter(self) -&gt; float:\n        \"\"\"Compute the perimeter of the geometry entity\n\n        Returns:\n            float: perimeter value\n        \"\"\"\n\n    @property\n    @abstractmethod\n    def centroid(self) -&gt; NDArray:\n        \"\"\"Compute the centroid point which can be seen as the center of gravity of\n        the shape\n\n        Returns:\n            NDArray: centroid point\n        \"\"\"\n\n    @property\n    @abstractmethod\n    def xmax(self) -&gt; float:\n        \"\"\"Get the maximum X coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n\n    @property\n    @abstractmethod\n    def xmin(self) -&gt; float:\n        \"\"\"Get the minimum X coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n\n    @property\n    @abstractmethod\n    def ymax(self) -&gt; float:\n        \"\"\"Get the maximum Y coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n\n    @property\n    @abstractmethod\n    def ymin(self) -&gt; float:\n        \"\"\"Get the minimum Y coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n\n    # ---------------------------- MODIFICATION METHODS -------------------------------\n\n    @abstractmethod\n    def rotate(\n        self,\n        angle: float,\n        is_degree: bool = False,\n        is_clockwise: bool = True,\n        pivot: Optional[NDArray] = None,\n    ) -&gt; Self:\n        \"\"\"Rotate the geometry entity object.\n        A pivot point can be passed as an argument to rotate the object around the pivot\n\n        Args:\n            angle (float): rotation angle\n            is_degree (bool, optional): whether the angle is in degree or radian.\n                Defaults to False which means radians.\n            is_clockwise (bool, optional): whether the rotation is clockwise or\n                counter-clockwise. Defaults to True.\n            pivot (NDArray, optional): pivot point.\n                Defaults to None which means that by default the centroid point of\n                the shape is taken as the pivot point.\n\n        Returns:\n            GeometryEntity: rotated geometry entity object.\n        \"\"\"\n\n    @abstractmethod\n    def shift(self, vector: NDArray) -&gt; Self:\n        \"\"\"Shift the geometry entity by the vector direction\n\n        Args:\n            vector (NDArray): vector that describes the shift as a array with\n                two elements. Example: [2, -8] which describes the\n                vector [[0, 0], [2, -8]]. The vector can also be a vector of shape\n                (2, 2) of the form [[2, 6], [1, 3]].\n\n        Returns:\n            GeometryEntity: shifted geometrical object\n        \"\"\"\n\n    @abstractmethod\n    def normalize(self, x: float, y: float) -&gt; Self:\n        \"\"\"Normalize the geometry entity by dividing the points by a norm on the\n        x and y coordinates.\n\n        Args:\n            x (float): x coordinate norm\n            y (float): y coordinate norm\n\n        Returns:\n            GeometryEntity: normalized GeometryEntity\n        \"\"\"\n\n    # ------------------------------- CLASSIC METHODS ---------------------------------\n\n    @abstractmethod\n    def copy(self) -&gt; Self:\n        \"\"\"Create a copy of the geometry entity object\n\n        Returns:\n            GeometryEntity: copy of the geometry entity object\n        \"\"\"\n\n    def intersection(self, other: GeometryEntity, only_points: bool = True) -&gt; NDArray:\n        \"\"\"Compute the intersections between two geometric objects.\n        If the only_points parameter is True, then we only consider intersection points\n        as valid. We can not have another type of intersection.\n\n        Args:\n            other (GeometryEntity): other GeometryEntity object\n            only_points (bool, optional): whether to consider only points.\n                Defaults to True.\n\n        Returns:\n            NDArray: list of n points of shape (n, 2)\n        \"\"\"\n        it = self.shapely_edges.intersection(other=other.shapely_edges)\n\n        if isinstance(it, SPoint):  # only one intersection point\n            return np.array([[it.x, it.y]])\n        if isinstance(it, MultiPoint):  # several intersection points\n            return np.asanyarray([[pt.x, pt.y] for pt in it.geoms])\n        if isinstance(it, LineString) and not only_points:  # one intersection line\n            return NotImplemented\n        if isinstance(it, MultiLineString) and not only_points:  # multilines\n            return NotImplemented\n        if isinstance(it, GeometryCollection):  # lines and pts\n            return NotImplemented\n\n        return np.array([])\n\n    @abstractmethod\n    def enclosing_axis_aligned_bbox(self) -&gt; AxisAlignedRectangle:\n        \"\"\"Compute the smallest area enclosing Axis-Aligned Bounding Box (AABB)\n        See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n        Returns:\n            AxisAlignedRectangle: AxisAlignedRectangle object\n        \"\"\"\n\n    def aabb(self) -&gt; AxisAlignedRectangle:\n        \"\"\"Alias for `enclosing_axis_aligned_bbox` method\n\n        Returns:\n            AxisAlignedRectangle: AxisAlignedRectangle object\n        \"\"\"\n        return self.enclosing_axis_aligned_bbox()\n\n    @abstractmethod\n    def enclosing_oriented_bbox(self) -&gt; Rectangle:\n        \"\"\"Compute the smallest area enclosing Oriented Bounding Box (OBB)\n        See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n        Returns:\n            Rectangle: Rectangle object\n        \"\"\"\n\n    def obb(self) -&gt; Rectangle:\n        \"\"\"Alias for `enclosing_oriented_bbox` method\n\n        Returns:\n            Rectangle: Rectangle object\n        \"\"\"\n        return self.enclosing_oriented_bbox()\n\n    @abstractmethod\n    def enclosing_convex_hull(self) -&gt; Polygon:\n        \"\"\"Compute the smallest area enclosing Convex Hull\n        See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n        Returns:\n            Polygon: Polygon object\n        \"\"\"\n</code></pre>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.area","title":"<code>area</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Compute the area of the geometry entity</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>area value</p>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.centroid","title":"<code>centroid</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Compute the centroid point which can be seen as the center of gravity of the shape</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>centroid point</p>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.perimeter","title":"<code>perimeter</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Compute the perimeter of the geometry entity</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>perimeter value</p>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.shapely_edges","title":"<code>shapely_edges</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Representation of the geometric object in the shapely library as a geometrical object defined only as a curve with no area. Particularly useful to look for points intersections</p>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.shapely_surface","title":"<code>shapely_surface</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Representation of the geometric object in the shapely library as a geometrical object with an area and a border. Particularly useful to check if two geometrical objects are contained within each other or not.</p>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.xmax","title":"<code>xmax</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Get the maximum X coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.xmin","title":"<code>xmin</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Get the minimum X coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.ymax","title":"<code>ymax</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Get the maximum Y coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.ymin","title":"<code>ymin</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Get the minimum Y coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.aabb","title":"<code>aabb()</code>","text":"<p>Alias for <code>enclosing_axis_aligned_bbox</code> method</p> <p>Returns:</p> Name Type Description <code>AxisAlignedRectangle</code> <code>AxisAlignedRectangle</code> <p>AxisAlignedRectangle object</p> Source code in <code>otary/geometry/entity.py</code> <pre><code>def aabb(self) -&gt; AxisAlignedRectangle:\n    \"\"\"Alias for `enclosing_axis_aligned_bbox` method\n\n    Returns:\n        AxisAlignedRectangle: AxisAlignedRectangle object\n    \"\"\"\n    return self.enclosing_axis_aligned_bbox()\n</code></pre>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.copy","title":"<code>copy()</code>  <code>abstractmethod</code>","text":"<p>Create a copy of the geometry entity object</p> <p>Returns:</p> Name Type Description <code>GeometryEntity</code> <code>Self</code> <p>copy of the geometry entity object</p> Source code in <code>otary/geometry/entity.py</code> <pre><code>@abstractmethod\ndef copy(self) -&gt; Self:\n    \"\"\"Create a copy of the geometry entity object\n\n    Returns:\n        GeometryEntity: copy of the geometry entity object\n    \"\"\"\n</code></pre>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.enclosing_axis_aligned_bbox","title":"<code>enclosing_axis_aligned_bbox()</code>  <code>abstractmethod</code>","text":"<p>Compute the smallest area enclosing Axis-Aligned Bounding Box (AABB) See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html</p> <p>Returns:</p> Name Type Description <code>AxisAlignedRectangle</code> <code>AxisAlignedRectangle</code> <p>AxisAlignedRectangle object</p> Source code in <code>otary/geometry/entity.py</code> <pre><code>@abstractmethod\ndef enclosing_axis_aligned_bbox(self) -&gt; AxisAlignedRectangle:\n    \"\"\"Compute the smallest area enclosing Axis-Aligned Bounding Box (AABB)\n    See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n    Returns:\n        AxisAlignedRectangle: AxisAlignedRectangle object\n    \"\"\"\n</code></pre>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.enclosing_convex_hull","title":"<code>enclosing_convex_hull()</code>  <code>abstractmethod</code>","text":"<p>Compute the smallest area enclosing Convex Hull See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html</p> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>Polygon object</p> Source code in <code>otary/geometry/entity.py</code> <pre><code>@abstractmethod\ndef enclosing_convex_hull(self) -&gt; Polygon:\n    \"\"\"Compute the smallest area enclosing Convex Hull\n    See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n    Returns:\n        Polygon: Polygon object\n    \"\"\"\n</code></pre>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.enclosing_oriented_bbox","title":"<code>enclosing_oriented_bbox()</code>  <code>abstractmethod</code>","text":"<p>Compute the smallest area enclosing Oriented Bounding Box (OBB) See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html</p> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Rectangle</code> <p>Rectangle object</p> Source code in <code>otary/geometry/entity.py</code> <pre><code>@abstractmethod\ndef enclosing_oriented_bbox(self) -&gt; Rectangle:\n    \"\"\"Compute the smallest area enclosing Oriented Bounding Box (OBB)\n    See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n    Returns:\n        Rectangle: Rectangle object\n    \"\"\"\n</code></pre>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.intersection","title":"<code>intersection(other, only_points=True)</code>","text":"<p>Compute the intersections between two geometric objects. If the only_points parameter is True, then we only consider intersection points as valid. We can not have another type of intersection.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>GeometryEntity</code> <p>other GeometryEntity object</p> required <code>only_points</code> <code>bool</code> <p>whether to consider only points. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>list of n points of shape (n, 2)</p> Source code in <code>otary/geometry/entity.py</code> <pre><code>def intersection(self, other: GeometryEntity, only_points: bool = True) -&gt; NDArray:\n    \"\"\"Compute the intersections between two geometric objects.\n    If the only_points parameter is True, then we only consider intersection points\n    as valid. We can not have another type of intersection.\n\n    Args:\n        other (GeometryEntity): other GeometryEntity object\n        only_points (bool, optional): whether to consider only points.\n            Defaults to True.\n\n    Returns:\n        NDArray: list of n points of shape (n, 2)\n    \"\"\"\n    it = self.shapely_edges.intersection(other=other.shapely_edges)\n\n    if isinstance(it, SPoint):  # only one intersection point\n        return np.array([[it.x, it.y]])\n    if isinstance(it, MultiPoint):  # several intersection points\n        return np.asanyarray([[pt.x, pt.y] for pt in it.geoms])\n    if isinstance(it, LineString) and not only_points:  # one intersection line\n        return NotImplemented\n    if isinstance(it, MultiLineString) and not only_points:  # multilines\n        return NotImplemented\n    if isinstance(it, GeometryCollection):  # lines and pts\n        return NotImplemented\n\n    return np.array([])\n</code></pre>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.normalize","title":"<code>normalize(x, y)</code>  <code>abstractmethod</code>","text":"<p>Normalize the geometry entity by dividing the points by a norm on the x and y coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>x coordinate norm</p> required <code>y</code> <code>float</code> <p>y coordinate norm</p> required <p>Returns:</p> Name Type Description <code>GeometryEntity</code> <code>Self</code> <p>normalized GeometryEntity</p> Source code in <code>otary/geometry/entity.py</code> <pre><code>@abstractmethod\ndef normalize(self, x: float, y: float) -&gt; Self:\n    \"\"\"Normalize the geometry entity by dividing the points by a norm on the\n    x and y coordinates.\n\n    Args:\n        x (float): x coordinate norm\n        y (float): y coordinate norm\n\n    Returns:\n        GeometryEntity: normalized GeometryEntity\n    \"\"\"\n</code></pre>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.obb","title":"<code>obb()</code>","text":"<p>Alias for <code>enclosing_oriented_bbox</code> method</p> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Rectangle</code> <p>Rectangle object</p> Source code in <code>otary/geometry/entity.py</code> <pre><code>def obb(self) -&gt; Rectangle:\n    \"\"\"Alias for `enclosing_oriented_bbox` method\n\n    Returns:\n        Rectangle: Rectangle object\n    \"\"\"\n    return self.enclosing_oriented_bbox()\n</code></pre>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.rotate","title":"<code>rotate(angle, is_degree=False, is_clockwise=True, pivot=None)</code>  <code>abstractmethod</code>","text":"<p>Rotate the geometry entity object. A pivot point can be passed as an argument to rotate the object around the pivot</p> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>float</code> <p>rotation angle</p> required <code>is_degree</code> <code>bool</code> <p>whether the angle is in degree or radian. Defaults to False which means radians.</p> <code>False</code> <code>is_clockwise</code> <code>bool</code> <p>whether the rotation is clockwise or counter-clockwise. Defaults to True.</p> <code>True</code> <code>pivot</code> <code>NDArray</code> <p>pivot point. Defaults to None which means that by default the centroid point of the shape is taken as the pivot point.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>GeometryEntity</code> <code>Self</code> <p>rotated geometry entity object.</p> Source code in <code>otary/geometry/entity.py</code> <pre><code>@abstractmethod\ndef rotate(\n    self,\n    angle: float,\n    is_degree: bool = False,\n    is_clockwise: bool = True,\n    pivot: Optional[NDArray] = None,\n) -&gt; Self:\n    \"\"\"Rotate the geometry entity object.\n    A pivot point can be passed as an argument to rotate the object around the pivot\n\n    Args:\n        angle (float): rotation angle\n        is_degree (bool, optional): whether the angle is in degree or radian.\n            Defaults to False which means radians.\n        is_clockwise (bool, optional): whether the rotation is clockwise or\n            counter-clockwise. Defaults to True.\n        pivot (NDArray, optional): pivot point.\n            Defaults to None which means that by default the centroid point of\n            the shape is taken as the pivot point.\n\n    Returns:\n        GeometryEntity: rotated geometry entity object.\n    \"\"\"\n</code></pre>"},{"location":"api/geometry/#otary.geometry.entity.GeometryEntity.shift","title":"<code>shift(vector)</code>  <code>abstractmethod</code>","text":"<p>Shift the geometry entity by the vector direction</p> <p>Parameters:</p> Name Type Description Default <code>vector</code> <code>NDArray</code> <p>vector that describes the shift as a array with two elements. Example: [2, -8] which describes the vector [[0, 0], [2, -8]]. The vector can also be a vector of shape (2, 2) of the form [[2, 6], [1, 3]].</p> required <p>Returns:</p> Name Type Description <code>GeometryEntity</code> <code>Self</code> <p>shifted geometrical object</p> Source code in <code>otary/geometry/entity.py</code> <pre><code>@abstractmethod\ndef shift(self, vector: NDArray) -&gt; Self:\n    \"\"\"Shift the geometry entity by the vector direction\n\n    Args:\n        vector (NDArray): vector that describes the shift as a array with\n            two elements. Example: [2, -8] which describes the\n            vector [[0, 0], [2, -8]]. The vector can also be a vector of shape\n            (2, 2) of the form [[2, 6], [1, 3]].\n\n    Returns:\n        GeometryEntity: shifted geometrical object\n    \"\"\"\n</code></pre>"},{"location":"api/geometry/#continuous-geometry","title":"Continuous Geometry","text":"<p>ContinuousGeometryEntity module class</p>"},{"location":"api/geometry/#otary.geometry.continuous.entity.ContinuousGeometryEntity","title":"<code>ContinuousGeometryEntity</code>","text":"<p>               Bases: <code>GeometryEntity</code>, <code>ABC</code></p> <p>ContinuousGeometryEntity class which is the abstract base class for continuous or smooth geometry objects like circles, ellipse, etc...</p> Source code in <code>otary/geometry/continuous/entity.py</code> <pre><code>class ContinuousGeometryEntity(GeometryEntity, ABC):\n    \"\"\"\n    ContinuousGeometryEntity class which is the abstract base class for\n    continuous or smooth geometry objects like circles, ellipse, etc...\n    \"\"\"\n\n    DEFAULT_N_POLY_APPROX = 1000  # number of pts to use in polygonal approximation\n\n    def __init__(self, n_points_polygonal_approx: int = DEFAULT_N_POLY_APPROX):\n        \"\"\"Initialize a ContinuousGeometryEntity object\n\n        Args:\n            n_points_polygonal_approx (int, optional): n points to be used in\n                the polygonal approximation.\n                Defaults to DEFAULT_N_POINTS_POLYGONAL_APPROX.\n        \"\"\"\n        self._n_points_polygonal_approx = n_points_polygonal_approx\n        # self._polyapprox = is defined in subclasses\n\n    # --------------------------------- PROPERTIES ------------------------------------\n\n    @property\n    def n_points_polygonal_approx(self) -&gt; int:\n        \"\"\"Get the number of points for the polygonal approximation.\n\n        Returns:\n            int: The number of points used in the polygonal approximation.\n        \"\"\"\n        return self._n_points_polygonal_approx\n\n    @n_points_polygonal_approx.setter\n    def n_points_polygonal_approx(self, value):\n        \"\"\"\n        Set the number of points for the polygonal approximation.\n        This would also update the polygonal approximation of the geometry entity.\n\n        Args:\n            value (int): The number of points to be used in the polygonal approximation.\n        \"\"\"\n        self._n_points_polygonal_approx = value\n        self.update_polyapprox()\n\n    @property\n    def polyaprox(self) -&gt; Polygon:\n        \"\"\"Generate a polygonal approximation of the continuous geometry entity.\n\n        Beware: No setter is defined for this property as it is a read-only property.\n        You can update the polygonal approximation using the method named\n        `update_polyapprox`.\n\n        Returns:\n            Polygon: polygonal approximation of the continuous geometry entity\n        \"\"\"\n        return self._polyapprox\n\n    @abstractmethod\n    def polygonal_approx(self, n_points: int, is_cast_int: bool) -&gt; Polygon:\n        \"\"\"Generate a polygonal approximation of the continuous geometry entity\n\n        Args:\n            n_points (int): number of points that make up the polygonal\n                approximation. The bigger the better to obtain more precise\n                results in intersection or other similar computations.\n\n        Returns:\n            Polygon: polygonal approximation of the continuous geometry entity\n        \"\"\"\n\n    @abstractmethod\n    def curvature(self, point: NDArray) -&gt; float:\n        \"\"\"Curvature at the point defined as parameter\n\n        Args:\n            point (NDArray): input point.\n\n        Returns:\n            float: _description_\n        \"\"\"\n\n    @property\n    def xmax(self) -&gt; float:\n        \"\"\"Get the maximum X coordinate of the geometry entity\n\n        Returns:\n            np.ndarray: 2D point\n        \"\"\"\n        return self.polyaprox.xmax\n\n    @property\n    def xmin(self) -&gt; float:\n        \"\"\"Get the minimum X coordinate of the geometry entity\n\n        Returns:\n            np.ndarray: 2D point\n        \"\"\"\n        return self.polyaprox.xmin\n\n    @property\n    def ymax(self) -&gt; float:\n        \"\"\"Get the maximum Y coordinate of the geometry entity\n\n        Returns:\n            np.ndarray: 2D point\n        \"\"\"\n        return self.polyaprox.ymax\n\n    @property\n    def ymin(self) -&gt; float:\n        \"\"\"Get the minimum Y coordinate of the geometry entity\n\n        Returns:\n            np.ndarray: 2D point\n        \"\"\"\n        return self.polyaprox.ymin\n\n    # ---------------------------- MODIFICATION METHODS -------------------------------\n\n    # done in the derived classes\n\n    # ------------------------------- CLASSIC METHODS ---------------------------------\n\n    def update_polyapprox(self) -&gt; None:\n        \"\"\"Update the polygonal approximation of the continuous geometry entity\"\"\"\n        # pylint: disable=attribute-defined-outside-init\n        self._polyapprox = self.polygonal_approx(\n            n_points=self.n_points_polygonal_approx, is_cast_int=False\n        )\n\n    def enclosing_axis_aligned_bbox(self) -&gt; AxisAlignedRectangle:\n        \"\"\"Compute the smallest area enclosing Axis-Aligned Bounding Box (AABB)\n        See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n        Returns:\n            AxisAlignedRectangle: AxisAlignedRectangle object\n        \"\"\"\n        topleft_x, topleft_y, width, height = cv2.boundingRect(\n            array=self.polyaprox.asarray.astype(np.float32)\n        )\n        topleft = np.array([topleft_x, topleft_y])\n        return AxisAlignedRectangle.from_topleft(\n            topleft=topleft, width=width, height=height\n        )\n\n    def enclosing_oriented_bbox(self) -&gt; Rectangle:\n        \"\"\"Compute the smallest area enclosing Oriented Bounding Box (OBB)\n        See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n        Returns:\n            Rectangle: Rectangle object\n        \"\"\"\n        rect = cv2.minAreaRect(self.polyaprox.asarray.astype(np.float32))\n        bbox = cv2.boxPoints(rect)\n        return Rectangle(bbox)\n\n    def enclosing_convex_hull(self) -&gt; Polygon:\n        \"\"\"Compute the smallest area enclosing Convex Hull\n        See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n        Returns:\n            Polygon: Polygon object\n        \"\"\"\n\n        convexhull = np.squeeze(cv2.convexHull(self.polyaprox.asarray))\n        return Polygon(convexhull)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.entity.ContinuousGeometryEntity.n_points_polygonal_approx","title":"<code>n_points_polygonal_approx</code>  <code>property</code> <code>writable</code>","text":"<p>Get the number of points for the polygonal approximation.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of points used in the polygonal approximation.</p>"},{"location":"api/geometry/#otary.geometry.continuous.entity.ContinuousGeometryEntity.polyaprox","title":"<code>polyaprox</code>  <code>property</code>","text":"<p>Generate a polygonal approximation of the continuous geometry entity.</p> <p>Beware: No setter is defined for this property as it is a read-only property. You can update the polygonal approximation using the method named <code>update_polyapprox</code>.</p> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>polygonal approximation of the continuous geometry entity</p>"},{"location":"api/geometry/#otary.geometry.continuous.entity.ContinuousGeometryEntity.xmax","title":"<code>xmax</code>  <code>property</code>","text":"<p>Get the maximum X coordinate of the geometry entity</p> <p>Returns:</p> Type Description <code>float</code> <p>np.ndarray: 2D point</p>"},{"location":"api/geometry/#otary.geometry.continuous.entity.ContinuousGeometryEntity.xmin","title":"<code>xmin</code>  <code>property</code>","text":"<p>Get the minimum X coordinate of the geometry entity</p> <p>Returns:</p> Type Description <code>float</code> <p>np.ndarray: 2D point</p>"},{"location":"api/geometry/#otary.geometry.continuous.entity.ContinuousGeometryEntity.ymax","title":"<code>ymax</code>  <code>property</code>","text":"<p>Get the maximum Y coordinate of the geometry entity</p> <p>Returns:</p> Type Description <code>float</code> <p>np.ndarray: 2D point</p>"},{"location":"api/geometry/#otary.geometry.continuous.entity.ContinuousGeometryEntity.ymin","title":"<code>ymin</code>  <code>property</code>","text":"<p>Get the minimum Y coordinate of the geometry entity</p> <p>Returns:</p> Type Description <code>float</code> <p>np.ndarray: 2D point</p>"},{"location":"api/geometry/#otary.geometry.continuous.entity.ContinuousGeometryEntity.__init__","title":"<code>__init__(n_points_polygonal_approx=DEFAULT_N_POLY_APPROX)</code>","text":"<p>Initialize a ContinuousGeometryEntity object</p> <p>Parameters:</p> Name Type Description Default <code>n_points_polygonal_approx</code> <code>int</code> <p>n points to be used in the polygonal approximation. Defaults to DEFAULT_N_POINTS_POLYGONAL_APPROX.</p> <code>DEFAULT_N_POLY_APPROX</code> Source code in <code>otary/geometry/continuous/entity.py</code> <pre><code>def __init__(self, n_points_polygonal_approx: int = DEFAULT_N_POLY_APPROX):\n    \"\"\"Initialize a ContinuousGeometryEntity object\n\n    Args:\n        n_points_polygonal_approx (int, optional): n points to be used in\n            the polygonal approximation.\n            Defaults to DEFAULT_N_POINTS_POLYGONAL_APPROX.\n    \"\"\"\n    self._n_points_polygonal_approx = n_points_polygonal_approx\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.entity.ContinuousGeometryEntity.curvature","title":"<code>curvature(point)</code>  <code>abstractmethod</code>","text":"<p>Curvature at the point defined as parameter</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>input point.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>description</p> Source code in <code>otary/geometry/continuous/entity.py</code> <pre><code>@abstractmethod\ndef curvature(self, point: NDArray) -&gt; float:\n    \"\"\"Curvature at the point defined as parameter\n\n    Args:\n        point (NDArray): input point.\n\n    Returns:\n        float: _description_\n    \"\"\"\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.entity.ContinuousGeometryEntity.enclosing_axis_aligned_bbox","title":"<code>enclosing_axis_aligned_bbox()</code>","text":"<p>Compute the smallest area enclosing Axis-Aligned Bounding Box (AABB) See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html</p> <p>Returns:</p> Name Type Description <code>AxisAlignedRectangle</code> <code>AxisAlignedRectangle</code> <p>AxisAlignedRectangle object</p> Source code in <code>otary/geometry/continuous/entity.py</code> <pre><code>def enclosing_axis_aligned_bbox(self) -&gt; AxisAlignedRectangle:\n    \"\"\"Compute the smallest area enclosing Axis-Aligned Bounding Box (AABB)\n    See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n    Returns:\n        AxisAlignedRectangle: AxisAlignedRectangle object\n    \"\"\"\n    topleft_x, topleft_y, width, height = cv2.boundingRect(\n        array=self.polyaprox.asarray.astype(np.float32)\n    )\n    topleft = np.array([topleft_x, topleft_y])\n    return AxisAlignedRectangle.from_topleft(\n        topleft=topleft, width=width, height=height\n    )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.entity.ContinuousGeometryEntity.enclosing_convex_hull","title":"<code>enclosing_convex_hull()</code>","text":"<p>Compute the smallest area enclosing Convex Hull See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html</p> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>Polygon object</p> Source code in <code>otary/geometry/continuous/entity.py</code> <pre><code>def enclosing_convex_hull(self) -&gt; Polygon:\n    \"\"\"Compute the smallest area enclosing Convex Hull\n    See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n    Returns:\n        Polygon: Polygon object\n    \"\"\"\n\n    convexhull = np.squeeze(cv2.convexHull(self.polyaprox.asarray))\n    return Polygon(convexhull)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.entity.ContinuousGeometryEntity.enclosing_oriented_bbox","title":"<code>enclosing_oriented_bbox()</code>","text":"<p>Compute the smallest area enclosing Oriented Bounding Box (OBB) See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html</p> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Rectangle</code> <p>Rectangle object</p> Source code in <code>otary/geometry/continuous/entity.py</code> <pre><code>def enclosing_oriented_bbox(self) -&gt; Rectangle:\n    \"\"\"Compute the smallest area enclosing Oriented Bounding Box (OBB)\n    See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n    Returns:\n        Rectangle: Rectangle object\n    \"\"\"\n    rect = cv2.minAreaRect(self.polyaprox.asarray.astype(np.float32))\n    bbox = cv2.boxPoints(rect)\n    return Rectangle(bbox)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.entity.ContinuousGeometryEntity.polygonal_approx","title":"<code>polygonal_approx(n_points, is_cast_int)</code>  <code>abstractmethod</code>","text":"<p>Generate a polygonal approximation of the continuous geometry entity</p> <p>Parameters:</p> Name Type Description Default <code>n_points</code> <code>int</code> <p>number of points that make up the polygonal approximation. The bigger the better to obtain more precise results in intersection or other similar computations.</p> required <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>polygonal approximation of the continuous geometry entity</p> Source code in <code>otary/geometry/continuous/entity.py</code> <pre><code>@abstractmethod\ndef polygonal_approx(self, n_points: int, is_cast_int: bool) -&gt; Polygon:\n    \"\"\"Generate a polygonal approximation of the continuous geometry entity\n\n    Args:\n        n_points (int): number of points that make up the polygonal\n            approximation. The bigger the better to obtain more precise\n            results in intersection or other similar computations.\n\n    Returns:\n        Polygon: polygonal approximation of the continuous geometry entity\n    \"\"\"\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.entity.ContinuousGeometryEntity.update_polyapprox","title":"<code>update_polyapprox()</code>","text":"<p>Update the polygonal approximation of the continuous geometry entity</p> Source code in <code>otary/geometry/continuous/entity.py</code> <pre><code>def update_polyapprox(self) -&gt; None:\n    \"\"\"Update the polygonal approximation of the continuous geometry entity\"\"\"\n    # pylint: disable=attribute-defined-outside-init\n    self._polyapprox = self.polygonal_approx(\n        n_points=self.n_points_polygonal_approx, is_cast_int=False\n    )\n</code></pre>"},{"location":"api/geometry/#shape","title":"Shape","text":"<p>Circle Geometric Object</p> <p>Ellipse Geometric Object</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle","title":"<code>Circle</code>","text":"<p>               Bases: <code>Ellipse</code></p> <p>Circle geometrical object</p> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>class Circle(Ellipse):\n    \"\"\"Circle geometrical object\"\"\"\n\n    def __init__(\n        self,\n        center: NDArray | list,\n        radius: float,\n        n_points_polygonal_approx: int = ContinuousGeometryEntity.DEFAULT_N_POLY_APPROX,\n    ):\n        \"\"\"Initialize a Circle geometrical object\n\n        Args:\n            center (NDArray): center 2D point\n            radius (float): radius value\n            n_points_polygonal_approx (int, optional): number of points to be used in\n                the polygonal approximation of the circle. Defaults to\n                ContinuousGeometryEntity.DEFAULT_N_POINTS_POLYGONAL_APPROX.\n        \"\"\"\n        super().__init__(\n            foci1=center,\n            foci2=center,\n            semi_major_axis=radius,\n            n_points_polygonal_approx=n_points_polygonal_approx,\n        )\n        self.center = np.asarray(center)\n        self.radius = radius\n        self.update_polyapprox()\n\n    # --------------------------------- PROPERTIES ------------------------------------\n\n    @property\n    def perimeter(self) -&gt; float:\n        \"\"\"Perimeter of the circle\n\n        Returns:\n            float: perimeter value\n        \"\"\"\n        return 2 * math.pi * self.radius\n\n    @property\n    def centroid(self) -&gt; NDArray:\n        \"\"\"Center of the circle\n\n        Returns:\n            float: center 2D point\n        \"\"\"\n        return self.center\n\n    @property\n    def shapely_surface(self) -&gt; SPolygon:\n        \"\"\"Returns the Shapely.Polygon as an surface representation of the Circle.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html\n\n        Returns:\n            Polygon: shapely.Polygon object\n        \"\"\"\n        return SPolygon(self.polyaprox.asarray, holes=None)\n\n    @property\n    def shapely_edges(self) -&gt; LinearRing:\n        \"\"\"Returns the Shapely.LinearRing as a curve representation of the Circle.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.LinearRing.html\n\n        Returns:\n            LinearRing: shapely.LinearRing object\n        \"\"\"\n        return LinearRing(coordinates=self.polyaprox.asarray)\n\n    def polygonal_approx(self, n_points: int, is_cast_int: bool = False) -&gt; Polygon:\n        \"\"\"Generate a Polygon object that is an approximation of the circle\n        as a discrete geometrical object made up of only points and segments.\n\n        Args:\n            n_points (int): number of points that make up the circle\n                polygonal approximation\n            is_cast_int (bool): whether to cast to int the points coordinates or\n                not. Defaults to False\n\n        Returns:\n            Polygon: Polygon representing the circle as a succession of n points\n\n        \"\"\"\n        points = []\n        for theta in np.linspace(0, 2 * math.pi, n_points):\n            x = self.center[0] + self.radius * math.cos(theta)\n            y = self.center[1] + self.radius * math.sin(theta)\n            points.append([x, y])\n\n        poly = Polygon(points=np.asarray(points), is_cast_int=is_cast_int)\n        return poly\n\n    def curvature(self, point: Optional[NDArray] = None) -&gt; float:\n        \"\"\"Curvature of circle is a constant and does not depend on a position of\n        a point\n\n        Returns:\n            float: curvature value\n        \"\"\"\n        return 1 / self.radius\n\n    @property\n    def xmax(self) -&gt; float:\n        \"\"\"Get the maximum X coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n        return self.center[0] + self.radius\n\n    @property\n    def xmin(self) -&gt; float:\n        \"\"\"Get the minimum X coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n        return self.center[0] - self.radius\n\n    @property\n    def ymax(self) -&gt; float:\n        \"\"\"Get the maximum Y coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n        return self.center[1] + self.radius\n\n    @property\n    def ymin(self) -&gt; float:\n        \"\"\"Get the minimum Y coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n        return self.center[1] - self.radius\n\n    @property\n    def is_circle(self) -&gt; bool:\n        \"\"\"Check if the circle is a circle\n\n        Returns:\n            bool: True if circle else False\n        \"\"\"\n        return True\n\n    # ---------------------------- MODIFICATION METHODS -------------------------------\n\n    def rotate(\n        self,\n        angle: float,\n        is_degree: bool = False,\n        is_clockwise: bool = True,\n        pivot: Optional[NDArray] = None,\n    ) -&gt; Self:\n        \"\"\"Rotate the circle around a pivot point.\n\n        Args:\n            angle (float): angle by which to rotate the circle\n            is_degree (bool, optional): whether the angle is in degrees.\n                Defaults to False.\n            is_clockwise (bool, optional): whether the rotation is clockwise.\n                Defaults to True.\n            pivot (Optional[NDArray], optional): pivot point around which to rotate.\n                Defaults to None.\n\n        Returns:\n            Self: rotated circle object\n        \"\"\"\n        if pivot is None:\n            # If no pivot is given, the circle is rotated around its center\n            # and thus is not modified\n            return self\n\n        self.center = rotate_2d_points(\n            points=self.center,\n            angle=angle,\n            is_degree=is_degree,\n            is_clockwise=is_clockwise,\n            pivot=pivot,\n        )\n        self.update_polyapprox()\n        return self\n\n    def shift(self, vector: NDArray) -&gt; Self:\n        \"\"\"Shift the circle by a given vector.\n\n        Args:\n            vector (NDArray): 2D vector by which to shift the circle\n\n        Returns:\n            Self: shifted circle object\n        \"\"\"\n        vector = assert_transform_shift_vector(vector=vector)\n        self.center += vector\n        self.update_polyapprox()\n        return self\n\n    def normalize(self, x: float, y: float) -&gt; Self:\n        \"\"\"Normalize the circle by dividing the points by a norm on the x and y\n        coordinates. This does not change the circle radius.\n\n        Args:\n            x (float): x coordinate norm\n            y (float): y coordinate norm\n\n        Returns:\n            Self: normalized circle object\n        \"\"\"\n        self.center = self.center / np.array([x, y])\n        self.update_polyapprox()\n        return self\n\n    # ------------------------------- CLASSIC METHODS ---------------------------------\n\n    def copy(self) -&gt; Self:\n        \"\"\"Copy the circle object\n\n        Returns:\n            Self: copied circle object\n        \"\"\"\n        return type(self)(\n            center=self.center,\n            radius=self.radius,\n            n_points_polygonal_approx=self.n_points_polygonal_approx,\n        )\n\n    def __str__(self) -&gt; str:\n        return f\"Circle(center={self.center}, radius={self.radius})\"\n\n    def __repr__(self):\n        return f\"Circle(center={self.center}, radius={self.radius})\"\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.centroid","title":"<code>centroid</code>  <code>property</code>","text":"<p>Center of the circle</p> <p>Returns:</p> Name Type Description <code>float</code> <code>NDArray</code> <p>center 2D point</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.is_circle","title":"<code>is_circle</code>  <code>property</code>","text":"<p>Check if the circle is a circle</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if circle else False</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.perimeter","title":"<code>perimeter</code>  <code>property</code>","text":"<p>Perimeter of the circle</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>perimeter value</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.shapely_edges","title":"<code>shapely_edges</code>  <code>property</code>","text":"<p>Returns the Shapely.LinearRing as a curve representation of the Circle. See https://shapely.readthedocs.io/en/stable/reference/shapely.LinearRing.html</p> <p>Returns:</p> Name Type Description <code>LinearRing</code> <code>LinearRing</code> <p>shapely.LinearRing object</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.shapely_surface","title":"<code>shapely_surface</code>  <code>property</code>","text":"<p>Returns the Shapely.Polygon as an surface representation of the Circle. See https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html</p> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>shapely.Polygon object</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.xmax","title":"<code>xmax</code>  <code>property</code>","text":"<p>Get the maximum X coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.xmin","title":"<code>xmin</code>  <code>property</code>","text":"<p>Get the minimum X coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.ymax","title":"<code>ymax</code>  <code>property</code>","text":"<p>Get the maximum Y coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.ymin","title":"<code>ymin</code>  <code>property</code>","text":"<p>Get the minimum Y coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.__init__","title":"<code>__init__(center, radius, n_points_polygonal_approx=ContinuousGeometryEntity.DEFAULT_N_POLY_APPROX)</code>","text":"<p>Initialize a Circle geometrical object</p> <p>Parameters:</p> Name Type Description Default <code>center</code> <code>NDArray</code> <p>center 2D point</p> required <code>radius</code> <code>float</code> <p>radius value</p> required <code>n_points_polygonal_approx</code> <code>int</code> <p>number of points to be used in the polygonal approximation of the circle. Defaults to ContinuousGeometryEntity.DEFAULT_N_POINTS_POLYGONAL_APPROX.</p> <code>DEFAULT_N_POLY_APPROX</code> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>def __init__(\n    self,\n    center: NDArray | list,\n    radius: float,\n    n_points_polygonal_approx: int = ContinuousGeometryEntity.DEFAULT_N_POLY_APPROX,\n):\n    \"\"\"Initialize a Circle geometrical object\n\n    Args:\n        center (NDArray): center 2D point\n        radius (float): radius value\n        n_points_polygonal_approx (int, optional): number of points to be used in\n            the polygonal approximation of the circle. Defaults to\n            ContinuousGeometryEntity.DEFAULT_N_POINTS_POLYGONAL_APPROX.\n    \"\"\"\n    super().__init__(\n        foci1=center,\n        foci2=center,\n        semi_major_axis=radius,\n        n_points_polygonal_approx=n_points_polygonal_approx,\n    )\n    self.center = np.asarray(center)\n    self.radius = radius\n    self.update_polyapprox()\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.copy","title":"<code>copy()</code>","text":"<p>Copy the circle object</p> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>copied circle object</p> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>def copy(self) -&gt; Self:\n    \"\"\"Copy the circle object\n\n    Returns:\n        Self: copied circle object\n    \"\"\"\n    return type(self)(\n        center=self.center,\n        radius=self.radius,\n        n_points_polygonal_approx=self.n_points_polygonal_approx,\n    )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.curvature","title":"<code>curvature(point=None)</code>","text":"<p>Curvature of circle is a constant and does not depend on a position of a point</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>curvature value</p> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>def curvature(self, point: Optional[NDArray] = None) -&gt; float:\n    \"\"\"Curvature of circle is a constant and does not depend on a position of\n    a point\n\n    Returns:\n        float: curvature value\n    \"\"\"\n    return 1 / self.radius\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.normalize","title":"<code>normalize(x, y)</code>","text":"<p>Normalize the circle by dividing the points by a norm on the x and y coordinates. This does not change the circle radius.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>x coordinate norm</p> required <code>y</code> <code>float</code> <p>y coordinate norm</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>normalized circle object</p> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>def normalize(self, x: float, y: float) -&gt; Self:\n    \"\"\"Normalize the circle by dividing the points by a norm on the x and y\n    coordinates. This does not change the circle radius.\n\n    Args:\n        x (float): x coordinate norm\n        y (float): y coordinate norm\n\n    Returns:\n        Self: normalized circle object\n    \"\"\"\n    self.center = self.center / np.array([x, y])\n    self.update_polyapprox()\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.polygonal_approx","title":"<code>polygonal_approx(n_points, is_cast_int=False)</code>","text":"<p>Generate a Polygon object that is an approximation of the circle as a discrete geometrical object made up of only points and segments.</p> <p>Parameters:</p> Name Type Description Default <code>n_points</code> <code>int</code> <p>number of points that make up the circle polygonal approximation</p> required <code>is_cast_int</code> <code>bool</code> <p>whether to cast to int the points coordinates or not. Defaults to False</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>Polygon representing the circle as a succession of n points</p> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>def polygonal_approx(self, n_points: int, is_cast_int: bool = False) -&gt; Polygon:\n    \"\"\"Generate a Polygon object that is an approximation of the circle\n    as a discrete geometrical object made up of only points and segments.\n\n    Args:\n        n_points (int): number of points that make up the circle\n            polygonal approximation\n        is_cast_int (bool): whether to cast to int the points coordinates or\n            not. Defaults to False\n\n    Returns:\n        Polygon: Polygon representing the circle as a succession of n points\n\n    \"\"\"\n    points = []\n    for theta in np.linspace(0, 2 * math.pi, n_points):\n        x = self.center[0] + self.radius * math.cos(theta)\n        y = self.center[1] + self.radius * math.sin(theta)\n        points.append([x, y])\n\n    poly = Polygon(points=np.asarray(points), is_cast_int=is_cast_int)\n    return poly\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.rotate","title":"<code>rotate(angle, is_degree=False, is_clockwise=True, pivot=None)</code>","text":"<p>Rotate the circle around a pivot point.</p> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>float</code> <p>angle by which to rotate the circle</p> required <code>is_degree</code> <code>bool</code> <p>whether the angle is in degrees. Defaults to False.</p> <code>False</code> <code>is_clockwise</code> <code>bool</code> <p>whether the rotation is clockwise. Defaults to True.</p> <code>True</code> <code>pivot</code> <code>Optional[NDArray]</code> <p>pivot point around which to rotate. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>rotated circle object</p> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>def rotate(\n    self,\n    angle: float,\n    is_degree: bool = False,\n    is_clockwise: bool = True,\n    pivot: Optional[NDArray] = None,\n) -&gt; Self:\n    \"\"\"Rotate the circle around a pivot point.\n\n    Args:\n        angle (float): angle by which to rotate the circle\n        is_degree (bool, optional): whether the angle is in degrees.\n            Defaults to False.\n        is_clockwise (bool, optional): whether the rotation is clockwise.\n            Defaults to True.\n        pivot (Optional[NDArray], optional): pivot point around which to rotate.\n            Defaults to None.\n\n    Returns:\n        Self: rotated circle object\n    \"\"\"\n    if pivot is None:\n        # If no pivot is given, the circle is rotated around its center\n        # and thus is not modified\n        return self\n\n    self.center = rotate_2d_points(\n        points=self.center,\n        angle=angle,\n        is_degree=is_degree,\n        is_clockwise=is_clockwise,\n        pivot=pivot,\n    )\n    self.update_polyapprox()\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.circle.Circle.shift","title":"<code>shift(vector)</code>","text":"<p>Shift the circle by a given vector.</p> <p>Parameters:</p> Name Type Description Default <code>vector</code> <code>NDArray</code> <p>2D vector by which to shift the circle</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>shifted circle object</p> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>def shift(self, vector: NDArray) -&gt; Self:\n    \"\"\"Shift the circle by a given vector.\n\n    Args:\n        vector (NDArray): 2D vector by which to shift the circle\n\n    Returns:\n        Self: shifted circle object\n    \"\"\"\n    vector = assert_transform_shift_vector(vector=vector)\n    self.center += vector\n    self.update_polyapprox()\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse","title":"<code>Ellipse</code>","text":"<p>               Bases: <code>ContinuousGeometryEntity</code></p> <p>Ellipse geometrical object</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>class Ellipse(ContinuousGeometryEntity):\n    \"\"\"Ellipse geometrical object\"\"\"\n\n    def __init__(\n        self,\n        foci1: NDArray | list,\n        foci2: NDArray | list,\n        semi_major_axis: float,\n        n_points_polygonal_approx: int = ContinuousGeometryEntity.DEFAULT_N_POLY_APPROX,\n    ):\n        \"\"\"Initialize a Ellipse geometrical object\n\n        Args:\n            foci1 (NDArray | list): first focal 2D point\n            foci2 (NDArray | list): second focal 2D point\n            semi_major_axis (float): semi major axis value\n            n_points_polygonal_approx (int, optional): number of points to be used in\n                the polygonal approximation.\n                Defaults to ContinuousGeometryEntity.DEFAULT_N_POINTS_POLYGONAL_APPROX.\n        \"\"\"\n        super().__init__(n_points_polygonal_approx=n_points_polygonal_approx)\n        self.foci1 = np.asarray(foci1)\n        self.foci2 = np.asarray(foci2)\n        self.semi_major_axis = semi_major_axis  # also called \"a\" usually\n        self.__assert_ellipse()\n\n        if type(self) is Ellipse:  # pylint: disable=unidiomatic-typecheck\n            # pylint check is wrong here since we want it to be ONLY an Ellipse\n            # not a circle. isinstance() check make children classes return True\n            # to avoid computation in circle class instantiation\n            # since the center attribute is not defined in the Circle class yet\n            self.update_polyapprox()\n\n    def __assert_ellipse(self) -&gt; None:\n        \"\"\"Assert the parameters of the ellipse.\n        If the parameters proposed do not make up a ellipse raise an error.\n        \"\"\"\n        if self.semi_major_axis &lt;= self.linear_eccentricity:\n            raise ValueError(\n                f\"The semi major-axis (a={self.semi_major_axis}) can not be smaller \"\n                f\"than the linear eccentricity (c={self.linear_eccentricity}). \"\n                \"The ellipse is thus not valid. Please increase the semi major-axis.\"\n            )\n\n    # --------------------------------- PROPERTIES ------------------------------------\n\n    @property\n    def centroid(self) -&gt; NDArray:\n        \"\"\"Compute the center point of the ellipse\n\n        Returns:\n            NDArray: 2D point defining the center of the ellipse\n        \"\"\"\n        return (self.foci1 + self.foci2) / 2\n\n    @property\n    def semi_minor_axis(self) -&gt; float:\n        \"\"\"Computed semi minor axis (also called b usually)\n\n        Returns:\n            float: _description_\n        \"\"\"\n        return math.sqrt(self.semi_major_axis**2 - self.linear_eccentricity**2)\n\n    @property\n    def linear_eccentricity(self) -&gt; float:\n        \"\"\"Distance from any focal point to the center\n\n        Returns:\n            float: linear eccentricity value\n        \"\"\"\n        return float(np.linalg.norm(self.foci2 - self.foci1) / 2)\n\n    @property\n    def focal_distance(self) -&gt; float:\n        \"\"\"Distance from any focal point to the center\n\n        Returns:\n            float: focal distance value\n        \"\"\"\n        return self.linear_eccentricity\n\n    @property\n    def eccentricity(self) -&gt; float:\n        \"\"\"Eccentricity value of the ellipse\n\n        Returns:\n            float: eccentricity value\n        \"\"\"\n        return self.linear_eccentricity / self.semi_major_axis\n\n    @property\n    def h(self) -&gt; float:\n        \"\"\"h is a common ellipse value used in calculation and kind of\n        represents the eccentricity of the ellipse but in another perspective.\n\n        Circle would have a h = 0. A really stretch out ellipse would have a h value\n        close o 1\n\n        Returns:\n            float: h value\n        \"\"\"\n        return (self.semi_major_axis - self.semi_minor_axis) ** 2 / (\n            self.semi_major_axis + self.semi_minor_axis\n        ) ** 2\n\n    @property\n    def area(self) -&gt; float:\n        \"\"\"Compute the area of the ellipse\n\n        Returns:\n            float: area value\n        \"\"\"\n        return math.pi * self.semi_major_axis * self.semi_minor_axis\n\n    @property\n    def perimeter(self) -&gt; float:\n        \"\"\"Compute the perimeter of the ellipse.\n        Beware this is only an approximation due to the computation of both pi\n        and the James Ivory's infinite serie.\n\n        Returns:\n            float: perimeter value\n        \"\"\"\n        return self.perimeter_approx()\n\n    @property\n    def shapely_surface(self) -&gt; SPolygon:\n        \"\"\"Returns the Shapely.Polygon as an surface representation of the Ellipse.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html\n\n        Returns:\n            Polygon: shapely.Polygon object\n        \"\"\"\n        return SPolygon(self.polyaprox.asarray, holes=None)\n\n    @property\n    def shapely_edges(self) -&gt; LinearRing:\n        \"\"\"Returns the Shapely.LinearRing as a curve representation of the Ellipse.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.LinearRing.html\n\n        Returns:\n            LinearRing: shapely.LinearRing object\n        \"\"\"\n        return LinearRing(coordinates=self.polyaprox.asarray)\n\n    @property\n    def is_circle(self) -&gt; bool:\n        \"\"\"Check if the ellipse is a circle\n\n        Returns:\n            bool: True if circle else False\n        \"\"\"\n        return self.semi_major_axis == self.semi_minor_axis\n\n    # ---------------------------- MODIFICATION METHODS -------------------------------\n\n    def rotate(\n        self,\n        angle: float,\n        is_degree: bool = False,\n        is_clockwise: bool = True,\n        pivot: Optional[NDArray] = None,\n    ) -&gt; Self:\n        \"\"\"Rotate the ellipse around a pivot point.\n\n        Args:\n            angle (float): angle to rotate the ellipse\n            is_degree (bool, optional): whether the angle is in degrees.\n                Defaults to False.\n            is_clockwise (bool, optional): whether the rotation is clockwise.\n                Defaults to True.\n            pivot (Optional[NDArray], optional): pivot point to rotate around.\n                Defaults to None.\n\n        Returns:\n            Self: rotated ellipse object\n        \"\"\"\n        if is_degree:\n            angle = math.radians(angle)\n        if is_clockwise:\n            angle = -angle\n\n        if pivot is None:\n            pivot = self.centroid\n\n        self.foci1 = rotate_2d_points(self.foci1, angle, pivot)\n        self.foci2 = rotate_2d_points(self.foci2, angle, pivot)\n        self.update_polyapprox()\n        return self\n\n    def shift(self, vector: NDArray) -&gt; Self:\n        \"\"\"Shift the ellipse by a given vector.\n\n        Args:\n            vector (NDArray): vector to shift the ellipse\n\n        Returns:\n            Self: shifted ellipse object\n        \"\"\"\n        assert_transform_shift_vector(vector)\n        self.foci1 += vector\n        self.foci2 += vector\n        self.update_polyapprox()\n        return self\n\n    def normalize(self, x: float, y: float) -&gt; Self:\n        \"\"\"Normalize the ellipse to a given bounding box.\n\n        Args:\n            x (float): width of the bounding box\n            y (float): height of the bounding box\n\n        Returns:\n            Self: normalized ellipse object\n        \"\"\"\n        factor = np.array([x, y])\n        self.foci1 = self.foci1 / factor\n        self.foci2 = self.foci2 / factor\n\n        self.update_polyapprox()\n        return self\n\n    # ------------------------------- CLASSIC METHODS ---------------------------------\n\n    def perimeter_approx(self, n_terms: int = 5, is_ramanujan: bool = False) -&gt; float:\n        \"\"\"Perimeter approximation of the ellipse using the James Ivory\n        infinite serie. In the case of the circle this always converges to the\n        exact value of the circumference no matter the number of terms.\n\n        See: https://en.wikipedia.org/wiki/Ellipse#Circumference\n\n        Args:\n            n_terms (int, optional): number of n first terms to calculate and\n                add up from the infinite series. Defaults to 5.\n            is_ramanujan (bool, optional): whether to use the Ramanujan's best\n                approximation.\n\n        Returns:\n            float: circumference approximation of the ellipse\n        \"\"\"\n        if is_ramanujan:\n            return (\n                math.pi\n                * (self.semi_major_axis + self.semi_minor_axis)\n                * (1 + (3 * self.h) / (10 + math.sqrt(4 - 3 * self.h)))\n            )\n\n        _sum = 1  # pre-calculated term n=0 equal 1\n        for n in range(1, n_terms):  # goes from term n=1 to n=(n_terms-1)\n            _sum += (((1 / ((2 * n - 1) * (4**n))) * math.comb(2 * n, n)) ** 2) * (\n                self.h**n\n            )\n\n        return math.pi * (self.semi_major_axis + self.semi_minor_axis) * _sum\n\n    def polygonal_approx(self, n_points: int, is_cast_int: bool = False) -&gt; Polygon:\n        \"\"\"Generate apolygonal approximation of the ellipse.\n\n        The way is done is the following:\n        1. suppose the ellipse centered at the origin\n        2. suppose the ellipse semi major axis to be parallel with the x-axis\n        3. compute pairs of (x, y) points that belong to the ellipse using the\n            parametric equation of the ellipse.\n        4. shift all points by the same shift as the center to origin\n        5. rotate using the ellipse center pivot point\n\n        Args:\n            n_points (int): number of points that make up the ellipse\n                polygonal approximation\n            is_cast_int (bool): whether to cast to int the points coordinates or\n                not. Defaults to False\n\n        Returns:\n            Polygon: Polygon representing the ellipse as a succession of n points\n        \"\"\"\n        points = []\n        for theta in np.linspace(0, 2 * math.pi, n_points):\n            x = self.semi_major_axis * math.cos(theta)\n            y = self.semi_minor_axis * math.sin(theta)\n            points.append([x, y])\n\n        poly = (\n            Polygon(points=np.asarray(points), is_cast_int=False)\n            .shift(vector=self.centroid)\n            .rotate(angle=self.angle())\n        )\n\n        if is_cast_int:\n            poly.asarray = poly.asarray.astype(int)\n\n        return poly\n\n    def angle(self, degree: bool = False, is_y_axis_down: bool = False) -&gt; float:\n        \"\"\"Angle of the ellipse\n\n        Args:\n            degree (bool, optional): whether to output angle in degree,\n                Defaults to False meaning radians.\n            is_y_axis_down (bool, optional): whether the y axis is down.\n                Defaults to False.\n\n        Returns:\n            float: angle value\n        \"\"\"\n        seg = Segment([self.foci1, self.foci2])\n        return seg.slope_angle(degree=degree, is_y_axis_down=is_y_axis_down)\n\n    def curvature(self, point: NDArray) -&gt; float:\n        r\"\"\"Computes the curvature of a point on the ellipse.\n\n        Equation is based on the following where a is semi major and b is minor axis.\n\n        \\kappa = \\frac{1}{a^2 b^2}\n            \\left(\n                \\frac{x^2}{a^4} + \\frac{y^2}{b^4}\n            \\right)^{-\\frac{3}{2}}\n\n        Args:\n            point (NDArray): point on the ellipse\n\n        Returns:\n            float: curvature of the point\n        \"\"\"\n        # TODO check that the point is on the ellipse\n        x, y = point\n        a = self.semi_major_axis\n        b = self.semi_minor_axis\n\n        numerator = 1 / (a * b) ** 2\n        inner = (x**2) / (a**4) + (y**2) / (b**4)\n        curvature = numerator * inner ** (-1.5)\n\n        return curvature\n\n    def copy(self) -&gt; Self:\n        \"\"\"Copy the current ellipse object\n\n        Returns:\n            Self: copied ellipse object\n        \"\"\"\n        return type(self)(\n            foci1=self.foci1,\n            foci2=self.foci2,\n            semi_major_axis=self.semi_major_axis,\n            n_points_polygonal_approx=self.n_points_polygonal_approx,\n        )\n\n    def enclosing_oriented_bbox(self) -&gt; Rectangle:\n        \"\"\"\n        Enclosing oriented bounding box.\n        Manage the case where the ellipse is a circle and return the enclosing\n        axis-aligned bounding box in that case.\n\n        Returns:\n            Rectangle: Enclosing oriented bounding box\n        \"\"\"\n        if self.is_circle:\n            # In a circle the enclosing oriented bounding box could be in any\n            # direction. Thus we return the enclosing axis-aligned bounding box\n            # by default as a Rectangle object\n            return Rectangle(self.enclosing_axis_aligned_bbox().asarray)\n        return super().enclosing_oriented_bbox()\n\n    def __str__(self) -&gt; str:\n        return (\n            f\"Ellipse(foci1={self.foci1}, foci2={self.foci2}, a={self.semi_major_axis})\"\n        )\n\n    def __repr__(self) -&gt; str:\n        return (\n            f\"Ellipse(foci1={self.foci1}, foci2={self.foci2}, a={self.semi_major_axis})\"\n        )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.area","title":"<code>area</code>  <code>property</code>","text":"<p>Compute the area of the ellipse</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>area value</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.centroid","title":"<code>centroid</code>  <code>property</code>","text":"<p>Compute the center point of the ellipse</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>2D point defining the center of the ellipse</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.eccentricity","title":"<code>eccentricity</code>  <code>property</code>","text":"<p>Eccentricity value of the ellipse</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>eccentricity value</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.focal_distance","title":"<code>focal_distance</code>  <code>property</code>","text":"<p>Distance from any focal point to the center</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>focal distance value</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.h","title":"<code>h</code>  <code>property</code>","text":"<p>h is a common ellipse value used in calculation and kind of represents the eccentricity of the ellipse but in another perspective.</p> <p>Circle would have a h = 0. A really stretch out ellipse would have a h value close o 1</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>h value</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.is_circle","title":"<code>is_circle</code>  <code>property</code>","text":"<p>Check if the ellipse is a circle</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if circle else False</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.linear_eccentricity","title":"<code>linear_eccentricity</code>  <code>property</code>","text":"<p>Distance from any focal point to the center</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>linear eccentricity value</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.perimeter","title":"<code>perimeter</code>  <code>property</code>","text":"<p>Compute the perimeter of the ellipse. Beware this is only an approximation due to the computation of both pi and the James Ivory's infinite serie.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>perimeter value</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.semi_minor_axis","title":"<code>semi_minor_axis</code>  <code>property</code>","text":"<p>Computed semi minor axis (also called b usually)</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>description</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.shapely_edges","title":"<code>shapely_edges</code>  <code>property</code>","text":"<p>Returns the Shapely.LinearRing as a curve representation of the Ellipse. See https://shapely.readthedocs.io/en/stable/reference/shapely.LinearRing.html</p> <p>Returns:</p> Name Type Description <code>LinearRing</code> <code>LinearRing</code> <p>shapely.LinearRing object</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.shapely_surface","title":"<code>shapely_surface</code>  <code>property</code>","text":"<p>Returns the Shapely.Polygon as an surface representation of the Ellipse. See https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html</p> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>shapely.Polygon object</p>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.__assert_ellipse","title":"<code>__assert_ellipse()</code>","text":"<p>Assert the parameters of the ellipse. If the parameters proposed do not make up a ellipse raise an error.</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def __assert_ellipse(self) -&gt; None:\n    \"\"\"Assert the parameters of the ellipse.\n    If the parameters proposed do not make up a ellipse raise an error.\n    \"\"\"\n    if self.semi_major_axis &lt;= self.linear_eccentricity:\n        raise ValueError(\n            f\"The semi major-axis (a={self.semi_major_axis}) can not be smaller \"\n            f\"than the linear eccentricity (c={self.linear_eccentricity}). \"\n            \"The ellipse is thus not valid. Please increase the semi major-axis.\"\n        )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.__init__","title":"<code>__init__(foci1, foci2, semi_major_axis, n_points_polygonal_approx=ContinuousGeometryEntity.DEFAULT_N_POLY_APPROX)</code>","text":"<p>Initialize a Ellipse geometrical object</p> <p>Parameters:</p> Name Type Description Default <code>foci1</code> <code>NDArray | list</code> <p>first focal 2D point</p> required <code>foci2</code> <code>NDArray | list</code> <p>second focal 2D point</p> required <code>semi_major_axis</code> <code>float</code> <p>semi major axis value</p> required <code>n_points_polygonal_approx</code> <code>int</code> <p>number of points to be used in the polygonal approximation. Defaults to ContinuousGeometryEntity.DEFAULT_N_POINTS_POLYGONAL_APPROX.</p> <code>DEFAULT_N_POLY_APPROX</code> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def __init__(\n    self,\n    foci1: NDArray | list,\n    foci2: NDArray | list,\n    semi_major_axis: float,\n    n_points_polygonal_approx: int = ContinuousGeometryEntity.DEFAULT_N_POLY_APPROX,\n):\n    \"\"\"Initialize a Ellipse geometrical object\n\n    Args:\n        foci1 (NDArray | list): first focal 2D point\n        foci2 (NDArray | list): second focal 2D point\n        semi_major_axis (float): semi major axis value\n        n_points_polygonal_approx (int, optional): number of points to be used in\n            the polygonal approximation.\n            Defaults to ContinuousGeometryEntity.DEFAULT_N_POINTS_POLYGONAL_APPROX.\n    \"\"\"\n    super().__init__(n_points_polygonal_approx=n_points_polygonal_approx)\n    self.foci1 = np.asarray(foci1)\n    self.foci2 = np.asarray(foci2)\n    self.semi_major_axis = semi_major_axis  # also called \"a\" usually\n    self.__assert_ellipse()\n\n    if type(self) is Ellipse:  # pylint: disable=unidiomatic-typecheck\n        # pylint check is wrong here since we want it to be ONLY an Ellipse\n        # not a circle. isinstance() check make children classes return True\n        # to avoid computation in circle class instantiation\n        # since the center attribute is not defined in the Circle class yet\n        self.update_polyapprox()\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.angle","title":"<code>angle(degree=False, is_y_axis_down=False)</code>","text":"<p>Angle of the ellipse</p> <p>Parameters:</p> Name Type Description Default <code>degree</code> <code>bool</code> <p>whether to output angle in degree, Defaults to False meaning radians.</p> <code>False</code> <code>is_y_axis_down</code> <code>bool</code> <p>whether the y axis is down. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>angle value</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def angle(self, degree: bool = False, is_y_axis_down: bool = False) -&gt; float:\n    \"\"\"Angle of the ellipse\n\n    Args:\n        degree (bool, optional): whether to output angle in degree,\n            Defaults to False meaning radians.\n        is_y_axis_down (bool, optional): whether the y axis is down.\n            Defaults to False.\n\n    Returns:\n        float: angle value\n    \"\"\"\n    seg = Segment([self.foci1, self.foci2])\n    return seg.slope_angle(degree=degree, is_y_axis_down=is_y_axis_down)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.copy","title":"<code>copy()</code>","text":"<p>Copy the current ellipse object</p> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>copied ellipse object</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def copy(self) -&gt; Self:\n    \"\"\"Copy the current ellipse object\n\n    Returns:\n        Self: copied ellipse object\n    \"\"\"\n    return type(self)(\n        foci1=self.foci1,\n        foci2=self.foci2,\n        semi_major_axis=self.semi_major_axis,\n        n_points_polygonal_approx=self.n_points_polygonal_approx,\n    )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.curvature","title":"<code>curvature(point)</code>","text":"<p>Computes the curvature of a point on the ellipse.</p> <p>Equation is based on the following where a is semi major and b is minor axis.</p> <p>\\kappa = \\frac{1}{a^2 b^2}     \\left(         \\frac{x^2}{a^4} + \\frac{y^2}{b^4}     \\right)^{-\\frac{3}{2}}</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>point on the ellipse</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>curvature of the point</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def curvature(self, point: NDArray) -&gt; float:\n    r\"\"\"Computes the curvature of a point on the ellipse.\n\n    Equation is based on the following where a is semi major and b is minor axis.\n\n    \\kappa = \\frac{1}{a^2 b^2}\n        \\left(\n            \\frac{x^2}{a^4} + \\frac{y^2}{b^4}\n        \\right)^{-\\frac{3}{2}}\n\n    Args:\n        point (NDArray): point on the ellipse\n\n    Returns:\n        float: curvature of the point\n    \"\"\"\n    # TODO check that the point is on the ellipse\n    x, y = point\n    a = self.semi_major_axis\n    b = self.semi_minor_axis\n\n    numerator = 1 / (a * b) ** 2\n    inner = (x**2) / (a**4) + (y**2) / (b**4)\n    curvature = numerator * inner ** (-1.5)\n\n    return curvature\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.enclosing_oriented_bbox","title":"<code>enclosing_oriented_bbox()</code>","text":"<p>Enclosing oriented bounding box. Manage the case where the ellipse is a circle and return the enclosing axis-aligned bounding box in that case.</p> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Rectangle</code> <p>Enclosing oriented bounding box</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def enclosing_oriented_bbox(self) -&gt; Rectangle:\n    \"\"\"\n    Enclosing oriented bounding box.\n    Manage the case where the ellipse is a circle and return the enclosing\n    axis-aligned bounding box in that case.\n\n    Returns:\n        Rectangle: Enclosing oriented bounding box\n    \"\"\"\n    if self.is_circle:\n        # In a circle the enclosing oriented bounding box could be in any\n        # direction. Thus we return the enclosing axis-aligned bounding box\n        # by default as a Rectangle object\n        return Rectangle(self.enclosing_axis_aligned_bbox().asarray)\n    return super().enclosing_oriented_bbox()\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.normalize","title":"<code>normalize(x, y)</code>","text":"<p>Normalize the ellipse to a given bounding box.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>width of the bounding box</p> required <code>y</code> <code>float</code> <p>height of the bounding box</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>normalized ellipse object</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def normalize(self, x: float, y: float) -&gt; Self:\n    \"\"\"Normalize the ellipse to a given bounding box.\n\n    Args:\n        x (float): width of the bounding box\n        y (float): height of the bounding box\n\n    Returns:\n        Self: normalized ellipse object\n    \"\"\"\n    factor = np.array([x, y])\n    self.foci1 = self.foci1 / factor\n    self.foci2 = self.foci2 / factor\n\n    self.update_polyapprox()\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.perimeter_approx","title":"<code>perimeter_approx(n_terms=5, is_ramanujan=False)</code>","text":"<p>Perimeter approximation of the ellipse using the James Ivory infinite serie. In the case of the circle this always converges to the exact value of the circumference no matter the number of terms.</p> <p>See: https://en.wikipedia.org/wiki/Ellipse#Circumference</p> <p>Parameters:</p> Name Type Description Default <code>n_terms</code> <code>int</code> <p>number of n first terms to calculate and add up from the infinite series. Defaults to 5.</p> <code>5</code> <code>is_ramanujan</code> <code>bool</code> <p>whether to use the Ramanujan's best approximation.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>circumference approximation of the ellipse</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def perimeter_approx(self, n_terms: int = 5, is_ramanujan: bool = False) -&gt; float:\n    \"\"\"Perimeter approximation of the ellipse using the James Ivory\n    infinite serie. In the case of the circle this always converges to the\n    exact value of the circumference no matter the number of terms.\n\n    See: https://en.wikipedia.org/wiki/Ellipse#Circumference\n\n    Args:\n        n_terms (int, optional): number of n first terms to calculate and\n            add up from the infinite series. Defaults to 5.\n        is_ramanujan (bool, optional): whether to use the Ramanujan's best\n            approximation.\n\n    Returns:\n        float: circumference approximation of the ellipse\n    \"\"\"\n    if is_ramanujan:\n        return (\n            math.pi\n            * (self.semi_major_axis + self.semi_minor_axis)\n            * (1 + (3 * self.h) / (10 + math.sqrt(4 - 3 * self.h)))\n        )\n\n    _sum = 1  # pre-calculated term n=0 equal 1\n    for n in range(1, n_terms):  # goes from term n=1 to n=(n_terms-1)\n        _sum += (((1 / ((2 * n - 1) * (4**n))) * math.comb(2 * n, n)) ** 2) * (\n            self.h**n\n        )\n\n    return math.pi * (self.semi_major_axis + self.semi_minor_axis) * _sum\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.polygonal_approx","title":"<code>polygonal_approx(n_points, is_cast_int=False)</code>","text":"<p>Generate apolygonal approximation of the ellipse.</p> <p>The way is done is the following: 1. suppose the ellipse centered at the origin 2. suppose the ellipse semi major axis to be parallel with the x-axis 3. compute pairs of (x, y) points that belong to the ellipse using the     parametric equation of the ellipse. 4. shift all points by the same shift as the center to origin 5. rotate using the ellipse center pivot point</p> <p>Parameters:</p> Name Type Description Default <code>n_points</code> <code>int</code> <p>number of points that make up the ellipse polygonal approximation</p> required <code>is_cast_int</code> <code>bool</code> <p>whether to cast to int the points coordinates or not. Defaults to False</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>Polygon representing the ellipse as a succession of n points</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def polygonal_approx(self, n_points: int, is_cast_int: bool = False) -&gt; Polygon:\n    \"\"\"Generate apolygonal approximation of the ellipse.\n\n    The way is done is the following:\n    1. suppose the ellipse centered at the origin\n    2. suppose the ellipse semi major axis to be parallel with the x-axis\n    3. compute pairs of (x, y) points that belong to the ellipse using the\n        parametric equation of the ellipse.\n    4. shift all points by the same shift as the center to origin\n    5. rotate using the ellipse center pivot point\n\n    Args:\n        n_points (int): number of points that make up the ellipse\n            polygonal approximation\n        is_cast_int (bool): whether to cast to int the points coordinates or\n            not. Defaults to False\n\n    Returns:\n        Polygon: Polygon representing the ellipse as a succession of n points\n    \"\"\"\n    points = []\n    for theta in np.linspace(0, 2 * math.pi, n_points):\n        x = self.semi_major_axis * math.cos(theta)\n        y = self.semi_minor_axis * math.sin(theta)\n        points.append([x, y])\n\n    poly = (\n        Polygon(points=np.asarray(points), is_cast_int=False)\n        .shift(vector=self.centroid)\n        .rotate(angle=self.angle())\n    )\n\n    if is_cast_int:\n        poly.asarray = poly.asarray.astype(int)\n\n    return poly\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.rotate","title":"<code>rotate(angle, is_degree=False, is_clockwise=True, pivot=None)</code>","text":"<p>Rotate the ellipse around a pivot point.</p> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>float</code> <p>angle to rotate the ellipse</p> required <code>is_degree</code> <code>bool</code> <p>whether the angle is in degrees. Defaults to False.</p> <code>False</code> <code>is_clockwise</code> <code>bool</code> <p>whether the rotation is clockwise. Defaults to True.</p> <code>True</code> <code>pivot</code> <code>Optional[NDArray]</code> <p>pivot point to rotate around. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>rotated ellipse object</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def rotate(\n    self,\n    angle: float,\n    is_degree: bool = False,\n    is_clockwise: bool = True,\n    pivot: Optional[NDArray] = None,\n) -&gt; Self:\n    \"\"\"Rotate the ellipse around a pivot point.\n\n    Args:\n        angle (float): angle to rotate the ellipse\n        is_degree (bool, optional): whether the angle is in degrees.\n            Defaults to False.\n        is_clockwise (bool, optional): whether the rotation is clockwise.\n            Defaults to True.\n        pivot (Optional[NDArray], optional): pivot point to rotate around.\n            Defaults to None.\n\n    Returns:\n        Self: rotated ellipse object\n    \"\"\"\n    if is_degree:\n        angle = math.radians(angle)\n    if is_clockwise:\n        angle = -angle\n\n    if pivot is None:\n        pivot = self.centroid\n\n    self.foci1 = rotate_2d_points(self.foci1, angle, pivot)\n    self.foci2 = rotate_2d_points(self.foci2, angle, pivot)\n    self.update_polyapprox()\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.continuous.shape.ellipse.Ellipse.shift","title":"<code>shift(vector)</code>","text":"<p>Shift the ellipse by a given vector.</p> <p>Parameters:</p> Name Type Description Default <code>vector</code> <code>NDArray</code> <p>vector to shift the ellipse</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>shifted ellipse object</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def shift(self, vector: NDArray) -&gt; Self:\n    \"\"\"Shift the ellipse by a given vector.\n\n    Args:\n        vector (NDArray): vector to shift the ellipse\n\n    Returns:\n        Self: shifted ellipse object\n    \"\"\"\n    assert_transform_shift_vector(vector)\n    self.foci1 += vector\n    self.foci2 += vector\n    self.update_polyapprox()\n    return self\n</code></pre>"},{"location":"api/geometry/#discrete-geometry","title":"Discrete Geometry","text":"<p>DiscreteGeometryEntity module class</p> <p>Point class useful to describe any kind of points</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity","title":"<code>DiscreteGeometryEntity</code>","text":"<p>               Bases: <code>GeometryEntity</code>, <code>ABC</code></p> <p>GeometryEntity class which is the abstract base class for all geometry classes</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>class DiscreteGeometryEntity(GeometryEntity, ABC):\n    \"\"\"GeometryEntity class which is the abstract base class for all geometry classes\"\"\"\n\n    # pylint: disable=too-many-public-methods\n\n    def __init__(self, points: NDArray | list, is_cast_int: bool = False) -&gt; None:\n        _arr = self._init_array(points, is_cast_int)\n        self.points = copy.deepcopy(_arr)\n        self.is_cast_int = is_cast_int\n\n    def _init_array(self, points: NDArray | list, is_cast_int: bool = False) -&gt; NDArray:\n        \"\"\"Initialize the array given the points.\n\n        Args:\n            points (NDArray | list): input points\n            is_cast_int (bool, optional): whether to cast points to int.\n                Defaults to False.\n\n        Returns:\n            NDArray: array describing the input points\n        \"\"\"\n        tmp = np.asarray(points)\n        is_all_elements_are_integer = np.all(np.equal(tmp, tmp.astype(int)))\n        if is_cast_int or is_all_elements_are_integer:\n            _arr = tmp.astype(np.int32)\n        else:\n            _arr = tmp.astype(np.float32)\n        return _arr\n\n    # --------------------------------- PROPERTIES ------------------------------------\n\n    @property\n    @abstractmethod\n    def shapely_edges(self) -&gt; GeometryCollection:\n        \"\"\"Representation of the geometric object in the shapely library\n        as a geometrical object defined only as a curve with no area. Particularly\n        useful to look for points intersections\n        \"\"\"\n\n    @property\n    @abstractmethod\n    def shapely_surface(self) -&gt; GeometryCollection:\n        \"\"\"Representation of the geometric object in the shapely library\n        as a geometrical object with an area and a border. Particularly useful\n        to check if two geometrical objects are contained within each other or not.\n        \"\"\"\n\n    @property\n    @abstractmethod\n    def edges(self) -&gt; NDArray:\n        \"\"\"Get the edges of the geometry entity\n\n        Returns:\n            NDArray: edges of the geometry entity\n        \"\"\"\n\n    @property\n    def segments(self) -&gt; list[Segment]:\n        \"\"\"Get the segments of the geometry entity\n\n        Returns:\n            NDArray: segments of the geometry entity\n        \"\"\"\n        # pylint: disable=import-outside-toplevel\n        from otary.geometry import Segment  # delayed import to avoid circular import\n\n        return [Segment(e) for e in self.edges]\n\n    @property\n    def n_points(self) -&gt; int:\n        \"\"\"Returns the number of points this geometric object is made of\n\n        Returns:\n            int: number of points that composes the geomtric object\n        \"\"\"\n        return self.points.shape[0]\n\n    @property\n    def asarray(self) -&gt; NDArray:\n        \"\"\"Array representation of the geometry object\"\"\"\n        return self.points\n\n    @asarray.setter\n    def asarray(self, value: NDArray):\n        \"\"\"Setter for the asarray property\n\n        Args:\n            value (NDArray): value of the asarray to be changed\n        \"\"\"\n        self.points = value\n\n    @property\n    @abstractmethod\n    def centroid(self) -&gt; NDArray:\n        \"\"\"Compute the centroid point which can be seen as the center of gravity\n        or center of mass of the shape\n\n        Returns:\n            NDArray: centroid point\n        \"\"\"\n\n    @property\n    def center_mean(self) -&gt; NDArray:\n        \"\"\"Compute the center as the mean of all the points. This can be really\n        different than the centroid.\n\n        Returns:\n            NDArray: center mean as a 2D point\n        \"\"\"\n        return np.mean(self.points, axis=0)\n\n    @property\n    def xmax(self) -&gt; float:\n        \"\"\"Get the maximum X coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n        return np.max(self.asarray[:, 0])\n\n    @property\n    def xmin(self) -&gt; float:\n        \"\"\"Get the minimum X coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n        return np.min(self.asarray[:, 0])\n\n    @property\n    def ymax(self) -&gt; float:\n        \"\"\"Get the maximum Y coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n        return np.max(self.asarray[:, 1])\n\n    @property\n    def ymin(self) -&gt; float:\n        \"\"\"Get the minimum Y coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n        return np.min(self.asarray[:, 1])\n\n    @property\n    def lengths(self) -&gt; NDArray:\n        \"\"\"Returns the length of all the segments that make up the geometry entity\n\n        Returns:\n            NDArray: array of shape (n_points)\n        \"\"\"\n        lengths: NDArray = np.linalg.norm(np.diff(self.edges, axis=1), axis=2)\n        return lengths.flatten()\n\n    @property\n    def crop_coordinates(self) -&gt; NDArray:\n        \"\"\"Compute the coordinates of the geometry entity in the context of\n        itself being in a crop image that make it fit pefectly\n\n        Returns:\n            Self: _description_\n        \"\"\"\n        return self.asarray - np.array([self.xmin, self.ymin])\n\n    # ---------------------------- MODIFICATION METHODS -------------------------------\n\n    def rotate(\n        self,\n        angle: float,\n        is_degree: bool = False,\n        is_clockwise: bool = True,\n        pivot: Optional[NDArray] = None,\n    ) -&gt; Self:\n        \"\"\"Rotate the geometry entity object.\n        A pivot point can be passed as an argument to rotate the object around the pivot\n\n        Args:\n            angle (float): rotation angle\n            is_degree (bool, optional): whether the angle is in degree or radian.\n                Defaults to False which means radians.\n            is_clockwise (bool, optional): whether the rotation is clockwise or\n                counter-clockwise. Defaults to True.\n            pivot (NDArray, optional): pivot point.\n                Defaults to None which means that by default the centroid point of\n                the shape is taken as the pivot point.\n\n        Returns:\n            GeometryEntity: rotated geometry entity object.\n        \"\"\"\n        if pivot is None:\n            pivot = self.centroid\n\n        self.points = rotate_2d_points(\n            points=self.points,\n            angle=angle,\n            pivot=pivot,\n            is_degree=is_degree,\n            is_clockwise=is_clockwise,\n        )\n        return self\n\n    def rotate_around_image_center(\n        self, img: NDArray, angle: float, degree: bool = False\n    ) -&gt; Self:\n        \"\"\"Given an geometric object and an image, rotate the object around\n        the image center point.\n\n        Args:\n            img (NDArray): image as a shape (x, y) sized array\n            angle (float): rotation angle\n            degree (bool, optional): whether the angle is in degree or radian.\n                Defaults to False which means radians.\n\n        Returns:\n            GeometryEntity: rotated geometry entity object.\n        \"\"\"\n        img_center_point = np.array([img.shape[1], img.shape[0]]) / 2\n        return self.rotate(angle=angle, pivot=img_center_point, is_degree=degree)\n\n    def shift(self, vector: NDArray) -&gt; Self:\n        \"\"\"Shift the geometry entity by the vector direction\n\n        Args:\n            vector (NDArray): vector that describes the shift as a array with\n                two elements. Example: [2, -8] which describes the\n                vector [[0, 0], [2, -8]]. The vector can also be a vector of shape\n                (2, 2) of the form [[2, 6], [1, 3]].\n\n        Returns:\n            GeometryEntity: shifted geometrical object\n        \"\"\"\n        vector = assert_transform_shift_vector(vector=vector)\n        self.points = self.points + vector\n        return self\n\n    def clamp(\n        self,\n        xmin: float = -np.inf,\n        xmax: float = np.inf,\n        ymin: float = -np.inf,\n        ymax: float = np.inf,\n    ) -&gt; Self:\n        \"\"\"Clamp the Geometry entity so that the x and y coordinates fit in the\n        min and max values in parameters.\n\n        Args:\n            xmin (float): x coordinate minimum\n            xmax (float): x coordinate maximum\n            ymin (float): y coordinate minimum\n            ymax (float): y coordinate maximum\n\n        Returns:\n            GeometryEntity: clamped GeometryEntity\n        \"\"\"\n        self.asarray[:, 0] = np.clip(self.asarray[:, 0], xmin, xmax)  # x values\n        self.asarray[:, 1] = np.clip(self.asarray[:, 1], ymin, ymax)  # y values\n        return self\n\n    def normalize(self, x: float, y: float) -&gt; Self:\n        \"\"\"Normalize the geometry entity by dividing the points by a norm on the\n        x and y coordinates.\n\n        Args:\n            x (float): x coordinate norm\n            y (float): y coordinate norm\n\n        Returns:\n            GeometryEntity: normalized GeometryEntity\n        \"\"\"\n        if x == 0 or y == 0:\n            raise ValueError(\"x or y cannot be 0\")\n        self.asarray = self.asarray / np.array([x, y])\n        return self\n\n    # ------------------------------- CLASSIC METHODS ---------------------------------\n\n    def copy(self) -&gt; Self:\n        \"\"\"Create a copy of the geometry entity object\n\n        Returns:\n            GeometryEntity: copy of the geometry entity object\n        \"\"\"\n        return type(self)(points=self.asarray.copy(), is_cast_int=self.is_cast_int)\n\n    def enclosing_axis_aligned_bbox(self) -&gt; AxisAlignedRectangle:\n        \"\"\"Compute the smallest area enclosing Axis-Aligned Bounding Box (AABB)\n        See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n        Return the points in the following order:\n        1. top left\n        2. top right\n        3. bottom right\n        4. bottom left\n\n        Returns:\n            Rectangle: Rectangle object\n        \"\"\"\n        # pylint: disable=import-outside-toplevel\n        from otary.geometry import (\n            AxisAlignedRectangle,\n        )  # delayed import to avoid circular import\n\n        topleft_x, topleft_y, width, height = cv2.boundingRect(\n            array=self.asarray.astype(np.float32)\n        )\n        topleft = np.array([topleft_x, topleft_y])\n        return AxisAlignedRectangle.from_topleft(\n            topleft=topleft, width=width, height=height\n        )\n\n    def enclosing_oriented_bbox(self) -&gt; Rectangle:\n        \"\"\"Compute the smallest area enclosing Oriented Bounding Box (OBB)\n        See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n        Returns:\n            Rectangle: Rectangle object\n        \"\"\"\n        # pylint: disable=import-outside-toplevel\n        from otary.geometry import Rectangle  # delayed import to avoid circular import\n\n        rect = cv2.minAreaRect(self.asarray.astype(np.float32))\n        bbox = cv2.boxPoints(rect)\n        return Rectangle(bbox)\n\n    def enclosing_convex_hull(self) -&gt; Polygon:\n        \"\"\"Compute the smallest area enclosing Convex Hull\n        See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n        Returns:\n            Polygon: Polygon object\n        \"\"\"\n        # pylint: disable=import-outside-toplevel\n        from otary.geometry import Polygon  # delayed import to avoid circular import\n\n        convexhull = np.squeeze(cv2.convexHull(self.asarray.astype(np.float32)))\n        return Polygon(convexhull)\n\n    def distances_vertices_to_point(self, point: NDArray) -&gt; NDArray:\n        \"\"\"Get the distance from all vertices in the geometry entity to the input point\n\n        Args:\n            point (NDArray): 2D point\n\n        Returns:\n            NDArray: array of the same len as the number of vertices in the geometry\n                entity.\n        \"\"\"\n        return np.linalg.norm(self.asarray - point, axis=1)\n\n    def shortest_dist_vertices_to_point(self, point: NDArray) -&gt; float:\n        \"\"\"Compute the shortest distance from the geometry entity vertices to the point\n\n        Args:\n            point (NDArray): 2D point\n\n        Returns:\n            float: shortest distance from the geometry entity vertices to the point\n        \"\"\"\n        return np.min(self.distances_vertices_to_point(point=point))\n\n    def longest_dist_vertices_to_point(self, point: NDArray) -&gt; float:\n        \"\"\"Compute the longest distance from the geometry entity vertices to the point\n\n        Args:\n            point (NDArray): 2D point\n\n        Returns:\n            float: longest distance from the geometry entity vertices to the point\n        \"\"\"\n        return np.max(self.distances_vertices_to_point(point=point))\n\n    def find_vertice_ix_farthest_from(self, point: NDArray) -&gt; int:\n        \"\"\"Get the index of the farthest vertice from a given point\n\n        Args:\n            point (NDArray): 2D point\n\n        Returns:\n            int: the index of the farthest vertice in the entity from the input point\n        \"\"\"\n        return np.argmax(self.distances_vertices_to_point(point=point)).astype(int)\n\n    def find_vertice_ix_closest_from(self, point: NDArray) -&gt; int:\n        \"\"\"Get the index of the closest vertice from a given point\n\n        Args:\n            point (NDArray): 2D point\n\n        Returns:\n            int: the index of the closest point in the entity from the input point\n        \"\"\"\n        return np.argmin(self.distances_vertices_to_point(point=point)).astype(int)\n\n    def find_shared_approx_vertices_ix(\n        self, other: DiscreteGeometryEntity, margin_dist_error: float = 5\n    ) -&gt; NDArray:\n        \"\"\"Compute the vertices indices from this entity that correspond to shared\n        vertices with the other geometric entity.\n\n        A vertice is considered shared if it is close enough to another vertice\n        in the other geometric structure.\n\n        Args:\n            other (DiscreteGeometryEntity): other Discrete Geometry entity\n            margin_dist_error (float, optional): minimum distance to have two vertices\n                considered as close enough to be shared. Defaults to 5.\n\n        Returns:\n            NDArray: list of indices\n        \"\"\"\n        return get_shared_point_indices(\n            points_to_check=self.asarray,\n            checkpoints=other.asarray,\n            margin_dist_error=margin_dist_error,\n            method=\"close\",\n            cond=\"any\",\n        )\n\n    def find_shared_approx_vertices(\n        self, other: DiscreteGeometryEntity, margin_dist_error: float = 5\n    ) -&gt; NDArray:\n        \"\"\"Get the shared vertices between two geometric objects.\n\n        A vertice is considered shared if it is close enough to another vertice\n        in the other geometric structure.\n\n        Args:\n            other (DiscreteGeometryEntity): a DiscreteGeometryEntity object\n            margin_dist_error (float, optional): the threshold to define a vertice as\n                shared or not. Defaults to 5.\n\n        Returns:\n            NDArray: list of vertices identified as shared between the two geometric\n                objects\n        \"\"\"\n        indices = self.find_shared_approx_vertices_ix(\n            other=other, margin_dist_error=margin_dist_error\n        )\n        return self.asarray[indices]\n\n    def find_vertices_far_from(\n        self, points: NDArray, min_distance: float = 5\n    ) -&gt; NDArray:\n        \"\"\"Get vertices that belongs to the geometric structure far from the points in\n        parameters.\n\n        Args:\n            points (NDArray): input list of points\n            min_distance (float, optional): the threshold to define a point as\n                far enough or not from a vertice. Defaults to 5.\n\n        Returns:\n            NDArray: vertices that belongs to the geometric structure and that\n                are far from the input points.\n        \"\"\"\n        indices = get_shared_point_indices(\n            points_to_check=self.asarray,\n            checkpoints=points,\n            margin_dist_error=min_distance,\n            method=\"far\",\n            cond=\"all\",\n        )\n        return self.asarray[indices]\n\n    def __eq__(self, value: object) -&gt; bool:\n        if not isinstance(value, DiscreteGeometryEntity):\n            return False\n        if not isinstance(self, type(value)):\n            return False\n        return np.array_equal(self.asarray, value.asarray)\n\n    def __neg__(self) -&gt; Self:\n        return type(self)(-self.asarray)\n\n    def __add__(self, other: NDArray | float | int) -&gt; Self:\n        return type(self)(self.asarray + other)\n\n    def __sub__(self, other: NDArray | float | int) -&gt; Self:\n        return type(self)(self.asarray - other)\n\n    def __mul__(self, other: NDArray | float | int) -&gt; Self:\n        return type(self)(self.asarray.astype(float) * other)\n\n    def __truediv__(self, other: NDArray | float | int) -&gt; Self:\n        return type(self)(self.asarray / other)\n\n    def __len__(self) -&gt; int:\n        return self.n_points\n\n    def __getitem__(self, index: int) -&gt; NDArray:\n        return self.points[index]\n\n    def __str__(self) -&gt; str:\n        return (\n            self.__class__.__name__\n            + \"(start=\"\n            + self.asarray[0].tolist().__str__()\n            + \", end=\"\n            + self.asarray[-1].tolist().__str__()\n            + \")\"\n        )\n\n    def __repr__(self) -&gt; str:\n        return str(self)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.asarray","title":"<code>asarray</code>  <code>property</code> <code>writable</code>","text":"<p>Array representation of the geometry object</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.center_mean","title":"<code>center_mean</code>  <code>property</code>","text":"<p>Compute the center as the mean of all the points. This can be really different than the centroid.</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>center mean as a 2D point</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.centroid","title":"<code>centroid</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Compute the centroid point which can be seen as the center of gravity or center of mass of the shape</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>centroid point</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.crop_coordinates","title":"<code>crop_coordinates</code>  <code>property</code>","text":"<p>Compute the coordinates of the geometry entity in the context of itself being in a crop image that make it fit pefectly</p> <p>Returns:</p> Name Type Description <code>Self</code> <code>NDArray</code> <p>description</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.edges","title":"<code>edges</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Get the edges of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>edges of the geometry entity</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.lengths","title":"<code>lengths</code>  <code>property</code>","text":"<p>Returns the length of all the segments that make up the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>array of shape (n_points)</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.n_points","title":"<code>n_points</code>  <code>property</code>","text":"<p>Returns the number of points this geometric object is made of</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of points that composes the geomtric object</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.segments","title":"<code>segments</code>  <code>property</code>","text":"<p>Get the segments of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>list[Segment]</code> <p>segments of the geometry entity</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.shapely_edges","title":"<code>shapely_edges</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Representation of the geometric object in the shapely library as a geometrical object defined only as a curve with no area. Particularly useful to look for points intersections</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.shapely_surface","title":"<code>shapely_surface</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Representation of the geometric object in the shapely library as a geometrical object with an area and a border. Particularly useful to check if two geometrical objects are contained within each other or not.</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.xmax","title":"<code>xmax</code>  <code>property</code>","text":"<p>Get the maximum X coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.xmin","title":"<code>xmin</code>  <code>property</code>","text":"<p>Get the minimum X coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.ymax","title":"<code>ymax</code>  <code>property</code>","text":"<p>Get the maximum Y coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.ymin","title":"<code>ymin</code>  <code>property</code>","text":"<p>Get the minimum Y coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.clamp","title":"<code>clamp(xmin=-np.inf, xmax=np.inf, ymin=-np.inf, ymax=np.inf)</code>","text":"<p>Clamp the Geometry entity so that the x and y coordinates fit in the min and max values in parameters.</p> <p>Parameters:</p> Name Type Description Default <code>xmin</code> <code>float</code> <p>x coordinate minimum</p> <code>-inf</code> <code>xmax</code> <code>float</code> <p>x coordinate maximum</p> <code>inf</code> <code>ymin</code> <code>float</code> <p>y coordinate minimum</p> <code>-inf</code> <code>ymax</code> <code>float</code> <p>y coordinate maximum</p> <code>inf</code> <p>Returns:</p> Name Type Description <code>GeometryEntity</code> <code>Self</code> <p>clamped GeometryEntity</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def clamp(\n    self,\n    xmin: float = -np.inf,\n    xmax: float = np.inf,\n    ymin: float = -np.inf,\n    ymax: float = np.inf,\n) -&gt; Self:\n    \"\"\"Clamp the Geometry entity so that the x and y coordinates fit in the\n    min and max values in parameters.\n\n    Args:\n        xmin (float): x coordinate minimum\n        xmax (float): x coordinate maximum\n        ymin (float): y coordinate minimum\n        ymax (float): y coordinate maximum\n\n    Returns:\n        GeometryEntity: clamped GeometryEntity\n    \"\"\"\n    self.asarray[:, 0] = np.clip(self.asarray[:, 0], xmin, xmax)  # x values\n    self.asarray[:, 1] = np.clip(self.asarray[:, 1], ymin, ymax)  # y values\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.copy","title":"<code>copy()</code>","text":"<p>Create a copy of the geometry entity object</p> <p>Returns:</p> Name Type Description <code>GeometryEntity</code> <code>Self</code> <p>copy of the geometry entity object</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def copy(self) -&gt; Self:\n    \"\"\"Create a copy of the geometry entity object\n\n    Returns:\n        GeometryEntity: copy of the geometry entity object\n    \"\"\"\n    return type(self)(points=self.asarray.copy(), is_cast_int=self.is_cast_int)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.distances_vertices_to_point","title":"<code>distances_vertices_to_point(point)</code>","text":"<p>Get the distance from all vertices in the geometry entity to the input point</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>2D point</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>array of the same len as the number of vertices in the geometry entity.</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def distances_vertices_to_point(self, point: NDArray) -&gt; NDArray:\n    \"\"\"Get the distance from all vertices in the geometry entity to the input point\n\n    Args:\n        point (NDArray): 2D point\n\n    Returns:\n        NDArray: array of the same len as the number of vertices in the geometry\n            entity.\n    \"\"\"\n    return np.linalg.norm(self.asarray - point, axis=1)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.enclosing_axis_aligned_bbox","title":"<code>enclosing_axis_aligned_bbox()</code>","text":"<p>Compute the smallest area enclosing Axis-Aligned Bounding Box (AABB) See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html</p> <p>Return the points in the following order: 1. top left 2. top right 3. bottom right 4. bottom left</p> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>AxisAlignedRectangle</code> <p>Rectangle object</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def enclosing_axis_aligned_bbox(self) -&gt; AxisAlignedRectangle:\n    \"\"\"Compute the smallest area enclosing Axis-Aligned Bounding Box (AABB)\n    See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n    Return the points in the following order:\n    1. top left\n    2. top right\n    3. bottom right\n    4. bottom left\n\n    Returns:\n        Rectangle: Rectangle object\n    \"\"\"\n    # pylint: disable=import-outside-toplevel\n    from otary.geometry import (\n        AxisAlignedRectangle,\n    )  # delayed import to avoid circular import\n\n    topleft_x, topleft_y, width, height = cv2.boundingRect(\n        array=self.asarray.astype(np.float32)\n    )\n    topleft = np.array([topleft_x, topleft_y])\n    return AxisAlignedRectangle.from_topleft(\n        topleft=topleft, width=width, height=height\n    )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.enclosing_convex_hull","title":"<code>enclosing_convex_hull()</code>","text":"<p>Compute the smallest area enclosing Convex Hull See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html</p> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>Polygon object</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def enclosing_convex_hull(self) -&gt; Polygon:\n    \"\"\"Compute the smallest area enclosing Convex Hull\n    See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n    Returns:\n        Polygon: Polygon object\n    \"\"\"\n    # pylint: disable=import-outside-toplevel\n    from otary.geometry import Polygon  # delayed import to avoid circular import\n\n    convexhull = np.squeeze(cv2.convexHull(self.asarray.astype(np.float32)))\n    return Polygon(convexhull)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.enclosing_oriented_bbox","title":"<code>enclosing_oriented_bbox()</code>","text":"<p>Compute the smallest area enclosing Oriented Bounding Box (OBB) See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html</p> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Rectangle</code> <p>Rectangle object</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def enclosing_oriented_bbox(self) -&gt; Rectangle:\n    \"\"\"Compute the smallest area enclosing Oriented Bounding Box (OBB)\n    See: https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html\n\n    Returns:\n        Rectangle: Rectangle object\n    \"\"\"\n    # pylint: disable=import-outside-toplevel\n    from otary.geometry import Rectangle  # delayed import to avoid circular import\n\n    rect = cv2.minAreaRect(self.asarray.astype(np.float32))\n    bbox = cv2.boxPoints(rect)\n    return Rectangle(bbox)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.find_shared_approx_vertices","title":"<code>find_shared_approx_vertices(other, margin_dist_error=5)</code>","text":"<p>Get the shared vertices between two geometric objects.</p> <p>A vertice is considered shared if it is close enough to another vertice in the other geometric structure.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>DiscreteGeometryEntity</code> <p>a DiscreteGeometryEntity object</p> required <code>margin_dist_error</code> <code>float</code> <p>the threshold to define a vertice as shared or not. Defaults to 5.</p> <code>5</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>list of vertices identified as shared between the two geometric objects</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def find_shared_approx_vertices(\n    self, other: DiscreteGeometryEntity, margin_dist_error: float = 5\n) -&gt; NDArray:\n    \"\"\"Get the shared vertices between two geometric objects.\n\n    A vertice is considered shared if it is close enough to another vertice\n    in the other geometric structure.\n\n    Args:\n        other (DiscreteGeometryEntity): a DiscreteGeometryEntity object\n        margin_dist_error (float, optional): the threshold to define a vertice as\n            shared or not. Defaults to 5.\n\n    Returns:\n        NDArray: list of vertices identified as shared between the two geometric\n            objects\n    \"\"\"\n    indices = self.find_shared_approx_vertices_ix(\n        other=other, margin_dist_error=margin_dist_error\n    )\n    return self.asarray[indices]\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.find_shared_approx_vertices_ix","title":"<code>find_shared_approx_vertices_ix(other, margin_dist_error=5)</code>","text":"<p>Compute the vertices indices from this entity that correspond to shared vertices with the other geometric entity.</p> <p>A vertice is considered shared if it is close enough to another vertice in the other geometric structure.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>DiscreteGeometryEntity</code> <p>other Discrete Geometry entity</p> required <code>margin_dist_error</code> <code>float</code> <p>minimum distance to have two vertices considered as close enough to be shared. Defaults to 5.</p> <code>5</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>list of indices</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def find_shared_approx_vertices_ix(\n    self, other: DiscreteGeometryEntity, margin_dist_error: float = 5\n) -&gt; NDArray:\n    \"\"\"Compute the vertices indices from this entity that correspond to shared\n    vertices with the other geometric entity.\n\n    A vertice is considered shared if it is close enough to another vertice\n    in the other geometric structure.\n\n    Args:\n        other (DiscreteGeometryEntity): other Discrete Geometry entity\n        margin_dist_error (float, optional): minimum distance to have two vertices\n            considered as close enough to be shared. Defaults to 5.\n\n    Returns:\n        NDArray: list of indices\n    \"\"\"\n    return get_shared_point_indices(\n        points_to_check=self.asarray,\n        checkpoints=other.asarray,\n        margin_dist_error=margin_dist_error,\n        method=\"close\",\n        cond=\"any\",\n    )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.find_vertice_ix_closest_from","title":"<code>find_vertice_ix_closest_from(point)</code>","text":"<p>Get the index of the closest vertice from a given point</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>2D point</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>the index of the closest point in the entity from the input point</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def find_vertice_ix_closest_from(self, point: NDArray) -&gt; int:\n    \"\"\"Get the index of the closest vertice from a given point\n\n    Args:\n        point (NDArray): 2D point\n\n    Returns:\n        int: the index of the closest point in the entity from the input point\n    \"\"\"\n    return np.argmin(self.distances_vertices_to_point(point=point)).astype(int)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.find_vertice_ix_farthest_from","title":"<code>find_vertice_ix_farthest_from(point)</code>","text":"<p>Get the index of the farthest vertice from a given point</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>2D point</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>the index of the farthest vertice in the entity from the input point</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def find_vertice_ix_farthest_from(self, point: NDArray) -&gt; int:\n    \"\"\"Get the index of the farthest vertice from a given point\n\n    Args:\n        point (NDArray): 2D point\n\n    Returns:\n        int: the index of the farthest vertice in the entity from the input point\n    \"\"\"\n    return np.argmax(self.distances_vertices_to_point(point=point)).astype(int)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.find_vertices_far_from","title":"<code>find_vertices_far_from(points, min_distance=5)</code>","text":"<p>Get vertices that belongs to the geometric structure far from the points in parameters.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>NDArray</code> <p>input list of points</p> required <code>min_distance</code> <code>float</code> <p>the threshold to define a point as far enough or not from a vertice. Defaults to 5.</p> <code>5</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>vertices that belongs to the geometric structure and that are far from the input points.</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def find_vertices_far_from(\n    self, points: NDArray, min_distance: float = 5\n) -&gt; NDArray:\n    \"\"\"Get vertices that belongs to the geometric structure far from the points in\n    parameters.\n\n    Args:\n        points (NDArray): input list of points\n        min_distance (float, optional): the threshold to define a point as\n            far enough or not from a vertice. Defaults to 5.\n\n    Returns:\n        NDArray: vertices that belongs to the geometric structure and that\n            are far from the input points.\n    \"\"\"\n    indices = get_shared_point_indices(\n        points_to_check=self.asarray,\n        checkpoints=points,\n        margin_dist_error=min_distance,\n        method=\"far\",\n        cond=\"all\",\n    )\n    return self.asarray[indices]\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.longest_dist_vertices_to_point","title":"<code>longest_dist_vertices_to_point(point)</code>","text":"<p>Compute the longest distance from the geometry entity vertices to the point</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>2D point</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>longest distance from the geometry entity vertices to the point</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def longest_dist_vertices_to_point(self, point: NDArray) -&gt; float:\n    \"\"\"Compute the longest distance from the geometry entity vertices to the point\n\n    Args:\n        point (NDArray): 2D point\n\n    Returns:\n        float: longest distance from the geometry entity vertices to the point\n    \"\"\"\n    return np.max(self.distances_vertices_to_point(point=point))\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.normalize","title":"<code>normalize(x, y)</code>","text":"<p>Normalize the geometry entity by dividing the points by a norm on the x and y coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>x coordinate norm</p> required <code>y</code> <code>float</code> <p>y coordinate norm</p> required <p>Returns:</p> Name Type Description <code>GeometryEntity</code> <code>Self</code> <p>normalized GeometryEntity</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def normalize(self, x: float, y: float) -&gt; Self:\n    \"\"\"Normalize the geometry entity by dividing the points by a norm on the\n    x and y coordinates.\n\n    Args:\n        x (float): x coordinate norm\n        y (float): y coordinate norm\n\n    Returns:\n        GeometryEntity: normalized GeometryEntity\n    \"\"\"\n    if x == 0 or y == 0:\n        raise ValueError(\"x or y cannot be 0\")\n    self.asarray = self.asarray / np.array([x, y])\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.rotate","title":"<code>rotate(angle, is_degree=False, is_clockwise=True, pivot=None)</code>","text":"<p>Rotate the geometry entity object. A pivot point can be passed as an argument to rotate the object around the pivot</p> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>float</code> <p>rotation angle</p> required <code>is_degree</code> <code>bool</code> <p>whether the angle is in degree or radian. Defaults to False which means radians.</p> <code>False</code> <code>is_clockwise</code> <code>bool</code> <p>whether the rotation is clockwise or counter-clockwise. Defaults to True.</p> <code>True</code> <code>pivot</code> <code>NDArray</code> <p>pivot point. Defaults to None which means that by default the centroid point of the shape is taken as the pivot point.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>GeometryEntity</code> <code>Self</code> <p>rotated geometry entity object.</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def rotate(\n    self,\n    angle: float,\n    is_degree: bool = False,\n    is_clockwise: bool = True,\n    pivot: Optional[NDArray] = None,\n) -&gt; Self:\n    \"\"\"Rotate the geometry entity object.\n    A pivot point can be passed as an argument to rotate the object around the pivot\n\n    Args:\n        angle (float): rotation angle\n        is_degree (bool, optional): whether the angle is in degree or radian.\n            Defaults to False which means radians.\n        is_clockwise (bool, optional): whether the rotation is clockwise or\n            counter-clockwise. Defaults to True.\n        pivot (NDArray, optional): pivot point.\n            Defaults to None which means that by default the centroid point of\n            the shape is taken as the pivot point.\n\n    Returns:\n        GeometryEntity: rotated geometry entity object.\n    \"\"\"\n    if pivot is None:\n        pivot = self.centroid\n\n    self.points = rotate_2d_points(\n        points=self.points,\n        angle=angle,\n        pivot=pivot,\n        is_degree=is_degree,\n        is_clockwise=is_clockwise,\n    )\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.rotate_around_image_center","title":"<code>rotate_around_image_center(img, angle, degree=False)</code>","text":"<p>Given an geometric object and an image, rotate the object around the image center point.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>NDArray</code> <p>image as a shape (x, y) sized array</p> required <code>angle</code> <code>float</code> <p>rotation angle</p> required <code>degree</code> <code>bool</code> <p>whether the angle is in degree or radian. Defaults to False which means radians.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>GeometryEntity</code> <code>Self</code> <p>rotated geometry entity object.</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def rotate_around_image_center(\n    self, img: NDArray, angle: float, degree: bool = False\n) -&gt; Self:\n    \"\"\"Given an geometric object and an image, rotate the object around\n    the image center point.\n\n    Args:\n        img (NDArray): image as a shape (x, y) sized array\n        angle (float): rotation angle\n        degree (bool, optional): whether the angle is in degree or radian.\n            Defaults to False which means radians.\n\n    Returns:\n        GeometryEntity: rotated geometry entity object.\n    \"\"\"\n    img_center_point = np.array([img.shape[1], img.shape[0]]) / 2\n    return self.rotate(angle=angle, pivot=img_center_point, is_degree=degree)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.shift","title":"<code>shift(vector)</code>","text":"<p>Shift the geometry entity by the vector direction</p> <p>Parameters:</p> Name Type Description Default <code>vector</code> <code>NDArray</code> <p>vector that describes the shift as a array with two elements. Example: [2, -8] which describes the vector [[0, 0], [2, -8]]. The vector can also be a vector of shape (2, 2) of the form [[2, 6], [1, 3]].</p> required <p>Returns:</p> Name Type Description <code>GeometryEntity</code> <code>Self</code> <p>shifted geometrical object</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def shift(self, vector: NDArray) -&gt; Self:\n    \"\"\"Shift the geometry entity by the vector direction\n\n    Args:\n        vector (NDArray): vector that describes the shift as a array with\n            two elements. Example: [2, -8] which describes the\n            vector [[0, 0], [2, -8]]. The vector can also be a vector of shape\n            (2, 2) of the form [[2, 6], [1, 3]].\n\n    Returns:\n        GeometryEntity: shifted geometrical object\n    \"\"\"\n    vector = assert_transform_shift_vector(vector=vector)\n    self.points = self.points + vector\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.entity.DiscreteGeometryEntity.shortest_dist_vertices_to_point","title":"<code>shortest_dist_vertices_to_point(point)</code>","text":"<p>Compute the shortest distance from the geometry entity vertices to the point</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>2D point</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>shortest distance from the geometry entity vertices to the point</p> Source code in <code>otary/geometry/discrete/entity.py</code> <pre><code>def shortest_dist_vertices_to_point(self, point: NDArray) -&gt; float:\n    \"\"\"Compute the shortest distance from the geometry entity vertices to the point\n\n    Args:\n        point (NDArray): 2D point\n\n    Returns:\n        float: shortest distance from the geometry entity vertices to the point\n    \"\"\"\n    return np.min(self.distances_vertices_to_point(point=point))\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.point.Point","title":"<code>Point</code>","text":"<p>               Bases: <code>DiscreteGeometryEntity</code></p> <p>Point class</p> Source code in <code>otary/geometry/discrete/point.py</code> <pre><code>class Point(DiscreteGeometryEntity):\n    \"\"\"Point class\"\"\"\n\n    def __init__(self, point: NDArray, is_cast_int: bool = False) -&gt; None:\n        point = self._ensure_transform_point_array(point=point)\n        super().__init__(points=point, is_cast_int=is_cast_int)\n\n    @staticmethod\n    def _ensure_transform_point_array(point: NDArray) -&gt; NDArray:\n        point = np.asarray(point)\n        if point.shape == (2,):\n            point = point.reshape((1, 2))\n        if len(point) != 1:\n            raise ValueError(f\"The input point has not the expected shape {point}\")\n        return point\n\n    @property\n    def asarray(self):\n        return self.points\n\n    @asarray.setter\n    def asarray(self, value: NDArray):\n        \"\"\"Setter for the asarray property\n\n        Args:\n            value (NDArray): value of the asarray to be changed\n        \"\"\"\n        self.points = self._ensure_transform_point_array(point=value)\n\n    @property\n    def centroid(self) -&gt; NDArray:\n        \"\"\"Return the point as the centroid of a point is simply the point\n\n        Returns:\n            NDArray: centroid of the point\n        \"\"\"\n        return self.asarray[0]\n\n    @property\n    def shapely_edges(self) -&gt; SPoint:\n        \"\"\"Returns the Shapely.Point representation of the point.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.Point.html\n\n        Returns:\n            Point: shapely.Point object\n        \"\"\"\n        return SPoint(self.asarray)\n\n    @property\n    def shapely_surface(self) -&gt; SPoint:\n        \"\"\"Returns None since a point has no surface\n\n        Returns:\n            None: None value\n        \"\"\"\n        return None\n\n    @property\n    def area(self) -&gt; float:\n        \"\"\"Compute the area of the geometry entity\n\n        Returns:\n            float: area value\n        \"\"\"\n        return 0\n\n    @property\n    def perimeter(self) -&gt; float:\n        \"\"\"Compute the perimeter of the geometry entity\n\n        Returns:\n            float: perimeter value\n        \"\"\"\n        return 0\n\n    @property\n    def edges(self) -&gt; NDArray:\n        \"\"\"Get the edges of the point which returns empty array\n        since a point has no edges\n\n        Returns:\n            NDArray: empty array of shape (0, 2, 2)\n        \"\"\"\n        return np.empty(shape=(0, 2, 2))\n\n    @staticmethod\n    def order_idxs_points_by_dist(points: NDArray, desc: bool = False) -&gt; NDArray:\n        \"\"\"Beware the method expects points to be collinear.\n\n        Given four points [p0, p1, p2, p3], we wish to have the order in which each\n        point is separated.\n        The one closest to the origin is placed at the origin and relative to this\n        point we are able to know at which position are the other points.\n\n        If p0 is closest to the origin and the closest points from p0 are in order\n        p2, p1 and p3. Thus the array returned by the function is [0, 2, 1, 3].\n\n        Args:\n            points (NDArray): numpy array of shape (n, 2)\n            desc (bool): if True returns the indices based on distances descending\n                order. Otherwise ascending order which is the default.\n\n        Returns:\n            NDArray: indices of the points\n        \"\"\"\n        distances = np.linalg.norm(x=points, axis=1)\n        idxs_order_by_dist = np.argsort(distances)\n        if not desc:  # change the order if in descending order\n            idxs_order_by_dist = idxs_order_by_dist[::-1]\n        return idxs_order_by_dist\n\n    def distances_vertices_to_point(self, point: NDArray) -&gt; NDArray:\n        \"\"\"Compute the distances to a given point\n\n        Args:\n            point (NDArray): point to which we want to compute the distances\n\n        Returns:\n            NDArray: distance to the given point\n        \"\"\"\n        return np.linalg.norm(self.points - point, axis=1)\n\n    def __str__(self) -&gt; str:\n        return self.__class__.__name__ + \"(\" + self.asarray[0].tolist().__str__() + \")\"\n\n    def __repr__(self) -&gt; str:\n        return str(self)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.point.Point.area","title":"<code>area</code>  <code>property</code>","text":"<p>Compute the area of the geometry entity</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>area value</p>"},{"location":"api/geometry/#otary.geometry.discrete.point.Point.centroid","title":"<code>centroid</code>  <code>property</code>","text":"<p>Return the point as the centroid of a point is simply the point</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>centroid of the point</p>"},{"location":"api/geometry/#otary.geometry.discrete.point.Point.edges","title":"<code>edges</code>  <code>property</code>","text":"<p>Get the edges of the point which returns empty array since a point has no edges</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>empty array of shape (0, 2, 2)</p>"},{"location":"api/geometry/#otary.geometry.discrete.point.Point.perimeter","title":"<code>perimeter</code>  <code>property</code>","text":"<p>Compute the perimeter of the geometry entity</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>perimeter value</p>"},{"location":"api/geometry/#otary.geometry.discrete.point.Point.shapely_edges","title":"<code>shapely_edges</code>  <code>property</code>","text":"<p>Returns the Shapely.Point representation of the point. See https://shapely.readthedocs.io/en/stable/reference/shapely.Point.html</p> <p>Returns:</p> Name Type Description <code>Point</code> <code>Point</code> <p>shapely.Point object</p>"},{"location":"api/geometry/#otary.geometry.discrete.point.Point.shapely_surface","title":"<code>shapely_surface</code>  <code>property</code>","text":"<p>Returns None since a point has no surface</p> <p>Returns:</p> Name Type Description <code>None</code> <code>Point</code> <p>None value</p>"},{"location":"api/geometry/#otary.geometry.discrete.point.Point.distances_vertices_to_point","title":"<code>distances_vertices_to_point(point)</code>","text":"<p>Compute the distances to a given point</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>point to which we want to compute the distances</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>distance to the given point</p> Source code in <code>otary/geometry/discrete/point.py</code> <pre><code>def distances_vertices_to_point(self, point: NDArray) -&gt; NDArray:\n    \"\"\"Compute the distances to a given point\n\n    Args:\n        point (NDArray): point to which we want to compute the distances\n\n    Returns:\n        NDArray: distance to the given point\n    \"\"\"\n    return np.linalg.norm(self.points - point, axis=1)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.point.Point.order_idxs_points_by_dist","title":"<code>order_idxs_points_by_dist(points, desc=False)</code>  <code>staticmethod</code>","text":"<p>Beware the method expects points to be collinear.</p> <p>Given four points [p0, p1, p2, p3], we wish to have the order in which each point is separated. The one closest to the origin is placed at the origin and relative to this point we are able to know at which position are the other points.</p> <p>If p0 is closest to the origin and the closest points from p0 are in order p2, p1 and p3. Thus the array returned by the function is [0, 2, 1, 3].</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>NDArray</code> <p>numpy array of shape (n, 2)</p> required <code>desc</code> <code>bool</code> <p>if True returns the indices based on distances descending order. Otherwise ascending order which is the default.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>indices of the points</p> Source code in <code>otary/geometry/discrete/point.py</code> <pre><code>@staticmethod\ndef order_idxs_points_by_dist(points: NDArray, desc: bool = False) -&gt; NDArray:\n    \"\"\"Beware the method expects points to be collinear.\n\n    Given four points [p0, p1, p2, p3], we wish to have the order in which each\n    point is separated.\n    The one closest to the origin is placed at the origin and relative to this\n    point we are able to know at which position are the other points.\n\n    If p0 is closest to the origin and the closest points from p0 are in order\n    p2, p1 and p3. Thus the array returned by the function is [0, 2, 1, 3].\n\n    Args:\n        points (NDArray): numpy array of shape (n, 2)\n        desc (bool): if True returns the indices based on distances descending\n            order. Otherwise ascending order which is the default.\n\n    Returns:\n        NDArray: indices of the points\n    \"\"\"\n    distances = np.linalg.norm(x=points, axis=1)\n    idxs_order_by_dist = np.argsort(distances)\n    if not desc:  # change the order if in descending order\n        idxs_order_by_dist = idxs_order_by_dist[::-1]\n    return idxs_order_by_dist\n</code></pre>"},{"location":"api/geometry/#shape_1","title":"Shape","text":"<p>Polygon class to handle complexity with polygon calculation</p> <p>Rectangle class. It will be particularly useful for the AITT project for describing bounding boxes.</p> <p>Triangle class module</p>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon","title":"<code>Polygon</code>","text":"<p>               Bases: <code>DiscreteGeometryEntity</code></p> <p>Polygon class which defines a polygon object which means any closed-shape</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>class Polygon(DiscreteGeometryEntity):\n    \"\"\"Polygon class which defines a polygon object which means any closed-shape\"\"\"\n\n    # pylint: disable=too-many-public-methods\n\n    def __init__(self, points: NDArray | list, is_cast_int: bool = False) -&gt; None:\n        if len(points) &lt;= 2:\n            raise ValueError(\n                \"Cannot create a Polygon since it must have 3 or more points\"\n            )\n        super().__init__(points=points, is_cast_int=is_cast_int)\n\n    # ---------------------------------- OTHER CONSTRUCTORS ----------------------------\n\n    @classmethod\n    def from_lines(cls, lines: NDArray) -&gt; Polygon:\n        \"\"\"The lines should describe a perfect closed shape polygon\n\n        Args:\n            lines (NDArray): array of lines of shape (n, 2, 2)\n\n        Returns:\n            (Polygon): a Polygon object\n        \"\"\"\n        nlines = len(lines)\n        shifted_lines = np.roll(\n            np.array(lines).reshape(nlines * 2, 2), shift=1, axis=0\n        ).reshape(nlines, 2, 2)\n        distances = np.linalg.norm(np.diff(shifted_lines, axis=1), axis=2)\n        if np.any(distances):  # a distance is different from 0\n            bad_idxs = np.nonzero(distances &gt; 0)\n            raise ValueError(\n                f\"Could not construct the polygon from the given lines.\"\n                f\"Please check at those indices: {bad_idxs}\"\n            )\n        points = lines[:, 0]\n        return Polygon(points=points)\n\n    @classmethod\n    def from_linear_entities_returns_vertices_ix(\n        cls, linear_entities: Sequence[LinearEntity]\n    ) -&gt; tuple[Polygon, list[int]]:\n        \"\"\"Convert a list of linear entities to polygon.\n\n        Beware: this method assumes entities are sorted and connected.\n        Conneted means that the last point of each entity is the first point\n        of the next entity.\n        This implies that the polygon is necessarily closed.\n\n        Args:\n            linear_entities (Sequence[LinearEntity]): List of linear entities.\n\n        Returns:\n            (Polygon, list[int]): polygon and indices of first vertex of each entity\n        \"\"\"\n        points = []\n        vertices_ix: list[int] = []\n        current_ix = 0\n        for i, linear_entity in enumerate(linear_entities):\n            if not isinstance(linear_entity, LinearEntity):\n                raise TypeError(\n                    f\"Expected a list of LinearEntity, but got {type(linear_entity)}\"\n                )\n\n            cond_first_pt_is_equal_prev_entity_last_pt = np.array_equal(\n                linear_entity.points[0], linear_entities[i - 1].points[-1]\n            )\n            if not cond_first_pt_is_equal_prev_entity_last_pt:\n                raise ValueError(\n                    f\"The first point of entity {i} ({linear_entity.points[0]}) \"\n                    f\"is not equal to the last point of entity {i-1} \"\n                    f\"({linear_entities[i-1].points[-1]})\"\n                )\n            pts_except_last = linear_entity.points[:-1, :]\n            points.append(pts_except_last)\n            vertices_ix.append(current_ix)\n            current_ix += len(pts_except_last)\n\n        points = np.concatenate(points, axis=0)\n        polygon = Polygon(points=points)\n        return polygon, vertices_ix\n\n    @classmethod\n    def from_linear_entities(\n        cls,\n        linear_entities: Sequence[LinearEntity],\n    ) -&gt; Polygon:\n        \"\"\"Convert a list of linear entities to polygon.\n\n        Beware: the method assumes entities are sorted and connected.\n\n        Args:\n            linear_entities (Sequence[LinearEntity]): List of linear entities.\n\n        Returns:\n            Polygon: polygon representation of the linear entity\n        \"\"\"\n        return cls.from_linear_entities_returns_vertices_ix(linear_entities)[0]\n\n    @classmethod\n    def from_unordered_lines_approx(\n        cls,\n        lines: NDArray,\n        max_dist_thresh: float = 50,\n        max_iterations: int = 50,\n        start_line_index: int = 0,\n    ) -&gt; Polygon:\n        \"\"\"Create a Polygon object from an unordered list of lines that approximate a\n        closed-shape. They approximate in the sense that they do not necessarily\n        share common points. This method computes the intersection points between lines.\n\n        Args:\n            lines (NDArray): array of lines of shape (n, 2, 2)\n            max_dist_thresh (float, optional): For any given point,\n                the maximum distance to consider two points as close. Defaults to 50.\n            max_iterations (float, optional): Maximum number of iterations before\n                finding a polygon.\n                It defines also the maximum number of lines in the polygon to be found.\n            start_line_index (int, optional): The starting line to find searching for\n                the polygon. Defaults to 0.\n\n        Returns:\n            (Polygon): a Polygon object\n        \"\"\"\n        # pylint: disable=too-many-locals\n        # pylint: disable=too-many-positional-arguments, too-many-arguments\n        lines = np.asarray(lines)\n        assert_list_of_lines(lines=lines)\n\n        _lines = copy.deepcopy(lines)\n        list_build_cnt = []\n        is_polygon_found = False\n        idx_seg_closest = start_line_index\n        i = 0\n        while not is_polygon_found and i &lt; max_iterations:\n            curseg = Segment(_lines[idx_seg_closest])\n            curpoint = curseg.asarray[1]\n            list_build_cnt.append(curseg.asarray)\n            _lines = np.delete(_lines, idx_seg_closest, axis=0)\n\n            if len(_lines) == 0:\n                logging.debug(\"No more lines to be processed.\")\n\n            # find the closest point to the current one and associated line\n            lines2points = _lines.reshape(len(_lines) * 2, 2)\n            dist_from_curpoint = np.linalg.norm(lines2points - curpoint, axis=1)\n            idx_closest_points = np.nonzero(dist_from_curpoint &lt; max_dist_thresh)[0]\n\n            if len(idx_closest_points) &gt; 1:\n                # more than one point close to the current point - take the closest\n                idx_closest_points = np.array([np.argmin(dist_from_curpoint)])\n            if len(idx_closest_points) == 0:\n                # no point detected - can mean that the polygon is done or not\n                first_seg = Segment(list_build_cnt[0])\n                if np.linalg.norm(first_seg.asarray[0] - curpoint) &lt; max_dist_thresh:\n                    intersect_point = curseg.intersection_line(first_seg)\n                    list_build_cnt[-1][1] = intersect_point\n                    list_build_cnt[0][0] = intersect_point\n                    is_polygon_found = True\n                    break\n                raise RuntimeError(\"No point detected close to the current point\")\n\n            # only one closest point - get indices of unique closest point on segment\n            idx_point_closest = int(idx_closest_points[0])\n            idx_seg_closest = int(np.floor(idx_point_closest / 2))\n\n            # arrange the line so that the closest point is in the first place\n            idx_point_in_line = 0 if (idx_point_closest / 2).is_integer() else 1\n            seg_closest = _lines[idx_seg_closest]\n            if idx_point_in_line == 1:  # flip points positions\n                seg_closest = np.flip(seg_closest, axis=0)\n            _lines[idx_seg_closest] = seg_closest\n\n            # find intersection point between the two lines\n            intersect_point = curseg.intersection_line(Segment(seg_closest))\n\n            # update arrays with the intersection point\n            _lines[idx_seg_closest][0] = intersect_point\n            list_build_cnt[i][1] = intersect_point\n\n            i += 1\n\n        cnt = Polygon.from_lines(np.array(list_build_cnt, dtype=np.int32))\n        return cnt\n\n    # --------------------------------- PROPERTIES ------------------------------------\n\n    @property\n    def shapely_surface(self) -&gt; SPolygon:\n        \"\"\"Returns the Shapely.Polygon as an surface representation of the Polygon.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html\n\n        Returns:\n            Polygon: shapely.Polygon object\n        \"\"\"\n        return SPolygon(self.asarray, holes=None)\n\n    @property\n    def shapely_edges(self) -&gt; LinearRing:\n        \"\"\"Returns the Shapely.LinearRing as a curve representation of the Polygon.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.LinearRing.html\n\n        Returns:\n            LinearRing: shapely.LinearRing object\n        \"\"\"\n        return LinearRing(coordinates=self.asarray)\n\n    @property\n    def centroid(self) -&gt; NDArray:\n        \"\"\"Compute the centroid point which can be seen as the center of gravity\n        or center of mass of the shape.\n\n        Beware: if the shape is degenerate, the centroid will be undefined.\n        In that case, the mean of the points is returned.\n\n        Returns:\n            NDArray: centroid point\n        \"\"\"\n        M = cv2.moments(self.asarray.astype(np.float32).reshape((-1, 1, 2)))\n\n        # Avoid division by zero\n        if M[\"m00\"] != 0:\n            cx = M[\"m10\"] / M[\"m00\"]\n            cy = M[\"m01\"] / M[\"m00\"]\n            centroid = np.asarray([cx, cy])\n        else:\n            centroid = self.center_mean\n\n        return centroid\n\n    @property\n    def area(self) -&gt; float:\n        \"\"\"Compute the area of the geometry entity\n\n        Returns:\n            float: area value\n        \"\"\"\n        return cv2.contourArea(self.points.astype(np.int32))\n\n    @property\n    def perimeter(self) -&gt; float:\n        \"\"\"Compute the perimeter of the geometry entity\n\n        Returns:\n            float: perimeter value\n        \"\"\"\n        return cv2.arcLength(self.points.astype(np.float32), True)\n\n    @property\n    def is_self_intersected(self) -&gt; bool:\n        \"\"\"Whether any of the segments intersect another segment in the same set\n\n        Returns:\n            bool: True if at least two lines intersect, False otherwise\n        \"\"\"\n        return not self.shapely_edges.is_simple\n\n    @property\n    def is_convex(self) -&gt; bool:\n        \"\"\"Whether the Polygon describes a convex shape of not.\n\n        Returns:\n            bool: True if convex else False\n        \"\"\"\n        return cv2.isContourConvex(contour=self.asarray)\n\n    @property\n    def edges(self) -&gt; NDArray:\n        \"\"\"Get the lines that compose the geometry entity.\n\n        Args:\n            points (NDArray): array of points of shape (n, 2)\n\n        Returns:\n            NDArray: array of lines of shape (n, 2, 2)\n        \"\"\"\n        return np.stack([self.points, np.roll(self.points, shift=-1, axis=0)], axis=1)\n\n    # ------------------------------- CLASSIC METHODS ----------------------------------\n\n    def is_regular(self, margin_dist_error_pct: float = 1e-2) -&gt; bool:\n        \"\"\"Identifies whether the polygon is regular, this means is rectangular or is\n        a square.\n\n        Args:\n            margin_dist_error_pct (float, optional): margin for a distance error.\n                The percentage is multiplied by the square root of the product of\n                the diagonals. Defaults to 1e-2.\n\n        Returns:\n            bool: True if the polygon describes a rectangle or square.\n        \"\"\"\n        # check we have four points\n        if len(self.asarray) != 4:\n            return False\n\n        # compute diagonal 1 = taking reference index as 1st point in list - index 0\n        refpoint = self.asarray[0]\n        idx_max_dist = self.find_vertice_ix_farthest_from(point=refpoint)\n        farther_point = self.asarray[idx_max_dist]\n        diag1 = Segment(points=[refpoint, farther_point])\n\n        # compute diagonal 2\n        diag2_idxs = [1, 2, 3]  # every index except 0\n        diag2_idxs.remove(idx_max_dist)  # delete index of point in first diag\n        diag2 = Segment(points=self.asarray[diag2_idxs])\n\n        # rectangular criteria = the diagonals have same lengths\n        normed_length = np.sqrt(diag1.length * diag2.length)\n        if np.abs(diag1.length - diag2.length) &gt; normed_length * margin_dist_error_pct:\n            return False\n\n        # there should exist only one intersection point\n        intersection_points = diag1.intersection(other=diag2)\n        if len(intersection_points) != 1:\n            return False\n\n        # diagonals bisect on the center of both diagonal\n        cross_point = intersection_points[0]\n        dist_mid_cross_diag1 = np.linalg.norm(cross_point - diag1.centroid)\n        dist_mid_cross_diag2 = np.linalg.norm(cross_point - diag2.centroid)\n        if (\n            np.abs(dist_mid_cross_diag1) &gt; normed_length * margin_dist_error_pct\n            or np.abs(dist_mid_cross_diag2) &gt; normed_length * margin_dist_error_pct\n        ):\n            return False\n\n        return True\n\n    def is_clockwise(self, is_y_axis_down: bool = False) -&gt; bool:\n        \"\"\"Determine if a polygon points go clockwise using the Shoelace formula.\n\n        True if polygon vertices order is clockwise in the \"y-axis points up\"\n        referential.\n\n        Args:\n            is_y_axis_down (bool, optional): If is_y_axis_down is True, then the image\n                referential is used where y axis points down.\n\n        Returns:\n            bool: True if clockwise, False if counter-clockwise\n        \"\"\"\n        x = self.asarray[:, 0]\n        y = self.asarray[:, 1]\n\n        x_next = np.roll(x, -1)\n        y_next = np.roll(y, -1)\n\n        s = np.sum((x_next - x) * (y_next + y))\n\n        is_clockwise = bool(s &gt; 0)  # Clockwise if positive (OpenCV's convention)\n\n        if is_y_axis_down:  # in referential where y axis points down\n            return not is_clockwise\n\n        return is_clockwise\n\n    def as_linear_spline(self, index: int = 0) -&gt; LinearSpline:\n        \"\"\"Get the polygon as a LinearSpline object.\n        This simply means a LinearSpline object with the same points as the Polygon\n        but with an extra point: the one at the index.\n\n        Returns:\n            LinearSpline: linear spline from polygon\n        \"\"\"\n        if index &lt; 0:\n            index += len(self)\n\n        index = index % len(self)\n\n        return LinearSpline(\n            points=np.concat(\n                [self.asarray[index : len(self)], self.asarray[0 : index + 1]], axis=0\n            )\n        )\n\n    def contains(self, other: GeometryEntity, dilate_scale: float = 1) -&gt; bool:\n        \"\"\"Whether the geometry contains the other or not\n\n        Args:\n            other (GeometryEntity): a GeometryEntity object\n            dilate_scale (float): if greater than 1, the object will be scaled up\n                before checking if it contains the other Geometry Entity. Can not be\n                a value less than 1.\n\n        Returns:\n            bool: True if the entity contains the other\n        \"\"\"\n        if dilate_scale != 1:\n            surface = self.copy().expand(scale=dilate_scale).shapely_surface\n        else:\n            surface = self.shapely_surface\n        return surface.contains(other.shapely_surface)\n\n    def score_vertices_in_points(self, points: NDArray, max_distance: float) -&gt; NDArray:\n        \"\"\"Returns a score of 0 or 1 for each point in the polygon if it is close\n        enough to any point in the input points.\n\n        Args:\n            points (NDArray): list of 2D points\n            max_distance (float): maximum distance to consider two points as\n                close enough to be considered as the same points\n\n        Returns:\n            NDArray: a list of score for each point in the contour\n        \"\"\"\n\n        indices = get_shared_point_indices(\n            points_to_check=self.asarray,\n            checkpoints=points,\n            margin_dist_error=max_distance,\n            method=\"close\",\n            cond=\"any\",\n        )\n        score = np.bincount(indices, minlength=len(self))\n        return score\n\n    def find_vertices_between(self, start_index: int, end_index: int) -&gt; NDArray:\n        \"\"\"Get the vertices between two indices.\n\n        Returns always the vertices between start_index and end_index using the\n        natural order of the vertices in the contour.\n\n        By convention, if start_index == end_index, then it returns the whole contour\n        plus the vertice at start_index.\n\n        Args:\n            start_index (int): index of the first vertex\n            end_index (int): index of the last vertex\n\n        Returns:\n            NDArray: array of vertices\n        \"\"\"\n        if start_index &lt; 0:\n            start_index += len(self)\n        if end_index &lt; 0:\n            end_index += len(self)\n\n        start_index = start_index % len(self)\n        end_index = end_index % len(self)\n\n        if start_index &gt; end_index:\n            vertices = np.concat(\n                [\n                    self.asarray[start_index : len(self)],\n                    self.asarray[0 : end_index + 1],\n                ],\n                axis=0,\n            )\n        elif start_index == end_index:\n            vertices = self.as_linear_spline(index=start_index).asarray\n        else:\n            vertices = self.asarray[start_index : end_index + 1]\n\n        return vertices\n\n    def find_interpolated_point_and_prev_ix(\n        self, start_index: int, end_index: int, pct_dist: float\n    ) -&gt; tuple[NDArray, int]:\n        \"\"\"Return a point along the contour path from start_idx to end_idx (inclusive),\n        at a relative distance pct_dist \u2208 [0, 1] along that path.\n\n        By convention, if start_index == end_index, then use the whole contour\n        start at this index position.\n\n        Parameters:\n            start_index (int): Index of the start point in the contour\n            end_index (int): Index of the end point in the contour\n            pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n                Any value in [0, 1] returns a point between start and end that is\n                pct_dist along the path.\n\n        Returns:\n            NDArray: Interpolated point [x, y]\n        \"\"\"\n        if not 0 &lt;= pct_dist &lt;= 1:\n            raise ValueError(\"pct_dist must be in [0, 1]\")\n\n        if start_index &lt; 0:\n            start_index += len(self)\n        if end_index &lt; 0:\n            end_index += len(self)\n\n        start_index = start_index % len(self)\n        end_index = end_index % len(self)\n\n        path = LinearSpline(\n            points=self.find_vertices_between(\n                start_index=start_index, end_index=end_index\n            )\n        )\n\n        point, index = path.find_interpolated_point_and_prev_ix(pct_dist=pct_dist)\n        index = (index + start_index) % len(self)\n\n        return point, index\n\n    def find_interpolated_point(\n        self, start_index: int, end_index: int, pct_dist: float\n    ) -&gt; NDArray:\n        \"\"\"Return a point along the contour path from start_idx to end_idx (inclusive),\n        at a relative distance pct_dist \u2208 [0, 1] along that path.\n\n        By convention, if start_index == end_index, then use the whole contour\n        start at this index position.\n\n        Parameters:\n            start_index (int): Index of the start point in the contour\n            end_index (int): Index of the end point in the contour\n            pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n                Any value in [0, 1] returns a point between start and end that is\n                pct_dist along the path.\n\n        Returns:\n            NDArray: Interpolated point [x, y]\n        \"\"\"\n        return self.find_interpolated_point_and_prev_ix(\n            start_index=start_index, end_index=end_index, pct_dist=pct_dist\n        )[0]\n\n    def normal_point(\n        self,\n        start_index: int,\n        end_index: int,\n        dist_along_edge_pct: float,\n        dist_from_edge: float,\n        is_outward: bool = True,\n    ) -&gt; NDArray:\n        \"\"\"Compute the outward normal point.\n        This is a point that points toward the outside of the polygon\n\n        Args:\n            start_index (int): start index for the edge selection\n            end_index (int): end index for the edge selection\n            dist_along_edge_pct (float): distance along the edge to place the point\n            dist_from_edge (float): distance outward from the edge\n            is_outward (bool, optional): True if the normal points to the outside of\n                the polygon. False if the normal points to the inside of the polygon.\n                Defaults to True.\n\n        Returns:\n            NDArray: 2D point as array\n        \"\"\"\n        # pylint: disable=too-many-locals\n        # pylint: disable=too-many-arguments, too-many-positional-arguments,\n        if not 0.0 &lt;= dist_along_edge_pct &lt;= 1.0:\n            raise ValueError(\"dist_along_edge_pct must be in [0, 1]\")\n\n        pt_interpolated, prev_ix = self.find_interpolated_point_and_prev_ix(\n            start_index=start_index, end_index=end_index, pct_dist=dist_along_edge_pct\n        )\n        next_ix = (prev_ix + 1) % len(self)\n\n        is_interpolated_pt_existing_edge = np.array_equal(\n            pt_interpolated, self.asarray[prev_ix]\n        ) or np.array_equal(pt_interpolated, self.asarray[next_ix])\n        if is_interpolated_pt_existing_edge:\n            raise ValueError(\n                \"Interpolated point for normal computation is an existing vertice \"\n                \"along polygon. Please choose another dist_along_edge_pct parameter.\"\n            )\n\n        edge = Vector(points=[self.asarray[prev_ix], self.asarray[next_ix]])\n\n        normal = edge.normal().normalized\n\n        pt_plus = pt_interpolated + dist_from_edge * normal\n        pt_minus = pt_interpolated - dist_from_edge * normal\n\n        dist_plus = np.linalg.norm(pt_plus - self.centroid)\n        dist_minus = np.linalg.norm(pt_minus - self.centroid)\n\n        # choose the point which distance to the center is greater\n        if dist_plus &gt; dist_minus:\n            if is_outward:\n                return pt_plus\n            return pt_minus\n\n        if is_outward:\n            return pt_minus\n        return pt_plus\n\n    def inter_area(self, other: Polygon) -&gt; float:\n        \"\"\"Inter area with another Polygon\n\n        Args:\n            other (Polygon): other Polygon\n\n        Returns:\n            float: inter area value\n        \"\"\"\n        inter_pts = cv2.intersectConvexConvex(self.asarray, other.asarray)\n        if inter_pts[0] &gt; 0:\n            inter_area = cv2.contourArea(inter_pts[1])\n        else:\n            inter_area = 0.0\n        return inter_area\n\n    def union_area(self, other: Polygon) -&gt; float:\n        \"\"\"Union area with another Polygon\n\n        Args:\n            other (Polygon): other Polygon\n\n        Returns:\n            float: union area value\n        \"\"\"\n        return self.area + other.area - self.inter_area(other)\n\n    def iou(self, other: Polygon) -&gt; float:\n        \"\"\"Intersection over union with another Polygon\n\n        Args:\n            other (Polygon): other Polygon\n\n        Returns:\n            float: intersection over union value\n        \"\"\"\n        inter_area = self.inter_area(other)\n\n        # optimized not to compute twice the inter area\n        union_area = self.area + other.area - inter_area\n\n        if union_area == 0:\n            return 0.0\n        return inter_area / union_area\n\n    # ---------------------------- MODIFICATION METHODS -------------------------------\n\n    def add_vertice(self, point: NDArray, index: int) -&gt; Self:\n        \"\"\"Add a point at a given index in the Polygon object\n\n        Args:\n            point (NDArray): point to be added\n            index (int): index where the point will be added\n\n        Returns:\n            Polygon: Polygon object with an added point\n        \"\"\"\n        size = len(self)\n        if index &gt;= size:\n            raise ValueError(\n                f\"The index value {index} is too big. \"\n                f\"The maximum possible index value is {size-1}.\"\n            )\n        if index &lt; 0:\n            if abs(index) &gt; size + 1:\n                raise ValueError(\n                    f\"The index value {index} is too small. \"\n                    f\"The minimum possible index value is {-(size+1)}\"\n                )\n            index = size + index + 1\n\n        self.points = np.concatenate(\n            [self.points[:index], [point], self.points[index:]]\n        )\n        return self\n\n    def rearrange_first_vertice_at_index(self, index: int) -&gt; Self:\n        \"\"\"Rearrange the list of points that defines the Polygon so that the first\n        point in the list of points is the one at index given by the argument of this\n        function.\n\n        Args:\n            index (int): index value\n\n        Returns:\n            Polygon: Polygon which is the exact same one but with a rearranged list\n                of points.\n        \"\"\"\n        size = len(self)\n        if index &gt;= size:\n            raise ValueError(\n                f\"The index value {index} is too big. \"\n                f\"The maximum possible index value is {size-1}.\"\n            )\n        if index &lt; 0:\n            if abs(index) &gt; size:\n                raise ValueError(\n                    f\"The index value {index} is too small. \"\n                    f\"The minimum possible index value is {-size}\"\n                )\n            index = size + index\n\n        self.points = np.concatenate([self.points[index:], self.points[:index]])\n        return self\n\n    def rearrange_first_vertice_closest_to_point(\n        self, point: NDArray = np.zeros(shape=(2,))\n    ) -&gt; Polygon:\n        \"\"\"Rearrange the list of vertices that defines the Polygon so that the first\n        point in the list of vertices is the one that is the closest by distance to\n        the reference point.\n\n        Args:\n            point (NDArray): point that is taken as a reference in the\n                space to find the one in the Polygon list of points that is the\n                closest to this reference point. Default to origin point [0, 0].\n\n        Returns:\n            Polygon: Polygon which is the exact same one but with a rearranged list\n                of points.\n        \"\"\"\n        idx_min_dist = self.find_vertice_ix_closest_from(point=point)\n        return self.rearrange_first_vertice_at_index(index=idx_min_dist)\n\n    def reorder_clockwise(self, is_y_axis_down: bool = False) -&gt; Polygon:\n        \"\"\"Reorder the vertices of the polygon in clockwise order where the first point\n        stays the same.\n\n        Args:\n            is_y_axis_down (bool, optional): True if cv2 is used. Defaults to False.\n\n        Returns:\n            Polygon: reordered polygon\n        \"\"\"\n        if self.is_clockwise(is_y_axis_down=is_y_axis_down):\n            return self\n        self.asarray = np.roll(self.asarray[::-1], shift=1, axis=0)\n        return self\n\n    def __rescale(self, scale: float) -&gt; Polygon:\n        \"\"\"Create a new polygon that is scaled up or down.\n\n        The rescale method compute the vector that is directed from the polygon center\n        to each point. Then it rescales each vector and use the head point of each\n        vector to compose the new scaled polygon.\n\n        Args:\n            scale (float): float value to scale the polygon\n\n        Returns:\n            Polygon: scaled polygon\n        \"\"\"\n        if scale == 1.0:  # no rescaling\n            return self\n\n        center = self.centroid\n        self.asarray = self.asarray.astype(float)\n        for i, point in enumerate(self.asarray):\n            self.asarray[i] = Vector([center, point]).rescale_head(scale).head\n        return self\n\n    def expand(self, scale: float) -&gt; Polygon:\n        \"\"\"Stretch, dilate or expand a polygon\n\n        Args:\n            scale (float): scale expanding factor. Must be greater than 1.\n\n        Returns:\n            Polygon: new bigger polygon\n        \"\"\"\n        if scale &lt; 1:\n            raise ValueError(\n                \"The scale value can not be less than 1 when expanding a polygon. \"\n                f\"Found {scale}\"\n            )\n        return self.__rescale(scale=scale)\n\n    def shrink(self, scale: float) -&gt; Polygon:\n        \"\"\"Contract or shrink a polygon\n\n        Args:\n            scale (float): scale shrinking factor. Must be greater than 1.\n\n        Returns:\n            Polygon: new bigger polygon\n        \"\"\"\n        if scale &lt; 1:\n            raise ValueError(\n                \"The scale value can not be less than 1 when shrinking a polygon. \"\n                f\"Found {scale}\"\n            )\n        return self.__rescale(scale=1 / scale)\n\n    def to_image_crop_referential(\n        self,\n        other: Polygon,\n        crop: Rectangle,\n        image_crop_shape: Optional[tuple[int, int]] = None,\n    ) -&gt; Polygon:\n        \"\"\"This function can be useful for a very specific need:\n        In a single image you have two same polygons and their coordinates are defined\n        in this image referential.\n\n        You want to obtain the original polygon and all its vertices information\n        in the image crop referential to match the other polygon within it.\n\n        This method manipulates three referentials:\n        1. image referential (main referential)\n        2. crop referential\n        3. image crop referential. It is different from the crop referential\n            because the width and height of the crop referential may not be the same.\n\n        Args:\n            other (Polygon): other Polygon in the image referential\n            crop (Rectangle): crop rectangle in the image referential\n            image_crop_shape (tuple[int, int], optionla): [width, height] of the crop\n                image. If None, the shape is assumed to be directly the crop shape.\n\n\n        Returns:\n            Polygon: original polygon in the image crop referential\n        \"\"\"\n        if not crop.contains(other=other):\n            raise ValueError(\n                f\"The crop rectangle {crop} does not contain the other polygon {other}\"\n            )\n        crop_width = int(crop.get_width_from_topleft(0))\n        crop_height = int(crop.get_height_from_topleft(0))\n\n        if image_crop_shape is None:\n            image_crop_shape = (crop_width, crop_height)\n\n        # self polygon in the original image shifted and normalized\n        aabb_main = self.enclosing_axis_aligned_bbox()\n        contour_main_shifted_normalized = self.copy().shift(\n            vector=-np.asarray([self.xmin, self.ymin])\n        ) / np.array([aabb_main.width, aabb_main.height])\n\n        # AABB of the polygon in the crop referential\n        aabb_crop = other.enclosing_axis_aligned_bbox()\n        aabb_crop_normalized = (\n            aabb_crop - np.asarray([crop.xmin, crop.ymin])\n        ) / np.array([crop_width, crop_height])\n\n        # obtain the self polygon in the image crop referential\n        aabb_crop2 = aabb_crop_normalized * np.array(image_crop_shape)\n        new_polygon = contour_main_shifted_normalized * np.array(\n            [\n                aabb_crop2.get_width_from_topleft(0),\n                aabb_crop2.get_height_from_topleft(0),\n            ]\n        ) + np.asarray([aabb_crop2.xmin, aabb_crop2.ymin])\n\n        return new_polygon\n\n    # ------------------------------- Fundamental Methods ------------------------------\n\n    def is_equal(self, polygon: Polygon, dist_margin_error: float = 5) -&gt; bool:\n        \"\"\"Check whether two polygons objects are equal by considering a margin of\n        error based on a distance between points.\n\n        Args:\n            polygon (Polygon): Polygon object\n            dist_margin_error (float, optional): distance margin of error.\n                Defaults to 5.\n\n        Returns:\n            bool: True if the polygon are equal, False otherwise\n        \"\"\"\n        if self.n_points != polygon.n_points:\n            # if polygons do not have the same number of points they can not be similar\n            return False\n\n        # check if each points composing the polygons are close to each other\n        new_cnt = polygon.copy().rearrange_first_vertice_closest_to_point(\n            self.points[0]\n        )\n        points_diff = new_cnt.points - self.points\n        distances = np.linalg.norm(points_diff, axis=1)\n        max_distance = np.max(distances)\n        return max_distance &lt;= dist_margin_error\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.area","title":"<code>area</code>  <code>property</code>","text":"<p>Compute the area of the geometry entity</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>area value</p>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.centroid","title":"<code>centroid</code>  <code>property</code>","text":"<p>Compute the centroid point which can be seen as the center of gravity or center of mass of the shape.</p> <p>Beware: if the shape is degenerate, the centroid will be undefined. In that case, the mean of the points is returned.</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>centroid point</p>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.edges","title":"<code>edges</code>  <code>property</code>","text":"<p>Get the lines that compose the geometry entity.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>NDArray</code> <p>array of points of shape (n, 2)</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>array of lines of shape (n, 2, 2)</p>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.is_convex","title":"<code>is_convex</code>  <code>property</code>","text":"<p>Whether the Polygon describes a convex shape of not.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if convex else False</p>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.is_self_intersected","title":"<code>is_self_intersected</code>  <code>property</code>","text":"<p>Whether any of the segments intersect another segment in the same set</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if at least two lines intersect, False otherwise</p>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.perimeter","title":"<code>perimeter</code>  <code>property</code>","text":"<p>Compute the perimeter of the geometry entity</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>perimeter value</p>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.shapely_edges","title":"<code>shapely_edges</code>  <code>property</code>","text":"<p>Returns the Shapely.LinearRing as a curve representation of the Polygon. See https://shapely.readthedocs.io/en/stable/reference/shapely.LinearRing.html</p> <p>Returns:</p> Name Type Description <code>LinearRing</code> <code>LinearRing</code> <p>shapely.LinearRing object</p>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.shapely_surface","title":"<code>shapely_surface</code>  <code>property</code>","text":"<p>Returns the Shapely.Polygon as an surface representation of the Polygon. See https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html</p> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>shapely.Polygon object</p>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.__rescale","title":"<code>__rescale(scale)</code>","text":"<p>Create a new polygon that is scaled up or down.</p> <p>The rescale method compute the vector that is directed from the polygon center to each point. Then it rescales each vector and use the head point of each vector to compose the new scaled polygon.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>float value to scale the polygon</p> required <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>scaled polygon</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def __rescale(self, scale: float) -&gt; Polygon:\n    \"\"\"Create a new polygon that is scaled up or down.\n\n    The rescale method compute the vector that is directed from the polygon center\n    to each point. Then it rescales each vector and use the head point of each\n    vector to compose the new scaled polygon.\n\n    Args:\n        scale (float): float value to scale the polygon\n\n    Returns:\n        Polygon: scaled polygon\n    \"\"\"\n    if scale == 1.0:  # no rescaling\n        return self\n\n    center = self.centroid\n    self.asarray = self.asarray.astype(float)\n    for i, point in enumerate(self.asarray):\n        self.asarray[i] = Vector([center, point]).rescale_head(scale).head\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.add_vertice","title":"<code>add_vertice(point, index)</code>","text":"<p>Add a point at a given index in the Polygon object</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>point to be added</p> required <code>index</code> <code>int</code> <p>index where the point will be added</p> required <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Self</code> <p>Polygon object with an added point</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def add_vertice(self, point: NDArray, index: int) -&gt; Self:\n    \"\"\"Add a point at a given index in the Polygon object\n\n    Args:\n        point (NDArray): point to be added\n        index (int): index where the point will be added\n\n    Returns:\n        Polygon: Polygon object with an added point\n    \"\"\"\n    size = len(self)\n    if index &gt;= size:\n        raise ValueError(\n            f\"The index value {index} is too big. \"\n            f\"The maximum possible index value is {size-1}.\"\n        )\n    if index &lt; 0:\n        if abs(index) &gt; size + 1:\n            raise ValueError(\n                f\"The index value {index} is too small. \"\n                f\"The minimum possible index value is {-(size+1)}\"\n            )\n        index = size + index + 1\n\n    self.points = np.concatenate(\n        [self.points[:index], [point], self.points[index:]]\n    )\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.as_linear_spline","title":"<code>as_linear_spline(index=0)</code>","text":"<p>Get the polygon as a LinearSpline object. This simply means a LinearSpline object with the same points as the Polygon but with an extra point: the one at the index.</p> <p>Returns:</p> Name Type Description <code>LinearSpline</code> <code>LinearSpline</code> <p>linear spline from polygon</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def as_linear_spline(self, index: int = 0) -&gt; LinearSpline:\n    \"\"\"Get the polygon as a LinearSpline object.\n    This simply means a LinearSpline object with the same points as the Polygon\n    but with an extra point: the one at the index.\n\n    Returns:\n        LinearSpline: linear spline from polygon\n    \"\"\"\n    if index &lt; 0:\n        index += len(self)\n\n    index = index % len(self)\n\n    return LinearSpline(\n        points=np.concat(\n            [self.asarray[index : len(self)], self.asarray[0 : index + 1]], axis=0\n        )\n    )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.contains","title":"<code>contains(other, dilate_scale=1)</code>","text":"<p>Whether the geometry contains the other or not</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>GeometryEntity</code> <p>a GeometryEntity object</p> required <code>dilate_scale</code> <code>float</code> <p>if greater than 1, the object will be scaled up before checking if it contains the other Geometry Entity. Can not be a value less than 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the entity contains the other</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def contains(self, other: GeometryEntity, dilate_scale: float = 1) -&gt; bool:\n    \"\"\"Whether the geometry contains the other or not\n\n    Args:\n        other (GeometryEntity): a GeometryEntity object\n        dilate_scale (float): if greater than 1, the object will be scaled up\n            before checking if it contains the other Geometry Entity. Can not be\n            a value less than 1.\n\n    Returns:\n        bool: True if the entity contains the other\n    \"\"\"\n    if dilate_scale != 1:\n        surface = self.copy().expand(scale=dilate_scale).shapely_surface\n    else:\n        surface = self.shapely_surface\n    return surface.contains(other.shapely_surface)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.expand","title":"<code>expand(scale)</code>","text":"<p>Stretch, dilate or expand a polygon</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>scale expanding factor. Must be greater than 1.</p> required <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>new bigger polygon</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def expand(self, scale: float) -&gt; Polygon:\n    \"\"\"Stretch, dilate or expand a polygon\n\n    Args:\n        scale (float): scale expanding factor. Must be greater than 1.\n\n    Returns:\n        Polygon: new bigger polygon\n    \"\"\"\n    if scale &lt; 1:\n        raise ValueError(\n            \"The scale value can not be less than 1 when expanding a polygon. \"\n            f\"Found {scale}\"\n        )\n    return self.__rescale(scale=scale)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.find_interpolated_point","title":"<code>find_interpolated_point(start_index, end_index, pct_dist)</code>","text":"<p>Return a point along the contour path from start_idx to end_idx (inclusive), at a relative distance pct_dist \u2208 [0, 1] along that path.</p> <p>By convention, if start_index == end_index, then use the whole contour start at this index position.</p> <p>Parameters:</p> Name Type Description Default <code>start_index</code> <code>int</code> <p>Index of the start point in the contour</p> required <code>end_index</code> <code>int</code> <p>Index of the end point in the contour</p> required <code>pct_dist</code> <code>float</code> <p>Value in [0, 1], 0 returns start, 1 returns end. Any value in [0, 1] returns a point between start and end that is pct_dist along the path.</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>Interpolated point [x, y]</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def find_interpolated_point(\n    self, start_index: int, end_index: int, pct_dist: float\n) -&gt; NDArray:\n    \"\"\"Return a point along the contour path from start_idx to end_idx (inclusive),\n    at a relative distance pct_dist \u2208 [0, 1] along that path.\n\n    By convention, if start_index == end_index, then use the whole contour\n    start at this index position.\n\n    Parameters:\n        start_index (int): Index of the start point in the contour\n        end_index (int): Index of the end point in the contour\n        pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n            Any value in [0, 1] returns a point between start and end that is\n            pct_dist along the path.\n\n    Returns:\n        NDArray: Interpolated point [x, y]\n    \"\"\"\n    return self.find_interpolated_point_and_prev_ix(\n        start_index=start_index, end_index=end_index, pct_dist=pct_dist\n    )[0]\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.find_interpolated_point_and_prev_ix","title":"<code>find_interpolated_point_and_prev_ix(start_index, end_index, pct_dist)</code>","text":"<p>Return a point along the contour path from start_idx to end_idx (inclusive), at a relative distance pct_dist \u2208 [0, 1] along that path.</p> <p>By convention, if start_index == end_index, then use the whole contour start at this index position.</p> <p>Parameters:</p> Name Type Description Default <code>start_index</code> <code>int</code> <p>Index of the start point in the contour</p> required <code>end_index</code> <code>int</code> <p>Index of the end point in the contour</p> required <code>pct_dist</code> <code>float</code> <p>Value in [0, 1], 0 returns start, 1 returns end. Any value in [0, 1] returns a point between start and end that is pct_dist along the path.</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>tuple[NDArray, int]</code> <p>Interpolated point [x, y]</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def find_interpolated_point_and_prev_ix(\n    self, start_index: int, end_index: int, pct_dist: float\n) -&gt; tuple[NDArray, int]:\n    \"\"\"Return a point along the contour path from start_idx to end_idx (inclusive),\n    at a relative distance pct_dist \u2208 [0, 1] along that path.\n\n    By convention, if start_index == end_index, then use the whole contour\n    start at this index position.\n\n    Parameters:\n        start_index (int): Index of the start point in the contour\n        end_index (int): Index of the end point in the contour\n        pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n            Any value in [0, 1] returns a point between start and end that is\n            pct_dist along the path.\n\n    Returns:\n        NDArray: Interpolated point [x, y]\n    \"\"\"\n    if not 0 &lt;= pct_dist &lt;= 1:\n        raise ValueError(\"pct_dist must be in [0, 1]\")\n\n    if start_index &lt; 0:\n        start_index += len(self)\n    if end_index &lt; 0:\n        end_index += len(self)\n\n    start_index = start_index % len(self)\n    end_index = end_index % len(self)\n\n    path = LinearSpline(\n        points=self.find_vertices_between(\n            start_index=start_index, end_index=end_index\n        )\n    )\n\n    point, index = path.find_interpolated_point_and_prev_ix(pct_dist=pct_dist)\n    index = (index + start_index) % len(self)\n\n    return point, index\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.find_vertices_between","title":"<code>find_vertices_between(start_index, end_index)</code>","text":"<p>Get the vertices between two indices.</p> <p>Returns always the vertices between start_index and end_index using the natural order of the vertices in the contour.</p> <p>By convention, if start_index == end_index, then it returns the whole contour plus the vertice at start_index.</p> <p>Parameters:</p> Name Type Description Default <code>start_index</code> <code>int</code> <p>index of the first vertex</p> required <code>end_index</code> <code>int</code> <p>index of the last vertex</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>array of vertices</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def find_vertices_between(self, start_index: int, end_index: int) -&gt; NDArray:\n    \"\"\"Get the vertices between two indices.\n\n    Returns always the vertices between start_index and end_index using the\n    natural order of the vertices in the contour.\n\n    By convention, if start_index == end_index, then it returns the whole contour\n    plus the vertice at start_index.\n\n    Args:\n        start_index (int): index of the first vertex\n        end_index (int): index of the last vertex\n\n    Returns:\n        NDArray: array of vertices\n    \"\"\"\n    if start_index &lt; 0:\n        start_index += len(self)\n    if end_index &lt; 0:\n        end_index += len(self)\n\n    start_index = start_index % len(self)\n    end_index = end_index % len(self)\n\n    if start_index &gt; end_index:\n        vertices = np.concat(\n            [\n                self.asarray[start_index : len(self)],\n                self.asarray[0 : end_index + 1],\n            ],\n            axis=0,\n        )\n    elif start_index == end_index:\n        vertices = self.as_linear_spline(index=start_index).asarray\n    else:\n        vertices = self.asarray[start_index : end_index + 1]\n\n    return vertices\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.from_linear_entities","title":"<code>from_linear_entities(linear_entities)</code>  <code>classmethod</code>","text":"<p>Convert a list of linear entities to polygon.</p> <p>Beware: the method assumes entities are sorted and connected.</p> <p>Parameters:</p> Name Type Description Default <code>linear_entities</code> <code>Sequence[LinearEntity]</code> <p>List of linear entities.</p> required <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>polygon representation of the linear entity</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>@classmethod\ndef from_linear_entities(\n    cls,\n    linear_entities: Sequence[LinearEntity],\n) -&gt; Polygon:\n    \"\"\"Convert a list of linear entities to polygon.\n\n    Beware: the method assumes entities are sorted and connected.\n\n    Args:\n        linear_entities (Sequence[LinearEntity]): List of linear entities.\n\n    Returns:\n        Polygon: polygon representation of the linear entity\n    \"\"\"\n    return cls.from_linear_entities_returns_vertices_ix(linear_entities)[0]\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.from_linear_entities_returns_vertices_ix","title":"<code>from_linear_entities_returns_vertices_ix(linear_entities)</code>  <code>classmethod</code>","text":"<p>Convert a list of linear entities to polygon.</p> <p>Beware: this method assumes entities are sorted and connected. Conneted means that the last point of each entity is the first point of the next entity. This implies that the polygon is necessarily closed.</p> <p>Parameters:</p> Name Type Description Default <code>linear_entities</code> <code>Sequence[LinearEntity]</code> <p>List of linear entities.</p> required <p>Returns:</p> Type Description <code>(Polygon, list[int])</code> <p>polygon and indices of first vertex of each entity</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>@classmethod\ndef from_linear_entities_returns_vertices_ix(\n    cls, linear_entities: Sequence[LinearEntity]\n) -&gt; tuple[Polygon, list[int]]:\n    \"\"\"Convert a list of linear entities to polygon.\n\n    Beware: this method assumes entities are sorted and connected.\n    Conneted means that the last point of each entity is the first point\n    of the next entity.\n    This implies that the polygon is necessarily closed.\n\n    Args:\n        linear_entities (Sequence[LinearEntity]): List of linear entities.\n\n    Returns:\n        (Polygon, list[int]): polygon and indices of first vertex of each entity\n    \"\"\"\n    points = []\n    vertices_ix: list[int] = []\n    current_ix = 0\n    for i, linear_entity in enumerate(linear_entities):\n        if not isinstance(linear_entity, LinearEntity):\n            raise TypeError(\n                f\"Expected a list of LinearEntity, but got {type(linear_entity)}\"\n            )\n\n        cond_first_pt_is_equal_prev_entity_last_pt = np.array_equal(\n            linear_entity.points[0], linear_entities[i - 1].points[-1]\n        )\n        if not cond_first_pt_is_equal_prev_entity_last_pt:\n            raise ValueError(\n                f\"The first point of entity {i} ({linear_entity.points[0]}) \"\n                f\"is not equal to the last point of entity {i-1} \"\n                f\"({linear_entities[i-1].points[-1]})\"\n            )\n        pts_except_last = linear_entity.points[:-1, :]\n        points.append(pts_except_last)\n        vertices_ix.append(current_ix)\n        current_ix += len(pts_except_last)\n\n    points = np.concatenate(points, axis=0)\n    polygon = Polygon(points=points)\n    return polygon, vertices_ix\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.from_lines","title":"<code>from_lines(lines)</code>  <code>classmethod</code>","text":"<p>The lines should describe a perfect closed shape polygon</p> <p>Parameters:</p> Name Type Description Default <code>lines</code> <code>NDArray</code> <p>array of lines of shape (n, 2, 2)</p> required <p>Returns:</p> Type Description <code>Polygon</code> <p>a Polygon object</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>@classmethod\ndef from_lines(cls, lines: NDArray) -&gt; Polygon:\n    \"\"\"The lines should describe a perfect closed shape polygon\n\n    Args:\n        lines (NDArray): array of lines of shape (n, 2, 2)\n\n    Returns:\n        (Polygon): a Polygon object\n    \"\"\"\n    nlines = len(lines)\n    shifted_lines = np.roll(\n        np.array(lines).reshape(nlines * 2, 2), shift=1, axis=0\n    ).reshape(nlines, 2, 2)\n    distances = np.linalg.norm(np.diff(shifted_lines, axis=1), axis=2)\n    if np.any(distances):  # a distance is different from 0\n        bad_idxs = np.nonzero(distances &gt; 0)\n        raise ValueError(\n            f\"Could not construct the polygon from the given lines.\"\n            f\"Please check at those indices: {bad_idxs}\"\n        )\n    points = lines[:, 0]\n    return Polygon(points=points)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.from_unordered_lines_approx","title":"<code>from_unordered_lines_approx(lines, max_dist_thresh=50, max_iterations=50, start_line_index=0)</code>  <code>classmethod</code>","text":"<p>Create a Polygon object from an unordered list of lines that approximate a closed-shape. They approximate in the sense that they do not necessarily share common points. This method computes the intersection points between lines.</p> <p>Parameters:</p> Name Type Description Default <code>lines</code> <code>NDArray</code> <p>array of lines of shape (n, 2, 2)</p> required <code>max_dist_thresh</code> <code>float</code> <p>For any given point, the maximum distance to consider two points as close. Defaults to 50.</p> <code>50</code> <code>max_iterations</code> <code>float</code> <p>Maximum number of iterations before finding a polygon. It defines also the maximum number of lines in the polygon to be found.</p> <code>50</code> <code>start_line_index</code> <code>int</code> <p>The starting line to find searching for the polygon. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>Polygon</code> <p>a Polygon object</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>@classmethod\ndef from_unordered_lines_approx(\n    cls,\n    lines: NDArray,\n    max_dist_thresh: float = 50,\n    max_iterations: int = 50,\n    start_line_index: int = 0,\n) -&gt; Polygon:\n    \"\"\"Create a Polygon object from an unordered list of lines that approximate a\n    closed-shape. They approximate in the sense that they do not necessarily\n    share common points. This method computes the intersection points between lines.\n\n    Args:\n        lines (NDArray): array of lines of shape (n, 2, 2)\n        max_dist_thresh (float, optional): For any given point,\n            the maximum distance to consider two points as close. Defaults to 50.\n        max_iterations (float, optional): Maximum number of iterations before\n            finding a polygon.\n            It defines also the maximum number of lines in the polygon to be found.\n        start_line_index (int, optional): The starting line to find searching for\n            the polygon. Defaults to 0.\n\n    Returns:\n        (Polygon): a Polygon object\n    \"\"\"\n    # pylint: disable=too-many-locals\n    # pylint: disable=too-many-positional-arguments, too-many-arguments\n    lines = np.asarray(lines)\n    assert_list_of_lines(lines=lines)\n\n    _lines = copy.deepcopy(lines)\n    list_build_cnt = []\n    is_polygon_found = False\n    idx_seg_closest = start_line_index\n    i = 0\n    while not is_polygon_found and i &lt; max_iterations:\n        curseg = Segment(_lines[idx_seg_closest])\n        curpoint = curseg.asarray[1]\n        list_build_cnt.append(curseg.asarray)\n        _lines = np.delete(_lines, idx_seg_closest, axis=0)\n\n        if len(_lines) == 0:\n            logging.debug(\"No more lines to be processed.\")\n\n        # find the closest point to the current one and associated line\n        lines2points = _lines.reshape(len(_lines) * 2, 2)\n        dist_from_curpoint = np.linalg.norm(lines2points - curpoint, axis=1)\n        idx_closest_points = np.nonzero(dist_from_curpoint &lt; max_dist_thresh)[0]\n\n        if len(idx_closest_points) &gt; 1:\n            # more than one point close to the current point - take the closest\n            idx_closest_points = np.array([np.argmin(dist_from_curpoint)])\n        if len(idx_closest_points) == 0:\n            # no point detected - can mean that the polygon is done or not\n            first_seg = Segment(list_build_cnt[0])\n            if np.linalg.norm(first_seg.asarray[0] - curpoint) &lt; max_dist_thresh:\n                intersect_point = curseg.intersection_line(first_seg)\n                list_build_cnt[-1][1] = intersect_point\n                list_build_cnt[0][0] = intersect_point\n                is_polygon_found = True\n                break\n            raise RuntimeError(\"No point detected close to the current point\")\n\n        # only one closest point - get indices of unique closest point on segment\n        idx_point_closest = int(idx_closest_points[0])\n        idx_seg_closest = int(np.floor(idx_point_closest / 2))\n\n        # arrange the line so that the closest point is in the first place\n        idx_point_in_line = 0 if (idx_point_closest / 2).is_integer() else 1\n        seg_closest = _lines[idx_seg_closest]\n        if idx_point_in_line == 1:  # flip points positions\n            seg_closest = np.flip(seg_closest, axis=0)\n        _lines[idx_seg_closest] = seg_closest\n\n        # find intersection point between the two lines\n        intersect_point = curseg.intersection_line(Segment(seg_closest))\n\n        # update arrays with the intersection point\n        _lines[idx_seg_closest][0] = intersect_point\n        list_build_cnt[i][1] = intersect_point\n\n        i += 1\n\n    cnt = Polygon.from_lines(np.array(list_build_cnt, dtype=np.int32))\n    return cnt\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.inter_area","title":"<code>inter_area(other)</code>","text":"<p>Inter area with another Polygon</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Polygon</code> <p>other Polygon</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>inter area value</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def inter_area(self, other: Polygon) -&gt; float:\n    \"\"\"Inter area with another Polygon\n\n    Args:\n        other (Polygon): other Polygon\n\n    Returns:\n        float: inter area value\n    \"\"\"\n    inter_pts = cv2.intersectConvexConvex(self.asarray, other.asarray)\n    if inter_pts[0] &gt; 0:\n        inter_area = cv2.contourArea(inter_pts[1])\n    else:\n        inter_area = 0.0\n    return inter_area\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.iou","title":"<code>iou(other)</code>","text":"<p>Intersection over union with another Polygon</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Polygon</code> <p>other Polygon</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>intersection over union value</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def iou(self, other: Polygon) -&gt; float:\n    \"\"\"Intersection over union with another Polygon\n\n    Args:\n        other (Polygon): other Polygon\n\n    Returns:\n        float: intersection over union value\n    \"\"\"\n    inter_area = self.inter_area(other)\n\n    # optimized not to compute twice the inter area\n    union_area = self.area + other.area - inter_area\n\n    if union_area == 0:\n        return 0.0\n    return inter_area / union_area\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.is_clockwise","title":"<code>is_clockwise(is_y_axis_down=False)</code>","text":"<p>Determine if a polygon points go clockwise using the Shoelace formula.</p> <p>True if polygon vertices order is clockwise in the \"y-axis points up\" referential.</p> <p>Parameters:</p> Name Type Description Default <code>is_y_axis_down</code> <code>bool</code> <p>If is_y_axis_down is True, then the image referential is used where y axis points down.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if clockwise, False if counter-clockwise</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def is_clockwise(self, is_y_axis_down: bool = False) -&gt; bool:\n    \"\"\"Determine if a polygon points go clockwise using the Shoelace formula.\n\n    True if polygon vertices order is clockwise in the \"y-axis points up\"\n    referential.\n\n    Args:\n        is_y_axis_down (bool, optional): If is_y_axis_down is True, then the image\n            referential is used where y axis points down.\n\n    Returns:\n        bool: True if clockwise, False if counter-clockwise\n    \"\"\"\n    x = self.asarray[:, 0]\n    y = self.asarray[:, 1]\n\n    x_next = np.roll(x, -1)\n    y_next = np.roll(y, -1)\n\n    s = np.sum((x_next - x) * (y_next + y))\n\n    is_clockwise = bool(s &gt; 0)  # Clockwise if positive (OpenCV's convention)\n\n    if is_y_axis_down:  # in referential where y axis points down\n        return not is_clockwise\n\n    return is_clockwise\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.is_equal","title":"<code>is_equal(polygon, dist_margin_error=5)</code>","text":"<p>Check whether two polygons objects are equal by considering a margin of error based on a distance between points.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Polygon object</p> required <code>dist_margin_error</code> <code>float</code> <p>distance margin of error. Defaults to 5.</p> <code>5</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the polygon are equal, False otherwise</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def is_equal(self, polygon: Polygon, dist_margin_error: float = 5) -&gt; bool:\n    \"\"\"Check whether two polygons objects are equal by considering a margin of\n    error based on a distance between points.\n\n    Args:\n        polygon (Polygon): Polygon object\n        dist_margin_error (float, optional): distance margin of error.\n            Defaults to 5.\n\n    Returns:\n        bool: True if the polygon are equal, False otherwise\n    \"\"\"\n    if self.n_points != polygon.n_points:\n        # if polygons do not have the same number of points they can not be similar\n        return False\n\n    # check if each points composing the polygons are close to each other\n    new_cnt = polygon.copy().rearrange_first_vertice_closest_to_point(\n        self.points[0]\n    )\n    points_diff = new_cnt.points - self.points\n    distances = np.linalg.norm(points_diff, axis=1)\n    max_distance = np.max(distances)\n    return max_distance &lt;= dist_margin_error\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.is_regular","title":"<code>is_regular(margin_dist_error_pct=0.01)</code>","text":"<p>Identifies whether the polygon is regular, this means is rectangular or is a square.</p> <p>Parameters:</p> Name Type Description Default <code>margin_dist_error_pct</code> <code>float</code> <p>margin for a distance error. The percentage is multiplied by the square root of the product of the diagonals. Defaults to 1e-2.</p> <code>0.01</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the polygon describes a rectangle or square.</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def is_regular(self, margin_dist_error_pct: float = 1e-2) -&gt; bool:\n    \"\"\"Identifies whether the polygon is regular, this means is rectangular or is\n    a square.\n\n    Args:\n        margin_dist_error_pct (float, optional): margin for a distance error.\n            The percentage is multiplied by the square root of the product of\n            the diagonals. Defaults to 1e-2.\n\n    Returns:\n        bool: True if the polygon describes a rectangle or square.\n    \"\"\"\n    # check we have four points\n    if len(self.asarray) != 4:\n        return False\n\n    # compute diagonal 1 = taking reference index as 1st point in list - index 0\n    refpoint = self.asarray[0]\n    idx_max_dist = self.find_vertice_ix_farthest_from(point=refpoint)\n    farther_point = self.asarray[idx_max_dist]\n    diag1 = Segment(points=[refpoint, farther_point])\n\n    # compute diagonal 2\n    diag2_idxs = [1, 2, 3]  # every index except 0\n    diag2_idxs.remove(idx_max_dist)  # delete index of point in first diag\n    diag2 = Segment(points=self.asarray[diag2_idxs])\n\n    # rectangular criteria = the diagonals have same lengths\n    normed_length = np.sqrt(diag1.length * diag2.length)\n    if np.abs(diag1.length - diag2.length) &gt; normed_length * margin_dist_error_pct:\n        return False\n\n    # there should exist only one intersection point\n    intersection_points = diag1.intersection(other=diag2)\n    if len(intersection_points) != 1:\n        return False\n\n    # diagonals bisect on the center of both diagonal\n    cross_point = intersection_points[0]\n    dist_mid_cross_diag1 = np.linalg.norm(cross_point - diag1.centroid)\n    dist_mid_cross_diag2 = np.linalg.norm(cross_point - diag2.centroid)\n    if (\n        np.abs(dist_mid_cross_diag1) &gt; normed_length * margin_dist_error_pct\n        or np.abs(dist_mid_cross_diag2) &gt; normed_length * margin_dist_error_pct\n    ):\n        return False\n\n    return True\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.normal_point","title":"<code>normal_point(start_index, end_index, dist_along_edge_pct, dist_from_edge, is_outward=True)</code>","text":"<p>Compute the outward normal point. This is a point that points toward the outside of the polygon</p> <p>Parameters:</p> Name Type Description Default <code>start_index</code> <code>int</code> <p>start index for the edge selection</p> required <code>end_index</code> <code>int</code> <p>end index for the edge selection</p> required <code>dist_along_edge_pct</code> <code>float</code> <p>distance along the edge to place the point</p> required <code>dist_from_edge</code> <code>float</code> <p>distance outward from the edge</p> required <code>is_outward</code> <code>bool</code> <p>True if the normal points to the outside of the polygon. False if the normal points to the inside of the polygon. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>2D point as array</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def normal_point(\n    self,\n    start_index: int,\n    end_index: int,\n    dist_along_edge_pct: float,\n    dist_from_edge: float,\n    is_outward: bool = True,\n) -&gt; NDArray:\n    \"\"\"Compute the outward normal point.\n    This is a point that points toward the outside of the polygon\n\n    Args:\n        start_index (int): start index for the edge selection\n        end_index (int): end index for the edge selection\n        dist_along_edge_pct (float): distance along the edge to place the point\n        dist_from_edge (float): distance outward from the edge\n        is_outward (bool, optional): True if the normal points to the outside of\n            the polygon. False if the normal points to the inside of the polygon.\n            Defaults to True.\n\n    Returns:\n        NDArray: 2D point as array\n    \"\"\"\n    # pylint: disable=too-many-locals\n    # pylint: disable=too-many-arguments, too-many-positional-arguments,\n    if not 0.0 &lt;= dist_along_edge_pct &lt;= 1.0:\n        raise ValueError(\"dist_along_edge_pct must be in [0, 1]\")\n\n    pt_interpolated, prev_ix = self.find_interpolated_point_and_prev_ix(\n        start_index=start_index, end_index=end_index, pct_dist=dist_along_edge_pct\n    )\n    next_ix = (prev_ix + 1) % len(self)\n\n    is_interpolated_pt_existing_edge = np.array_equal(\n        pt_interpolated, self.asarray[prev_ix]\n    ) or np.array_equal(pt_interpolated, self.asarray[next_ix])\n    if is_interpolated_pt_existing_edge:\n        raise ValueError(\n            \"Interpolated point for normal computation is an existing vertice \"\n            \"along polygon. Please choose another dist_along_edge_pct parameter.\"\n        )\n\n    edge = Vector(points=[self.asarray[prev_ix], self.asarray[next_ix]])\n\n    normal = edge.normal().normalized\n\n    pt_plus = pt_interpolated + dist_from_edge * normal\n    pt_minus = pt_interpolated - dist_from_edge * normal\n\n    dist_plus = np.linalg.norm(pt_plus - self.centroid)\n    dist_minus = np.linalg.norm(pt_minus - self.centroid)\n\n    # choose the point which distance to the center is greater\n    if dist_plus &gt; dist_minus:\n        if is_outward:\n            return pt_plus\n        return pt_minus\n\n    if is_outward:\n        return pt_minus\n    return pt_plus\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.rearrange_first_vertice_at_index","title":"<code>rearrange_first_vertice_at_index(index)</code>","text":"<p>Rearrange the list of points that defines the Polygon so that the first point in the list of points is the one at index given by the argument of this function.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>index value</p> required <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Self</code> <p>Polygon which is the exact same one but with a rearranged list of points.</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def rearrange_first_vertice_at_index(self, index: int) -&gt; Self:\n    \"\"\"Rearrange the list of points that defines the Polygon so that the first\n    point in the list of points is the one at index given by the argument of this\n    function.\n\n    Args:\n        index (int): index value\n\n    Returns:\n        Polygon: Polygon which is the exact same one but with a rearranged list\n            of points.\n    \"\"\"\n    size = len(self)\n    if index &gt;= size:\n        raise ValueError(\n            f\"The index value {index} is too big. \"\n            f\"The maximum possible index value is {size-1}.\"\n        )\n    if index &lt; 0:\n        if abs(index) &gt; size:\n            raise ValueError(\n                f\"The index value {index} is too small. \"\n                f\"The minimum possible index value is {-size}\"\n            )\n        index = size + index\n\n    self.points = np.concatenate([self.points[index:], self.points[:index]])\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.rearrange_first_vertice_closest_to_point","title":"<code>rearrange_first_vertice_closest_to_point(point=np.zeros(shape=(2,)))</code>","text":"<p>Rearrange the list of vertices that defines the Polygon so that the first point in the list of vertices is the one that is the closest by distance to the reference point.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>point that is taken as a reference in the space to find the one in the Polygon list of points that is the closest to this reference point. Default to origin point [0, 0].</p> <code>zeros(shape=(2,))</code> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>Polygon which is the exact same one but with a rearranged list of points.</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def rearrange_first_vertice_closest_to_point(\n    self, point: NDArray = np.zeros(shape=(2,))\n) -&gt; Polygon:\n    \"\"\"Rearrange the list of vertices that defines the Polygon so that the first\n    point in the list of vertices is the one that is the closest by distance to\n    the reference point.\n\n    Args:\n        point (NDArray): point that is taken as a reference in the\n            space to find the one in the Polygon list of points that is the\n            closest to this reference point. Default to origin point [0, 0].\n\n    Returns:\n        Polygon: Polygon which is the exact same one but with a rearranged list\n            of points.\n    \"\"\"\n    idx_min_dist = self.find_vertice_ix_closest_from(point=point)\n    return self.rearrange_first_vertice_at_index(index=idx_min_dist)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.reorder_clockwise","title":"<code>reorder_clockwise(is_y_axis_down=False)</code>","text":"<p>Reorder the vertices of the polygon in clockwise order where the first point stays the same.</p> <p>Parameters:</p> Name Type Description Default <code>is_y_axis_down</code> <code>bool</code> <p>True if cv2 is used. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>reordered polygon</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def reorder_clockwise(self, is_y_axis_down: bool = False) -&gt; Polygon:\n    \"\"\"Reorder the vertices of the polygon in clockwise order where the first point\n    stays the same.\n\n    Args:\n        is_y_axis_down (bool, optional): True if cv2 is used. Defaults to False.\n\n    Returns:\n        Polygon: reordered polygon\n    \"\"\"\n    if self.is_clockwise(is_y_axis_down=is_y_axis_down):\n        return self\n    self.asarray = np.roll(self.asarray[::-1], shift=1, axis=0)\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.score_vertices_in_points","title":"<code>score_vertices_in_points(points, max_distance)</code>","text":"<p>Returns a score of 0 or 1 for each point in the polygon if it is close enough to any point in the input points.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>NDArray</code> <p>list of 2D points</p> required <code>max_distance</code> <code>float</code> <p>maximum distance to consider two points as close enough to be considered as the same points</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>a list of score for each point in the contour</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def score_vertices_in_points(self, points: NDArray, max_distance: float) -&gt; NDArray:\n    \"\"\"Returns a score of 0 or 1 for each point in the polygon if it is close\n    enough to any point in the input points.\n\n    Args:\n        points (NDArray): list of 2D points\n        max_distance (float): maximum distance to consider two points as\n            close enough to be considered as the same points\n\n    Returns:\n        NDArray: a list of score for each point in the contour\n    \"\"\"\n\n    indices = get_shared_point_indices(\n        points_to_check=self.asarray,\n        checkpoints=points,\n        margin_dist_error=max_distance,\n        method=\"close\",\n        cond=\"any\",\n    )\n    score = np.bincount(indices, minlength=len(self))\n    return score\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.shrink","title":"<code>shrink(scale)</code>","text":"<p>Contract or shrink a polygon</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>scale shrinking factor. Must be greater than 1.</p> required <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>new bigger polygon</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def shrink(self, scale: float) -&gt; Polygon:\n    \"\"\"Contract or shrink a polygon\n\n    Args:\n        scale (float): scale shrinking factor. Must be greater than 1.\n\n    Returns:\n        Polygon: new bigger polygon\n    \"\"\"\n    if scale &lt; 1:\n        raise ValueError(\n            \"The scale value can not be less than 1 when shrinking a polygon. \"\n            f\"Found {scale}\"\n        )\n    return self.__rescale(scale=1 / scale)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.to_image_crop_referential","title":"<code>to_image_crop_referential(other, crop, image_crop_shape=None)</code>","text":"<p>This function can be useful for a very specific need: In a single image you have two same polygons and their coordinates are defined in this image referential.</p> <p>You want to obtain the original polygon and all its vertices information in the image crop referential to match the other polygon within it.</p> <p>This method manipulates three referentials: 1. image referential (main referential) 2. crop referential 3. image crop referential. It is different from the crop referential     because the width and height of the crop referential may not be the same.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Polygon</code> <p>other Polygon in the image referential</p> required <code>crop</code> <code>Rectangle</code> <p>crop rectangle in the image referential</p> required <code>image_crop_shape</code> <code>(tuple[int, int], optionla)</code> <p>[width, height] of the crop image. If None, the shape is assumed to be directly the crop shape.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>original polygon in the image crop referential</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def to_image_crop_referential(\n    self,\n    other: Polygon,\n    crop: Rectangle,\n    image_crop_shape: Optional[tuple[int, int]] = None,\n) -&gt; Polygon:\n    \"\"\"This function can be useful for a very specific need:\n    In a single image you have two same polygons and their coordinates are defined\n    in this image referential.\n\n    You want to obtain the original polygon and all its vertices information\n    in the image crop referential to match the other polygon within it.\n\n    This method manipulates three referentials:\n    1. image referential (main referential)\n    2. crop referential\n    3. image crop referential. It is different from the crop referential\n        because the width and height of the crop referential may not be the same.\n\n    Args:\n        other (Polygon): other Polygon in the image referential\n        crop (Rectangle): crop rectangle in the image referential\n        image_crop_shape (tuple[int, int], optionla): [width, height] of the crop\n            image. If None, the shape is assumed to be directly the crop shape.\n\n\n    Returns:\n        Polygon: original polygon in the image crop referential\n    \"\"\"\n    if not crop.contains(other=other):\n        raise ValueError(\n            f\"The crop rectangle {crop} does not contain the other polygon {other}\"\n        )\n    crop_width = int(crop.get_width_from_topleft(0))\n    crop_height = int(crop.get_height_from_topleft(0))\n\n    if image_crop_shape is None:\n        image_crop_shape = (crop_width, crop_height)\n\n    # self polygon in the original image shifted and normalized\n    aabb_main = self.enclosing_axis_aligned_bbox()\n    contour_main_shifted_normalized = self.copy().shift(\n        vector=-np.asarray([self.xmin, self.ymin])\n    ) / np.array([aabb_main.width, aabb_main.height])\n\n    # AABB of the polygon in the crop referential\n    aabb_crop = other.enclosing_axis_aligned_bbox()\n    aabb_crop_normalized = (\n        aabb_crop - np.asarray([crop.xmin, crop.ymin])\n    ) / np.array([crop_width, crop_height])\n\n    # obtain the self polygon in the image crop referential\n    aabb_crop2 = aabb_crop_normalized * np.array(image_crop_shape)\n    new_polygon = contour_main_shifted_normalized * np.array(\n        [\n            aabb_crop2.get_width_from_topleft(0),\n            aabb_crop2.get_height_from_topleft(0),\n        ]\n    ) + np.asarray([aabb_crop2.xmin, aabb_crop2.ymin])\n\n    return new_polygon\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.polygon.Polygon.union_area","title":"<code>union_area(other)</code>","text":"<p>Union area with another Polygon</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Polygon</code> <p>other Polygon</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>union area value</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def union_area(self, other: Polygon) -&gt; float:\n    \"\"\"Union area with another Polygon\n\n    Args:\n        other (Polygon): other Polygon\n\n    Returns:\n        float: union area value\n    \"\"\"\n    return self.area + other.area - self.inter_area(other)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle","title":"<code>Rectangle</code>","text":"<p>               Bases: <code>Polygon</code></p> <p>Rectangle class to manipulate rectangle object</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>class Rectangle(Polygon):\n    \"\"\"Rectangle class to manipulate rectangle object\"\"\"\n\n    def __init__(\n        self,\n        points: NDArray | list,\n        is_cast_int: bool = False,\n        regularity_margin_error: float = 1e-2,\n        desintersect: bool = True,\n    ) -&gt; None:\n        \"\"\"Create a Rectangle object.\n\n        Args:\n            points (NDArray | list): 2D points that define the rectangle\n            is_cast_int (bool, optional): cast points to int. Defaults to False.\n            regularity_margin_error (float, optional): defines the allowed margin\n                distance error when checking if the points form a rectangle or not\n                on initialization.\n            desintersect (bool, optional): whether to desintersect the rectangle or not.\n                Can be useful if the input points are in a random order and\n                self-intersection is possible. In any case, if you try to instantiate\n                a self-intersected rectangle a ValueError will be raised.\n                Defaults to True.\n        \"\"\"\n        if len(points) != 4:\n            raise ValueError(\"Cannot create a Rectangle since it must have 4 points\")\n        super().__init__(points=points, is_cast_int=is_cast_int)\n\n        if desintersect:\n            self.desintersect()\n\n        if self.is_self_intersected:\n            raise ValueError(\n                \"The points form a self-intersected geometric object which is not \"\n                f\"allowed for a {self.__class__.__name__}\"\n            )\n\n        if not self.is_regular(margin_dist_error_pct=regularity_margin_error):\n            raise ValueError(\n                \"Try to create a Rectangle object but the coordinates \"\n                \"do not form a valid Rectangle. Please check your input coordinates, \"\n                \"the regularity_margin_error and the desintersect parameters.\"\n            )\n\n    @classmethod\n    def unit(cls) -&gt; Rectangle:\n        \"\"\"Create a unit Rectangle object\n\n        Returns:\n            Rectangle: new Rectangle object\n        \"\"\"\n        return cls(points=[[0, 0], [0, 1], [1, 1], [1, 0]])\n\n    @classmethod\n    def from_center(\n        cls,\n        center: NDArray,\n        width: float,\n        height: float,\n        is_cast_int: bool = False,\n    ) -&gt; Rectangle:\n        \"\"\"Create a Rectangle object using the center point, width, height.\n\n        Convention to create the rectangle is:\n            index 0: top left point\n            index 1: top right point\n            index 2: bottom right point\n            index 3: bottom left point\n\n        Args:\n            center (NDArray): center point of the rectangle\n            width (float): width of the rectangle\n            height (float): height of the rectangle\n            is_cast_int (bool, optional): cast the points coordinates to int\n\n        Returns:\n            Rectangle: Rectangle object\n        \"\"\"\n        # compute the halves lengths\n        half_width = width / 2\n        half_height = height / 2\n\n        # get center coordinates\n        center_x, center_y = center[0], center[1]\n\n        # get the rectangle coordinates\n        points = np.array(\n            [\n                [center_x - half_width, center_y - half_height],\n                [center_x + half_width, center_y - half_height],\n                [center_x + half_width, center_y + half_height],\n                [center_x - half_width, center_y + half_height],\n            ]\n        )\n\n        return Rectangle(points=points, is_cast_int=is_cast_int)\n\n    @classmethod\n    def from_topleft_bottomright(\n        cls,\n        topleft: NDArray,\n        bottomright: NDArray,\n        is_cast_int: bool = False,\n    ) -&gt; Self:\n        \"\"\"Create a Rectangle object using the top left and bottom right points.\n\n        Convention to create the rectangle is:\n            index 0: top left point\n            index 1: top right point\n            index 2: bottom right point\n            index 3: bottom left point\n\n        Args:\n            topleft (NDArray): top left point of the rectangle\n            bottomright (NDArray): bottom right point of the rectangle\n\n        Returns:\n            Rectangle: new Rectangle object\n        \"\"\"\n        topright_vertice = np.array([bottomright[0], topleft[1]])\n        bottomleft_vertice = np.array([topleft[0], bottomright[1]])\n        return cls(\n            np.asarray([topleft, topright_vertice, bottomright, bottomleft_vertice]),\n            is_cast_int=is_cast_int,\n        )\n\n    @classmethod\n    def from_topleft(\n        cls,\n        topleft: NDArray,\n        width: float,\n        height: float,\n        is_cast_int: bool = False,\n    ) -&gt; Self:\n        \"\"\"Create a Rectangle object using the top left point, width, height and angle.\n\n        Convention to create the rectangle is:\n            index 0: top left point\n            index 1: top right point\n            index 2: bottom right point\n            index 3: bottom left point\n\n        Args:\n            topleft (NDArray): top left point of the rectangle\n            width (float): width of the rectangle\n            height (float): height of the rectangle\n            is_cast_int (bool, optional): whether to cast int or not. Defaults to False.\n\n        Returns:\n            Rectangle: Rectangle object\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        bottomright_vertice = np.array([topleft[0] + width, topleft[1] + height])\n        return cls.from_topleft_bottomright(\n            topleft=topleft,\n            bottomright=bottomright_vertice,\n            is_cast_int=is_cast_int,\n        )\n\n    @property\n    def is_square(self) -&gt; bool:\n        \"\"\"Whether the rectangle is a square or not\n\n        Returns:\n            bool: True if the Rectangle is a Square\n        \"\"\"\n        if self.shortside_length == self.longside_length:\n            return True\n\n        return False\n\n    def is_axis_aligned_approx(self, precision: int = 3) -&gt; bool:\n        \"\"\"Check if the rectangle is axis-aligned\n\n        Args:\n            precision (int, optional): precision for the slope angle.\n                This define the number of decimals to consider for the angle\n                calculation of both the longside and shortside angle. Defaults to 3.\n\n        Returns:\n            bool: True if the rectangle is axis-aligned, False otherwise\n        \"\"\"\n\n        def is_mult_of_90_approx(x, precision: int) -&gt; bool:\n            return bool(round((x + 90 * 100), precision) % 90 == 0)\n\n        longside_cond = is_mult_of_90_approx(\n            self.longside_slope_angle(degree=True), precision=precision\n        )\n        shortside_cond = is_mult_of_90_approx(\n            self.shortside_slope_angle(degree=True), precision=precision\n        )\n        return longside_cond and shortside_cond\n\n    @property\n    def is_axis_aligned(self) -&gt; bool:\n        \"\"\"Check if the rectangle is exactly axis-aligned.\n        If you wish to check if a rectangle is only approximately axis-aligned,\n        use the `is_axis_aligned_approx` method.\n\n        Returns:\n            bool: True if the rectangle is exactly axis-aligned, False otherwise\n        \"\"\"\n        if self.points[0][1] != self.points[1][1]:  # top left y == top right y\n            return False\n        if self.points[1][0] != self.points[2][0]:  # top right x == bottom right x\n            return False\n        if self.points[2][1] != self.points[3][1]:  # bottom right y == bottom left y\n            return False\n        if self.points[3][0] != self.points[0][0]:  # bottom left x == top left x\n            return False\n        return True\n\n    @property\n    def longside_length(self) -&gt; float:\n        \"\"\"Compute the biggest side of the rectangle\n\n        Returns:\n            float: the biggest side length\n        \"\"\"\n        seg1 = self.segments[0]\n        seg2 = self.segments[1]\n        return seg1.length if seg1.length &gt; seg2.length else seg2.length\n\n    @property\n    def shortside_length(self) -&gt; float:\n        \"\"\"Compute the smallest side of the rectangle\n\n        Returns:\n            Segment: Longest side of the Rectangle as a Segment object\n        \"\"\"\n        seg1 = self.segments[0]\n        seg2 = self.segments[1]\n        return seg2.length if seg1.length &gt; seg2.length else seg1.length\n\n    def longside_slope_angle(\n        self, degree: bool = False, is_y_axis_down: bool = False\n    ) -&gt; float:\n        \"\"\"Compute the biggest slope of the rectangle\n\n        Returns:\n            float: the biggest slope\n        \"\"\"\n        seg1 = self.segments[0]\n        seg2 = self.segments[1]\n        seg_bigside = seg1 if seg1.length &gt; seg2.length else seg2\n        return seg_bigside.slope_angle(degree=degree, is_y_axis_down=is_y_axis_down)\n\n    def shortside_slope_angle(\n        self, degree: bool = False, is_y_axis_down: bool = False\n    ) -&gt; float:\n        \"\"\"Compute the smallest slope of the rectangle\n\n        Returns:\n            float: the smallest slope\n        \"\"\"\n        seg1 = self.segments[0]\n        seg2 = self.segments[1]\n        seg_smallside = seg2 if seg1.length &gt; seg2.length else seg1\n        return seg_smallside.slope_angle(degree=degree, is_y_axis_down=is_y_axis_down)\n\n    def desintersect(self) -&gt; Self:\n        \"\"\"Desintersect the rectangle if it is self-intersected.\n        If the rectangle is not self-intersected, returns the same rectangle.\n\n        Returns:\n            Rectangle: the desintersected Rectangle object\n        \"\"\"\n        if not self.is_self_intersected:\n            return self\n\n        # Sort points based on angle from centroid\n        def angle_from_center(pt):\n            return np.arctan2(pt[1] - self.centroid[1], pt[0] - self.centroid[0])\n\n        sorted_vertices = sorted(self.asarray, key=angle_from_center)\n        self.asarray = np.array(sorted_vertices)\n        return self\n\n    def join(\n        self, rect: Rectangle, margin_dist_error: float = 1e-5\n    ) -&gt; Optional[Rectangle]:\n        \"\"\"Join two rectangles into a single one.\n        If they share no point in common or only a single point returns None.\n        If they share two points, returns a new Rectangle that is the concatenation\n        of the two rectangles and that is not self-intersected.\n        If they share 3 or more points they represent the same rectangle, thus\n        returns this object.\n\n        Args:\n            rect (Rectangle): the other Rectangle object\n            margin_dist_error (float, optional): the threshold to consider whether the\n                rectangle share a common point. Defaults to 1e-5.\n\n        Returns:\n            Rectangle: the join new Rectangle object\n        \"\"\"\n        shared_points = self.find_shared_approx_vertices(rect, margin_dist_error)\n        n_shared_points = len(shared_points)\n\n        if n_shared_points in (0, 1):\n            return None\n        if n_shared_points == 2:\n            new_rect_points = np.concatenate(\n                (\n                    self.find_vertices_far_from(shared_points, margin_dist_error),\n                    rect.find_vertices_far_from(shared_points, margin_dist_error),\n                ),\n                axis=0,\n            )\n            return Rectangle(points=new_rect_points).desintersect()\n        # if 3 or more points in common it is the same rectangle\n        return self\n\n    def _topright_vertice_from_topleft(self, topleft_index: int) -&gt; NDArray:\n        \"\"\"Get the top-right vertice from the topleft vertice\n\n        Args:\n            topleft_index (int): index of the topleft vertice\n\n        Returns:\n            NDArray: topright vertice\n        \"\"\"\n        if self.is_clockwise(is_y_axis_down=True):\n            return self.asarray[(topleft_index + 1) % len(self)]\n        return self.asarray[topleft_index - 1]\n\n    def _bottomleft_vertice_from_topleft(self, topleft_index: int) -&gt; NDArray:\n        \"\"\"Get the bottom-left vertice from the topleft vertice\n\n        Args:\n            topleft_index (int): index of the topleft vertice\n\n        Returns:\n            NDArray: topright vertice\n        \"\"\"\n        if self.is_clockwise(is_y_axis_down=True):\n            return self.asarray[topleft_index - 1]\n        return self.asarray[(topleft_index + 1) % len(self)]\n\n    def _bottomright_vertice_from_topleft(self, topleft_index: int) -&gt; NDArray:\n        \"\"\"Get the bottom-right vertice from the topleft vertice\n\n        Args:\n            topleft_index (int): index of the topleft vertice\n\n        Returns:\n            NDArray: topright vertice\n        \"\"\"\n        return self.asarray[(topleft_index + 2) % len(self)]\n\n    def get_vertice_from_topleft(\n        self, topleft_index: int, vertice: str = \"topright\"\n    ) -&gt; NDArray:\n        \"\"\"Get vertice from the topleft vertice. You can use this method to\n        obtain the topright, bottomleft, bottomright vertice from the topleft vertice.\n\n        Returns:\n            NDArray: topright vertice\n        \"\"\"\n        if vertice not in (\"topright\", \"bottomleft\", \"bottomright\"):\n            raise ValueError(\n                \"Parameter vertice must be one of\"\n                \"'topright', 'bottomleft', 'bottomright'\"\n                f\"but got {vertice}\"\n            )\n        return getattr(self, f\"_{vertice}_vertice_from_topleft\")(topleft_index)\n\n    def get_width_from_topleft(self, topleft_index: int) -&gt; float:\n        \"\"\"Get the width from the topleft vertice\n\n        Args:\n            topleft_index (int): top-left vertice index\n\n        Returns:\n            float: width value\n        \"\"\"\n        return float(\n            np.linalg.norm(\n                self.asarray[topleft_index]\n                - self.get_vertice_from_topleft(topleft_index, \"topright\")\n            )\n        )\n\n    def get_height_from_topleft(self, topleft_index: int) -&gt; float:\n        \"\"\"Get the heigth from the topleft vertice\n\n        Args:\n            topleft_index (int): top-left vertice index\n\n        Returns:\n            float: height value\n        \"\"\"\n        return float(\n            np.linalg.norm(\n                self.asarray[topleft_index]\n                - self.get_vertice_from_topleft(topleft_index, \"bottomleft\")\n            )\n        )\n\n    def get_vector_up_from_topleft(self, topleft_index: int) -&gt; Vector:\n        \"\"\"Get the vector that goes from the bottomleft vertice to the topleft vertice\n\n        Args:\n            topleft_index (int): top-left vertice index\n\n        Returns:\n            Vector: Vector object descripting the vector\n        \"\"\"\n        bottomleft_vertice = self.get_vertice_from_topleft(\n            topleft_index=topleft_index, vertice=\"bottomleft\"\n        )\n        return Vector([bottomleft_vertice, self[topleft_index]])\n\n    def get_vector_left_from_topleft(self, topleft_index: int) -&gt; Vector:\n        \"\"\"Get the vector that goes from the topleft vertice to the topright vertice\n\n        Args:\n            topleft_index (int): top-left vertice index\n\n        Returns:\n            Vector: Vector object descripting the vector\n        \"\"\"\n        rect_topright_vertice = self.get_vertice_from_topleft(\n            topleft_index=topleft_index, vertice=\"topright\"\n        )\n        return Vector([self[topleft_index], rect_topright_vertice])\n\n    def __str__(self) -&gt; str:\n        return (  # pylint: disable=duplicate-code\n            self.__class__.__name__\n            + \"([\"\n            + self.asarray[0].tolist().__str__()\n            + \", \"\n            + self.asarray[1].tolist().__str__()\n            + \", \"\n            + self.asarray[2].tolist().__str__()\n            + \", \"\n            + self.asarray[3].tolist().__str__()\n            + \"])\"\n        )\n\n    def __repr__(self) -&gt; str:\n        return str(self)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.is_axis_aligned","title":"<code>is_axis_aligned</code>  <code>property</code>","text":"<p>Check if the rectangle is exactly axis-aligned. If you wish to check if a rectangle is only approximately axis-aligned, use the <code>is_axis_aligned_approx</code> method.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the rectangle is exactly axis-aligned, False otherwise</p>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.is_square","title":"<code>is_square</code>  <code>property</code>","text":"<p>Whether the rectangle is a square or not</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the Rectangle is a Square</p>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.longside_length","title":"<code>longside_length</code>  <code>property</code>","text":"<p>Compute the biggest side of the rectangle</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>the biggest side length</p>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.shortside_length","title":"<code>shortside_length</code>  <code>property</code>","text":"<p>Compute the smallest side of the rectangle</p> <p>Returns:</p> Name Type Description <code>Segment</code> <code>float</code> <p>Longest side of the Rectangle as a Segment object</p>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.__init__","title":"<code>__init__(points, is_cast_int=False, regularity_margin_error=0.01, desintersect=True)</code>","text":"<p>Create a Rectangle object.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>NDArray | list</code> <p>2D points that define the rectangle</p> required <code>is_cast_int</code> <code>bool</code> <p>cast points to int. Defaults to False.</p> <code>False</code> <code>regularity_margin_error</code> <code>float</code> <p>defines the allowed margin distance error when checking if the points form a rectangle or not on initialization.</p> <code>0.01</code> <code>desintersect</code> <code>bool</code> <p>whether to desintersect the rectangle or not. Can be useful if the input points are in a random order and self-intersection is possible. In any case, if you try to instantiate a self-intersected rectangle a ValueError will be raised. Defaults to True.</p> <code>True</code> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def __init__(\n    self,\n    points: NDArray | list,\n    is_cast_int: bool = False,\n    regularity_margin_error: float = 1e-2,\n    desintersect: bool = True,\n) -&gt; None:\n    \"\"\"Create a Rectangle object.\n\n    Args:\n        points (NDArray | list): 2D points that define the rectangle\n        is_cast_int (bool, optional): cast points to int. Defaults to False.\n        regularity_margin_error (float, optional): defines the allowed margin\n            distance error when checking if the points form a rectangle or not\n            on initialization.\n        desintersect (bool, optional): whether to desintersect the rectangle or not.\n            Can be useful if the input points are in a random order and\n            self-intersection is possible. In any case, if you try to instantiate\n            a self-intersected rectangle a ValueError will be raised.\n            Defaults to True.\n    \"\"\"\n    if len(points) != 4:\n        raise ValueError(\"Cannot create a Rectangle since it must have 4 points\")\n    super().__init__(points=points, is_cast_int=is_cast_int)\n\n    if desintersect:\n        self.desintersect()\n\n    if self.is_self_intersected:\n        raise ValueError(\n            \"The points form a self-intersected geometric object which is not \"\n            f\"allowed for a {self.__class__.__name__}\"\n        )\n\n    if not self.is_regular(margin_dist_error_pct=regularity_margin_error):\n        raise ValueError(\n            \"Try to create a Rectangle object but the coordinates \"\n            \"do not form a valid Rectangle. Please check your input coordinates, \"\n            \"the regularity_margin_error and the desintersect parameters.\"\n        )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.desintersect","title":"<code>desintersect()</code>","text":"<p>Desintersect the rectangle if it is self-intersected. If the rectangle is not self-intersected, returns the same rectangle.</p> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Self</code> <p>the desintersected Rectangle object</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def desintersect(self) -&gt; Self:\n    \"\"\"Desintersect the rectangle if it is self-intersected.\n    If the rectangle is not self-intersected, returns the same rectangle.\n\n    Returns:\n        Rectangle: the desintersected Rectangle object\n    \"\"\"\n    if not self.is_self_intersected:\n        return self\n\n    # Sort points based on angle from centroid\n    def angle_from_center(pt):\n        return np.arctan2(pt[1] - self.centroid[1], pt[0] - self.centroid[0])\n\n    sorted_vertices = sorted(self.asarray, key=angle_from_center)\n    self.asarray = np.array(sorted_vertices)\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.from_center","title":"<code>from_center(center, width, height, is_cast_int=False)</code>  <code>classmethod</code>","text":"<p>Create a Rectangle object using the center point, width, height.</p> Convention to create the rectangle is <p>index 0: top left point index 1: top right point index 2: bottom right point index 3: bottom left point</p> <p>Parameters:</p> Name Type Description Default <code>center</code> <code>NDArray</code> <p>center point of the rectangle</p> required <code>width</code> <code>float</code> <p>width of the rectangle</p> required <code>height</code> <code>float</code> <p>height of the rectangle</p> required <code>is_cast_int</code> <code>bool</code> <p>cast the points coordinates to int</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Rectangle</code> <p>Rectangle object</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>@classmethod\ndef from_center(\n    cls,\n    center: NDArray,\n    width: float,\n    height: float,\n    is_cast_int: bool = False,\n) -&gt; Rectangle:\n    \"\"\"Create a Rectangle object using the center point, width, height.\n\n    Convention to create the rectangle is:\n        index 0: top left point\n        index 1: top right point\n        index 2: bottom right point\n        index 3: bottom left point\n\n    Args:\n        center (NDArray): center point of the rectangle\n        width (float): width of the rectangle\n        height (float): height of the rectangle\n        is_cast_int (bool, optional): cast the points coordinates to int\n\n    Returns:\n        Rectangle: Rectangle object\n    \"\"\"\n    # compute the halves lengths\n    half_width = width / 2\n    half_height = height / 2\n\n    # get center coordinates\n    center_x, center_y = center[0], center[1]\n\n    # get the rectangle coordinates\n    points = np.array(\n        [\n            [center_x - half_width, center_y - half_height],\n            [center_x + half_width, center_y - half_height],\n            [center_x + half_width, center_y + half_height],\n            [center_x - half_width, center_y + half_height],\n        ]\n    )\n\n    return Rectangle(points=points, is_cast_int=is_cast_int)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.from_topleft","title":"<code>from_topleft(topleft, width, height, is_cast_int=False)</code>  <code>classmethod</code>","text":"<p>Create a Rectangle object using the top left point, width, height and angle.</p> Convention to create the rectangle is <p>index 0: top left point index 1: top right point index 2: bottom right point index 3: bottom left point</p> <p>Parameters:</p> Name Type Description Default <code>topleft</code> <code>NDArray</code> <p>top left point of the rectangle</p> required <code>width</code> <code>float</code> <p>width of the rectangle</p> required <code>height</code> <code>float</code> <p>height of the rectangle</p> required <code>is_cast_int</code> <code>bool</code> <p>whether to cast int or not. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Self</code> <p>Rectangle object</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>@classmethod\ndef from_topleft(\n    cls,\n    topleft: NDArray,\n    width: float,\n    height: float,\n    is_cast_int: bool = False,\n) -&gt; Self:\n    \"\"\"Create a Rectangle object using the top left point, width, height and angle.\n\n    Convention to create the rectangle is:\n        index 0: top left point\n        index 1: top right point\n        index 2: bottom right point\n        index 3: bottom left point\n\n    Args:\n        topleft (NDArray): top left point of the rectangle\n        width (float): width of the rectangle\n        height (float): height of the rectangle\n        is_cast_int (bool, optional): whether to cast int or not. Defaults to False.\n\n    Returns:\n        Rectangle: Rectangle object\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    bottomright_vertice = np.array([topleft[0] + width, topleft[1] + height])\n    return cls.from_topleft_bottomright(\n        topleft=topleft,\n        bottomright=bottomright_vertice,\n        is_cast_int=is_cast_int,\n    )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.from_topleft_bottomright","title":"<code>from_topleft_bottomright(topleft, bottomright, is_cast_int=False)</code>  <code>classmethod</code>","text":"<p>Create a Rectangle object using the top left and bottom right points.</p> Convention to create the rectangle is <p>index 0: top left point index 1: top right point index 2: bottom right point index 3: bottom left point</p> <p>Parameters:</p> Name Type Description Default <code>topleft</code> <code>NDArray</code> <p>top left point of the rectangle</p> required <code>bottomright</code> <code>NDArray</code> <p>bottom right point of the rectangle</p> required <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Self</code> <p>new Rectangle object</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>@classmethod\ndef from_topleft_bottomright(\n    cls,\n    topleft: NDArray,\n    bottomright: NDArray,\n    is_cast_int: bool = False,\n) -&gt; Self:\n    \"\"\"Create a Rectangle object using the top left and bottom right points.\n\n    Convention to create the rectangle is:\n        index 0: top left point\n        index 1: top right point\n        index 2: bottom right point\n        index 3: bottom left point\n\n    Args:\n        topleft (NDArray): top left point of the rectangle\n        bottomright (NDArray): bottom right point of the rectangle\n\n    Returns:\n        Rectangle: new Rectangle object\n    \"\"\"\n    topright_vertice = np.array([bottomright[0], topleft[1]])\n    bottomleft_vertice = np.array([topleft[0], bottomright[1]])\n    return cls(\n        np.asarray([topleft, topright_vertice, bottomright, bottomleft_vertice]),\n        is_cast_int=is_cast_int,\n    )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.get_height_from_topleft","title":"<code>get_height_from_topleft(topleft_index)</code>","text":"<p>Get the heigth from the topleft vertice</p> <p>Parameters:</p> Name Type Description Default <code>topleft_index</code> <code>int</code> <p>top-left vertice index</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>height value</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def get_height_from_topleft(self, topleft_index: int) -&gt; float:\n    \"\"\"Get the heigth from the topleft vertice\n\n    Args:\n        topleft_index (int): top-left vertice index\n\n    Returns:\n        float: height value\n    \"\"\"\n    return float(\n        np.linalg.norm(\n            self.asarray[topleft_index]\n            - self.get_vertice_from_topleft(topleft_index, \"bottomleft\")\n        )\n    )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.get_vector_left_from_topleft","title":"<code>get_vector_left_from_topleft(topleft_index)</code>","text":"<p>Get the vector that goes from the topleft vertice to the topright vertice</p> <p>Parameters:</p> Name Type Description Default <code>topleft_index</code> <code>int</code> <p>top-left vertice index</p> required <p>Returns:</p> Name Type Description <code>Vector</code> <code>Vector</code> <p>Vector object descripting the vector</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def get_vector_left_from_topleft(self, topleft_index: int) -&gt; Vector:\n    \"\"\"Get the vector that goes from the topleft vertice to the topright vertice\n\n    Args:\n        topleft_index (int): top-left vertice index\n\n    Returns:\n        Vector: Vector object descripting the vector\n    \"\"\"\n    rect_topright_vertice = self.get_vertice_from_topleft(\n        topleft_index=topleft_index, vertice=\"topright\"\n    )\n    return Vector([self[topleft_index], rect_topright_vertice])\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.get_vector_up_from_topleft","title":"<code>get_vector_up_from_topleft(topleft_index)</code>","text":"<p>Get the vector that goes from the bottomleft vertice to the topleft vertice</p> <p>Parameters:</p> Name Type Description Default <code>topleft_index</code> <code>int</code> <p>top-left vertice index</p> required <p>Returns:</p> Name Type Description <code>Vector</code> <code>Vector</code> <p>Vector object descripting the vector</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def get_vector_up_from_topleft(self, topleft_index: int) -&gt; Vector:\n    \"\"\"Get the vector that goes from the bottomleft vertice to the topleft vertice\n\n    Args:\n        topleft_index (int): top-left vertice index\n\n    Returns:\n        Vector: Vector object descripting the vector\n    \"\"\"\n    bottomleft_vertice = self.get_vertice_from_topleft(\n        topleft_index=topleft_index, vertice=\"bottomleft\"\n    )\n    return Vector([bottomleft_vertice, self[topleft_index]])\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.get_vertice_from_topleft","title":"<code>get_vertice_from_topleft(topleft_index, vertice='topright')</code>","text":"<p>Get vertice from the topleft vertice. You can use this method to obtain the topright, bottomleft, bottomright vertice from the topleft vertice.</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>topright vertice</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def get_vertice_from_topleft(\n    self, topleft_index: int, vertice: str = \"topright\"\n) -&gt; NDArray:\n    \"\"\"Get vertice from the topleft vertice. You can use this method to\n    obtain the topright, bottomleft, bottomright vertice from the topleft vertice.\n\n    Returns:\n        NDArray: topright vertice\n    \"\"\"\n    if vertice not in (\"topright\", \"bottomleft\", \"bottomright\"):\n        raise ValueError(\n            \"Parameter vertice must be one of\"\n            \"'topright', 'bottomleft', 'bottomright'\"\n            f\"but got {vertice}\"\n        )\n    return getattr(self, f\"_{vertice}_vertice_from_topleft\")(topleft_index)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.get_width_from_topleft","title":"<code>get_width_from_topleft(topleft_index)</code>","text":"<p>Get the width from the topleft vertice</p> <p>Parameters:</p> Name Type Description Default <code>topleft_index</code> <code>int</code> <p>top-left vertice index</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>width value</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def get_width_from_topleft(self, topleft_index: int) -&gt; float:\n    \"\"\"Get the width from the topleft vertice\n\n    Args:\n        topleft_index (int): top-left vertice index\n\n    Returns:\n        float: width value\n    \"\"\"\n    return float(\n        np.linalg.norm(\n            self.asarray[topleft_index]\n            - self.get_vertice_from_topleft(topleft_index, \"topright\")\n        )\n    )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.is_axis_aligned_approx","title":"<code>is_axis_aligned_approx(precision=3)</code>","text":"<p>Check if the rectangle is axis-aligned</p> <p>Parameters:</p> Name Type Description Default <code>precision</code> <code>int</code> <p>precision for the slope angle. This define the number of decimals to consider for the angle calculation of both the longside and shortside angle. Defaults to 3.</p> <code>3</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the rectangle is axis-aligned, False otherwise</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def is_axis_aligned_approx(self, precision: int = 3) -&gt; bool:\n    \"\"\"Check if the rectangle is axis-aligned\n\n    Args:\n        precision (int, optional): precision for the slope angle.\n            This define the number of decimals to consider for the angle\n            calculation of both the longside and shortside angle. Defaults to 3.\n\n    Returns:\n        bool: True if the rectangle is axis-aligned, False otherwise\n    \"\"\"\n\n    def is_mult_of_90_approx(x, precision: int) -&gt; bool:\n        return bool(round((x + 90 * 100), precision) % 90 == 0)\n\n    longside_cond = is_mult_of_90_approx(\n        self.longside_slope_angle(degree=True), precision=precision\n    )\n    shortside_cond = is_mult_of_90_approx(\n        self.shortside_slope_angle(degree=True), precision=precision\n    )\n    return longside_cond and shortside_cond\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.join","title":"<code>join(rect, margin_dist_error=1e-05)</code>","text":"<p>Join two rectangles into a single one. If they share no point in common or only a single point returns None. If they share two points, returns a new Rectangle that is the concatenation of the two rectangles and that is not self-intersected. If they share 3 or more points they represent the same rectangle, thus returns this object.</p> <p>Parameters:</p> Name Type Description Default <code>rect</code> <code>Rectangle</code> <p>the other Rectangle object</p> required <code>margin_dist_error</code> <code>float</code> <p>the threshold to consider whether the rectangle share a common point. Defaults to 1e-5.</p> <code>1e-05</code> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Optional[Rectangle]</code> <p>the join new Rectangle object</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def join(\n    self, rect: Rectangle, margin_dist_error: float = 1e-5\n) -&gt; Optional[Rectangle]:\n    \"\"\"Join two rectangles into a single one.\n    If they share no point in common or only a single point returns None.\n    If they share two points, returns a new Rectangle that is the concatenation\n    of the two rectangles and that is not self-intersected.\n    If they share 3 or more points they represent the same rectangle, thus\n    returns this object.\n\n    Args:\n        rect (Rectangle): the other Rectangle object\n        margin_dist_error (float, optional): the threshold to consider whether the\n            rectangle share a common point. Defaults to 1e-5.\n\n    Returns:\n        Rectangle: the join new Rectangle object\n    \"\"\"\n    shared_points = self.find_shared_approx_vertices(rect, margin_dist_error)\n    n_shared_points = len(shared_points)\n\n    if n_shared_points in (0, 1):\n        return None\n    if n_shared_points == 2:\n        new_rect_points = np.concatenate(\n            (\n                self.find_vertices_far_from(shared_points, margin_dist_error),\n                rect.find_vertices_far_from(shared_points, margin_dist_error),\n            ),\n            axis=0,\n        )\n        return Rectangle(points=new_rect_points).desintersect()\n    # if 3 or more points in common it is the same rectangle\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.longside_slope_angle","title":"<code>longside_slope_angle(degree=False, is_y_axis_down=False)</code>","text":"<p>Compute the biggest slope of the rectangle</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>the biggest slope</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def longside_slope_angle(\n    self, degree: bool = False, is_y_axis_down: bool = False\n) -&gt; float:\n    \"\"\"Compute the biggest slope of the rectangle\n\n    Returns:\n        float: the biggest slope\n    \"\"\"\n    seg1 = self.segments[0]\n    seg2 = self.segments[1]\n    seg_bigside = seg1 if seg1.length &gt; seg2.length else seg2\n    return seg_bigside.slope_angle(degree=degree, is_y_axis_down=is_y_axis_down)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.shortside_slope_angle","title":"<code>shortside_slope_angle(degree=False, is_y_axis_down=False)</code>","text":"<p>Compute the smallest slope of the rectangle</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>the smallest slope</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def shortside_slope_angle(\n    self, degree: bool = False, is_y_axis_down: bool = False\n) -&gt; float:\n    \"\"\"Compute the smallest slope of the rectangle\n\n    Returns:\n        float: the smallest slope\n    \"\"\"\n    seg1 = self.segments[0]\n    seg2 = self.segments[1]\n    seg_smallside = seg2 if seg1.length &gt; seg2.length else seg1\n    return seg_smallside.slope_angle(degree=degree, is_y_axis_down=is_y_axis_down)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.rectangle.Rectangle.unit","title":"<code>unit()</code>  <code>classmethod</code>","text":"<p>Create a unit Rectangle object</p> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Rectangle</code> <p>new Rectangle object</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>@classmethod\ndef unit(cls) -&gt; Rectangle:\n    \"\"\"Create a unit Rectangle object\n\n    Returns:\n        Rectangle: new Rectangle object\n    \"\"\"\n    return cls(points=[[0, 0], [0, 1], [1, 1], [1, 0]])\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.shape.triangle.Triangle","title":"<code>Triangle</code>","text":"<p>               Bases: <code>Polygon</code></p> <p>Triangle class</p> Source code in <code>otary/geometry/discrete/shape/triangle.py</code> <pre><code>class Triangle(Polygon):\n    \"\"\"Triangle class\"\"\"\n\n    def __init__(self, points: np.ndarray | list, is_cast_int: bool = False) -&gt; None:\n        if len(points) != 3:\n            raise ValueError(\"Cannot create a Triangle since it must have 3 points\")\n        super().__init__(points=points, is_cast_int=is_cast_int)\n\n    def __str__(self) -&gt; str:\n        return (  # pylint: disable=duplicate-code\n            self.__class__.__name__\n            + \"([\"\n            + self.asarray[0].tolist().__str__()\n            + \", \"\n            + self.asarray[1].tolist().__str__()\n            + \", \"\n            + self.asarray[2].tolist().__str__()\n            + \"])\"\n        )\n\n    def __repr__(self) -&gt; str:\n        return str(self)\n</code></pre>"},{"location":"api/geometry/#linear","title":"Linear","text":"<p>LinearEntity class useful to describe any kind of linear object</p> <p>Segment class to describe defined lines and segments</p> <p>Curve class useful to describe any kind of curves</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.entity.LinearEntity","title":"<code>LinearEntity</code>","text":"<p>               Bases: <code>DiscreteGeometryEntity</code>, <code>ABC</code></p> <p>Define Linear objects</p> Source code in <code>otary/geometry/discrete/linear/entity.py</code> <pre><code>class LinearEntity(DiscreteGeometryEntity, ABC):\n    \"\"\"Define Linear objects\"\"\"\n\n    @property\n    def length(self) -&gt; float:\n        \"\"\"Compute the length of the linear object.\n\n        Returns:\n            float: length of the curve\n        \"\"\"\n        return np.sum(self.lengths)\n\n    @property\n    def perimeter(self) -&gt; float:\n        \"\"\"Perimeter of the segment which we define to be its length\n\n        Returns:\n            float: segment perimeter\n        \"\"\"\n        return self.length\n\n    @property\n    def area(self) -&gt; float:\n        \"\"\"Area of the segment which we define to be its length\n\n        Returns:\n            float: segment area\n        \"\"\"\n        return 0\n\n    @property\n    def shapely_edges(self) -&gt; LineString:\n        \"\"\"Returns the Shapely.LineString representation of the segment.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.LineString.html\n\n        Returns:\n            LineString: shapely.LineString object\n        \"\"\"\n        return LineString(coordinates=self.asarray)\n\n    @property\n    def shapely_surface(self) -&gt; LineString:\n        \"\"\"Returns the Shapely.LineString representation of the segment.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.LineString.html\n\n        Returns:\n            LineString: shapely.LineString object\n        \"\"\"\n        return self.shapely_edges\n\n    @property\n    def edges(self) -&gt; NDArray:\n        \"\"\"Get the edges of the linear spline\n\n        Returns:\n            NDArray: edges of the linear spline\n        \"\"\"\n        return np.stack([self.points, np.roll(self.points, shift=-1, axis=0)], axis=1)[\n            :-1, :, :\n        ]\n\n    @property\n    @abstractmethod\n    def midpoint(self) -&gt; NDArray:\n        \"\"\"Returns the mid-point of the linear entity that is within or\n        along the entity.\n\n        This method can be useful in the case of a curved linear entity. The\n        centroid is not necessarily along the curved linear entity, the mid-point is.\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.entity.LinearEntity.area","title":"<code>area</code>  <code>property</code>","text":"<p>Area of the segment which we define to be its length</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>segment area</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.entity.LinearEntity.edges","title":"<code>edges</code>  <code>property</code>","text":"<p>Get the edges of the linear spline</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>edges of the linear spline</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.entity.LinearEntity.length","title":"<code>length</code>  <code>property</code>","text":"<p>Compute the length of the linear object.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>length of the curve</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.entity.LinearEntity.midpoint","title":"<code>midpoint</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns the mid-point of the linear entity that is within or along the entity.</p> <p>This method can be useful in the case of a curved linear entity. The centroid is not necessarily along the curved linear entity, the mid-point is.</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>2D point</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.entity.LinearEntity.perimeter","title":"<code>perimeter</code>  <code>property</code>","text":"<p>Perimeter of the segment which we define to be its length</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>segment perimeter</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.entity.LinearEntity.shapely_edges","title":"<code>shapely_edges</code>  <code>property</code>","text":"<p>Returns the Shapely.LineString representation of the segment. See https://shapely.readthedocs.io/en/stable/reference/shapely.LineString.html</p> <p>Returns:</p> Name Type Description <code>LineString</code> <code>LineString</code> <p>shapely.LineString object</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.entity.LinearEntity.shapely_surface","title":"<code>shapely_surface</code>  <code>property</code>","text":"<p>Returns the Shapely.LineString representation of the segment. See https://shapely.readthedocs.io/en/stable/reference/shapely.LineString.html</p> <p>Returns:</p> Name Type Description <code>LineString</code> <code>LineString</code> <p>shapely.LineString object</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.segment.Segment","title":"<code>Segment</code>","text":"<p>               Bases: <code>LinearEntity</code></p> <p>Segment class</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>class Segment(LinearEntity):\n    \"\"\"Segment class\"\"\"\n\n    def __init__(self, points: NDArray | list, is_cast_int: bool = False) -&gt; None:\n        assert len(points) == 2\n        assert len(points[0]) == 2\n        assert len(points[1]) == 2\n        super().__init__(points=points, is_cast_int=is_cast_int)\n\n    @property\n    def centroid(self) -&gt; NDArray:\n        \"\"\"Returns the center point of the segment\n\n        Returns:\n            NDArray: point of shape (1, 2)\n        \"\"\"\n        return np.sum(self.points, axis=0) / 2\n\n    @property\n    def midpoint(self) -&gt; NDArray:\n        \"\"\"In the Segment, this is equivalent to the centroid\n\n        Returns:\n            NDArray: point of shape (1, 2)\n        \"\"\"\n        return self.centroid\n\n    @property\n    def direction_vector(self) -&gt; NDArray:\n        \"\"\"Returns the direction vector of the segment from point 1 to point 2\n\n        Returns:\n            NDArray: direction vector of shape (2,)\n        \"\"\"\n        return self.points[1] - self.points[0]\n\n    @property\n    def slope(self) -&gt; float:\n        \"\"\"Returns the segment slope in the classical XY coordinates referential\n\n        Can return inf if you have a really specific vertical line of the form:\n\n        &gt;&gt;&gt; seg = ot.Segment([[1e-9, 0], [0, 1]])\n        &gt;&gt;&gt; seg.slope\n        inf\n\n        Returns:\n            float: segment slope value\n        \"\"\"\n        p1, p2 = self.points[0], self.points[1]\n        with warnings.catch_warnings():\n            warnings.filterwarnings(\"error\", category=RuntimeWarning)\n            try:\n                slope = (p2[1] - p1[1]) / (p2[0] - p1[0] + 1e-9)\n            except RuntimeWarning:  # Now this is raised as an exception\n                slope = np.inf\n        return slope\n\n    @property\n    def slope_cv2(self) -&gt; float:\n        \"\"\"Compute the slope seen as in the cv2 coordinates with y-axis inverted\n\n        Returns:\n            float: segment slope value\n        \"\"\"\n        return -self.slope\n\n    def slope_angle(self, degree: bool = False, is_y_axis_down: bool = False) -&gt; float:\n        \"\"\"Calculate the slope angle of a single line in the cartesian space\n\n        Args:\n            degree (bool): whether to output the result in degree. By default in radian.\n\n        Returns:\n            float: slope angle in ]-pi/2, pi/2[\n        \"\"\"\n        angle = np.arctan(self.slope_cv2) if is_y_axis_down else np.arctan(self.slope)\n        if degree:\n            angle = np.rad2deg(angle)\n        return angle\n\n    def is_parallel(\n        self, other: Segment, margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR\n    ) -&gt; bool:\n        \"\"\"Check if two lines are parallel by calculating the slope of the two lines\n\n        Angle Difference = |theta_0 - theta_1| mod pi\n        Because always returns positive results due to the modulo we took into account\n        the special case where angle difference = pi - epsilon ~ 3.139,\n        this implies also two parallel lines.\n\n        Args:\n            other (np.array): segment of shape (2, 2)\n            margin_error_angle (float, optional): Threshold value for validating\n                if the lines are parallel. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.\n\n        Returns:\n            bool: whether we qualify the lines as parallel or not\n        \"\"\"\n        if margin_error_angle == 0:\n            # no margin of error, strict equality\n            M = np.array([self.direction_vector, -other.direction_vector]).T  # (2,2)\n            # Check if matrix is singular (parallel lines)\n            cond = np.linalg.det(M) == 0\n        else:\n            # with margin of error, we use angle difference\n            angle_difference = np.mod(\n                np.abs(self.slope_angle() - other.slope_angle()), math.pi\n            )\n            cond = bool(\n                angle_difference &lt;= margin_error_angle\n                or np.abs(angle_difference - math.pi) &lt;= margin_error_angle\n            )\n        return cond\n\n    @staticmethod\n    def is_points_collinear(\n        p1: NDArray,\n        p2: NDArray,\n        p3: NDArray,\n        margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR,\n    ) -&gt; bool:\n        \"\"\"Verify whether three points on the plane are collinear or not.\n        Method by angle or slope: For three points, slope of any pair of points must\n        be same as other pair.\n\n        Args:\n            p1 (np.array): point of shape (2,)\n            p2 (np.array): point of shape (2,)\n            p3 (np.array): point of shape (2,)\n            margin_error_angle (float, optional): Threshold value for validating\n                collinearity. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.\n\n        Returns:\n            bool: 1 if colinear, 0 otherwise\n        \"\"\"\n        p1, p2, p3 = np.array(p1), np.array(p2), np.array(p3)\n\n        # 2 or 3 points equal\n        if (\n            not np.logical_or(*(p1 - p2))\n            or not np.logical_or(*(p1 - p3))\n            or not np.logical_or(*(p2 - p3))\n        ):\n            return True\n\n        segment1, segment2 = Segment([p1, p2]), Segment([p1, p3])\n        return segment1.is_parallel(\n            other=segment2, margin_error_angle=margin_error_angle\n        )\n\n    def is_point_collinear(\n        self,\n        point: NDArray,\n        margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR,\n    ) -&gt; bool:\n        \"\"\"Check whether a point is collinear with the segment\n\n        Args:\n            point (NDArray): point of shape (2,)\n            margin_error_angle (float, optional): Threshold value for validating\n                collinearity. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.\n\n        Returns:\n            bool: True if the point is collinear with the segment\n        \"\"\"\n        return self.is_points_collinear(\n            p1=self.asarray[0],\n            p2=self.asarray[1],\n            p3=point,\n            margin_error_angle=margin_error_angle,\n        )\n\n    def is_collinear(\n        self, segment: Segment, margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR\n    ) -&gt; bool:\n        \"\"\"Verify whether two segments on the plane are collinear or not.\n        This means that they are parallel and have at least three points in common.\n\n        We needed to make all the combination verification in order to proove cause we\n        could end up with two points very very close by and it would end up not\n        providing the expected result. Consider the following example:\n\n        &gt;&gt;&gt; segment1 = Segment([[339, 615], [564, 650]])\n        &gt;&gt;&gt; segment2 = Segment([[340, 614], [611, 657]])\n        &gt;&gt;&gt; segment1.is_collinear(segment2)\n        Angle difference: 0.9397169393235674 Margin: 0.06283185307179587\n        False\n\n        Only because [339, 615] and [340, 614] are really close and do not provide the\n        appropriate slope does not means that overall the two segments are not\n        collinear.\n\n        Args:\n            segment (np.array): segment of shape (2, 2)\n            margin_error_angle (float, optional): Threshold value for validating\n                collinearity.\n\n        Returns:\n            bool: 1 if colinear, 0 otherwise\n        \"\"\"\n        cur2lines = np.array([self.asarray, segment.asarray])\n        points = np.concatenate(cur2lines, axis=0)\n        val_arr = np.zeros(shape=4)\n        for i, combi in enumerate(\n            itertools.combinations(np.linspace(0, 3, 4, dtype=int), 3)\n        ):\n            val_arr[i] = Segment.is_points_collinear(\n                p1=points[combi[0]],\n                p2=points[combi[1]],\n                p3=points[combi[2]],\n                margin_error_angle=margin_error_angle,\n            )\n\n        _is_parallel = self.is_parallel(\n            other=segment, margin_error_angle=margin_error_angle\n        )\n        _is_collinear = 1 in val_arr\n        return bool(_is_parallel and _is_collinear)\n\n    def intersection_line(self, other: Segment) -&gt; NDArray:\n        \"\"\"Compute the intersection point that would exist between two segments if we\n        consider them as lines - which means as lines with infinite length.\n\n        Lines would thus define infinite extension in both extremities directions\n        of the input segments objects.\n\n        Args:\n            other (Segment): other Segment object\n\n        Returns:\n            NDArray: intersection point between the two lines\n        \"\"\"\n        if self.is_parallel(other, margin_error_angle=0):\n            return np.array([])\n\n        M = np.array([self.direction_vector, -other.direction_vector]).T  # shape (2,2)\n        b = other.asarray[0] - self.asarray[0]  # shape (2,)\n        solution, _ = np.linalg.solve(M, b)\n\n        intersection = self.asarray[0] + solution * self.direction_vector\n        return intersection\n\n    def normal(self) -&gt; Self:\n        \"\"\"\n        Returns the normal segment of the segment.\n        The normal segment is a segment that is orthogonal to the input segment.\n\n        Please note that the normal segment have the same length as the input segment.\n        Moreover the normal segment is rotated by 90 degrees clockwise.\n\n        Returns:\n            Segment: normal segment centered at the original segment centroid\n        \"\"\"\n        normal = self.copy().rotate(\n            angle=math.pi / 2, is_degree=False, is_clockwise=True\n        )\n        return normal\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.segment.Segment.centroid","title":"<code>centroid</code>  <code>property</code>","text":"<p>Returns the center point of the segment</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>point of shape (1, 2)</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.segment.Segment.direction_vector","title":"<code>direction_vector</code>  <code>property</code>","text":"<p>Returns the direction vector of the segment from point 1 to point 2</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>direction vector of shape (2,)</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.segment.Segment.midpoint","title":"<code>midpoint</code>  <code>property</code>","text":"<p>In the Segment, this is equivalent to the centroid</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>point of shape (1, 2)</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.segment.Segment.slope","title":"<code>slope</code>  <code>property</code>","text":"<p>Returns the segment slope in the classical XY coordinates referential</p> <p>Can return inf if you have a really specific vertical line of the form:</p> <p>seg = ot.Segment([[1e-9, 0], [0, 1]]) seg.slope inf</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>segment slope value</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.segment.Segment.slope_cv2","title":"<code>slope_cv2</code>  <code>property</code>","text":"<p>Compute the slope seen as in the cv2 coordinates with y-axis inverted</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>segment slope value</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.segment.Segment.intersection_line","title":"<code>intersection_line(other)</code>","text":"<p>Compute the intersection point that would exist between two segments if we consider them as lines - which means as lines with infinite length.</p> <p>Lines would thus define infinite extension in both extremities directions of the input segments objects.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Segment</code> <p>other Segment object</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>intersection point between the two lines</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>def intersection_line(self, other: Segment) -&gt; NDArray:\n    \"\"\"Compute the intersection point that would exist between two segments if we\n    consider them as lines - which means as lines with infinite length.\n\n    Lines would thus define infinite extension in both extremities directions\n    of the input segments objects.\n\n    Args:\n        other (Segment): other Segment object\n\n    Returns:\n        NDArray: intersection point between the two lines\n    \"\"\"\n    if self.is_parallel(other, margin_error_angle=0):\n        return np.array([])\n\n    M = np.array([self.direction_vector, -other.direction_vector]).T  # shape (2,2)\n    b = other.asarray[0] - self.asarray[0]  # shape (2,)\n    solution, _ = np.linalg.solve(M, b)\n\n    intersection = self.asarray[0] + solution * self.direction_vector\n    return intersection\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.segment.Segment.is_collinear","title":"<code>is_collinear(segment, margin_error_angle=DEFAULT_MARGIN_ANGLE_ERROR)</code>","text":"<p>Verify whether two segments on the plane are collinear or not. This means that they are parallel and have at least three points in common.</p> <p>We needed to make all the combination verification in order to proove cause we could end up with two points very very close by and it would end up not providing the expected result. Consider the following example:</p> <p>segment1 = Segment([[339, 615], [564, 650]]) segment2 = Segment([[340, 614], [611, 657]]) segment1.is_collinear(segment2) Angle difference: 0.9397169393235674 Margin: 0.06283185307179587 False</p> <p>Only because [339, 615] and [340, 614] are really close and do not provide the appropriate slope does not means that overall the two segments are not collinear.</p> <p>Parameters:</p> Name Type Description Default <code>segment</code> <code>array</code> <p>segment of shape (2, 2)</p> required <code>margin_error_angle</code> <code>float</code> <p>Threshold value for validating collinearity.</p> <code>DEFAULT_MARGIN_ANGLE_ERROR</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>1 if colinear, 0 otherwise</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>def is_collinear(\n    self, segment: Segment, margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR\n) -&gt; bool:\n    \"\"\"Verify whether two segments on the plane are collinear or not.\n    This means that they are parallel and have at least three points in common.\n\n    We needed to make all the combination verification in order to proove cause we\n    could end up with two points very very close by and it would end up not\n    providing the expected result. Consider the following example:\n\n    &gt;&gt;&gt; segment1 = Segment([[339, 615], [564, 650]])\n    &gt;&gt;&gt; segment2 = Segment([[340, 614], [611, 657]])\n    &gt;&gt;&gt; segment1.is_collinear(segment2)\n    Angle difference: 0.9397169393235674 Margin: 0.06283185307179587\n    False\n\n    Only because [339, 615] and [340, 614] are really close and do not provide the\n    appropriate slope does not means that overall the two segments are not\n    collinear.\n\n    Args:\n        segment (np.array): segment of shape (2, 2)\n        margin_error_angle (float, optional): Threshold value for validating\n            collinearity.\n\n    Returns:\n        bool: 1 if colinear, 0 otherwise\n    \"\"\"\n    cur2lines = np.array([self.asarray, segment.asarray])\n    points = np.concatenate(cur2lines, axis=0)\n    val_arr = np.zeros(shape=4)\n    for i, combi in enumerate(\n        itertools.combinations(np.linspace(0, 3, 4, dtype=int), 3)\n    ):\n        val_arr[i] = Segment.is_points_collinear(\n            p1=points[combi[0]],\n            p2=points[combi[1]],\n            p3=points[combi[2]],\n            margin_error_angle=margin_error_angle,\n        )\n\n    _is_parallel = self.is_parallel(\n        other=segment, margin_error_angle=margin_error_angle\n    )\n    _is_collinear = 1 in val_arr\n    return bool(_is_parallel and _is_collinear)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.segment.Segment.is_parallel","title":"<code>is_parallel(other, margin_error_angle=DEFAULT_MARGIN_ANGLE_ERROR)</code>","text":"<p>Check if two lines are parallel by calculating the slope of the two lines</p> <p>Angle Difference = |theta_0 - theta_1| mod pi Because always returns positive results due to the modulo we took into account the special case where angle difference = pi - epsilon ~ 3.139, this implies also two parallel lines.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>array</code> <p>segment of shape (2, 2)</p> required <code>margin_error_angle</code> <code>float</code> <p>Threshold value for validating if the lines are parallel. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.</p> <code>DEFAULT_MARGIN_ANGLE_ERROR</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>whether we qualify the lines as parallel or not</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>def is_parallel(\n    self, other: Segment, margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR\n) -&gt; bool:\n    \"\"\"Check if two lines are parallel by calculating the slope of the two lines\n\n    Angle Difference = |theta_0 - theta_1| mod pi\n    Because always returns positive results due to the modulo we took into account\n    the special case where angle difference = pi - epsilon ~ 3.139,\n    this implies also two parallel lines.\n\n    Args:\n        other (np.array): segment of shape (2, 2)\n        margin_error_angle (float, optional): Threshold value for validating\n            if the lines are parallel. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.\n\n    Returns:\n        bool: whether we qualify the lines as parallel or not\n    \"\"\"\n    if margin_error_angle == 0:\n        # no margin of error, strict equality\n        M = np.array([self.direction_vector, -other.direction_vector]).T  # (2,2)\n        # Check if matrix is singular (parallel lines)\n        cond = np.linalg.det(M) == 0\n    else:\n        # with margin of error, we use angle difference\n        angle_difference = np.mod(\n            np.abs(self.slope_angle() - other.slope_angle()), math.pi\n        )\n        cond = bool(\n            angle_difference &lt;= margin_error_angle\n            or np.abs(angle_difference - math.pi) &lt;= margin_error_angle\n        )\n    return cond\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.segment.Segment.is_point_collinear","title":"<code>is_point_collinear(point, margin_error_angle=DEFAULT_MARGIN_ANGLE_ERROR)</code>","text":"<p>Check whether a point is collinear with the segment</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>point of shape (2,)</p> required <code>margin_error_angle</code> <code>float</code> <p>Threshold value for validating collinearity. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.</p> <code>DEFAULT_MARGIN_ANGLE_ERROR</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the point is collinear with the segment</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>def is_point_collinear(\n    self,\n    point: NDArray,\n    margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR,\n) -&gt; bool:\n    \"\"\"Check whether a point is collinear with the segment\n\n    Args:\n        point (NDArray): point of shape (2,)\n        margin_error_angle (float, optional): Threshold value for validating\n            collinearity. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.\n\n    Returns:\n        bool: True if the point is collinear with the segment\n    \"\"\"\n    return self.is_points_collinear(\n        p1=self.asarray[0],\n        p2=self.asarray[1],\n        p3=point,\n        margin_error_angle=margin_error_angle,\n    )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.segment.Segment.is_points_collinear","title":"<code>is_points_collinear(p1, p2, p3, margin_error_angle=DEFAULT_MARGIN_ANGLE_ERROR)</code>  <code>staticmethod</code>","text":"<p>Verify whether three points on the plane are collinear or not. Method by angle or slope: For three points, slope of any pair of points must be same as other pair.</p> <p>Parameters:</p> Name Type Description Default <code>p1</code> <code>array</code> <p>point of shape (2,)</p> required <code>p2</code> <code>array</code> <p>point of shape (2,)</p> required <code>p3</code> <code>array</code> <p>point of shape (2,)</p> required <code>margin_error_angle</code> <code>float</code> <p>Threshold value for validating collinearity. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.</p> <code>DEFAULT_MARGIN_ANGLE_ERROR</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>1 if colinear, 0 otherwise</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>@staticmethod\ndef is_points_collinear(\n    p1: NDArray,\n    p2: NDArray,\n    p3: NDArray,\n    margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR,\n) -&gt; bool:\n    \"\"\"Verify whether three points on the plane are collinear or not.\n    Method by angle or slope: For three points, slope of any pair of points must\n    be same as other pair.\n\n    Args:\n        p1 (np.array): point of shape (2,)\n        p2 (np.array): point of shape (2,)\n        p3 (np.array): point of shape (2,)\n        margin_error_angle (float, optional): Threshold value for validating\n            collinearity. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.\n\n    Returns:\n        bool: 1 if colinear, 0 otherwise\n    \"\"\"\n    p1, p2, p3 = np.array(p1), np.array(p2), np.array(p3)\n\n    # 2 or 3 points equal\n    if (\n        not np.logical_or(*(p1 - p2))\n        or not np.logical_or(*(p1 - p3))\n        or not np.logical_or(*(p2 - p3))\n    ):\n        return True\n\n    segment1, segment2 = Segment([p1, p2]), Segment([p1, p3])\n    return segment1.is_parallel(\n        other=segment2, margin_error_angle=margin_error_angle\n    )\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.segment.Segment.normal","title":"<code>normal()</code>","text":"<p>Returns the normal segment of the segment. The normal segment is a segment that is orthogonal to the input segment.</p> <p>Please note that the normal segment have the same length as the input segment. Moreover the normal segment is rotated by 90 degrees clockwise.</p> <p>Returns:</p> Name Type Description <code>Segment</code> <code>Self</code> <p>normal segment centered at the original segment centroid</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>def normal(self) -&gt; Self:\n    \"\"\"\n    Returns the normal segment of the segment.\n    The normal segment is a segment that is orthogonal to the input segment.\n\n    Please note that the normal segment have the same length as the input segment.\n    Moreover the normal segment is rotated by 90 degrees clockwise.\n\n    Returns:\n        Segment: normal segment centered at the original segment centroid\n    \"\"\"\n    normal = self.copy().rotate(\n        angle=math.pi / 2, is_degree=False, is_clockwise=True\n    )\n    return normal\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.segment.Segment.slope_angle","title":"<code>slope_angle(degree=False, is_y_axis_down=False)</code>","text":"<p>Calculate the slope angle of a single line in the cartesian space</p> <p>Parameters:</p> Name Type Description Default <code>degree</code> <code>bool</code> <p>whether to output the result in degree. By default in radian.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>slope angle in ]-pi/2, pi/2[</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>def slope_angle(self, degree: bool = False, is_y_axis_down: bool = False) -&gt; float:\n    \"\"\"Calculate the slope angle of a single line in the cartesian space\n\n    Args:\n        degree (bool): whether to output the result in degree. By default in radian.\n\n    Returns:\n        float: slope angle in ]-pi/2, pi/2[\n    \"\"\"\n    angle = np.arctan(self.slope_cv2) if is_y_axis_down else np.arctan(self.slope)\n    if degree:\n        angle = np.rad2deg(angle)\n    return angle\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.linear_spline.LinearSpline","title":"<code>LinearSpline</code>","text":"<p>               Bases: <code>LinearEntity</code></p> <p>LinearSpline class</p> Source code in <code>otary/geometry/discrete/linear/linear_spline.py</code> <pre><code>class LinearSpline(LinearEntity):\n    \"\"\"LinearSpline class\"\"\"\n\n    def __init__(self, points: NDArray | list, is_cast_int: bool = False) -&gt; None:\n        if len(points) &lt; 2:\n            raise ValueError(\n                \"Cannot create a LinearSpline since it must have 2 or more points\"\n            )\n        super().__init__(points=points, is_cast_int=is_cast_int)\n\n    @property\n    def curvature(self) -&gt; float:\n        \"\"\"Get the curvature of the linear spline as-if it had a well-defined\n        curvature, meaning as-if it were a continuous curve.\n\n        Returns:\n            float: curvature value\n        \"\"\"\n        # TODO\n        raise NotImplementedError\n\n    @property\n    def centroid(self) -&gt; NDArray:\n        \"\"\"Returns the center point that is within the linear spline.\n        This means that this points necessarily belongs to the linear spline.\n\n        This can be useful when the centroid is not a good representation of what\n        is needed as 'center'.\n\n        Returns:\n            NDArray: point of shape (1, 2)\n        \"\"\"\n        total_length: float = 0.0\n        cx: float = 0.0\n        cy: float = 0.0\n\n        for i in range(len(self.points) - 1):\n            p1, p2 = self.points[i], self.points[i + 1]\n            mid = (p1 + p2) / 2\n            length = float(np.linalg.norm(p2 - p1))\n            cx += mid[0] * length\n            cy += mid[1] * length\n            total_length += length\n\n        if total_length == 0:\n            return self.points[0]  # or handle degenerate case\n        return np.asarray([cx / total_length, cy / total_length])\n\n    @property\n    def midpoint(self) -&gt; NDArray:\n        \"\"\"Returns the center point that is within the linear spline.\n        This means that this points necessarily belongs to the linear spline.\n\n        This can be useful when the centroid is not a good representation of what\n        is needed as 'center'.\n\n        Returns:\n            NDArray: point of shape (1, 2)\n        \"\"\"\n        return self.find_interpolated_point(pct_dist=0.5)\n\n    def find_interpolated_point_and_prev_ix(\n        self, pct_dist: float\n    ) -&gt; tuple[NDArray, int]:\n        \"\"\"Return a point along the curve at a relative distance pct_dist \u2208 [0, 1]\n\n        Parameters:\n            pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n                Any value in [0, 1] returns a point between start and end that is\n                pct_dist along the path.\n\n        Returns:\n            tuple[NDArray, int]: Interpolated point [x, y] and previous index in path.\n        \"\"\"\n        if not 0 &lt;= pct_dist &lt;= 1:\n            raise ValueError(\"pct_dist must be in [0, 1]\")\n\n        if self.length == 0 or pct_dist == 0:\n            return self[0], 0\n        if pct_dist == 1:\n            return self[-1], len(self) - 1\n\n        # Walk along the path to find the point at pct_dist * total_dist\n        target_dist = pct_dist * self.length\n        accumulated = 0\n        for i in range(len(self.edges)):\n            cur_edge_length = self.lengths[i]\n            if accumulated + cur_edge_length &gt;= target_dist:\n                remain = target_dist - accumulated\n                direction = self[i + 1] - self[i]\n                unit_dir = direction / cur_edge_length\n                return self[i] + remain * unit_dir, i\n            accumulated += cur_edge_length\n\n        # Fallback\n        return self[-1], i\n\n    def find_interpolated_point(self, pct_dist: float) -&gt; NDArray:\n        \"\"\"Return a point along the curve at a relative distance pct_dist \u2208 [0, 1]\n\n        Parameters:\n            pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n                Any value in [0, 1] returns a point between start and end that is\n                pct_dist along the path.\n\n        Returns:\n            NDArray: Interpolated point [x, y]\n        \"\"\"\n        return self.find_interpolated_point_and_prev_ix(pct_dist)[0]\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.linear_spline.LinearSpline.centroid","title":"<code>centroid</code>  <code>property</code>","text":"<p>Returns the center point that is within the linear spline. This means that this points necessarily belongs to the linear spline.</p> <p>This can be useful when the centroid is not a good representation of what is needed as 'center'.</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>point of shape (1, 2)</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.linear_spline.LinearSpline.curvature","title":"<code>curvature</code>  <code>property</code>","text":"<p>Get the curvature of the linear spline as-if it had a well-defined curvature, meaning as-if it were a continuous curve.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>curvature value</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.linear_spline.LinearSpline.midpoint","title":"<code>midpoint</code>  <code>property</code>","text":"<p>Returns the center point that is within the linear spline. This means that this points necessarily belongs to the linear spline.</p> <p>This can be useful when the centroid is not a good representation of what is needed as 'center'.</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>point of shape (1, 2)</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.linear_spline.LinearSpline.find_interpolated_point","title":"<code>find_interpolated_point(pct_dist)</code>","text":"<p>Return a point along the curve at a relative distance pct_dist \u2208 [0, 1]</p> <p>Parameters:</p> Name Type Description Default <code>pct_dist</code> <code>float</code> <p>Value in [0, 1], 0 returns start, 1 returns end. Any value in [0, 1] returns a point between start and end that is pct_dist along the path.</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>Interpolated point [x, y]</p> Source code in <code>otary/geometry/discrete/linear/linear_spline.py</code> <pre><code>def find_interpolated_point(self, pct_dist: float) -&gt; NDArray:\n    \"\"\"Return a point along the curve at a relative distance pct_dist \u2208 [0, 1]\n\n    Parameters:\n        pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n            Any value in [0, 1] returns a point between start and end that is\n            pct_dist along the path.\n\n    Returns:\n        NDArray: Interpolated point [x, y]\n    \"\"\"\n    return self.find_interpolated_point_and_prev_ix(pct_dist)[0]\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.linear_spline.LinearSpline.find_interpolated_point_and_prev_ix","title":"<code>find_interpolated_point_and_prev_ix(pct_dist)</code>","text":"<p>Return a point along the curve at a relative distance pct_dist \u2208 [0, 1]</p> <p>Parameters:</p> Name Type Description Default <code>pct_dist</code> <code>float</code> <p>Value in [0, 1], 0 returns start, 1 returns end. Any value in [0, 1] returns a point between start and end that is pct_dist along the path.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray, int]</code> <p>tuple[NDArray, int]: Interpolated point [x, y] and previous index in path.</p> Source code in <code>otary/geometry/discrete/linear/linear_spline.py</code> <pre><code>def find_interpolated_point_and_prev_ix(\n    self, pct_dist: float\n) -&gt; tuple[NDArray, int]:\n    \"\"\"Return a point along the curve at a relative distance pct_dist \u2208 [0, 1]\n\n    Parameters:\n        pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n            Any value in [0, 1] returns a point between start and end that is\n            pct_dist along the path.\n\n    Returns:\n        tuple[NDArray, int]: Interpolated point [x, y] and previous index in path.\n    \"\"\"\n    if not 0 &lt;= pct_dist &lt;= 1:\n        raise ValueError(\"pct_dist must be in [0, 1]\")\n\n    if self.length == 0 or pct_dist == 0:\n        return self[0], 0\n    if pct_dist == 1:\n        return self[-1], len(self) - 1\n\n    # Walk along the path to find the point at pct_dist * total_dist\n    target_dist = pct_dist * self.length\n    accumulated = 0\n    for i in range(len(self.edges)):\n        cur_edge_length = self.lengths[i]\n        if accumulated + cur_edge_length &gt;= target_dist:\n            remain = target_dist - accumulated\n            direction = self[i + 1] - self[i]\n            unit_dir = direction / cur_edge_length\n            return self[i] + remain * unit_dir, i\n        accumulated += cur_edge_length\n\n    # Fallback\n    return self[-1], i\n</code></pre>"},{"location":"api/geometry/#linear-directed","title":"Linear Directed","text":"<p>Module to define Linear Directed Geometric Entity</p> <p>Vectors class they are like segments, but with a given direction</p> <p>Vectorized Curve class useful to describe any kind of vectorized curves</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.entity.DirectedLinearEntity","title":"<code>DirectedLinearEntity</code>","text":"<p>               Bases: <code>LinearEntity</code></p> <p>DirectedLinearEntity class</p> Source code in <code>otary/geometry/discrete/linear/directed/entity.py</code> <pre><code>class DirectedLinearEntity(LinearEntity):\n    \"\"\"DirectedLinearEntity class\"\"\"\n\n    @property\n    @abstractmethod\n    def cardinal_degree(self) -&gt; float:\n        \"\"\"Return the cardinal degree of the Directed Linear Entity\"\"\"\n\n    @property\n    def head(self) -&gt; NDArray:\n        \"\"\"Return the head point at the end-extremity of the arrow directed object.\n\n        Returns:\n            NDArray: the head point\n        \"\"\"\n        return self.asarray[-1]\n\n    @property\n    def tail(self) -&gt; NDArray:\n        \"\"\"Return the tail point at the start-extremity of the arrow directed object.\n\n        Returns:\n            NDArray: the tail point\n        \"\"\"\n        return self.asarray[0]\n\n    @property\n    def origin(self) -&gt; NDArray:\n        \"\"\"Representation shifted to the origin (0,0)\n        It is the same entity but with the tail point at (0,0) and the other\n        points shifted accordingly.\n        \"\"\"\n        return self.asarray - self.tail\n\n    @property\n    def cv2_space_coords(self) -&gt; NDArray:\n        \"\"\"Inverted coordinates in the cv2 space\n\n        Returns:\n            NDArray: with inverted coordinates\n        \"\"\"\n        return np.roll(self.points, shift=1, axis=1)\n\n    @property\n    def is_x_first_pt_gt_x_last_pt(self) -&gt; bool:\n        \"\"\"Whether the x coordinate of the first point is greater than the x\n        coordinate of the second point that forms the directed linear entity\n\n        Returns:\n            bool: if x0 &gt; x1 returns True, else False\n        \"\"\"\n        return bool(self.asarray[0][0] &gt; self.asarray[-1][0])\n\n    @property\n    def is_y_first_pt_gt_y_last_pt(self) -&gt; bool:\n        \"\"\"Whether the y coordinate of the first point is greater than the y\n        coordinate of the second point that forms the directed linear entity\n\n        Returns:\n            bool: if y0 &gt; y1 returns True, else False\n        \"\"\"\n        return bool(self.asarray[0][1] &gt; self.asarray[-1][1])\n\n    def cardinal_direction(self, full: bool = False, level: int = 2) -&gt; str:\n        \"\"\"Cardinal direction\n\n        Args:\n            full (bool, optional): True returns full text (South), False returns\n                abbreviated text (S). Defaults to False.\n            level (int, optional): Level of detail (3 = N/NNE/NE/ENE/E...\n                2 = N/NE/E/SE... 1 = N/E/S/W). Defaults to 2.\n\n        Returns:\n            str: _description_\n        \"\"\"\n        return angle_to_direction(angle=self.cardinal_degree, full=full, level=level)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.entity.DirectedLinearEntity.cardinal_degree","title":"<code>cardinal_degree</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Return the cardinal degree of the Directed Linear Entity</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.entity.DirectedLinearEntity.cv2_space_coords","title":"<code>cv2_space_coords</code>  <code>property</code>","text":"<p>Inverted coordinates in the cv2 space</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>with inverted coordinates</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.entity.DirectedLinearEntity.head","title":"<code>head</code>  <code>property</code>","text":"<p>Return the head point at the end-extremity of the arrow directed object.</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>the head point</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.entity.DirectedLinearEntity.is_x_first_pt_gt_x_last_pt","title":"<code>is_x_first_pt_gt_x_last_pt</code>  <code>property</code>","text":"<p>Whether the x coordinate of the first point is greater than the x coordinate of the second point that forms the directed linear entity</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>if x0 &gt; x1 returns True, else False</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.entity.DirectedLinearEntity.is_y_first_pt_gt_y_last_pt","title":"<code>is_y_first_pt_gt_y_last_pt</code>  <code>property</code>","text":"<p>Whether the y coordinate of the first point is greater than the y coordinate of the second point that forms the directed linear entity</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>if y0 &gt; y1 returns True, else False</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.entity.DirectedLinearEntity.origin","title":"<code>origin</code>  <code>property</code>","text":"<p>Representation shifted to the origin (0,0) It is the same entity but with the tail point at (0,0) and the other points shifted accordingly.</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.entity.DirectedLinearEntity.tail","title":"<code>tail</code>  <code>property</code>","text":"<p>Return the tail point at the start-extremity of the arrow directed object.</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>the tail point</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.entity.DirectedLinearEntity.cardinal_direction","title":"<code>cardinal_direction(full=False, level=2)</code>","text":"<p>Cardinal direction</p> <p>Parameters:</p> Name Type Description Default <code>full</code> <code>bool</code> <p>True returns full text (South), False returns abbreviated text (S). Defaults to False.</p> <code>False</code> <code>level</code> <code>int</code> <p>Level of detail (3 = N/NNE/NE/ENE/E... 2 = N/NE/E/SE... 1 = N/E/S/W). Defaults to 2.</p> <code>2</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>description</p> Source code in <code>otary/geometry/discrete/linear/directed/entity.py</code> <pre><code>def cardinal_direction(self, full: bool = False, level: int = 2) -&gt; str:\n    \"\"\"Cardinal direction\n\n    Args:\n        full (bool, optional): True returns full text (South), False returns\n            abbreviated text (S). Defaults to False.\n        level (int, optional): Level of detail (3 = N/NNE/NE/ENE/E...\n            2 = N/NE/E/SE... 1 = N/E/S/W). Defaults to 2.\n\n    Returns:\n        str: _description_\n    \"\"\"\n    return angle_to_direction(angle=self.cardinal_degree, full=full, level=level)\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.vector.Vector","title":"<code>Vector</code>","text":"<p>               Bases: <code>Segment</code>, <code>DirectedLinearEntity</code></p> <p>Vector class to manipulate vector which can be seen as Segment with direction</p> Source code in <code>otary/geometry/discrete/linear/directed/vector.py</code> <pre><code>class Vector(Segment, DirectedLinearEntity):\n    \"\"\"Vector class to manipulate vector which can be seen as Segment with direction\"\"\"\n\n    @classmethod\n    def from_single_point(cls, point: NDArray) -&gt; Vector:\n        \"\"\"Get vector that goes from [0, 0] to point\n\n        Args:\n            point (NDArray): point of shape 2\n\n        Returns:\n            Vector: new vector object\n        \"\"\"\n        return cls(points=[[0, 0], point])\n\n    @property\n    def cardinal_degree(self) -&gt; float:\n        \"\"\"Returns the cardinal degree of the vector in the cv2 space.\n        We consider the top of the image to point toward the north as default and thus\n        represent the cardinal degree value 0 mod 360.\n\n        Returns:\n            float: cardinal degree\n        \"\"\"\n        angle = self.slope_angle(degree=True, is_y_axis_down=True)\n\n        # if angle is negative\n        is_neg_sign_angle = bool(np.sign(angle) - 1)\n        if is_neg_sign_angle:\n            angle = 90 + np.abs(angle)\n        else:\n            angle = 90 - angle\n\n        # if vector points towards west\n        if self.is_x_first_pt_gt_x_last_pt:\n            angle += 180\n\n        cardinal_degree = np.mod(360 + angle, 360)  # avoid negative value case\n        return cardinal_degree\n\n    @property\n    def coordinates_shift(self) -&gt; NDArray:\n        \"\"\"Return the vector as a single point (x1-x0, y1-y0)\n\n        Returns:\n            NDArray: coordinates shift\n        \"\"\"\n        return self.origin[1]\n\n    @property\n    def normalized(self) -&gt; NDArray:\n        \"\"\"Nornalized vector\n\n        Returns:\n            NDArray: normalized vector\n        \"\"\"\n        return self.coordinates_shift / np.linalg.norm(self.coordinates_shift) + 1e-9\n\n    def rescale_head(self, scale: float) -&gt; Vector:\n        \"\"\"Rescale the head part of the vector without moving the first point.\n        This method only updates the second point that composes the vector.\n\n        Args:\n            scale (float): scale factor\n\n        Returns:\n            Vector: scaled vector\n        \"\"\"\n        self.asarray = (self.asarray - self.tail) * scale + self.tail\n        return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.vector.Vector.cardinal_degree","title":"<code>cardinal_degree</code>  <code>property</code>","text":"<p>Returns the cardinal degree of the vector in the cv2 space. We consider the top of the image to point toward the north as default and thus represent the cardinal degree value 0 mod 360.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>cardinal degree</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.vector.Vector.coordinates_shift","title":"<code>coordinates_shift</code>  <code>property</code>","text":"<p>Return the vector as a single point (x1-x0, y1-y0)</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>coordinates shift</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.vector.Vector.normalized","title":"<code>normalized</code>  <code>property</code>","text":"<p>Nornalized vector</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>normalized vector</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.vector.Vector.from_single_point","title":"<code>from_single_point(point)</code>  <code>classmethod</code>","text":"<p>Get vector that goes from [0, 0] to point</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>point of shape 2</p> required <p>Returns:</p> Name Type Description <code>Vector</code> <code>Vector</code> <p>new vector object</p> Source code in <code>otary/geometry/discrete/linear/directed/vector.py</code> <pre><code>@classmethod\ndef from_single_point(cls, point: NDArray) -&gt; Vector:\n    \"\"\"Get vector that goes from [0, 0] to point\n\n    Args:\n        point (NDArray): point of shape 2\n\n    Returns:\n        Vector: new vector object\n    \"\"\"\n    return cls(points=[[0, 0], point])\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.vector.Vector.rescale_head","title":"<code>rescale_head(scale)</code>","text":"<p>Rescale the head part of the vector without moving the first point. This method only updates the second point that composes the vector.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>scale factor</p> required <p>Returns:</p> Name Type Description <code>Vector</code> <code>Vector</code> <p>scaled vector</p> Source code in <code>otary/geometry/discrete/linear/directed/vector.py</code> <pre><code>def rescale_head(self, scale: float) -&gt; Vector:\n    \"\"\"Rescale the head part of the vector without moving the first point.\n    This method only updates the second point that composes the vector.\n\n    Args:\n        scale (float): scale factor\n\n    Returns:\n        Vector: scaled vector\n    \"\"\"\n    self.asarray = (self.asarray - self.tail) * scale + self.tail\n    return self\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.vectorized_linear_spline.VectorizedLinearSpline","title":"<code>VectorizedLinearSpline</code>","text":"<p>               Bases: <code>LinearSpline</code>, <code>DirectedLinearEntity</code></p> <p>VectorizedLinearSpline class</p> Source code in <code>otary/geometry/discrete/linear/directed/vectorized_linear_spline.py</code> <pre><code>class VectorizedLinearSpline(LinearSpline, DirectedLinearEntity):\n    \"\"\"VectorizedLinearSpline class\"\"\"\n\n    def __init__(self, points, is_cast_int=False):\n        super().__init__(points, is_cast_int)\n        self.vector_extremities = Vector(points=np.array([points[0], points[-1]]))\n\n    @property\n    def is_simple_vector(self) -&gt; bool:\n        \"\"\"Whether the VectorizedLinearSpline is just a two points vector or not\n\n        Returns:\n            bool: True or false\n        \"\"\"\n        return np.array_equal(self.asarray, self.vector_extremities.asarray)\n\n    @property\n    def cardinal_degree(self) -&gt; float:\n        \"\"\"Returns the cardinal degree of the VectorizedLinearSpline in the cv2 space.\n        It is calculated using the two extremities points that compose the object.\n\n        We consider the top of the image to point toward the north as default and thus\n        represent the cardinal degree value 0 mod 360.\n\n        Returns:\n            float: cardinal degree\n        \"\"\"\n        return self.vector_extremities.cardinal_degree\n</code></pre>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.vectorized_linear_spline.VectorizedLinearSpline.cardinal_degree","title":"<code>cardinal_degree</code>  <code>property</code>","text":"<p>Returns the cardinal degree of the VectorizedLinearSpline in the cv2 space. It is calculated using the two extremities points that compose the object.</p> <p>We consider the top of the image to point toward the north as default and thus represent the cardinal degree value 0 mod 360.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>cardinal degree</p>"},{"location":"api/geometry/#otary.geometry.discrete.linear.directed.vectorized_linear_spline.VectorizedLinearSpline.is_simple_vector","title":"<code>is_simple_vector</code>  <code>property</code>","text":"<p>Whether the VectorizedLinearSpline is just a two points vector or not</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True or false</p>"},{"location":"api/geometry/continuous/circle/","title":"Circle","text":"<p>Circle Geometric Object</p>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle","title":"<code>Circle</code>","text":"<p>               Bases: <code>Ellipse</code></p> <p>Circle geometrical object</p> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>class Circle(Ellipse):\n    \"\"\"Circle geometrical object\"\"\"\n\n    def __init__(\n        self,\n        center: NDArray | list,\n        radius: float,\n        n_points_polygonal_approx: int = ContinuousGeometryEntity.DEFAULT_N_POLY_APPROX,\n    ):\n        \"\"\"Initialize a Circle geometrical object\n\n        Args:\n            center (NDArray): center 2D point\n            radius (float): radius value\n            n_points_polygonal_approx (int, optional): number of points to be used in\n                the polygonal approximation of the circle. Defaults to\n                ContinuousGeometryEntity.DEFAULT_N_POINTS_POLYGONAL_APPROX.\n        \"\"\"\n        super().__init__(\n            foci1=center,\n            foci2=center,\n            semi_major_axis=radius,\n            n_points_polygonal_approx=n_points_polygonal_approx,\n        )\n        self.center = np.asarray(center)\n        self.radius = radius\n        self.update_polyapprox()\n\n    # --------------------------------- PROPERTIES ------------------------------------\n\n    @property\n    def perimeter(self) -&gt; float:\n        \"\"\"Perimeter of the circle\n\n        Returns:\n            float: perimeter value\n        \"\"\"\n        return 2 * math.pi * self.radius\n\n    @property\n    def centroid(self) -&gt; NDArray:\n        \"\"\"Center of the circle\n\n        Returns:\n            float: center 2D point\n        \"\"\"\n        return self.center\n\n    @property\n    def shapely_surface(self) -&gt; SPolygon:\n        \"\"\"Returns the Shapely.Polygon as an surface representation of the Circle.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html\n\n        Returns:\n            Polygon: shapely.Polygon object\n        \"\"\"\n        return SPolygon(self.polyaprox.asarray, holes=None)\n\n    @property\n    def shapely_edges(self) -&gt; LinearRing:\n        \"\"\"Returns the Shapely.LinearRing as a curve representation of the Circle.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.LinearRing.html\n\n        Returns:\n            LinearRing: shapely.LinearRing object\n        \"\"\"\n        return LinearRing(coordinates=self.polyaprox.asarray)\n\n    def polygonal_approx(self, n_points: int, is_cast_int: bool = False) -&gt; Polygon:\n        \"\"\"Generate a Polygon object that is an approximation of the circle\n        as a discrete geometrical object made up of only points and segments.\n\n        Args:\n            n_points (int): number of points that make up the circle\n                polygonal approximation\n            is_cast_int (bool): whether to cast to int the points coordinates or\n                not. Defaults to False\n\n        Returns:\n            Polygon: Polygon representing the circle as a succession of n points\n\n        \"\"\"\n        points = []\n        for theta in np.linspace(0, 2 * math.pi, n_points):\n            x = self.center[0] + self.radius * math.cos(theta)\n            y = self.center[1] + self.radius * math.sin(theta)\n            points.append([x, y])\n\n        poly = Polygon(points=np.asarray(points), is_cast_int=is_cast_int)\n        return poly\n\n    def curvature(self, point: Optional[NDArray] = None) -&gt; float:\n        \"\"\"Curvature of circle is a constant and does not depend on a position of\n        a point\n\n        Returns:\n            float: curvature value\n        \"\"\"\n        return 1 / self.radius\n\n    @property\n    def xmax(self) -&gt; float:\n        \"\"\"Get the maximum X coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n        return self.center[0] + self.radius\n\n    @property\n    def xmin(self) -&gt; float:\n        \"\"\"Get the minimum X coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n        return self.center[0] - self.radius\n\n    @property\n    def ymax(self) -&gt; float:\n        \"\"\"Get the maximum Y coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n        return self.center[1] + self.radius\n\n    @property\n    def ymin(self) -&gt; float:\n        \"\"\"Get the minimum Y coordinate of the geometry entity\n\n        Returns:\n            NDArray: 2D point\n        \"\"\"\n        return self.center[1] - self.radius\n\n    @property\n    def is_circle(self) -&gt; bool:\n        \"\"\"Check if the circle is a circle\n\n        Returns:\n            bool: True if circle else False\n        \"\"\"\n        return True\n\n    # ---------------------------- MODIFICATION METHODS -------------------------------\n\n    def rotate(\n        self,\n        angle: float,\n        is_degree: bool = False,\n        is_clockwise: bool = True,\n        pivot: Optional[NDArray] = None,\n    ) -&gt; Self:\n        \"\"\"Rotate the circle around a pivot point.\n\n        Args:\n            angle (float): angle by which to rotate the circle\n            is_degree (bool, optional): whether the angle is in degrees.\n                Defaults to False.\n            is_clockwise (bool, optional): whether the rotation is clockwise.\n                Defaults to True.\n            pivot (Optional[NDArray], optional): pivot point around which to rotate.\n                Defaults to None.\n\n        Returns:\n            Self: rotated circle object\n        \"\"\"\n        if pivot is None:\n            # If no pivot is given, the circle is rotated around its center\n            # and thus is not modified\n            return self\n\n        self.center = rotate_2d_points(\n            points=self.center,\n            angle=angle,\n            is_degree=is_degree,\n            is_clockwise=is_clockwise,\n            pivot=pivot,\n        )\n        self.update_polyapprox()\n        return self\n\n    def shift(self, vector: NDArray) -&gt; Self:\n        \"\"\"Shift the circle by a given vector.\n\n        Args:\n            vector (NDArray): 2D vector by which to shift the circle\n\n        Returns:\n            Self: shifted circle object\n        \"\"\"\n        vector = assert_transform_shift_vector(vector=vector)\n        self.center += vector\n        self.update_polyapprox()\n        return self\n\n    def normalize(self, x: float, y: float) -&gt; Self:\n        \"\"\"Normalize the circle by dividing the points by a norm on the x and y\n        coordinates. This does not change the circle radius.\n\n        Args:\n            x (float): x coordinate norm\n            y (float): y coordinate norm\n\n        Returns:\n            Self: normalized circle object\n        \"\"\"\n        self.center = self.center / np.array([x, y])\n        self.update_polyapprox()\n        return self\n\n    # ------------------------------- CLASSIC METHODS ---------------------------------\n\n    def copy(self) -&gt; Self:\n        \"\"\"Copy the circle object\n\n        Returns:\n            Self: copied circle object\n        \"\"\"\n        return type(self)(\n            center=self.center,\n            radius=self.radius,\n            n_points_polygonal_approx=self.n_points_polygonal_approx,\n        )\n\n    def __str__(self) -&gt; str:\n        return f\"Circle(center={self.center}, radius={self.radius})\"\n\n    def __repr__(self):\n        return f\"Circle(center={self.center}, radius={self.radius})\"\n</code></pre>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.centroid","title":"<code>centroid</code>  <code>property</code>","text":"<p>Center of the circle</p> <p>Returns:</p> Name Type Description <code>float</code> <code>NDArray</code> <p>center 2D point</p>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.is_circle","title":"<code>is_circle</code>  <code>property</code>","text":"<p>Check if the circle is a circle</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if circle else False</p>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.perimeter","title":"<code>perimeter</code>  <code>property</code>","text":"<p>Perimeter of the circle</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>perimeter value</p>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.shapely_edges","title":"<code>shapely_edges</code>  <code>property</code>","text":"<p>Returns the Shapely.LinearRing as a curve representation of the Circle. See https://shapely.readthedocs.io/en/stable/reference/shapely.LinearRing.html</p> <p>Returns:</p> Name Type Description <code>LinearRing</code> <code>LinearRing</code> <p>shapely.LinearRing object</p>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.shapely_surface","title":"<code>shapely_surface</code>  <code>property</code>","text":"<p>Returns the Shapely.Polygon as an surface representation of the Circle. See https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html</p> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>shapely.Polygon object</p>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.xmax","title":"<code>xmax</code>  <code>property</code>","text":"<p>Get the maximum X coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.xmin","title":"<code>xmin</code>  <code>property</code>","text":"<p>Get the minimum X coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.ymax","title":"<code>ymax</code>  <code>property</code>","text":"<p>Get the maximum Y coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.ymin","title":"<code>ymin</code>  <code>property</code>","text":"<p>Get the minimum Y coordinate of the geometry entity</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>float</code> <p>2D point</p>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.__init__","title":"<code>__init__(center, radius, n_points_polygonal_approx=ContinuousGeometryEntity.DEFAULT_N_POLY_APPROX)</code>","text":"<p>Initialize a Circle geometrical object</p> <p>Parameters:</p> Name Type Description Default <code>center</code> <code>NDArray</code> <p>center 2D point</p> required <code>radius</code> <code>float</code> <p>radius value</p> required <code>n_points_polygonal_approx</code> <code>int</code> <p>number of points to be used in the polygonal approximation of the circle. Defaults to ContinuousGeometryEntity.DEFAULT_N_POINTS_POLYGONAL_APPROX.</p> <code>DEFAULT_N_POLY_APPROX</code> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>def __init__(\n    self,\n    center: NDArray | list,\n    radius: float,\n    n_points_polygonal_approx: int = ContinuousGeometryEntity.DEFAULT_N_POLY_APPROX,\n):\n    \"\"\"Initialize a Circle geometrical object\n\n    Args:\n        center (NDArray): center 2D point\n        radius (float): radius value\n        n_points_polygonal_approx (int, optional): number of points to be used in\n            the polygonal approximation of the circle. Defaults to\n            ContinuousGeometryEntity.DEFAULT_N_POINTS_POLYGONAL_APPROX.\n    \"\"\"\n    super().__init__(\n        foci1=center,\n        foci2=center,\n        semi_major_axis=radius,\n        n_points_polygonal_approx=n_points_polygonal_approx,\n    )\n    self.center = np.asarray(center)\n    self.radius = radius\n    self.update_polyapprox()\n</code></pre>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.copy","title":"<code>copy()</code>","text":"<p>Copy the circle object</p> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>copied circle object</p> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>def copy(self) -&gt; Self:\n    \"\"\"Copy the circle object\n\n    Returns:\n        Self: copied circle object\n    \"\"\"\n    return type(self)(\n        center=self.center,\n        radius=self.radius,\n        n_points_polygonal_approx=self.n_points_polygonal_approx,\n    )\n</code></pre>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.curvature","title":"<code>curvature(point=None)</code>","text":"<p>Curvature of circle is a constant and does not depend on a position of a point</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>curvature value</p> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>def curvature(self, point: Optional[NDArray] = None) -&gt; float:\n    \"\"\"Curvature of circle is a constant and does not depend on a position of\n    a point\n\n    Returns:\n        float: curvature value\n    \"\"\"\n    return 1 / self.radius\n</code></pre>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.normalize","title":"<code>normalize(x, y)</code>","text":"<p>Normalize the circle by dividing the points by a norm on the x and y coordinates. This does not change the circle radius.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>x coordinate norm</p> required <code>y</code> <code>float</code> <p>y coordinate norm</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>normalized circle object</p> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>def normalize(self, x: float, y: float) -&gt; Self:\n    \"\"\"Normalize the circle by dividing the points by a norm on the x and y\n    coordinates. This does not change the circle radius.\n\n    Args:\n        x (float): x coordinate norm\n        y (float): y coordinate norm\n\n    Returns:\n        Self: normalized circle object\n    \"\"\"\n    self.center = self.center / np.array([x, y])\n    self.update_polyapprox()\n    return self\n</code></pre>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.polygonal_approx","title":"<code>polygonal_approx(n_points, is_cast_int=False)</code>","text":"<p>Generate a Polygon object that is an approximation of the circle as a discrete geometrical object made up of only points and segments.</p> <p>Parameters:</p> Name Type Description Default <code>n_points</code> <code>int</code> <p>number of points that make up the circle polygonal approximation</p> required <code>is_cast_int</code> <code>bool</code> <p>whether to cast to int the points coordinates or not. Defaults to False</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>Polygon representing the circle as a succession of n points</p> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>def polygonal_approx(self, n_points: int, is_cast_int: bool = False) -&gt; Polygon:\n    \"\"\"Generate a Polygon object that is an approximation of the circle\n    as a discrete geometrical object made up of only points and segments.\n\n    Args:\n        n_points (int): number of points that make up the circle\n            polygonal approximation\n        is_cast_int (bool): whether to cast to int the points coordinates or\n            not. Defaults to False\n\n    Returns:\n        Polygon: Polygon representing the circle as a succession of n points\n\n    \"\"\"\n    points = []\n    for theta in np.linspace(0, 2 * math.pi, n_points):\n        x = self.center[0] + self.radius * math.cos(theta)\n        y = self.center[1] + self.radius * math.sin(theta)\n        points.append([x, y])\n\n    poly = Polygon(points=np.asarray(points), is_cast_int=is_cast_int)\n    return poly\n</code></pre>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.rotate","title":"<code>rotate(angle, is_degree=False, is_clockwise=True, pivot=None)</code>","text":"<p>Rotate the circle around a pivot point.</p> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>float</code> <p>angle by which to rotate the circle</p> required <code>is_degree</code> <code>bool</code> <p>whether the angle is in degrees. Defaults to False.</p> <code>False</code> <code>is_clockwise</code> <code>bool</code> <p>whether the rotation is clockwise. Defaults to True.</p> <code>True</code> <code>pivot</code> <code>Optional[NDArray]</code> <p>pivot point around which to rotate. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>rotated circle object</p> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>def rotate(\n    self,\n    angle: float,\n    is_degree: bool = False,\n    is_clockwise: bool = True,\n    pivot: Optional[NDArray] = None,\n) -&gt; Self:\n    \"\"\"Rotate the circle around a pivot point.\n\n    Args:\n        angle (float): angle by which to rotate the circle\n        is_degree (bool, optional): whether the angle is in degrees.\n            Defaults to False.\n        is_clockwise (bool, optional): whether the rotation is clockwise.\n            Defaults to True.\n        pivot (Optional[NDArray], optional): pivot point around which to rotate.\n            Defaults to None.\n\n    Returns:\n        Self: rotated circle object\n    \"\"\"\n    if pivot is None:\n        # If no pivot is given, the circle is rotated around its center\n        # and thus is not modified\n        return self\n\n    self.center = rotate_2d_points(\n        points=self.center,\n        angle=angle,\n        is_degree=is_degree,\n        is_clockwise=is_clockwise,\n        pivot=pivot,\n    )\n    self.update_polyapprox()\n    return self\n</code></pre>"},{"location":"api/geometry/continuous/circle/#otary.geometry.continuous.shape.circle.Circle.shift","title":"<code>shift(vector)</code>","text":"<p>Shift the circle by a given vector.</p> <p>Parameters:</p> Name Type Description Default <code>vector</code> <code>NDArray</code> <p>2D vector by which to shift the circle</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>shifted circle object</p> Source code in <code>otary/geometry/continuous/shape/circle.py</code> <pre><code>def shift(self, vector: NDArray) -&gt; Self:\n    \"\"\"Shift the circle by a given vector.\n\n    Args:\n        vector (NDArray): 2D vector by which to shift the circle\n\n    Returns:\n        Self: shifted circle object\n    \"\"\"\n    vector = assert_transform_shift_vector(vector=vector)\n    self.center += vector\n    self.update_polyapprox()\n    return self\n</code></pre>"},{"location":"api/geometry/continuous/ellipse/","title":"Ellipse","text":"<p>Ellipse Geometric Object</p>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse","title":"<code>Ellipse</code>","text":"<p>               Bases: <code>ContinuousGeometryEntity</code></p> <p>Ellipse geometrical object</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>class Ellipse(ContinuousGeometryEntity):\n    \"\"\"Ellipse geometrical object\"\"\"\n\n    def __init__(\n        self,\n        foci1: NDArray | list,\n        foci2: NDArray | list,\n        semi_major_axis: float,\n        n_points_polygonal_approx: int = ContinuousGeometryEntity.DEFAULT_N_POLY_APPROX,\n    ):\n        \"\"\"Initialize a Ellipse geometrical object\n\n        Args:\n            foci1 (NDArray | list): first focal 2D point\n            foci2 (NDArray | list): second focal 2D point\n            semi_major_axis (float): semi major axis value\n            n_points_polygonal_approx (int, optional): number of points to be used in\n                the polygonal approximation.\n                Defaults to ContinuousGeometryEntity.DEFAULT_N_POINTS_POLYGONAL_APPROX.\n        \"\"\"\n        super().__init__(n_points_polygonal_approx=n_points_polygonal_approx)\n        self.foci1 = np.asarray(foci1)\n        self.foci2 = np.asarray(foci2)\n        self.semi_major_axis = semi_major_axis  # also called \"a\" usually\n        self.__assert_ellipse()\n\n        if type(self) is Ellipse:  # pylint: disable=unidiomatic-typecheck\n            # pylint check is wrong here since we want it to be ONLY an Ellipse\n            # not a circle. isinstance() check make children classes return True\n            # to avoid computation in circle class instantiation\n            # since the center attribute is not defined in the Circle class yet\n            self.update_polyapprox()\n\n    def __assert_ellipse(self) -&gt; None:\n        \"\"\"Assert the parameters of the ellipse.\n        If the parameters proposed do not make up a ellipse raise an error.\n        \"\"\"\n        if self.semi_major_axis &lt;= self.linear_eccentricity:\n            raise ValueError(\n                f\"The semi major-axis (a={self.semi_major_axis}) can not be smaller \"\n                f\"than the linear eccentricity (c={self.linear_eccentricity}). \"\n                \"The ellipse is thus not valid. Please increase the semi major-axis.\"\n            )\n\n    # --------------------------------- PROPERTIES ------------------------------------\n\n    @property\n    def centroid(self) -&gt; NDArray:\n        \"\"\"Compute the center point of the ellipse\n\n        Returns:\n            NDArray: 2D point defining the center of the ellipse\n        \"\"\"\n        return (self.foci1 + self.foci2) / 2\n\n    @property\n    def semi_minor_axis(self) -&gt; float:\n        \"\"\"Computed semi minor axis (also called b usually)\n\n        Returns:\n            float: _description_\n        \"\"\"\n        return math.sqrt(self.semi_major_axis**2 - self.linear_eccentricity**2)\n\n    @property\n    def linear_eccentricity(self) -&gt; float:\n        \"\"\"Distance from any focal point to the center\n\n        Returns:\n            float: linear eccentricity value\n        \"\"\"\n        return float(np.linalg.norm(self.foci2 - self.foci1) / 2)\n\n    @property\n    def focal_distance(self) -&gt; float:\n        \"\"\"Distance from any focal point to the center\n\n        Returns:\n            float: focal distance value\n        \"\"\"\n        return self.linear_eccentricity\n\n    @property\n    def eccentricity(self) -&gt; float:\n        \"\"\"Eccentricity value of the ellipse\n\n        Returns:\n            float: eccentricity value\n        \"\"\"\n        return self.linear_eccentricity / self.semi_major_axis\n\n    @property\n    def h(self) -&gt; float:\n        \"\"\"h is a common ellipse value used in calculation and kind of\n        represents the eccentricity of the ellipse but in another perspective.\n\n        Circle would have a h = 0. A really stretch out ellipse would have a h value\n        close o 1\n\n        Returns:\n            float: h value\n        \"\"\"\n        return (self.semi_major_axis - self.semi_minor_axis) ** 2 / (\n            self.semi_major_axis + self.semi_minor_axis\n        ) ** 2\n\n    @property\n    def area(self) -&gt; float:\n        \"\"\"Compute the area of the ellipse\n\n        Returns:\n            float: area value\n        \"\"\"\n        return math.pi * self.semi_major_axis * self.semi_minor_axis\n\n    @property\n    def perimeter(self) -&gt; float:\n        \"\"\"Compute the perimeter of the ellipse.\n        Beware this is only an approximation due to the computation of both pi\n        and the James Ivory's infinite serie.\n\n        Returns:\n            float: perimeter value\n        \"\"\"\n        return self.perimeter_approx()\n\n    @property\n    def shapely_surface(self) -&gt; SPolygon:\n        \"\"\"Returns the Shapely.Polygon as an surface representation of the Ellipse.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html\n\n        Returns:\n            Polygon: shapely.Polygon object\n        \"\"\"\n        return SPolygon(self.polyaprox.asarray, holes=None)\n\n    @property\n    def shapely_edges(self) -&gt; LinearRing:\n        \"\"\"Returns the Shapely.LinearRing as a curve representation of the Ellipse.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.LinearRing.html\n\n        Returns:\n            LinearRing: shapely.LinearRing object\n        \"\"\"\n        return LinearRing(coordinates=self.polyaprox.asarray)\n\n    @property\n    def is_circle(self) -&gt; bool:\n        \"\"\"Check if the ellipse is a circle\n\n        Returns:\n            bool: True if circle else False\n        \"\"\"\n        return self.semi_major_axis == self.semi_minor_axis\n\n    # ---------------------------- MODIFICATION METHODS -------------------------------\n\n    def rotate(\n        self,\n        angle: float,\n        is_degree: bool = False,\n        is_clockwise: bool = True,\n        pivot: Optional[NDArray] = None,\n    ) -&gt; Self:\n        \"\"\"Rotate the ellipse around a pivot point.\n\n        Args:\n            angle (float): angle to rotate the ellipse\n            is_degree (bool, optional): whether the angle is in degrees.\n                Defaults to False.\n            is_clockwise (bool, optional): whether the rotation is clockwise.\n                Defaults to True.\n            pivot (Optional[NDArray], optional): pivot point to rotate around.\n                Defaults to None.\n\n        Returns:\n            Self: rotated ellipse object\n        \"\"\"\n        if is_degree:\n            angle = math.radians(angle)\n        if is_clockwise:\n            angle = -angle\n\n        if pivot is None:\n            pivot = self.centroid\n\n        self.foci1 = rotate_2d_points(self.foci1, angle, pivot)\n        self.foci2 = rotate_2d_points(self.foci2, angle, pivot)\n        self.update_polyapprox()\n        return self\n\n    def shift(self, vector: NDArray) -&gt; Self:\n        \"\"\"Shift the ellipse by a given vector.\n\n        Args:\n            vector (NDArray): vector to shift the ellipse\n\n        Returns:\n            Self: shifted ellipse object\n        \"\"\"\n        assert_transform_shift_vector(vector)\n        self.foci1 += vector\n        self.foci2 += vector\n        self.update_polyapprox()\n        return self\n\n    def normalize(self, x: float, y: float) -&gt; Self:\n        \"\"\"Normalize the ellipse to a given bounding box.\n\n        Args:\n            x (float): width of the bounding box\n            y (float): height of the bounding box\n\n        Returns:\n            Self: normalized ellipse object\n        \"\"\"\n        factor = np.array([x, y])\n        self.foci1 = self.foci1 / factor\n        self.foci2 = self.foci2 / factor\n\n        self.update_polyapprox()\n        return self\n\n    # ------------------------------- CLASSIC METHODS ---------------------------------\n\n    def perimeter_approx(self, n_terms: int = 5, is_ramanujan: bool = False) -&gt; float:\n        \"\"\"Perimeter approximation of the ellipse using the James Ivory\n        infinite serie. In the case of the circle this always converges to the\n        exact value of the circumference no matter the number of terms.\n\n        See: https://en.wikipedia.org/wiki/Ellipse#Circumference\n\n        Args:\n            n_terms (int, optional): number of n first terms to calculate and\n                add up from the infinite series. Defaults to 5.\n            is_ramanujan (bool, optional): whether to use the Ramanujan's best\n                approximation.\n\n        Returns:\n            float: circumference approximation of the ellipse\n        \"\"\"\n        if is_ramanujan:\n            return (\n                math.pi\n                * (self.semi_major_axis + self.semi_minor_axis)\n                * (1 + (3 * self.h) / (10 + math.sqrt(4 - 3 * self.h)))\n            )\n\n        _sum = 1  # pre-calculated term n=0 equal 1\n        for n in range(1, n_terms):  # goes from term n=1 to n=(n_terms-1)\n            _sum += (((1 / ((2 * n - 1) * (4**n))) * math.comb(2 * n, n)) ** 2) * (\n                self.h**n\n            )\n\n        return math.pi * (self.semi_major_axis + self.semi_minor_axis) * _sum\n\n    def polygonal_approx(self, n_points: int, is_cast_int: bool = False) -&gt; Polygon:\n        \"\"\"Generate apolygonal approximation of the ellipse.\n\n        The way is done is the following:\n        1. suppose the ellipse centered at the origin\n        2. suppose the ellipse semi major axis to be parallel with the x-axis\n        3. compute pairs of (x, y) points that belong to the ellipse using the\n            parametric equation of the ellipse.\n        4. shift all points by the same shift as the center to origin\n        5. rotate using the ellipse center pivot point\n\n        Args:\n            n_points (int): number of points that make up the ellipse\n                polygonal approximation\n            is_cast_int (bool): whether to cast to int the points coordinates or\n                not. Defaults to False\n\n        Returns:\n            Polygon: Polygon representing the ellipse as a succession of n points\n        \"\"\"\n        points = []\n        for theta in np.linspace(0, 2 * math.pi, n_points):\n            x = self.semi_major_axis * math.cos(theta)\n            y = self.semi_minor_axis * math.sin(theta)\n            points.append([x, y])\n\n        poly = (\n            Polygon(points=np.asarray(points), is_cast_int=False)\n            .shift(vector=self.centroid)\n            .rotate(angle=self.angle())\n        )\n\n        if is_cast_int:\n            poly.asarray = poly.asarray.astype(int)\n\n        return poly\n\n    def angle(self, degree: bool = False, is_y_axis_down: bool = False) -&gt; float:\n        \"\"\"Angle of the ellipse\n\n        Args:\n            degree (bool, optional): whether to output angle in degree,\n                Defaults to False meaning radians.\n            is_y_axis_down (bool, optional): whether the y axis is down.\n                Defaults to False.\n\n        Returns:\n            float: angle value\n        \"\"\"\n        seg = Segment([self.foci1, self.foci2])\n        return seg.slope_angle(degree=degree, is_y_axis_down=is_y_axis_down)\n\n    def curvature(self, point: NDArray) -&gt; float:\n        r\"\"\"Computes the curvature of a point on the ellipse.\n\n        Equation is based on the following where a is semi major and b is minor axis.\n\n        \\kappa = \\frac{1}{a^2 b^2}\n            \\left(\n                \\frac{x^2}{a^4} + \\frac{y^2}{b^4}\n            \\right)^{-\\frac{3}{2}}\n\n        Args:\n            point (NDArray): point on the ellipse\n\n        Returns:\n            float: curvature of the point\n        \"\"\"\n        # TODO check that the point is on the ellipse\n        x, y = point\n        a = self.semi_major_axis\n        b = self.semi_minor_axis\n\n        numerator = 1 / (a * b) ** 2\n        inner = (x**2) / (a**4) + (y**2) / (b**4)\n        curvature = numerator * inner ** (-1.5)\n\n        return curvature\n\n    def copy(self) -&gt; Self:\n        \"\"\"Copy the current ellipse object\n\n        Returns:\n            Self: copied ellipse object\n        \"\"\"\n        return type(self)(\n            foci1=self.foci1,\n            foci2=self.foci2,\n            semi_major_axis=self.semi_major_axis,\n            n_points_polygonal_approx=self.n_points_polygonal_approx,\n        )\n\n    def enclosing_oriented_bbox(self) -&gt; Rectangle:\n        \"\"\"\n        Enclosing oriented bounding box.\n        Manage the case where the ellipse is a circle and return the enclosing\n        axis-aligned bounding box in that case.\n\n        Returns:\n            Rectangle: Enclosing oriented bounding box\n        \"\"\"\n        if self.is_circle:\n            # In a circle the enclosing oriented bounding box could be in any\n            # direction. Thus we return the enclosing axis-aligned bounding box\n            # by default as a Rectangle object\n            return Rectangle(self.enclosing_axis_aligned_bbox().asarray)\n        return super().enclosing_oriented_bbox()\n\n    def __str__(self) -&gt; str:\n        return (\n            f\"Ellipse(foci1={self.foci1}, foci2={self.foci2}, a={self.semi_major_axis})\"\n        )\n\n    def __repr__(self) -&gt; str:\n        return (\n            f\"Ellipse(foci1={self.foci1}, foci2={self.foci2}, a={self.semi_major_axis})\"\n        )\n</code></pre>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.area","title":"<code>area</code>  <code>property</code>","text":"<p>Compute the area of the ellipse</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>area value</p>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.centroid","title":"<code>centroid</code>  <code>property</code>","text":"<p>Compute the center point of the ellipse</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>2D point defining the center of the ellipse</p>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.eccentricity","title":"<code>eccentricity</code>  <code>property</code>","text":"<p>Eccentricity value of the ellipse</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>eccentricity value</p>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.focal_distance","title":"<code>focal_distance</code>  <code>property</code>","text":"<p>Distance from any focal point to the center</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>focal distance value</p>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.h","title":"<code>h</code>  <code>property</code>","text":"<p>h is a common ellipse value used in calculation and kind of represents the eccentricity of the ellipse but in another perspective.</p> <p>Circle would have a h = 0. A really stretch out ellipse would have a h value close o 1</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>h value</p>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.is_circle","title":"<code>is_circle</code>  <code>property</code>","text":"<p>Check if the ellipse is a circle</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if circle else False</p>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.linear_eccentricity","title":"<code>linear_eccentricity</code>  <code>property</code>","text":"<p>Distance from any focal point to the center</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>linear eccentricity value</p>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.perimeter","title":"<code>perimeter</code>  <code>property</code>","text":"<p>Compute the perimeter of the ellipse. Beware this is only an approximation due to the computation of both pi and the James Ivory's infinite serie.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>perimeter value</p>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.semi_minor_axis","title":"<code>semi_minor_axis</code>  <code>property</code>","text":"<p>Computed semi minor axis (also called b usually)</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>description</p>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.shapely_edges","title":"<code>shapely_edges</code>  <code>property</code>","text":"<p>Returns the Shapely.LinearRing as a curve representation of the Ellipse. See https://shapely.readthedocs.io/en/stable/reference/shapely.LinearRing.html</p> <p>Returns:</p> Name Type Description <code>LinearRing</code> <code>LinearRing</code> <p>shapely.LinearRing object</p>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.shapely_surface","title":"<code>shapely_surface</code>  <code>property</code>","text":"<p>Returns the Shapely.Polygon as an surface representation of the Ellipse. See https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html</p> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>shapely.Polygon object</p>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.__assert_ellipse","title":"<code>__assert_ellipse()</code>","text":"<p>Assert the parameters of the ellipse. If the parameters proposed do not make up a ellipse raise an error.</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def __assert_ellipse(self) -&gt; None:\n    \"\"\"Assert the parameters of the ellipse.\n    If the parameters proposed do not make up a ellipse raise an error.\n    \"\"\"\n    if self.semi_major_axis &lt;= self.linear_eccentricity:\n        raise ValueError(\n            f\"The semi major-axis (a={self.semi_major_axis}) can not be smaller \"\n            f\"than the linear eccentricity (c={self.linear_eccentricity}). \"\n            \"The ellipse is thus not valid. Please increase the semi major-axis.\"\n        )\n</code></pre>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.__init__","title":"<code>__init__(foci1, foci2, semi_major_axis, n_points_polygonal_approx=ContinuousGeometryEntity.DEFAULT_N_POLY_APPROX)</code>","text":"<p>Initialize a Ellipse geometrical object</p> <p>Parameters:</p> Name Type Description Default <code>foci1</code> <code>NDArray | list</code> <p>first focal 2D point</p> required <code>foci2</code> <code>NDArray | list</code> <p>second focal 2D point</p> required <code>semi_major_axis</code> <code>float</code> <p>semi major axis value</p> required <code>n_points_polygonal_approx</code> <code>int</code> <p>number of points to be used in the polygonal approximation. Defaults to ContinuousGeometryEntity.DEFAULT_N_POINTS_POLYGONAL_APPROX.</p> <code>DEFAULT_N_POLY_APPROX</code> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def __init__(\n    self,\n    foci1: NDArray | list,\n    foci2: NDArray | list,\n    semi_major_axis: float,\n    n_points_polygonal_approx: int = ContinuousGeometryEntity.DEFAULT_N_POLY_APPROX,\n):\n    \"\"\"Initialize a Ellipse geometrical object\n\n    Args:\n        foci1 (NDArray | list): first focal 2D point\n        foci2 (NDArray | list): second focal 2D point\n        semi_major_axis (float): semi major axis value\n        n_points_polygonal_approx (int, optional): number of points to be used in\n            the polygonal approximation.\n            Defaults to ContinuousGeometryEntity.DEFAULT_N_POINTS_POLYGONAL_APPROX.\n    \"\"\"\n    super().__init__(n_points_polygonal_approx=n_points_polygonal_approx)\n    self.foci1 = np.asarray(foci1)\n    self.foci2 = np.asarray(foci2)\n    self.semi_major_axis = semi_major_axis  # also called \"a\" usually\n    self.__assert_ellipse()\n\n    if type(self) is Ellipse:  # pylint: disable=unidiomatic-typecheck\n        # pylint check is wrong here since we want it to be ONLY an Ellipse\n        # not a circle. isinstance() check make children classes return True\n        # to avoid computation in circle class instantiation\n        # since the center attribute is not defined in the Circle class yet\n        self.update_polyapprox()\n</code></pre>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.angle","title":"<code>angle(degree=False, is_y_axis_down=False)</code>","text":"<p>Angle of the ellipse</p> <p>Parameters:</p> Name Type Description Default <code>degree</code> <code>bool</code> <p>whether to output angle in degree, Defaults to False meaning radians.</p> <code>False</code> <code>is_y_axis_down</code> <code>bool</code> <p>whether the y axis is down. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>angle value</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def angle(self, degree: bool = False, is_y_axis_down: bool = False) -&gt; float:\n    \"\"\"Angle of the ellipse\n\n    Args:\n        degree (bool, optional): whether to output angle in degree,\n            Defaults to False meaning radians.\n        is_y_axis_down (bool, optional): whether the y axis is down.\n            Defaults to False.\n\n    Returns:\n        float: angle value\n    \"\"\"\n    seg = Segment([self.foci1, self.foci2])\n    return seg.slope_angle(degree=degree, is_y_axis_down=is_y_axis_down)\n</code></pre>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.copy","title":"<code>copy()</code>","text":"<p>Copy the current ellipse object</p> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>copied ellipse object</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def copy(self) -&gt; Self:\n    \"\"\"Copy the current ellipse object\n\n    Returns:\n        Self: copied ellipse object\n    \"\"\"\n    return type(self)(\n        foci1=self.foci1,\n        foci2=self.foci2,\n        semi_major_axis=self.semi_major_axis,\n        n_points_polygonal_approx=self.n_points_polygonal_approx,\n    )\n</code></pre>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.curvature","title":"<code>curvature(point)</code>","text":"<p>Computes the curvature of a point on the ellipse.</p> <p>Equation is based on the following where a is semi major and b is minor axis.</p> <p>\\kappa = \\frac{1}{a^2 b^2}     \\left(         \\frac{x^2}{a^4} + \\frac{y^2}{b^4}     \\right)^{-\\frac{3}{2}}</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>point on the ellipse</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>curvature of the point</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def curvature(self, point: NDArray) -&gt; float:\n    r\"\"\"Computes the curvature of a point on the ellipse.\n\n    Equation is based on the following where a is semi major and b is minor axis.\n\n    \\kappa = \\frac{1}{a^2 b^2}\n        \\left(\n            \\frac{x^2}{a^4} + \\frac{y^2}{b^4}\n        \\right)^{-\\frac{3}{2}}\n\n    Args:\n        point (NDArray): point on the ellipse\n\n    Returns:\n        float: curvature of the point\n    \"\"\"\n    # TODO check that the point is on the ellipse\n    x, y = point\n    a = self.semi_major_axis\n    b = self.semi_minor_axis\n\n    numerator = 1 / (a * b) ** 2\n    inner = (x**2) / (a**4) + (y**2) / (b**4)\n    curvature = numerator * inner ** (-1.5)\n\n    return curvature\n</code></pre>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.enclosing_oriented_bbox","title":"<code>enclosing_oriented_bbox()</code>","text":"<p>Enclosing oriented bounding box. Manage the case where the ellipse is a circle and return the enclosing axis-aligned bounding box in that case.</p> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Rectangle</code> <p>Enclosing oriented bounding box</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def enclosing_oriented_bbox(self) -&gt; Rectangle:\n    \"\"\"\n    Enclosing oriented bounding box.\n    Manage the case where the ellipse is a circle and return the enclosing\n    axis-aligned bounding box in that case.\n\n    Returns:\n        Rectangle: Enclosing oriented bounding box\n    \"\"\"\n    if self.is_circle:\n        # In a circle the enclosing oriented bounding box could be in any\n        # direction. Thus we return the enclosing axis-aligned bounding box\n        # by default as a Rectangle object\n        return Rectangle(self.enclosing_axis_aligned_bbox().asarray)\n    return super().enclosing_oriented_bbox()\n</code></pre>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.normalize","title":"<code>normalize(x, y)</code>","text":"<p>Normalize the ellipse to a given bounding box.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float</code> <p>width of the bounding box</p> required <code>y</code> <code>float</code> <p>height of the bounding box</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>normalized ellipse object</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def normalize(self, x: float, y: float) -&gt; Self:\n    \"\"\"Normalize the ellipse to a given bounding box.\n\n    Args:\n        x (float): width of the bounding box\n        y (float): height of the bounding box\n\n    Returns:\n        Self: normalized ellipse object\n    \"\"\"\n    factor = np.array([x, y])\n    self.foci1 = self.foci1 / factor\n    self.foci2 = self.foci2 / factor\n\n    self.update_polyapprox()\n    return self\n</code></pre>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.perimeter_approx","title":"<code>perimeter_approx(n_terms=5, is_ramanujan=False)</code>","text":"<p>Perimeter approximation of the ellipse using the James Ivory infinite serie. In the case of the circle this always converges to the exact value of the circumference no matter the number of terms.</p> <p>See: https://en.wikipedia.org/wiki/Ellipse#Circumference</p> <p>Parameters:</p> Name Type Description Default <code>n_terms</code> <code>int</code> <p>number of n first terms to calculate and add up from the infinite series. Defaults to 5.</p> <code>5</code> <code>is_ramanujan</code> <code>bool</code> <p>whether to use the Ramanujan's best approximation.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>circumference approximation of the ellipse</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def perimeter_approx(self, n_terms: int = 5, is_ramanujan: bool = False) -&gt; float:\n    \"\"\"Perimeter approximation of the ellipse using the James Ivory\n    infinite serie. In the case of the circle this always converges to the\n    exact value of the circumference no matter the number of terms.\n\n    See: https://en.wikipedia.org/wiki/Ellipse#Circumference\n\n    Args:\n        n_terms (int, optional): number of n first terms to calculate and\n            add up from the infinite series. Defaults to 5.\n        is_ramanujan (bool, optional): whether to use the Ramanujan's best\n            approximation.\n\n    Returns:\n        float: circumference approximation of the ellipse\n    \"\"\"\n    if is_ramanujan:\n        return (\n            math.pi\n            * (self.semi_major_axis + self.semi_minor_axis)\n            * (1 + (3 * self.h) / (10 + math.sqrt(4 - 3 * self.h)))\n        )\n\n    _sum = 1  # pre-calculated term n=0 equal 1\n    for n in range(1, n_terms):  # goes from term n=1 to n=(n_terms-1)\n        _sum += (((1 / ((2 * n - 1) * (4**n))) * math.comb(2 * n, n)) ** 2) * (\n            self.h**n\n        )\n\n    return math.pi * (self.semi_major_axis + self.semi_minor_axis) * _sum\n</code></pre>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.polygonal_approx","title":"<code>polygonal_approx(n_points, is_cast_int=False)</code>","text":"<p>Generate apolygonal approximation of the ellipse.</p> <p>The way is done is the following: 1. suppose the ellipse centered at the origin 2. suppose the ellipse semi major axis to be parallel with the x-axis 3. compute pairs of (x, y) points that belong to the ellipse using the     parametric equation of the ellipse. 4. shift all points by the same shift as the center to origin 5. rotate using the ellipse center pivot point</p> <p>Parameters:</p> Name Type Description Default <code>n_points</code> <code>int</code> <p>number of points that make up the ellipse polygonal approximation</p> required <code>is_cast_int</code> <code>bool</code> <p>whether to cast to int the points coordinates or not. Defaults to False</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>Polygon representing the ellipse as a succession of n points</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def polygonal_approx(self, n_points: int, is_cast_int: bool = False) -&gt; Polygon:\n    \"\"\"Generate apolygonal approximation of the ellipse.\n\n    The way is done is the following:\n    1. suppose the ellipse centered at the origin\n    2. suppose the ellipse semi major axis to be parallel with the x-axis\n    3. compute pairs of (x, y) points that belong to the ellipse using the\n        parametric equation of the ellipse.\n    4. shift all points by the same shift as the center to origin\n    5. rotate using the ellipse center pivot point\n\n    Args:\n        n_points (int): number of points that make up the ellipse\n            polygonal approximation\n        is_cast_int (bool): whether to cast to int the points coordinates or\n            not. Defaults to False\n\n    Returns:\n        Polygon: Polygon representing the ellipse as a succession of n points\n    \"\"\"\n    points = []\n    for theta in np.linspace(0, 2 * math.pi, n_points):\n        x = self.semi_major_axis * math.cos(theta)\n        y = self.semi_minor_axis * math.sin(theta)\n        points.append([x, y])\n\n    poly = (\n        Polygon(points=np.asarray(points), is_cast_int=False)\n        .shift(vector=self.centroid)\n        .rotate(angle=self.angle())\n    )\n\n    if is_cast_int:\n        poly.asarray = poly.asarray.astype(int)\n\n    return poly\n</code></pre>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.rotate","title":"<code>rotate(angle, is_degree=False, is_clockwise=True, pivot=None)</code>","text":"<p>Rotate the ellipse around a pivot point.</p> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>float</code> <p>angle to rotate the ellipse</p> required <code>is_degree</code> <code>bool</code> <p>whether the angle is in degrees. Defaults to False.</p> <code>False</code> <code>is_clockwise</code> <code>bool</code> <p>whether the rotation is clockwise. Defaults to True.</p> <code>True</code> <code>pivot</code> <code>Optional[NDArray]</code> <p>pivot point to rotate around. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>rotated ellipse object</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def rotate(\n    self,\n    angle: float,\n    is_degree: bool = False,\n    is_clockwise: bool = True,\n    pivot: Optional[NDArray] = None,\n) -&gt; Self:\n    \"\"\"Rotate the ellipse around a pivot point.\n\n    Args:\n        angle (float): angle to rotate the ellipse\n        is_degree (bool, optional): whether the angle is in degrees.\n            Defaults to False.\n        is_clockwise (bool, optional): whether the rotation is clockwise.\n            Defaults to True.\n        pivot (Optional[NDArray], optional): pivot point to rotate around.\n            Defaults to None.\n\n    Returns:\n        Self: rotated ellipse object\n    \"\"\"\n    if is_degree:\n        angle = math.radians(angle)\n    if is_clockwise:\n        angle = -angle\n\n    if pivot is None:\n        pivot = self.centroid\n\n    self.foci1 = rotate_2d_points(self.foci1, angle, pivot)\n    self.foci2 = rotate_2d_points(self.foci2, angle, pivot)\n    self.update_polyapprox()\n    return self\n</code></pre>"},{"location":"api/geometry/continuous/ellipse/#otary.geometry.continuous.shape.ellipse.Ellipse.shift","title":"<code>shift(vector)</code>","text":"<p>Shift the ellipse by a given vector.</p> <p>Parameters:</p> Name Type Description Default <code>vector</code> <code>NDArray</code> <p>vector to shift the ellipse</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>shifted ellipse object</p> Source code in <code>otary/geometry/continuous/shape/ellipse.py</code> <pre><code>def shift(self, vector: NDArray) -&gt; Self:\n    \"\"\"Shift the ellipse by a given vector.\n\n    Args:\n        vector (NDArray): vector to shift the ellipse\n\n    Returns:\n        Self: shifted ellipse object\n    \"\"\"\n    assert_transform_shift_vector(vector)\n    self.foci1 += vector\n    self.foci2 += vector\n    self.update_polyapprox()\n    return self\n</code></pre>"},{"location":"api/geometry/discrete/point/","title":"Point","text":"<p>Point class useful to describe any kind of points</p>"},{"location":"api/geometry/discrete/point/#otary.geometry.discrete.point.Point","title":"<code>Point</code>","text":"<p>               Bases: <code>DiscreteGeometryEntity</code></p> <p>Point class</p> Source code in <code>otary/geometry/discrete/point.py</code> <pre><code>class Point(DiscreteGeometryEntity):\n    \"\"\"Point class\"\"\"\n\n    def __init__(self, point: NDArray, is_cast_int: bool = False) -&gt; None:\n        point = self._ensure_transform_point_array(point=point)\n        super().__init__(points=point, is_cast_int=is_cast_int)\n\n    @staticmethod\n    def _ensure_transform_point_array(point: NDArray) -&gt; NDArray:\n        point = np.asarray(point)\n        if point.shape == (2,):\n            point = point.reshape((1, 2))\n        if len(point) != 1:\n            raise ValueError(f\"The input point has not the expected shape {point}\")\n        return point\n\n    @property\n    def asarray(self):\n        return self.points\n\n    @asarray.setter\n    def asarray(self, value: NDArray):\n        \"\"\"Setter for the asarray property\n\n        Args:\n            value (NDArray): value of the asarray to be changed\n        \"\"\"\n        self.points = self._ensure_transform_point_array(point=value)\n\n    @property\n    def centroid(self) -&gt; NDArray:\n        \"\"\"Return the point as the centroid of a point is simply the point\n\n        Returns:\n            NDArray: centroid of the point\n        \"\"\"\n        return self.asarray[0]\n\n    @property\n    def shapely_edges(self) -&gt; SPoint:\n        \"\"\"Returns the Shapely.Point representation of the point.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.Point.html\n\n        Returns:\n            Point: shapely.Point object\n        \"\"\"\n        return SPoint(self.asarray)\n\n    @property\n    def shapely_surface(self) -&gt; SPoint:\n        \"\"\"Returns None since a point has no surface\n\n        Returns:\n            None: None value\n        \"\"\"\n        return None\n\n    @property\n    def area(self) -&gt; float:\n        \"\"\"Compute the area of the geometry entity\n\n        Returns:\n            float: area value\n        \"\"\"\n        return 0\n\n    @property\n    def perimeter(self) -&gt; float:\n        \"\"\"Compute the perimeter of the geometry entity\n\n        Returns:\n            float: perimeter value\n        \"\"\"\n        return 0\n\n    @property\n    def edges(self) -&gt; NDArray:\n        \"\"\"Get the edges of the point which returns empty array\n        since a point has no edges\n\n        Returns:\n            NDArray: empty array of shape (0, 2, 2)\n        \"\"\"\n        return np.empty(shape=(0, 2, 2))\n\n    @staticmethod\n    def order_idxs_points_by_dist(points: NDArray, desc: bool = False) -&gt; NDArray:\n        \"\"\"Beware the method expects points to be collinear.\n\n        Given four points [p0, p1, p2, p3], we wish to have the order in which each\n        point is separated.\n        The one closest to the origin is placed at the origin and relative to this\n        point we are able to know at which position are the other points.\n\n        If p0 is closest to the origin and the closest points from p0 are in order\n        p2, p1 and p3. Thus the array returned by the function is [0, 2, 1, 3].\n\n        Args:\n            points (NDArray): numpy array of shape (n, 2)\n            desc (bool): if True returns the indices based on distances descending\n                order. Otherwise ascending order which is the default.\n\n        Returns:\n            NDArray: indices of the points\n        \"\"\"\n        distances = np.linalg.norm(x=points, axis=1)\n        idxs_order_by_dist = np.argsort(distances)\n        if not desc:  # change the order if in descending order\n            idxs_order_by_dist = idxs_order_by_dist[::-1]\n        return idxs_order_by_dist\n\n    def distances_vertices_to_point(self, point: NDArray) -&gt; NDArray:\n        \"\"\"Compute the distances to a given point\n\n        Args:\n            point (NDArray): point to which we want to compute the distances\n\n        Returns:\n            NDArray: distance to the given point\n        \"\"\"\n        return np.linalg.norm(self.points - point, axis=1)\n\n    def __str__(self) -&gt; str:\n        return self.__class__.__name__ + \"(\" + self.asarray[0].tolist().__str__() + \")\"\n\n    def __repr__(self) -&gt; str:\n        return str(self)\n</code></pre>"},{"location":"api/geometry/discrete/point/#otary.geometry.discrete.point.Point.area","title":"<code>area</code>  <code>property</code>","text":"<p>Compute the area of the geometry entity</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>area value</p>"},{"location":"api/geometry/discrete/point/#otary.geometry.discrete.point.Point.centroid","title":"<code>centroid</code>  <code>property</code>","text":"<p>Return the point as the centroid of a point is simply the point</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>centroid of the point</p>"},{"location":"api/geometry/discrete/point/#otary.geometry.discrete.point.Point.edges","title":"<code>edges</code>  <code>property</code>","text":"<p>Get the edges of the point which returns empty array since a point has no edges</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>empty array of shape (0, 2, 2)</p>"},{"location":"api/geometry/discrete/point/#otary.geometry.discrete.point.Point.perimeter","title":"<code>perimeter</code>  <code>property</code>","text":"<p>Compute the perimeter of the geometry entity</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>perimeter value</p>"},{"location":"api/geometry/discrete/point/#otary.geometry.discrete.point.Point.shapely_edges","title":"<code>shapely_edges</code>  <code>property</code>","text":"<p>Returns the Shapely.Point representation of the point. See https://shapely.readthedocs.io/en/stable/reference/shapely.Point.html</p> <p>Returns:</p> Name Type Description <code>Point</code> <code>Point</code> <p>shapely.Point object</p>"},{"location":"api/geometry/discrete/point/#otary.geometry.discrete.point.Point.shapely_surface","title":"<code>shapely_surface</code>  <code>property</code>","text":"<p>Returns None since a point has no surface</p> <p>Returns:</p> Name Type Description <code>None</code> <code>Point</code> <p>None value</p>"},{"location":"api/geometry/discrete/point/#otary.geometry.discrete.point.Point.distances_vertices_to_point","title":"<code>distances_vertices_to_point(point)</code>","text":"<p>Compute the distances to a given point</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>point to which we want to compute the distances</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>distance to the given point</p> Source code in <code>otary/geometry/discrete/point.py</code> <pre><code>def distances_vertices_to_point(self, point: NDArray) -&gt; NDArray:\n    \"\"\"Compute the distances to a given point\n\n    Args:\n        point (NDArray): point to which we want to compute the distances\n\n    Returns:\n        NDArray: distance to the given point\n    \"\"\"\n    return np.linalg.norm(self.points - point, axis=1)\n</code></pre>"},{"location":"api/geometry/discrete/point/#otary.geometry.discrete.point.Point.order_idxs_points_by_dist","title":"<code>order_idxs_points_by_dist(points, desc=False)</code>  <code>staticmethod</code>","text":"<p>Beware the method expects points to be collinear.</p> <p>Given four points [p0, p1, p2, p3], we wish to have the order in which each point is separated. The one closest to the origin is placed at the origin and relative to this point we are able to know at which position are the other points.</p> <p>If p0 is closest to the origin and the closest points from p0 are in order p2, p1 and p3. Thus the array returned by the function is [0, 2, 1, 3].</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>NDArray</code> <p>numpy array of shape (n, 2)</p> required <code>desc</code> <code>bool</code> <p>if True returns the indices based on distances descending order. Otherwise ascending order which is the default.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>indices of the points</p> Source code in <code>otary/geometry/discrete/point.py</code> <pre><code>@staticmethod\ndef order_idxs_points_by_dist(points: NDArray, desc: bool = False) -&gt; NDArray:\n    \"\"\"Beware the method expects points to be collinear.\n\n    Given four points [p0, p1, p2, p3], we wish to have the order in which each\n    point is separated.\n    The one closest to the origin is placed at the origin and relative to this\n    point we are able to know at which position are the other points.\n\n    If p0 is closest to the origin and the closest points from p0 are in order\n    p2, p1 and p3. Thus the array returned by the function is [0, 2, 1, 3].\n\n    Args:\n        points (NDArray): numpy array of shape (n, 2)\n        desc (bool): if True returns the indices based on distances descending\n            order. Otherwise ascending order which is the default.\n\n    Returns:\n        NDArray: indices of the points\n    \"\"\"\n    distances = np.linalg.norm(x=points, axis=1)\n    idxs_order_by_dist = np.argsort(distances)\n    if not desc:  # change the order if in descending order\n        idxs_order_by_dist = idxs_order_by_dist[::-1]\n    return idxs_order_by_dist\n</code></pre>"},{"location":"api/geometry/discrete/linear/linear_spline/","title":"Linear Spline","text":"<p>Curve class useful to describe any kind of curves</p>"},{"location":"api/geometry/discrete/linear/linear_spline/#otary.geometry.discrete.linear.linear_spline.LinearSpline","title":"<code>LinearSpline</code>","text":"<p>               Bases: <code>LinearEntity</code></p> <p>LinearSpline class</p> Source code in <code>otary/geometry/discrete/linear/linear_spline.py</code> <pre><code>class LinearSpline(LinearEntity):\n    \"\"\"LinearSpline class\"\"\"\n\n    def __init__(self, points: NDArray | list, is_cast_int: bool = False) -&gt; None:\n        if len(points) &lt; 2:\n            raise ValueError(\n                \"Cannot create a LinearSpline since it must have 2 or more points\"\n            )\n        super().__init__(points=points, is_cast_int=is_cast_int)\n\n    @property\n    def curvature(self) -&gt; float:\n        \"\"\"Get the curvature of the linear spline as-if it had a well-defined\n        curvature, meaning as-if it were a continuous curve.\n\n        Returns:\n            float: curvature value\n        \"\"\"\n        # TODO\n        raise NotImplementedError\n\n    @property\n    def centroid(self) -&gt; NDArray:\n        \"\"\"Returns the center point that is within the linear spline.\n        This means that this points necessarily belongs to the linear spline.\n\n        This can be useful when the centroid is not a good representation of what\n        is needed as 'center'.\n\n        Returns:\n            NDArray: point of shape (1, 2)\n        \"\"\"\n        total_length: float = 0.0\n        cx: float = 0.0\n        cy: float = 0.0\n\n        for i in range(len(self.points) - 1):\n            p1, p2 = self.points[i], self.points[i + 1]\n            mid = (p1 + p2) / 2\n            length = float(np.linalg.norm(p2 - p1))\n            cx += mid[0] * length\n            cy += mid[1] * length\n            total_length += length\n\n        if total_length == 0:\n            return self.points[0]  # or handle degenerate case\n        return np.asarray([cx / total_length, cy / total_length])\n\n    @property\n    def midpoint(self) -&gt; NDArray:\n        \"\"\"Returns the center point that is within the linear spline.\n        This means that this points necessarily belongs to the linear spline.\n\n        This can be useful when the centroid is not a good representation of what\n        is needed as 'center'.\n\n        Returns:\n            NDArray: point of shape (1, 2)\n        \"\"\"\n        return self.find_interpolated_point(pct_dist=0.5)\n\n    def find_interpolated_point_and_prev_ix(\n        self, pct_dist: float\n    ) -&gt; tuple[NDArray, int]:\n        \"\"\"Return a point along the curve at a relative distance pct_dist \u2208 [0, 1]\n\n        Parameters:\n            pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n                Any value in [0, 1] returns a point between start and end that is\n                pct_dist along the path.\n\n        Returns:\n            tuple[NDArray, int]: Interpolated point [x, y] and previous index in path.\n        \"\"\"\n        if not 0 &lt;= pct_dist &lt;= 1:\n            raise ValueError(\"pct_dist must be in [0, 1]\")\n\n        if self.length == 0 or pct_dist == 0:\n            return self[0], 0\n        if pct_dist == 1:\n            return self[-1], len(self) - 1\n\n        # Walk along the path to find the point at pct_dist * total_dist\n        target_dist = pct_dist * self.length\n        accumulated = 0\n        for i in range(len(self.edges)):\n            cur_edge_length = self.lengths[i]\n            if accumulated + cur_edge_length &gt;= target_dist:\n                remain = target_dist - accumulated\n                direction = self[i + 1] - self[i]\n                unit_dir = direction / cur_edge_length\n                return self[i] + remain * unit_dir, i\n            accumulated += cur_edge_length\n\n        # Fallback\n        return self[-1], i\n\n    def find_interpolated_point(self, pct_dist: float) -&gt; NDArray:\n        \"\"\"Return a point along the curve at a relative distance pct_dist \u2208 [0, 1]\n\n        Parameters:\n            pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n                Any value in [0, 1] returns a point between start and end that is\n                pct_dist along the path.\n\n        Returns:\n            NDArray: Interpolated point [x, y]\n        \"\"\"\n        return self.find_interpolated_point_and_prev_ix(pct_dist)[0]\n</code></pre>"},{"location":"api/geometry/discrete/linear/linear_spline/#otary.geometry.discrete.linear.linear_spline.LinearSpline.centroid","title":"<code>centroid</code>  <code>property</code>","text":"<p>Returns the center point that is within the linear spline. This means that this points necessarily belongs to the linear spline.</p> <p>This can be useful when the centroid is not a good representation of what is needed as 'center'.</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>point of shape (1, 2)</p>"},{"location":"api/geometry/discrete/linear/linear_spline/#otary.geometry.discrete.linear.linear_spline.LinearSpline.curvature","title":"<code>curvature</code>  <code>property</code>","text":"<p>Get the curvature of the linear spline as-if it had a well-defined curvature, meaning as-if it were a continuous curve.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>curvature value</p>"},{"location":"api/geometry/discrete/linear/linear_spline/#otary.geometry.discrete.linear.linear_spline.LinearSpline.midpoint","title":"<code>midpoint</code>  <code>property</code>","text":"<p>Returns the center point that is within the linear spline. This means that this points necessarily belongs to the linear spline.</p> <p>This can be useful when the centroid is not a good representation of what is needed as 'center'.</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>point of shape (1, 2)</p>"},{"location":"api/geometry/discrete/linear/linear_spline/#otary.geometry.discrete.linear.linear_spline.LinearSpline.find_interpolated_point","title":"<code>find_interpolated_point(pct_dist)</code>","text":"<p>Return a point along the curve at a relative distance pct_dist \u2208 [0, 1]</p> <p>Parameters:</p> Name Type Description Default <code>pct_dist</code> <code>float</code> <p>Value in [0, 1], 0 returns start, 1 returns end. Any value in [0, 1] returns a point between start and end that is pct_dist along the path.</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>Interpolated point [x, y]</p> Source code in <code>otary/geometry/discrete/linear/linear_spline.py</code> <pre><code>def find_interpolated_point(self, pct_dist: float) -&gt; NDArray:\n    \"\"\"Return a point along the curve at a relative distance pct_dist \u2208 [0, 1]\n\n    Parameters:\n        pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n            Any value in [0, 1] returns a point between start and end that is\n            pct_dist along the path.\n\n    Returns:\n        NDArray: Interpolated point [x, y]\n    \"\"\"\n    return self.find_interpolated_point_and_prev_ix(pct_dist)[0]\n</code></pre>"},{"location":"api/geometry/discrete/linear/linear_spline/#otary.geometry.discrete.linear.linear_spline.LinearSpline.find_interpolated_point_and_prev_ix","title":"<code>find_interpolated_point_and_prev_ix(pct_dist)</code>","text":"<p>Return a point along the curve at a relative distance pct_dist \u2208 [0, 1]</p> <p>Parameters:</p> Name Type Description Default <code>pct_dist</code> <code>float</code> <p>Value in [0, 1], 0 returns start, 1 returns end. Any value in [0, 1] returns a point between start and end that is pct_dist along the path.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray, int]</code> <p>tuple[NDArray, int]: Interpolated point [x, y] and previous index in path.</p> Source code in <code>otary/geometry/discrete/linear/linear_spline.py</code> <pre><code>def find_interpolated_point_and_prev_ix(\n    self, pct_dist: float\n) -&gt; tuple[NDArray, int]:\n    \"\"\"Return a point along the curve at a relative distance pct_dist \u2208 [0, 1]\n\n    Parameters:\n        pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n            Any value in [0, 1] returns a point between start and end that is\n            pct_dist along the path.\n\n    Returns:\n        tuple[NDArray, int]: Interpolated point [x, y] and previous index in path.\n    \"\"\"\n    if not 0 &lt;= pct_dist &lt;= 1:\n        raise ValueError(\"pct_dist must be in [0, 1]\")\n\n    if self.length == 0 or pct_dist == 0:\n        return self[0], 0\n    if pct_dist == 1:\n        return self[-1], len(self) - 1\n\n    # Walk along the path to find the point at pct_dist * total_dist\n    target_dist = pct_dist * self.length\n    accumulated = 0\n    for i in range(len(self.edges)):\n        cur_edge_length = self.lengths[i]\n        if accumulated + cur_edge_length &gt;= target_dist:\n            remain = target_dist - accumulated\n            direction = self[i + 1] - self[i]\n            unit_dir = direction / cur_edge_length\n            return self[i] + remain * unit_dir, i\n        accumulated += cur_edge_length\n\n    # Fallback\n    return self[-1], i\n</code></pre>"},{"location":"api/geometry/discrete/linear/segment/","title":"Segment","text":"<p>Segment class to describe defined lines and segments</p>"},{"location":"api/geometry/discrete/linear/segment/#otary.geometry.discrete.linear.segment.Segment","title":"<code>Segment</code>","text":"<p>               Bases: <code>LinearEntity</code></p> <p>Segment class</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>class Segment(LinearEntity):\n    \"\"\"Segment class\"\"\"\n\n    def __init__(self, points: NDArray | list, is_cast_int: bool = False) -&gt; None:\n        assert len(points) == 2\n        assert len(points[0]) == 2\n        assert len(points[1]) == 2\n        super().__init__(points=points, is_cast_int=is_cast_int)\n\n    @property\n    def centroid(self) -&gt; NDArray:\n        \"\"\"Returns the center point of the segment\n\n        Returns:\n            NDArray: point of shape (1, 2)\n        \"\"\"\n        return np.sum(self.points, axis=0) / 2\n\n    @property\n    def midpoint(self) -&gt; NDArray:\n        \"\"\"In the Segment, this is equivalent to the centroid\n\n        Returns:\n            NDArray: point of shape (1, 2)\n        \"\"\"\n        return self.centroid\n\n    @property\n    def direction_vector(self) -&gt; NDArray:\n        \"\"\"Returns the direction vector of the segment from point 1 to point 2\n\n        Returns:\n            NDArray: direction vector of shape (2,)\n        \"\"\"\n        return self.points[1] - self.points[0]\n\n    @property\n    def slope(self) -&gt; float:\n        \"\"\"Returns the segment slope in the classical XY coordinates referential\n\n        Can return inf if you have a really specific vertical line of the form:\n\n        &gt;&gt;&gt; seg = ot.Segment([[1e-9, 0], [0, 1]])\n        &gt;&gt;&gt; seg.slope\n        inf\n\n        Returns:\n            float: segment slope value\n        \"\"\"\n        p1, p2 = self.points[0], self.points[1]\n        with warnings.catch_warnings():\n            warnings.filterwarnings(\"error\", category=RuntimeWarning)\n            try:\n                slope = (p2[1] - p1[1]) / (p2[0] - p1[0] + 1e-9)\n            except RuntimeWarning:  # Now this is raised as an exception\n                slope = np.inf\n        return slope\n\n    @property\n    def slope_cv2(self) -&gt; float:\n        \"\"\"Compute the slope seen as in the cv2 coordinates with y-axis inverted\n\n        Returns:\n            float: segment slope value\n        \"\"\"\n        return -self.slope\n\n    def slope_angle(self, degree: bool = False, is_y_axis_down: bool = False) -&gt; float:\n        \"\"\"Calculate the slope angle of a single line in the cartesian space\n\n        Args:\n            degree (bool): whether to output the result in degree. By default in radian.\n\n        Returns:\n            float: slope angle in ]-pi/2, pi/2[\n        \"\"\"\n        angle = np.arctan(self.slope_cv2) if is_y_axis_down else np.arctan(self.slope)\n        if degree:\n            angle = np.rad2deg(angle)\n        return angle\n\n    def is_parallel(\n        self, other: Segment, margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR\n    ) -&gt; bool:\n        \"\"\"Check if two lines are parallel by calculating the slope of the two lines\n\n        Angle Difference = |theta_0 - theta_1| mod pi\n        Because always returns positive results due to the modulo we took into account\n        the special case where angle difference = pi - epsilon ~ 3.139,\n        this implies also two parallel lines.\n\n        Args:\n            other (np.array): segment of shape (2, 2)\n            margin_error_angle (float, optional): Threshold value for validating\n                if the lines are parallel. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.\n\n        Returns:\n            bool: whether we qualify the lines as parallel or not\n        \"\"\"\n        if margin_error_angle == 0:\n            # no margin of error, strict equality\n            M = np.array([self.direction_vector, -other.direction_vector]).T  # (2,2)\n            # Check if matrix is singular (parallel lines)\n            cond = np.linalg.det(M) == 0\n        else:\n            # with margin of error, we use angle difference\n            angle_difference = np.mod(\n                np.abs(self.slope_angle() - other.slope_angle()), math.pi\n            )\n            cond = bool(\n                angle_difference &lt;= margin_error_angle\n                or np.abs(angle_difference - math.pi) &lt;= margin_error_angle\n            )\n        return cond\n\n    @staticmethod\n    def is_points_collinear(\n        p1: NDArray,\n        p2: NDArray,\n        p3: NDArray,\n        margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR,\n    ) -&gt; bool:\n        \"\"\"Verify whether three points on the plane are collinear or not.\n        Method by angle or slope: For three points, slope of any pair of points must\n        be same as other pair.\n\n        Args:\n            p1 (np.array): point of shape (2,)\n            p2 (np.array): point of shape (2,)\n            p3 (np.array): point of shape (2,)\n            margin_error_angle (float, optional): Threshold value for validating\n                collinearity. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.\n\n        Returns:\n            bool: 1 if colinear, 0 otherwise\n        \"\"\"\n        p1, p2, p3 = np.array(p1), np.array(p2), np.array(p3)\n\n        # 2 or 3 points equal\n        if (\n            not np.logical_or(*(p1 - p2))\n            or not np.logical_or(*(p1 - p3))\n            or not np.logical_or(*(p2 - p3))\n        ):\n            return True\n\n        segment1, segment2 = Segment([p1, p2]), Segment([p1, p3])\n        return segment1.is_parallel(\n            other=segment2, margin_error_angle=margin_error_angle\n        )\n\n    def is_point_collinear(\n        self,\n        point: NDArray,\n        margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR,\n    ) -&gt; bool:\n        \"\"\"Check whether a point is collinear with the segment\n\n        Args:\n            point (NDArray): point of shape (2,)\n            margin_error_angle (float, optional): Threshold value for validating\n                collinearity. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.\n\n        Returns:\n            bool: True if the point is collinear with the segment\n        \"\"\"\n        return self.is_points_collinear(\n            p1=self.asarray[0],\n            p2=self.asarray[1],\n            p3=point,\n            margin_error_angle=margin_error_angle,\n        )\n\n    def is_collinear(\n        self, segment: Segment, margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR\n    ) -&gt; bool:\n        \"\"\"Verify whether two segments on the plane are collinear or not.\n        This means that they are parallel and have at least three points in common.\n\n        We needed to make all the combination verification in order to proove cause we\n        could end up with two points very very close by and it would end up not\n        providing the expected result. Consider the following example:\n\n        &gt;&gt;&gt; segment1 = Segment([[339, 615], [564, 650]])\n        &gt;&gt;&gt; segment2 = Segment([[340, 614], [611, 657]])\n        &gt;&gt;&gt; segment1.is_collinear(segment2)\n        Angle difference: 0.9397169393235674 Margin: 0.06283185307179587\n        False\n\n        Only because [339, 615] and [340, 614] are really close and do not provide the\n        appropriate slope does not means that overall the two segments are not\n        collinear.\n\n        Args:\n            segment (np.array): segment of shape (2, 2)\n            margin_error_angle (float, optional): Threshold value for validating\n                collinearity.\n\n        Returns:\n            bool: 1 if colinear, 0 otherwise\n        \"\"\"\n        cur2lines = np.array([self.asarray, segment.asarray])\n        points = np.concatenate(cur2lines, axis=0)\n        val_arr = np.zeros(shape=4)\n        for i, combi in enumerate(\n            itertools.combinations(np.linspace(0, 3, 4, dtype=int), 3)\n        ):\n            val_arr[i] = Segment.is_points_collinear(\n                p1=points[combi[0]],\n                p2=points[combi[1]],\n                p3=points[combi[2]],\n                margin_error_angle=margin_error_angle,\n            )\n\n        _is_parallel = self.is_parallel(\n            other=segment, margin_error_angle=margin_error_angle\n        )\n        _is_collinear = 1 in val_arr\n        return bool(_is_parallel and _is_collinear)\n\n    def intersection_line(self, other: Segment) -&gt; NDArray:\n        \"\"\"Compute the intersection point that would exist between two segments if we\n        consider them as lines - which means as lines with infinite length.\n\n        Lines would thus define infinite extension in both extremities directions\n        of the input segments objects.\n\n        Args:\n            other (Segment): other Segment object\n\n        Returns:\n            NDArray: intersection point between the two lines\n        \"\"\"\n        if self.is_parallel(other, margin_error_angle=0):\n            return np.array([])\n\n        M = np.array([self.direction_vector, -other.direction_vector]).T  # shape (2,2)\n        b = other.asarray[0] - self.asarray[0]  # shape (2,)\n        solution, _ = np.linalg.solve(M, b)\n\n        intersection = self.asarray[0] + solution * self.direction_vector\n        return intersection\n\n    def normal(self) -&gt; Self:\n        \"\"\"\n        Returns the normal segment of the segment.\n        The normal segment is a segment that is orthogonal to the input segment.\n\n        Please note that the normal segment have the same length as the input segment.\n        Moreover the normal segment is rotated by 90 degrees clockwise.\n\n        Returns:\n            Segment: normal segment centered at the original segment centroid\n        \"\"\"\n        normal = self.copy().rotate(\n            angle=math.pi / 2, is_degree=False, is_clockwise=True\n        )\n        return normal\n</code></pre>"},{"location":"api/geometry/discrete/linear/segment/#otary.geometry.discrete.linear.segment.Segment.centroid","title":"<code>centroid</code>  <code>property</code>","text":"<p>Returns the center point of the segment</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>point of shape (1, 2)</p>"},{"location":"api/geometry/discrete/linear/segment/#otary.geometry.discrete.linear.segment.Segment.direction_vector","title":"<code>direction_vector</code>  <code>property</code>","text":"<p>Returns the direction vector of the segment from point 1 to point 2</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>direction vector of shape (2,)</p>"},{"location":"api/geometry/discrete/linear/segment/#otary.geometry.discrete.linear.segment.Segment.midpoint","title":"<code>midpoint</code>  <code>property</code>","text":"<p>In the Segment, this is equivalent to the centroid</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>point of shape (1, 2)</p>"},{"location":"api/geometry/discrete/linear/segment/#otary.geometry.discrete.linear.segment.Segment.slope","title":"<code>slope</code>  <code>property</code>","text":"<p>Returns the segment slope in the classical XY coordinates referential</p> <p>Can return inf if you have a really specific vertical line of the form:</p> <p>seg = ot.Segment([[1e-9, 0], [0, 1]]) seg.slope inf</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>segment slope value</p>"},{"location":"api/geometry/discrete/linear/segment/#otary.geometry.discrete.linear.segment.Segment.slope_cv2","title":"<code>slope_cv2</code>  <code>property</code>","text":"<p>Compute the slope seen as in the cv2 coordinates with y-axis inverted</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>segment slope value</p>"},{"location":"api/geometry/discrete/linear/segment/#otary.geometry.discrete.linear.segment.Segment.intersection_line","title":"<code>intersection_line(other)</code>","text":"<p>Compute the intersection point that would exist between two segments if we consider them as lines - which means as lines with infinite length.</p> <p>Lines would thus define infinite extension in both extremities directions of the input segments objects.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Segment</code> <p>other Segment object</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>intersection point between the two lines</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>def intersection_line(self, other: Segment) -&gt; NDArray:\n    \"\"\"Compute the intersection point that would exist between two segments if we\n    consider them as lines - which means as lines with infinite length.\n\n    Lines would thus define infinite extension in both extremities directions\n    of the input segments objects.\n\n    Args:\n        other (Segment): other Segment object\n\n    Returns:\n        NDArray: intersection point between the two lines\n    \"\"\"\n    if self.is_parallel(other, margin_error_angle=0):\n        return np.array([])\n\n    M = np.array([self.direction_vector, -other.direction_vector]).T  # shape (2,2)\n    b = other.asarray[0] - self.asarray[0]  # shape (2,)\n    solution, _ = np.linalg.solve(M, b)\n\n    intersection = self.asarray[0] + solution * self.direction_vector\n    return intersection\n</code></pre>"},{"location":"api/geometry/discrete/linear/segment/#otary.geometry.discrete.linear.segment.Segment.is_collinear","title":"<code>is_collinear(segment, margin_error_angle=DEFAULT_MARGIN_ANGLE_ERROR)</code>","text":"<p>Verify whether two segments on the plane are collinear or not. This means that they are parallel and have at least three points in common.</p> <p>We needed to make all the combination verification in order to proove cause we could end up with two points very very close by and it would end up not providing the expected result. Consider the following example:</p> <p>segment1 = Segment([[339, 615], [564, 650]]) segment2 = Segment([[340, 614], [611, 657]]) segment1.is_collinear(segment2) Angle difference: 0.9397169393235674 Margin: 0.06283185307179587 False</p> <p>Only because [339, 615] and [340, 614] are really close and do not provide the appropriate slope does not means that overall the two segments are not collinear.</p> <p>Parameters:</p> Name Type Description Default <code>segment</code> <code>array</code> <p>segment of shape (2, 2)</p> required <code>margin_error_angle</code> <code>float</code> <p>Threshold value for validating collinearity.</p> <code>DEFAULT_MARGIN_ANGLE_ERROR</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>1 if colinear, 0 otherwise</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>def is_collinear(\n    self, segment: Segment, margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR\n) -&gt; bool:\n    \"\"\"Verify whether two segments on the plane are collinear or not.\n    This means that they are parallel and have at least three points in common.\n\n    We needed to make all the combination verification in order to proove cause we\n    could end up with two points very very close by and it would end up not\n    providing the expected result. Consider the following example:\n\n    &gt;&gt;&gt; segment1 = Segment([[339, 615], [564, 650]])\n    &gt;&gt;&gt; segment2 = Segment([[340, 614], [611, 657]])\n    &gt;&gt;&gt; segment1.is_collinear(segment2)\n    Angle difference: 0.9397169393235674 Margin: 0.06283185307179587\n    False\n\n    Only because [339, 615] and [340, 614] are really close and do not provide the\n    appropriate slope does not means that overall the two segments are not\n    collinear.\n\n    Args:\n        segment (np.array): segment of shape (2, 2)\n        margin_error_angle (float, optional): Threshold value for validating\n            collinearity.\n\n    Returns:\n        bool: 1 if colinear, 0 otherwise\n    \"\"\"\n    cur2lines = np.array([self.asarray, segment.asarray])\n    points = np.concatenate(cur2lines, axis=0)\n    val_arr = np.zeros(shape=4)\n    for i, combi in enumerate(\n        itertools.combinations(np.linspace(0, 3, 4, dtype=int), 3)\n    ):\n        val_arr[i] = Segment.is_points_collinear(\n            p1=points[combi[0]],\n            p2=points[combi[1]],\n            p3=points[combi[2]],\n            margin_error_angle=margin_error_angle,\n        )\n\n    _is_parallel = self.is_parallel(\n        other=segment, margin_error_angle=margin_error_angle\n    )\n    _is_collinear = 1 in val_arr\n    return bool(_is_parallel and _is_collinear)\n</code></pre>"},{"location":"api/geometry/discrete/linear/segment/#otary.geometry.discrete.linear.segment.Segment.is_parallel","title":"<code>is_parallel(other, margin_error_angle=DEFAULT_MARGIN_ANGLE_ERROR)</code>","text":"<p>Check if two lines are parallel by calculating the slope of the two lines</p> <p>Angle Difference = |theta_0 - theta_1| mod pi Because always returns positive results due to the modulo we took into account the special case where angle difference = pi - epsilon ~ 3.139, this implies also two parallel lines.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>array</code> <p>segment of shape (2, 2)</p> required <code>margin_error_angle</code> <code>float</code> <p>Threshold value for validating if the lines are parallel. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.</p> <code>DEFAULT_MARGIN_ANGLE_ERROR</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>whether we qualify the lines as parallel or not</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>def is_parallel(\n    self, other: Segment, margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR\n) -&gt; bool:\n    \"\"\"Check if two lines are parallel by calculating the slope of the two lines\n\n    Angle Difference = |theta_0 - theta_1| mod pi\n    Because always returns positive results due to the modulo we took into account\n    the special case where angle difference = pi - epsilon ~ 3.139,\n    this implies also two parallel lines.\n\n    Args:\n        other (np.array): segment of shape (2, 2)\n        margin_error_angle (float, optional): Threshold value for validating\n            if the lines are parallel. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.\n\n    Returns:\n        bool: whether we qualify the lines as parallel or not\n    \"\"\"\n    if margin_error_angle == 0:\n        # no margin of error, strict equality\n        M = np.array([self.direction_vector, -other.direction_vector]).T  # (2,2)\n        # Check if matrix is singular (parallel lines)\n        cond = np.linalg.det(M) == 0\n    else:\n        # with margin of error, we use angle difference\n        angle_difference = np.mod(\n            np.abs(self.slope_angle() - other.slope_angle()), math.pi\n        )\n        cond = bool(\n            angle_difference &lt;= margin_error_angle\n            or np.abs(angle_difference - math.pi) &lt;= margin_error_angle\n        )\n    return cond\n</code></pre>"},{"location":"api/geometry/discrete/linear/segment/#otary.geometry.discrete.linear.segment.Segment.is_point_collinear","title":"<code>is_point_collinear(point, margin_error_angle=DEFAULT_MARGIN_ANGLE_ERROR)</code>","text":"<p>Check whether a point is collinear with the segment</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>point of shape (2,)</p> required <code>margin_error_angle</code> <code>float</code> <p>Threshold value for validating collinearity. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.</p> <code>DEFAULT_MARGIN_ANGLE_ERROR</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the point is collinear with the segment</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>def is_point_collinear(\n    self,\n    point: NDArray,\n    margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR,\n) -&gt; bool:\n    \"\"\"Check whether a point is collinear with the segment\n\n    Args:\n        point (NDArray): point of shape (2,)\n        margin_error_angle (float, optional): Threshold value for validating\n            collinearity. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.\n\n    Returns:\n        bool: True if the point is collinear with the segment\n    \"\"\"\n    return self.is_points_collinear(\n        p1=self.asarray[0],\n        p2=self.asarray[1],\n        p3=point,\n        margin_error_angle=margin_error_angle,\n    )\n</code></pre>"},{"location":"api/geometry/discrete/linear/segment/#otary.geometry.discrete.linear.segment.Segment.is_points_collinear","title":"<code>is_points_collinear(p1, p2, p3, margin_error_angle=DEFAULT_MARGIN_ANGLE_ERROR)</code>  <code>staticmethod</code>","text":"<p>Verify whether three points on the plane are collinear or not. Method by angle or slope: For three points, slope of any pair of points must be same as other pair.</p> <p>Parameters:</p> Name Type Description Default <code>p1</code> <code>array</code> <p>point of shape (2,)</p> required <code>p2</code> <code>array</code> <p>point of shape (2,)</p> required <code>p3</code> <code>array</code> <p>point of shape (2,)</p> required <code>margin_error_angle</code> <code>float</code> <p>Threshold value for validating collinearity. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.</p> <code>DEFAULT_MARGIN_ANGLE_ERROR</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>1 if colinear, 0 otherwise</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>@staticmethod\ndef is_points_collinear(\n    p1: NDArray,\n    p2: NDArray,\n    p3: NDArray,\n    margin_error_angle: float = DEFAULT_MARGIN_ANGLE_ERROR,\n) -&gt; bool:\n    \"\"\"Verify whether three points on the plane are collinear or not.\n    Method by angle or slope: For three points, slope of any pair of points must\n    be same as other pair.\n\n    Args:\n        p1 (np.array): point of shape (2,)\n        p2 (np.array): point of shape (2,)\n        p3 (np.array): point of shape (2,)\n        margin_error_angle (float, optional): Threshold value for validating\n            collinearity. Defaults to DEFAULT_MARGIN_ANGLE_ERROR.\n\n    Returns:\n        bool: 1 if colinear, 0 otherwise\n    \"\"\"\n    p1, p2, p3 = np.array(p1), np.array(p2), np.array(p3)\n\n    # 2 or 3 points equal\n    if (\n        not np.logical_or(*(p1 - p2))\n        or not np.logical_or(*(p1 - p3))\n        or not np.logical_or(*(p2 - p3))\n    ):\n        return True\n\n    segment1, segment2 = Segment([p1, p2]), Segment([p1, p3])\n    return segment1.is_parallel(\n        other=segment2, margin_error_angle=margin_error_angle\n    )\n</code></pre>"},{"location":"api/geometry/discrete/linear/segment/#otary.geometry.discrete.linear.segment.Segment.normal","title":"<code>normal()</code>","text":"<p>Returns the normal segment of the segment. The normal segment is a segment that is orthogonal to the input segment.</p> <p>Please note that the normal segment have the same length as the input segment. Moreover the normal segment is rotated by 90 degrees clockwise.</p> <p>Returns:</p> Name Type Description <code>Segment</code> <code>Self</code> <p>normal segment centered at the original segment centroid</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>def normal(self) -&gt; Self:\n    \"\"\"\n    Returns the normal segment of the segment.\n    The normal segment is a segment that is orthogonal to the input segment.\n\n    Please note that the normal segment have the same length as the input segment.\n    Moreover the normal segment is rotated by 90 degrees clockwise.\n\n    Returns:\n        Segment: normal segment centered at the original segment centroid\n    \"\"\"\n    normal = self.copy().rotate(\n        angle=math.pi / 2, is_degree=False, is_clockwise=True\n    )\n    return normal\n</code></pre>"},{"location":"api/geometry/discrete/linear/segment/#otary.geometry.discrete.linear.segment.Segment.slope_angle","title":"<code>slope_angle(degree=False, is_y_axis_down=False)</code>","text":"<p>Calculate the slope angle of a single line in the cartesian space</p> <p>Parameters:</p> Name Type Description Default <code>degree</code> <code>bool</code> <p>whether to output the result in degree. By default in radian.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>slope angle in ]-pi/2, pi/2[</p> Source code in <code>otary/geometry/discrete/linear/segment.py</code> <pre><code>def slope_angle(self, degree: bool = False, is_y_axis_down: bool = False) -&gt; float:\n    \"\"\"Calculate the slope angle of a single line in the cartesian space\n\n    Args:\n        degree (bool): whether to output the result in degree. By default in radian.\n\n    Returns:\n        float: slope angle in ]-pi/2, pi/2[\n    \"\"\"\n    angle = np.arctan(self.slope_cv2) if is_y_axis_down else np.arctan(self.slope)\n    if degree:\n        angle = np.rad2deg(angle)\n    return angle\n</code></pre>"},{"location":"api/geometry/discrete/linear/directed/vector/","title":"Vector","text":"<p>Vectors class they are like segments, but with a given direction</p>"},{"location":"api/geometry/discrete/linear/directed/vector/#otary.geometry.discrete.linear.directed.vector.Vector","title":"<code>Vector</code>","text":"<p>               Bases: <code>Segment</code>, <code>DirectedLinearEntity</code></p> <p>Vector class to manipulate vector which can be seen as Segment with direction</p> Source code in <code>otary/geometry/discrete/linear/directed/vector.py</code> <pre><code>class Vector(Segment, DirectedLinearEntity):\n    \"\"\"Vector class to manipulate vector which can be seen as Segment with direction\"\"\"\n\n    @classmethod\n    def from_single_point(cls, point: NDArray) -&gt; Vector:\n        \"\"\"Get vector that goes from [0, 0] to point\n\n        Args:\n            point (NDArray): point of shape 2\n\n        Returns:\n            Vector: new vector object\n        \"\"\"\n        return cls(points=[[0, 0], point])\n\n    @property\n    def cardinal_degree(self) -&gt; float:\n        \"\"\"Returns the cardinal degree of the vector in the cv2 space.\n        We consider the top of the image to point toward the north as default and thus\n        represent the cardinal degree value 0 mod 360.\n\n        Returns:\n            float: cardinal degree\n        \"\"\"\n        angle = self.slope_angle(degree=True, is_y_axis_down=True)\n\n        # if angle is negative\n        is_neg_sign_angle = bool(np.sign(angle) - 1)\n        if is_neg_sign_angle:\n            angle = 90 + np.abs(angle)\n        else:\n            angle = 90 - angle\n\n        # if vector points towards west\n        if self.is_x_first_pt_gt_x_last_pt:\n            angle += 180\n\n        cardinal_degree = np.mod(360 + angle, 360)  # avoid negative value case\n        return cardinal_degree\n\n    @property\n    def coordinates_shift(self) -&gt; NDArray:\n        \"\"\"Return the vector as a single point (x1-x0, y1-y0)\n\n        Returns:\n            NDArray: coordinates shift\n        \"\"\"\n        return self.origin[1]\n\n    @property\n    def normalized(self) -&gt; NDArray:\n        \"\"\"Nornalized vector\n\n        Returns:\n            NDArray: normalized vector\n        \"\"\"\n        return self.coordinates_shift / np.linalg.norm(self.coordinates_shift) + 1e-9\n\n    def rescale_head(self, scale: float) -&gt; Vector:\n        \"\"\"Rescale the head part of the vector without moving the first point.\n        This method only updates the second point that composes the vector.\n\n        Args:\n            scale (float): scale factor\n\n        Returns:\n            Vector: scaled vector\n        \"\"\"\n        self.asarray = (self.asarray - self.tail) * scale + self.tail\n        return self\n</code></pre>"},{"location":"api/geometry/discrete/linear/directed/vector/#otary.geometry.discrete.linear.directed.vector.Vector.cardinal_degree","title":"<code>cardinal_degree</code>  <code>property</code>","text":"<p>Returns the cardinal degree of the vector in the cv2 space. We consider the top of the image to point toward the north as default and thus represent the cardinal degree value 0 mod 360.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>cardinal degree</p>"},{"location":"api/geometry/discrete/linear/directed/vector/#otary.geometry.discrete.linear.directed.vector.Vector.coordinates_shift","title":"<code>coordinates_shift</code>  <code>property</code>","text":"<p>Return the vector as a single point (x1-x0, y1-y0)</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>coordinates shift</p>"},{"location":"api/geometry/discrete/linear/directed/vector/#otary.geometry.discrete.linear.directed.vector.Vector.normalized","title":"<code>normalized</code>  <code>property</code>","text":"<p>Nornalized vector</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>normalized vector</p>"},{"location":"api/geometry/discrete/linear/directed/vector/#otary.geometry.discrete.linear.directed.vector.Vector.from_single_point","title":"<code>from_single_point(point)</code>  <code>classmethod</code>","text":"<p>Get vector that goes from [0, 0] to point</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>point of shape 2</p> required <p>Returns:</p> Name Type Description <code>Vector</code> <code>Vector</code> <p>new vector object</p> Source code in <code>otary/geometry/discrete/linear/directed/vector.py</code> <pre><code>@classmethod\ndef from_single_point(cls, point: NDArray) -&gt; Vector:\n    \"\"\"Get vector that goes from [0, 0] to point\n\n    Args:\n        point (NDArray): point of shape 2\n\n    Returns:\n        Vector: new vector object\n    \"\"\"\n    return cls(points=[[0, 0], point])\n</code></pre>"},{"location":"api/geometry/discrete/linear/directed/vector/#otary.geometry.discrete.linear.directed.vector.Vector.rescale_head","title":"<code>rescale_head(scale)</code>","text":"<p>Rescale the head part of the vector without moving the first point. This method only updates the second point that composes the vector.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>scale factor</p> required <p>Returns:</p> Name Type Description <code>Vector</code> <code>Vector</code> <p>scaled vector</p> Source code in <code>otary/geometry/discrete/linear/directed/vector.py</code> <pre><code>def rescale_head(self, scale: float) -&gt; Vector:\n    \"\"\"Rescale the head part of the vector without moving the first point.\n    This method only updates the second point that composes the vector.\n\n    Args:\n        scale (float): scale factor\n\n    Returns:\n        Vector: scaled vector\n    \"\"\"\n    self.asarray = (self.asarray - self.tail) * scale + self.tail\n    return self\n</code></pre>"},{"location":"api/geometry/discrete/linear/directed/vectorized_linear_spline/","title":"Vectorized Linear Spline","text":"<p>Vectorized Curve class useful to describe any kind of vectorized curves</p>"},{"location":"api/geometry/discrete/linear/directed/vectorized_linear_spline/#otary.geometry.discrete.linear.directed.vectorized_linear_spline.VectorizedLinearSpline","title":"<code>VectorizedLinearSpline</code>","text":"<p>               Bases: <code>LinearSpline</code>, <code>DirectedLinearEntity</code></p> <p>VectorizedLinearSpline class</p> Source code in <code>otary/geometry/discrete/linear/directed/vectorized_linear_spline.py</code> <pre><code>class VectorizedLinearSpline(LinearSpline, DirectedLinearEntity):\n    \"\"\"VectorizedLinearSpline class\"\"\"\n\n    def __init__(self, points, is_cast_int=False):\n        super().__init__(points, is_cast_int)\n        self.vector_extremities = Vector(points=np.array([points[0], points[-1]]))\n\n    @property\n    def is_simple_vector(self) -&gt; bool:\n        \"\"\"Whether the VectorizedLinearSpline is just a two points vector or not\n\n        Returns:\n            bool: True or false\n        \"\"\"\n        return np.array_equal(self.asarray, self.vector_extremities.asarray)\n\n    @property\n    def cardinal_degree(self) -&gt; float:\n        \"\"\"Returns the cardinal degree of the VectorizedLinearSpline in the cv2 space.\n        It is calculated using the two extremities points that compose the object.\n\n        We consider the top of the image to point toward the north as default and thus\n        represent the cardinal degree value 0 mod 360.\n\n        Returns:\n            float: cardinal degree\n        \"\"\"\n        return self.vector_extremities.cardinal_degree\n</code></pre>"},{"location":"api/geometry/discrete/linear/directed/vectorized_linear_spline/#otary.geometry.discrete.linear.directed.vectorized_linear_spline.VectorizedLinearSpline.cardinal_degree","title":"<code>cardinal_degree</code>  <code>property</code>","text":"<p>Returns the cardinal degree of the VectorizedLinearSpline in the cv2 space. It is calculated using the two extremities points that compose the object.</p> <p>We consider the top of the image to point toward the north as default and thus represent the cardinal degree value 0 mod 360.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>cardinal degree</p>"},{"location":"api/geometry/discrete/linear/directed/vectorized_linear_spline/#otary.geometry.discrete.linear.directed.vectorized_linear_spline.VectorizedLinearSpline.is_simple_vector","title":"<code>is_simple_vector</code>  <code>property</code>","text":"<p>Whether the VectorizedLinearSpline is just a two points vector or not</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True or false</p>"},{"location":"api/geometry/discrete/shape/polygon/","title":"Polygon","text":"<p>Polygon class to handle complexity with polygon calculation</p>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon","title":"<code>Polygon</code>","text":"<p>               Bases: <code>DiscreteGeometryEntity</code></p> <p>Polygon class which defines a polygon object which means any closed-shape</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>class Polygon(DiscreteGeometryEntity):\n    \"\"\"Polygon class which defines a polygon object which means any closed-shape\"\"\"\n\n    # pylint: disable=too-many-public-methods\n\n    def __init__(self, points: NDArray | list, is_cast_int: bool = False) -&gt; None:\n        if len(points) &lt;= 2:\n            raise ValueError(\n                \"Cannot create a Polygon since it must have 3 or more points\"\n            )\n        super().__init__(points=points, is_cast_int=is_cast_int)\n\n    # ---------------------------------- OTHER CONSTRUCTORS ----------------------------\n\n    @classmethod\n    def from_lines(cls, lines: NDArray) -&gt; Polygon:\n        \"\"\"The lines should describe a perfect closed shape polygon\n\n        Args:\n            lines (NDArray): array of lines of shape (n, 2, 2)\n\n        Returns:\n            (Polygon): a Polygon object\n        \"\"\"\n        nlines = len(lines)\n        shifted_lines = np.roll(\n            np.array(lines).reshape(nlines * 2, 2), shift=1, axis=0\n        ).reshape(nlines, 2, 2)\n        distances = np.linalg.norm(np.diff(shifted_lines, axis=1), axis=2)\n        if np.any(distances):  # a distance is different from 0\n            bad_idxs = np.nonzero(distances &gt; 0)\n            raise ValueError(\n                f\"Could not construct the polygon from the given lines.\"\n                f\"Please check at those indices: {bad_idxs}\"\n            )\n        points = lines[:, 0]\n        return Polygon(points=points)\n\n    @classmethod\n    def from_linear_entities_returns_vertices_ix(\n        cls, linear_entities: Sequence[LinearEntity]\n    ) -&gt; tuple[Polygon, list[int]]:\n        \"\"\"Convert a list of linear entities to polygon.\n\n        Beware: this method assumes entities are sorted and connected.\n        Conneted means that the last point of each entity is the first point\n        of the next entity.\n        This implies that the polygon is necessarily closed.\n\n        Args:\n            linear_entities (Sequence[LinearEntity]): List of linear entities.\n\n        Returns:\n            (Polygon, list[int]): polygon and indices of first vertex of each entity\n        \"\"\"\n        points = []\n        vertices_ix: list[int] = []\n        current_ix = 0\n        for i, linear_entity in enumerate(linear_entities):\n            if not isinstance(linear_entity, LinearEntity):\n                raise TypeError(\n                    f\"Expected a list of LinearEntity, but got {type(linear_entity)}\"\n                )\n\n            cond_first_pt_is_equal_prev_entity_last_pt = np.array_equal(\n                linear_entity.points[0], linear_entities[i - 1].points[-1]\n            )\n            if not cond_first_pt_is_equal_prev_entity_last_pt:\n                raise ValueError(\n                    f\"The first point of entity {i} ({linear_entity.points[0]}) \"\n                    f\"is not equal to the last point of entity {i-1} \"\n                    f\"({linear_entities[i-1].points[-1]})\"\n                )\n            pts_except_last = linear_entity.points[:-1, :]\n            points.append(pts_except_last)\n            vertices_ix.append(current_ix)\n            current_ix += len(pts_except_last)\n\n        points = np.concatenate(points, axis=0)\n        polygon = Polygon(points=points)\n        return polygon, vertices_ix\n\n    @classmethod\n    def from_linear_entities(\n        cls,\n        linear_entities: Sequence[LinearEntity],\n    ) -&gt; Polygon:\n        \"\"\"Convert a list of linear entities to polygon.\n\n        Beware: the method assumes entities are sorted and connected.\n\n        Args:\n            linear_entities (Sequence[LinearEntity]): List of linear entities.\n\n        Returns:\n            Polygon: polygon representation of the linear entity\n        \"\"\"\n        return cls.from_linear_entities_returns_vertices_ix(linear_entities)[0]\n\n    @classmethod\n    def from_unordered_lines_approx(\n        cls,\n        lines: NDArray,\n        max_dist_thresh: float = 50,\n        max_iterations: int = 50,\n        start_line_index: int = 0,\n    ) -&gt; Polygon:\n        \"\"\"Create a Polygon object from an unordered list of lines that approximate a\n        closed-shape. They approximate in the sense that they do not necessarily\n        share common points. This method computes the intersection points between lines.\n\n        Args:\n            lines (NDArray): array of lines of shape (n, 2, 2)\n            max_dist_thresh (float, optional): For any given point,\n                the maximum distance to consider two points as close. Defaults to 50.\n            max_iterations (float, optional): Maximum number of iterations before\n                finding a polygon.\n                It defines also the maximum number of lines in the polygon to be found.\n            start_line_index (int, optional): The starting line to find searching for\n                the polygon. Defaults to 0.\n\n        Returns:\n            (Polygon): a Polygon object\n        \"\"\"\n        # pylint: disable=too-many-locals\n        # pylint: disable=too-many-positional-arguments, too-many-arguments\n        lines = np.asarray(lines)\n        assert_list_of_lines(lines=lines)\n\n        _lines = copy.deepcopy(lines)\n        list_build_cnt = []\n        is_polygon_found = False\n        idx_seg_closest = start_line_index\n        i = 0\n        while not is_polygon_found and i &lt; max_iterations:\n            curseg = Segment(_lines[idx_seg_closest])\n            curpoint = curseg.asarray[1]\n            list_build_cnt.append(curseg.asarray)\n            _lines = np.delete(_lines, idx_seg_closest, axis=0)\n\n            if len(_lines) == 0:\n                logging.debug(\"No more lines to be processed.\")\n\n            # find the closest point to the current one and associated line\n            lines2points = _lines.reshape(len(_lines) * 2, 2)\n            dist_from_curpoint = np.linalg.norm(lines2points - curpoint, axis=1)\n            idx_closest_points = np.nonzero(dist_from_curpoint &lt; max_dist_thresh)[0]\n\n            if len(idx_closest_points) &gt; 1:\n                # more than one point close to the current point - take the closest\n                idx_closest_points = np.array([np.argmin(dist_from_curpoint)])\n            if len(idx_closest_points) == 0:\n                # no point detected - can mean that the polygon is done or not\n                first_seg = Segment(list_build_cnt[0])\n                if np.linalg.norm(first_seg.asarray[0] - curpoint) &lt; max_dist_thresh:\n                    intersect_point = curseg.intersection_line(first_seg)\n                    list_build_cnt[-1][1] = intersect_point\n                    list_build_cnt[0][0] = intersect_point\n                    is_polygon_found = True\n                    break\n                raise RuntimeError(\"No point detected close to the current point\")\n\n            # only one closest point - get indices of unique closest point on segment\n            idx_point_closest = int(idx_closest_points[0])\n            idx_seg_closest = int(np.floor(idx_point_closest / 2))\n\n            # arrange the line so that the closest point is in the first place\n            idx_point_in_line = 0 if (idx_point_closest / 2).is_integer() else 1\n            seg_closest = _lines[idx_seg_closest]\n            if idx_point_in_line == 1:  # flip points positions\n                seg_closest = np.flip(seg_closest, axis=0)\n            _lines[idx_seg_closest] = seg_closest\n\n            # find intersection point between the two lines\n            intersect_point = curseg.intersection_line(Segment(seg_closest))\n\n            # update arrays with the intersection point\n            _lines[idx_seg_closest][0] = intersect_point\n            list_build_cnt[i][1] = intersect_point\n\n            i += 1\n\n        cnt = Polygon.from_lines(np.array(list_build_cnt, dtype=np.int32))\n        return cnt\n\n    # --------------------------------- PROPERTIES ------------------------------------\n\n    @property\n    def shapely_surface(self) -&gt; SPolygon:\n        \"\"\"Returns the Shapely.Polygon as an surface representation of the Polygon.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html\n\n        Returns:\n            Polygon: shapely.Polygon object\n        \"\"\"\n        return SPolygon(self.asarray, holes=None)\n\n    @property\n    def shapely_edges(self) -&gt; LinearRing:\n        \"\"\"Returns the Shapely.LinearRing as a curve representation of the Polygon.\n        See https://shapely.readthedocs.io/en/stable/reference/shapely.LinearRing.html\n\n        Returns:\n            LinearRing: shapely.LinearRing object\n        \"\"\"\n        return LinearRing(coordinates=self.asarray)\n\n    @property\n    def centroid(self) -&gt; NDArray:\n        \"\"\"Compute the centroid point which can be seen as the center of gravity\n        or center of mass of the shape.\n\n        Beware: if the shape is degenerate, the centroid will be undefined.\n        In that case, the mean of the points is returned.\n\n        Returns:\n            NDArray: centroid point\n        \"\"\"\n        M = cv2.moments(self.asarray.astype(np.float32).reshape((-1, 1, 2)))\n\n        # Avoid division by zero\n        if M[\"m00\"] != 0:\n            cx = M[\"m10\"] / M[\"m00\"]\n            cy = M[\"m01\"] / M[\"m00\"]\n            centroid = np.asarray([cx, cy])\n        else:\n            centroid = self.center_mean\n\n        return centroid\n\n    @property\n    def area(self) -&gt; float:\n        \"\"\"Compute the area of the geometry entity\n\n        Returns:\n            float: area value\n        \"\"\"\n        return cv2.contourArea(self.points.astype(np.int32))\n\n    @property\n    def perimeter(self) -&gt; float:\n        \"\"\"Compute the perimeter of the geometry entity\n\n        Returns:\n            float: perimeter value\n        \"\"\"\n        return cv2.arcLength(self.points.astype(np.float32), True)\n\n    @property\n    def is_self_intersected(self) -&gt; bool:\n        \"\"\"Whether any of the segments intersect another segment in the same set\n\n        Returns:\n            bool: True if at least two lines intersect, False otherwise\n        \"\"\"\n        return not self.shapely_edges.is_simple\n\n    @property\n    def is_convex(self) -&gt; bool:\n        \"\"\"Whether the Polygon describes a convex shape of not.\n\n        Returns:\n            bool: True if convex else False\n        \"\"\"\n        return cv2.isContourConvex(contour=self.asarray)\n\n    @property\n    def edges(self) -&gt; NDArray:\n        \"\"\"Get the lines that compose the geometry entity.\n\n        Args:\n            points (NDArray): array of points of shape (n, 2)\n\n        Returns:\n            NDArray: array of lines of shape (n, 2, 2)\n        \"\"\"\n        return np.stack([self.points, np.roll(self.points, shift=-1, axis=0)], axis=1)\n\n    # ------------------------------- CLASSIC METHODS ----------------------------------\n\n    def is_regular(self, margin_dist_error_pct: float = 1e-2) -&gt; bool:\n        \"\"\"Identifies whether the polygon is regular, this means is rectangular or is\n        a square.\n\n        Args:\n            margin_dist_error_pct (float, optional): margin for a distance error.\n                The percentage is multiplied by the square root of the product of\n                the diagonals. Defaults to 1e-2.\n\n        Returns:\n            bool: True if the polygon describes a rectangle or square.\n        \"\"\"\n        # check we have four points\n        if len(self.asarray) != 4:\n            return False\n\n        # compute diagonal 1 = taking reference index as 1st point in list - index 0\n        refpoint = self.asarray[0]\n        idx_max_dist = self.find_vertice_ix_farthest_from(point=refpoint)\n        farther_point = self.asarray[idx_max_dist]\n        diag1 = Segment(points=[refpoint, farther_point])\n\n        # compute diagonal 2\n        diag2_idxs = [1, 2, 3]  # every index except 0\n        diag2_idxs.remove(idx_max_dist)  # delete index of point in first diag\n        diag2 = Segment(points=self.asarray[diag2_idxs])\n\n        # rectangular criteria = the diagonals have same lengths\n        normed_length = np.sqrt(diag1.length * diag2.length)\n        if np.abs(diag1.length - diag2.length) &gt; normed_length * margin_dist_error_pct:\n            return False\n\n        # there should exist only one intersection point\n        intersection_points = diag1.intersection(other=diag2)\n        if len(intersection_points) != 1:\n            return False\n\n        # diagonals bisect on the center of both diagonal\n        cross_point = intersection_points[0]\n        dist_mid_cross_diag1 = np.linalg.norm(cross_point - diag1.centroid)\n        dist_mid_cross_diag2 = np.linalg.norm(cross_point - diag2.centroid)\n        if (\n            np.abs(dist_mid_cross_diag1) &gt; normed_length * margin_dist_error_pct\n            or np.abs(dist_mid_cross_diag2) &gt; normed_length * margin_dist_error_pct\n        ):\n            return False\n\n        return True\n\n    def is_clockwise(self, is_y_axis_down: bool = False) -&gt; bool:\n        \"\"\"Determine if a polygon points go clockwise using the Shoelace formula.\n\n        True if polygon vertices order is clockwise in the \"y-axis points up\"\n        referential.\n\n        Args:\n            is_y_axis_down (bool, optional): If is_y_axis_down is True, then the image\n                referential is used where y axis points down.\n\n        Returns:\n            bool: True if clockwise, False if counter-clockwise\n        \"\"\"\n        x = self.asarray[:, 0]\n        y = self.asarray[:, 1]\n\n        x_next = np.roll(x, -1)\n        y_next = np.roll(y, -1)\n\n        s = np.sum((x_next - x) * (y_next + y))\n\n        is_clockwise = bool(s &gt; 0)  # Clockwise if positive (OpenCV's convention)\n\n        if is_y_axis_down:  # in referential where y axis points down\n            return not is_clockwise\n\n        return is_clockwise\n\n    def as_linear_spline(self, index: int = 0) -&gt; LinearSpline:\n        \"\"\"Get the polygon as a LinearSpline object.\n        This simply means a LinearSpline object with the same points as the Polygon\n        but with an extra point: the one at the index.\n\n        Returns:\n            LinearSpline: linear spline from polygon\n        \"\"\"\n        if index &lt; 0:\n            index += len(self)\n\n        index = index % len(self)\n\n        return LinearSpline(\n            points=np.concat(\n                [self.asarray[index : len(self)], self.asarray[0 : index + 1]], axis=0\n            )\n        )\n\n    def contains(self, other: GeometryEntity, dilate_scale: float = 1) -&gt; bool:\n        \"\"\"Whether the geometry contains the other or not\n\n        Args:\n            other (GeometryEntity): a GeometryEntity object\n            dilate_scale (float): if greater than 1, the object will be scaled up\n                before checking if it contains the other Geometry Entity. Can not be\n                a value less than 1.\n\n        Returns:\n            bool: True if the entity contains the other\n        \"\"\"\n        if dilate_scale != 1:\n            surface = self.copy().expand(scale=dilate_scale).shapely_surface\n        else:\n            surface = self.shapely_surface\n        return surface.contains(other.shapely_surface)\n\n    def score_vertices_in_points(self, points: NDArray, max_distance: float) -&gt; NDArray:\n        \"\"\"Returns a score of 0 or 1 for each point in the polygon if it is close\n        enough to any point in the input points.\n\n        Args:\n            points (NDArray): list of 2D points\n            max_distance (float): maximum distance to consider two points as\n                close enough to be considered as the same points\n\n        Returns:\n            NDArray: a list of score for each point in the contour\n        \"\"\"\n\n        indices = get_shared_point_indices(\n            points_to_check=self.asarray,\n            checkpoints=points,\n            margin_dist_error=max_distance,\n            method=\"close\",\n            cond=\"any\",\n        )\n        score = np.bincount(indices, minlength=len(self))\n        return score\n\n    def find_vertices_between(self, start_index: int, end_index: int) -&gt; NDArray:\n        \"\"\"Get the vertices between two indices.\n\n        Returns always the vertices between start_index and end_index using the\n        natural order of the vertices in the contour.\n\n        By convention, if start_index == end_index, then it returns the whole contour\n        plus the vertice at start_index.\n\n        Args:\n            start_index (int): index of the first vertex\n            end_index (int): index of the last vertex\n\n        Returns:\n            NDArray: array of vertices\n        \"\"\"\n        if start_index &lt; 0:\n            start_index += len(self)\n        if end_index &lt; 0:\n            end_index += len(self)\n\n        start_index = start_index % len(self)\n        end_index = end_index % len(self)\n\n        if start_index &gt; end_index:\n            vertices = np.concat(\n                [\n                    self.asarray[start_index : len(self)],\n                    self.asarray[0 : end_index + 1],\n                ],\n                axis=0,\n            )\n        elif start_index == end_index:\n            vertices = self.as_linear_spline(index=start_index).asarray\n        else:\n            vertices = self.asarray[start_index : end_index + 1]\n\n        return vertices\n\n    def find_interpolated_point_and_prev_ix(\n        self, start_index: int, end_index: int, pct_dist: float\n    ) -&gt; tuple[NDArray, int]:\n        \"\"\"Return a point along the contour path from start_idx to end_idx (inclusive),\n        at a relative distance pct_dist \u2208 [0, 1] along that path.\n\n        By convention, if start_index == end_index, then use the whole contour\n        start at this index position.\n\n        Parameters:\n            start_index (int): Index of the start point in the contour\n            end_index (int): Index of the end point in the contour\n            pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n                Any value in [0, 1] returns a point between start and end that is\n                pct_dist along the path.\n\n        Returns:\n            NDArray: Interpolated point [x, y]\n        \"\"\"\n        if not 0 &lt;= pct_dist &lt;= 1:\n            raise ValueError(\"pct_dist must be in [0, 1]\")\n\n        if start_index &lt; 0:\n            start_index += len(self)\n        if end_index &lt; 0:\n            end_index += len(self)\n\n        start_index = start_index % len(self)\n        end_index = end_index % len(self)\n\n        path = LinearSpline(\n            points=self.find_vertices_between(\n                start_index=start_index, end_index=end_index\n            )\n        )\n\n        point, index = path.find_interpolated_point_and_prev_ix(pct_dist=pct_dist)\n        index = (index + start_index) % len(self)\n\n        return point, index\n\n    def find_interpolated_point(\n        self, start_index: int, end_index: int, pct_dist: float\n    ) -&gt; NDArray:\n        \"\"\"Return a point along the contour path from start_idx to end_idx (inclusive),\n        at a relative distance pct_dist \u2208 [0, 1] along that path.\n\n        By convention, if start_index == end_index, then use the whole contour\n        start at this index position.\n\n        Parameters:\n            start_index (int): Index of the start point in the contour\n            end_index (int): Index of the end point in the contour\n            pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n                Any value in [0, 1] returns a point between start and end that is\n                pct_dist along the path.\n\n        Returns:\n            NDArray: Interpolated point [x, y]\n        \"\"\"\n        return self.find_interpolated_point_and_prev_ix(\n            start_index=start_index, end_index=end_index, pct_dist=pct_dist\n        )[0]\n\n    def normal_point(\n        self,\n        start_index: int,\n        end_index: int,\n        dist_along_edge_pct: float,\n        dist_from_edge: float,\n        is_outward: bool = True,\n    ) -&gt; NDArray:\n        \"\"\"Compute the outward normal point.\n        This is a point that points toward the outside of the polygon\n\n        Args:\n            start_index (int): start index for the edge selection\n            end_index (int): end index for the edge selection\n            dist_along_edge_pct (float): distance along the edge to place the point\n            dist_from_edge (float): distance outward from the edge\n            is_outward (bool, optional): True if the normal points to the outside of\n                the polygon. False if the normal points to the inside of the polygon.\n                Defaults to True.\n\n        Returns:\n            NDArray: 2D point as array\n        \"\"\"\n        # pylint: disable=too-many-locals\n        # pylint: disable=too-many-arguments, too-many-positional-arguments,\n        if not 0.0 &lt;= dist_along_edge_pct &lt;= 1.0:\n            raise ValueError(\"dist_along_edge_pct must be in [0, 1]\")\n\n        pt_interpolated, prev_ix = self.find_interpolated_point_and_prev_ix(\n            start_index=start_index, end_index=end_index, pct_dist=dist_along_edge_pct\n        )\n        next_ix = (prev_ix + 1) % len(self)\n\n        is_interpolated_pt_existing_edge = np.array_equal(\n            pt_interpolated, self.asarray[prev_ix]\n        ) or np.array_equal(pt_interpolated, self.asarray[next_ix])\n        if is_interpolated_pt_existing_edge:\n            raise ValueError(\n                \"Interpolated point for normal computation is an existing vertice \"\n                \"along polygon. Please choose another dist_along_edge_pct parameter.\"\n            )\n\n        edge = Vector(points=[self.asarray[prev_ix], self.asarray[next_ix]])\n\n        normal = edge.normal().normalized\n\n        pt_plus = pt_interpolated + dist_from_edge * normal\n        pt_minus = pt_interpolated - dist_from_edge * normal\n\n        dist_plus = np.linalg.norm(pt_plus - self.centroid)\n        dist_minus = np.linalg.norm(pt_minus - self.centroid)\n\n        # choose the point which distance to the center is greater\n        if dist_plus &gt; dist_minus:\n            if is_outward:\n                return pt_plus\n            return pt_minus\n\n        if is_outward:\n            return pt_minus\n        return pt_plus\n\n    def inter_area(self, other: Polygon) -&gt; float:\n        \"\"\"Inter area with another Polygon\n\n        Args:\n            other (Polygon): other Polygon\n\n        Returns:\n            float: inter area value\n        \"\"\"\n        inter_pts = cv2.intersectConvexConvex(self.asarray, other.asarray)\n        if inter_pts[0] &gt; 0:\n            inter_area = cv2.contourArea(inter_pts[1])\n        else:\n            inter_area = 0.0\n        return inter_area\n\n    def union_area(self, other: Polygon) -&gt; float:\n        \"\"\"Union area with another Polygon\n\n        Args:\n            other (Polygon): other Polygon\n\n        Returns:\n            float: union area value\n        \"\"\"\n        return self.area + other.area - self.inter_area(other)\n\n    def iou(self, other: Polygon) -&gt; float:\n        \"\"\"Intersection over union with another Polygon\n\n        Args:\n            other (Polygon): other Polygon\n\n        Returns:\n            float: intersection over union value\n        \"\"\"\n        inter_area = self.inter_area(other)\n\n        # optimized not to compute twice the inter area\n        union_area = self.area + other.area - inter_area\n\n        if union_area == 0:\n            return 0.0\n        return inter_area / union_area\n\n    # ---------------------------- MODIFICATION METHODS -------------------------------\n\n    def add_vertice(self, point: NDArray, index: int) -&gt; Self:\n        \"\"\"Add a point at a given index in the Polygon object\n\n        Args:\n            point (NDArray): point to be added\n            index (int): index where the point will be added\n\n        Returns:\n            Polygon: Polygon object with an added point\n        \"\"\"\n        size = len(self)\n        if index &gt;= size:\n            raise ValueError(\n                f\"The index value {index} is too big. \"\n                f\"The maximum possible index value is {size-1}.\"\n            )\n        if index &lt; 0:\n            if abs(index) &gt; size + 1:\n                raise ValueError(\n                    f\"The index value {index} is too small. \"\n                    f\"The minimum possible index value is {-(size+1)}\"\n                )\n            index = size + index + 1\n\n        self.points = np.concatenate(\n            [self.points[:index], [point], self.points[index:]]\n        )\n        return self\n\n    def rearrange_first_vertice_at_index(self, index: int) -&gt; Self:\n        \"\"\"Rearrange the list of points that defines the Polygon so that the first\n        point in the list of points is the one at index given by the argument of this\n        function.\n\n        Args:\n            index (int): index value\n\n        Returns:\n            Polygon: Polygon which is the exact same one but with a rearranged list\n                of points.\n        \"\"\"\n        size = len(self)\n        if index &gt;= size:\n            raise ValueError(\n                f\"The index value {index} is too big. \"\n                f\"The maximum possible index value is {size-1}.\"\n            )\n        if index &lt; 0:\n            if abs(index) &gt; size:\n                raise ValueError(\n                    f\"The index value {index} is too small. \"\n                    f\"The minimum possible index value is {-size}\"\n                )\n            index = size + index\n\n        self.points = np.concatenate([self.points[index:], self.points[:index]])\n        return self\n\n    def rearrange_first_vertice_closest_to_point(\n        self, point: NDArray = np.zeros(shape=(2,))\n    ) -&gt; Polygon:\n        \"\"\"Rearrange the list of vertices that defines the Polygon so that the first\n        point in the list of vertices is the one that is the closest by distance to\n        the reference point.\n\n        Args:\n            point (NDArray): point that is taken as a reference in the\n                space to find the one in the Polygon list of points that is the\n                closest to this reference point. Default to origin point [0, 0].\n\n        Returns:\n            Polygon: Polygon which is the exact same one but with a rearranged list\n                of points.\n        \"\"\"\n        idx_min_dist = self.find_vertice_ix_closest_from(point=point)\n        return self.rearrange_first_vertice_at_index(index=idx_min_dist)\n\n    def reorder_clockwise(self, is_y_axis_down: bool = False) -&gt; Polygon:\n        \"\"\"Reorder the vertices of the polygon in clockwise order where the first point\n        stays the same.\n\n        Args:\n            is_y_axis_down (bool, optional): True if cv2 is used. Defaults to False.\n\n        Returns:\n            Polygon: reordered polygon\n        \"\"\"\n        if self.is_clockwise(is_y_axis_down=is_y_axis_down):\n            return self\n        self.asarray = np.roll(self.asarray[::-1], shift=1, axis=0)\n        return self\n\n    def __rescale(self, scale: float) -&gt; Polygon:\n        \"\"\"Create a new polygon that is scaled up or down.\n\n        The rescale method compute the vector that is directed from the polygon center\n        to each point. Then it rescales each vector and use the head point of each\n        vector to compose the new scaled polygon.\n\n        Args:\n            scale (float): float value to scale the polygon\n\n        Returns:\n            Polygon: scaled polygon\n        \"\"\"\n        if scale == 1.0:  # no rescaling\n            return self\n\n        center = self.centroid\n        self.asarray = self.asarray.astype(float)\n        for i, point in enumerate(self.asarray):\n            self.asarray[i] = Vector([center, point]).rescale_head(scale).head\n        return self\n\n    def expand(self, scale: float) -&gt; Polygon:\n        \"\"\"Stretch, dilate or expand a polygon\n\n        Args:\n            scale (float): scale expanding factor. Must be greater than 1.\n\n        Returns:\n            Polygon: new bigger polygon\n        \"\"\"\n        if scale &lt; 1:\n            raise ValueError(\n                \"The scale value can not be less than 1 when expanding a polygon. \"\n                f\"Found {scale}\"\n            )\n        return self.__rescale(scale=scale)\n\n    def shrink(self, scale: float) -&gt; Polygon:\n        \"\"\"Contract or shrink a polygon\n\n        Args:\n            scale (float): scale shrinking factor. Must be greater than 1.\n\n        Returns:\n            Polygon: new bigger polygon\n        \"\"\"\n        if scale &lt; 1:\n            raise ValueError(\n                \"The scale value can not be less than 1 when shrinking a polygon. \"\n                f\"Found {scale}\"\n            )\n        return self.__rescale(scale=1 / scale)\n\n    def to_image_crop_referential(\n        self,\n        other: Polygon,\n        crop: Rectangle,\n        image_crop_shape: Optional[tuple[int, int]] = None,\n    ) -&gt; Polygon:\n        \"\"\"This function can be useful for a very specific need:\n        In a single image you have two same polygons and their coordinates are defined\n        in this image referential.\n\n        You want to obtain the original polygon and all its vertices information\n        in the image crop referential to match the other polygon within it.\n\n        This method manipulates three referentials:\n        1. image referential (main referential)\n        2. crop referential\n        3. image crop referential. It is different from the crop referential\n            because the width and height of the crop referential may not be the same.\n\n        Args:\n            other (Polygon): other Polygon in the image referential\n            crop (Rectangle): crop rectangle in the image referential\n            image_crop_shape (tuple[int, int], optionla): [width, height] of the crop\n                image. If None, the shape is assumed to be directly the crop shape.\n\n\n        Returns:\n            Polygon: original polygon in the image crop referential\n        \"\"\"\n        if not crop.contains(other=other):\n            raise ValueError(\n                f\"The crop rectangle {crop} does not contain the other polygon {other}\"\n            )\n        crop_width = int(crop.get_width_from_topleft(0))\n        crop_height = int(crop.get_height_from_topleft(0))\n\n        if image_crop_shape is None:\n            image_crop_shape = (crop_width, crop_height)\n\n        # self polygon in the original image shifted and normalized\n        aabb_main = self.enclosing_axis_aligned_bbox()\n        contour_main_shifted_normalized = self.copy().shift(\n            vector=-np.asarray([self.xmin, self.ymin])\n        ) / np.array([aabb_main.width, aabb_main.height])\n\n        # AABB of the polygon in the crop referential\n        aabb_crop = other.enclosing_axis_aligned_bbox()\n        aabb_crop_normalized = (\n            aabb_crop - np.asarray([crop.xmin, crop.ymin])\n        ) / np.array([crop_width, crop_height])\n\n        # obtain the self polygon in the image crop referential\n        aabb_crop2 = aabb_crop_normalized * np.array(image_crop_shape)\n        new_polygon = contour_main_shifted_normalized * np.array(\n            [\n                aabb_crop2.get_width_from_topleft(0),\n                aabb_crop2.get_height_from_topleft(0),\n            ]\n        ) + np.asarray([aabb_crop2.xmin, aabb_crop2.ymin])\n\n        return new_polygon\n\n    # ------------------------------- Fundamental Methods ------------------------------\n\n    def is_equal(self, polygon: Polygon, dist_margin_error: float = 5) -&gt; bool:\n        \"\"\"Check whether two polygons objects are equal by considering a margin of\n        error based on a distance between points.\n\n        Args:\n            polygon (Polygon): Polygon object\n            dist_margin_error (float, optional): distance margin of error.\n                Defaults to 5.\n\n        Returns:\n            bool: True if the polygon are equal, False otherwise\n        \"\"\"\n        if self.n_points != polygon.n_points:\n            # if polygons do not have the same number of points they can not be similar\n            return False\n\n        # check if each points composing the polygons are close to each other\n        new_cnt = polygon.copy().rearrange_first_vertice_closest_to_point(\n            self.points[0]\n        )\n        points_diff = new_cnt.points - self.points\n        distances = np.linalg.norm(points_diff, axis=1)\n        max_distance = np.max(distances)\n        return max_distance &lt;= dist_margin_error\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.area","title":"<code>area</code>  <code>property</code>","text":"<p>Compute the area of the geometry entity</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>area value</p>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.centroid","title":"<code>centroid</code>  <code>property</code>","text":"<p>Compute the centroid point which can be seen as the center of gravity or center of mass of the shape.</p> <p>Beware: if the shape is degenerate, the centroid will be undefined. In that case, the mean of the points is returned.</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>centroid point</p>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.edges","title":"<code>edges</code>  <code>property</code>","text":"<p>Get the lines that compose the geometry entity.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>NDArray</code> <p>array of points of shape (n, 2)</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>array of lines of shape (n, 2, 2)</p>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.is_convex","title":"<code>is_convex</code>  <code>property</code>","text":"<p>Whether the Polygon describes a convex shape of not.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if convex else False</p>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.is_self_intersected","title":"<code>is_self_intersected</code>  <code>property</code>","text":"<p>Whether any of the segments intersect another segment in the same set</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if at least two lines intersect, False otherwise</p>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.perimeter","title":"<code>perimeter</code>  <code>property</code>","text":"<p>Compute the perimeter of the geometry entity</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>perimeter value</p>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.shapely_edges","title":"<code>shapely_edges</code>  <code>property</code>","text":"<p>Returns the Shapely.LinearRing as a curve representation of the Polygon. See https://shapely.readthedocs.io/en/stable/reference/shapely.LinearRing.html</p> <p>Returns:</p> Name Type Description <code>LinearRing</code> <code>LinearRing</code> <p>shapely.LinearRing object</p>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.shapely_surface","title":"<code>shapely_surface</code>  <code>property</code>","text":"<p>Returns the Shapely.Polygon as an surface representation of the Polygon. See https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html</p> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>shapely.Polygon object</p>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.__rescale","title":"<code>__rescale(scale)</code>","text":"<p>Create a new polygon that is scaled up or down.</p> <p>The rescale method compute the vector that is directed from the polygon center to each point. Then it rescales each vector and use the head point of each vector to compose the new scaled polygon.</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>float value to scale the polygon</p> required <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>scaled polygon</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def __rescale(self, scale: float) -&gt; Polygon:\n    \"\"\"Create a new polygon that is scaled up or down.\n\n    The rescale method compute the vector that is directed from the polygon center\n    to each point. Then it rescales each vector and use the head point of each\n    vector to compose the new scaled polygon.\n\n    Args:\n        scale (float): float value to scale the polygon\n\n    Returns:\n        Polygon: scaled polygon\n    \"\"\"\n    if scale == 1.0:  # no rescaling\n        return self\n\n    center = self.centroid\n    self.asarray = self.asarray.astype(float)\n    for i, point in enumerate(self.asarray):\n        self.asarray[i] = Vector([center, point]).rescale_head(scale).head\n    return self\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.add_vertice","title":"<code>add_vertice(point, index)</code>","text":"<p>Add a point at a given index in the Polygon object</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>point to be added</p> required <code>index</code> <code>int</code> <p>index where the point will be added</p> required <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Self</code> <p>Polygon object with an added point</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def add_vertice(self, point: NDArray, index: int) -&gt; Self:\n    \"\"\"Add a point at a given index in the Polygon object\n\n    Args:\n        point (NDArray): point to be added\n        index (int): index where the point will be added\n\n    Returns:\n        Polygon: Polygon object with an added point\n    \"\"\"\n    size = len(self)\n    if index &gt;= size:\n        raise ValueError(\n            f\"The index value {index} is too big. \"\n            f\"The maximum possible index value is {size-1}.\"\n        )\n    if index &lt; 0:\n        if abs(index) &gt; size + 1:\n            raise ValueError(\n                f\"The index value {index} is too small. \"\n                f\"The minimum possible index value is {-(size+1)}\"\n            )\n        index = size + index + 1\n\n    self.points = np.concatenate(\n        [self.points[:index], [point], self.points[index:]]\n    )\n    return self\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.as_linear_spline","title":"<code>as_linear_spline(index=0)</code>","text":"<p>Get the polygon as a LinearSpline object. This simply means a LinearSpline object with the same points as the Polygon but with an extra point: the one at the index.</p> <p>Returns:</p> Name Type Description <code>LinearSpline</code> <code>LinearSpline</code> <p>linear spline from polygon</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def as_linear_spline(self, index: int = 0) -&gt; LinearSpline:\n    \"\"\"Get the polygon as a LinearSpline object.\n    This simply means a LinearSpline object with the same points as the Polygon\n    but with an extra point: the one at the index.\n\n    Returns:\n        LinearSpline: linear spline from polygon\n    \"\"\"\n    if index &lt; 0:\n        index += len(self)\n\n    index = index % len(self)\n\n    return LinearSpline(\n        points=np.concat(\n            [self.asarray[index : len(self)], self.asarray[0 : index + 1]], axis=0\n        )\n    )\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.contains","title":"<code>contains(other, dilate_scale=1)</code>","text":"<p>Whether the geometry contains the other or not</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>GeometryEntity</code> <p>a GeometryEntity object</p> required <code>dilate_scale</code> <code>float</code> <p>if greater than 1, the object will be scaled up before checking if it contains the other Geometry Entity. Can not be a value less than 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the entity contains the other</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def contains(self, other: GeometryEntity, dilate_scale: float = 1) -&gt; bool:\n    \"\"\"Whether the geometry contains the other or not\n\n    Args:\n        other (GeometryEntity): a GeometryEntity object\n        dilate_scale (float): if greater than 1, the object will be scaled up\n            before checking if it contains the other Geometry Entity. Can not be\n            a value less than 1.\n\n    Returns:\n        bool: True if the entity contains the other\n    \"\"\"\n    if dilate_scale != 1:\n        surface = self.copy().expand(scale=dilate_scale).shapely_surface\n    else:\n        surface = self.shapely_surface\n    return surface.contains(other.shapely_surface)\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.expand","title":"<code>expand(scale)</code>","text":"<p>Stretch, dilate or expand a polygon</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>scale expanding factor. Must be greater than 1.</p> required <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>new bigger polygon</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def expand(self, scale: float) -&gt; Polygon:\n    \"\"\"Stretch, dilate or expand a polygon\n\n    Args:\n        scale (float): scale expanding factor. Must be greater than 1.\n\n    Returns:\n        Polygon: new bigger polygon\n    \"\"\"\n    if scale &lt; 1:\n        raise ValueError(\n            \"The scale value can not be less than 1 when expanding a polygon. \"\n            f\"Found {scale}\"\n        )\n    return self.__rescale(scale=scale)\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.find_interpolated_point","title":"<code>find_interpolated_point(start_index, end_index, pct_dist)</code>","text":"<p>Return a point along the contour path from start_idx to end_idx (inclusive), at a relative distance pct_dist \u2208 [0, 1] along that path.</p> <p>By convention, if start_index == end_index, then use the whole contour start at this index position.</p> <p>Parameters:</p> Name Type Description Default <code>start_index</code> <code>int</code> <p>Index of the start point in the contour</p> required <code>end_index</code> <code>int</code> <p>Index of the end point in the contour</p> required <code>pct_dist</code> <code>float</code> <p>Value in [0, 1], 0 returns start, 1 returns end. Any value in [0, 1] returns a point between start and end that is pct_dist along the path.</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>Interpolated point [x, y]</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def find_interpolated_point(\n    self, start_index: int, end_index: int, pct_dist: float\n) -&gt; NDArray:\n    \"\"\"Return a point along the contour path from start_idx to end_idx (inclusive),\n    at a relative distance pct_dist \u2208 [0, 1] along that path.\n\n    By convention, if start_index == end_index, then use the whole contour\n    start at this index position.\n\n    Parameters:\n        start_index (int): Index of the start point in the contour\n        end_index (int): Index of the end point in the contour\n        pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n            Any value in [0, 1] returns a point between start and end that is\n            pct_dist along the path.\n\n    Returns:\n        NDArray: Interpolated point [x, y]\n    \"\"\"\n    return self.find_interpolated_point_and_prev_ix(\n        start_index=start_index, end_index=end_index, pct_dist=pct_dist\n    )[0]\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.find_interpolated_point_and_prev_ix","title":"<code>find_interpolated_point_and_prev_ix(start_index, end_index, pct_dist)</code>","text":"<p>Return a point along the contour path from start_idx to end_idx (inclusive), at a relative distance pct_dist \u2208 [0, 1] along that path.</p> <p>By convention, if start_index == end_index, then use the whole contour start at this index position.</p> <p>Parameters:</p> Name Type Description Default <code>start_index</code> <code>int</code> <p>Index of the start point in the contour</p> required <code>end_index</code> <code>int</code> <p>Index of the end point in the contour</p> required <code>pct_dist</code> <code>float</code> <p>Value in [0, 1], 0 returns start, 1 returns end. Any value in [0, 1] returns a point between start and end that is pct_dist along the path.</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>tuple[NDArray, int]</code> <p>Interpolated point [x, y]</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def find_interpolated_point_and_prev_ix(\n    self, start_index: int, end_index: int, pct_dist: float\n) -&gt; tuple[NDArray, int]:\n    \"\"\"Return a point along the contour path from start_idx to end_idx (inclusive),\n    at a relative distance pct_dist \u2208 [0, 1] along that path.\n\n    By convention, if start_index == end_index, then use the whole contour\n    start at this index position.\n\n    Parameters:\n        start_index (int): Index of the start point in the contour\n        end_index (int): Index of the end point in the contour\n        pct_dist (float): Value in [0, 1], 0 returns start, 1 returns end.\n            Any value in [0, 1] returns a point between start and end that is\n            pct_dist along the path.\n\n    Returns:\n        NDArray: Interpolated point [x, y]\n    \"\"\"\n    if not 0 &lt;= pct_dist &lt;= 1:\n        raise ValueError(\"pct_dist must be in [0, 1]\")\n\n    if start_index &lt; 0:\n        start_index += len(self)\n    if end_index &lt; 0:\n        end_index += len(self)\n\n    start_index = start_index % len(self)\n    end_index = end_index % len(self)\n\n    path = LinearSpline(\n        points=self.find_vertices_between(\n            start_index=start_index, end_index=end_index\n        )\n    )\n\n    point, index = path.find_interpolated_point_and_prev_ix(pct_dist=pct_dist)\n    index = (index + start_index) % len(self)\n\n    return point, index\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.find_vertices_between","title":"<code>find_vertices_between(start_index, end_index)</code>","text":"<p>Get the vertices between two indices.</p> <p>Returns always the vertices between start_index and end_index using the natural order of the vertices in the contour.</p> <p>By convention, if start_index == end_index, then it returns the whole contour plus the vertice at start_index.</p> <p>Parameters:</p> Name Type Description Default <code>start_index</code> <code>int</code> <p>index of the first vertex</p> required <code>end_index</code> <code>int</code> <p>index of the last vertex</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>array of vertices</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def find_vertices_between(self, start_index: int, end_index: int) -&gt; NDArray:\n    \"\"\"Get the vertices between two indices.\n\n    Returns always the vertices between start_index and end_index using the\n    natural order of the vertices in the contour.\n\n    By convention, if start_index == end_index, then it returns the whole contour\n    plus the vertice at start_index.\n\n    Args:\n        start_index (int): index of the first vertex\n        end_index (int): index of the last vertex\n\n    Returns:\n        NDArray: array of vertices\n    \"\"\"\n    if start_index &lt; 0:\n        start_index += len(self)\n    if end_index &lt; 0:\n        end_index += len(self)\n\n    start_index = start_index % len(self)\n    end_index = end_index % len(self)\n\n    if start_index &gt; end_index:\n        vertices = np.concat(\n            [\n                self.asarray[start_index : len(self)],\n                self.asarray[0 : end_index + 1],\n            ],\n            axis=0,\n        )\n    elif start_index == end_index:\n        vertices = self.as_linear_spline(index=start_index).asarray\n    else:\n        vertices = self.asarray[start_index : end_index + 1]\n\n    return vertices\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.from_linear_entities","title":"<code>from_linear_entities(linear_entities)</code>  <code>classmethod</code>","text":"<p>Convert a list of linear entities to polygon.</p> <p>Beware: the method assumes entities are sorted and connected.</p> <p>Parameters:</p> Name Type Description Default <code>linear_entities</code> <code>Sequence[LinearEntity]</code> <p>List of linear entities.</p> required <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>polygon representation of the linear entity</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>@classmethod\ndef from_linear_entities(\n    cls,\n    linear_entities: Sequence[LinearEntity],\n) -&gt; Polygon:\n    \"\"\"Convert a list of linear entities to polygon.\n\n    Beware: the method assumes entities are sorted and connected.\n\n    Args:\n        linear_entities (Sequence[LinearEntity]): List of linear entities.\n\n    Returns:\n        Polygon: polygon representation of the linear entity\n    \"\"\"\n    return cls.from_linear_entities_returns_vertices_ix(linear_entities)[0]\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.from_linear_entities_returns_vertices_ix","title":"<code>from_linear_entities_returns_vertices_ix(linear_entities)</code>  <code>classmethod</code>","text":"<p>Convert a list of linear entities to polygon.</p> <p>Beware: this method assumes entities are sorted and connected. Conneted means that the last point of each entity is the first point of the next entity. This implies that the polygon is necessarily closed.</p> <p>Parameters:</p> Name Type Description Default <code>linear_entities</code> <code>Sequence[LinearEntity]</code> <p>List of linear entities.</p> required <p>Returns:</p> Type Description <code>(Polygon, list[int])</code> <p>polygon and indices of first vertex of each entity</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>@classmethod\ndef from_linear_entities_returns_vertices_ix(\n    cls, linear_entities: Sequence[LinearEntity]\n) -&gt; tuple[Polygon, list[int]]:\n    \"\"\"Convert a list of linear entities to polygon.\n\n    Beware: this method assumes entities are sorted and connected.\n    Conneted means that the last point of each entity is the first point\n    of the next entity.\n    This implies that the polygon is necessarily closed.\n\n    Args:\n        linear_entities (Sequence[LinearEntity]): List of linear entities.\n\n    Returns:\n        (Polygon, list[int]): polygon and indices of first vertex of each entity\n    \"\"\"\n    points = []\n    vertices_ix: list[int] = []\n    current_ix = 0\n    for i, linear_entity in enumerate(linear_entities):\n        if not isinstance(linear_entity, LinearEntity):\n            raise TypeError(\n                f\"Expected a list of LinearEntity, but got {type(linear_entity)}\"\n            )\n\n        cond_first_pt_is_equal_prev_entity_last_pt = np.array_equal(\n            linear_entity.points[0], linear_entities[i - 1].points[-1]\n        )\n        if not cond_first_pt_is_equal_prev_entity_last_pt:\n            raise ValueError(\n                f\"The first point of entity {i} ({linear_entity.points[0]}) \"\n                f\"is not equal to the last point of entity {i-1} \"\n                f\"({linear_entities[i-1].points[-1]})\"\n            )\n        pts_except_last = linear_entity.points[:-1, :]\n        points.append(pts_except_last)\n        vertices_ix.append(current_ix)\n        current_ix += len(pts_except_last)\n\n    points = np.concatenate(points, axis=0)\n    polygon = Polygon(points=points)\n    return polygon, vertices_ix\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.from_lines","title":"<code>from_lines(lines)</code>  <code>classmethod</code>","text":"<p>The lines should describe a perfect closed shape polygon</p> <p>Parameters:</p> Name Type Description Default <code>lines</code> <code>NDArray</code> <p>array of lines of shape (n, 2, 2)</p> required <p>Returns:</p> Type Description <code>Polygon</code> <p>a Polygon object</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>@classmethod\ndef from_lines(cls, lines: NDArray) -&gt; Polygon:\n    \"\"\"The lines should describe a perfect closed shape polygon\n\n    Args:\n        lines (NDArray): array of lines of shape (n, 2, 2)\n\n    Returns:\n        (Polygon): a Polygon object\n    \"\"\"\n    nlines = len(lines)\n    shifted_lines = np.roll(\n        np.array(lines).reshape(nlines * 2, 2), shift=1, axis=0\n    ).reshape(nlines, 2, 2)\n    distances = np.linalg.norm(np.diff(shifted_lines, axis=1), axis=2)\n    if np.any(distances):  # a distance is different from 0\n        bad_idxs = np.nonzero(distances &gt; 0)\n        raise ValueError(\n            f\"Could not construct the polygon from the given lines.\"\n            f\"Please check at those indices: {bad_idxs}\"\n        )\n    points = lines[:, 0]\n    return Polygon(points=points)\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.from_unordered_lines_approx","title":"<code>from_unordered_lines_approx(lines, max_dist_thresh=50, max_iterations=50, start_line_index=0)</code>  <code>classmethod</code>","text":"<p>Create a Polygon object from an unordered list of lines that approximate a closed-shape. They approximate in the sense that they do not necessarily share common points. This method computes the intersection points between lines.</p> <p>Parameters:</p> Name Type Description Default <code>lines</code> <code>NDArray</code> <p>array of lines of shape (n, 2, 2)</p> required <code>max_dist_thresh</code> <code>float</code> <p>For any given point, the maximum distance to consider two points as close. Defaults to 50.</p> <code>50</code> <code>max_iterations</code> <code>float</code> <p>Maximum number of iterations before finding a polygon. It defines also the maximum number of lines in the polygon to be found.</p> <code>50</code> <code>start_line_index</code> <code>int</code> <p>The starting line to find searching for the polygon. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>Polygon</code> <p>a Polygon object</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>@classmethod\ndef from_unordered_lines_approx(\n    cls,\n    lines: NDArray,\n    max_dist_thresh: float = 50,\n    max_iterations: int = 50,\n    start_line_index: int = 0,\n) -&gt; Polygon:\n    \"\"\"Create a Polygon object from an unordered list of lines that approximate a\n    closed-shape. They approximate in the sense that they do not necessarily\n    share common points. This method computes the intersection points between lines.\n\n    Args:\n        lines (NDArray): array of lines of shape (n, 2, 2)\n        max_dist_thresh (float, optional): For any given point,\n            the maximum distance to consider two points as close. Defaults to 50.\n        max_iterations (float, optional): Maximum number of iterations before\n            finding a polygon.\n            It defines also the maximum number of lines in the polygon to be found.\n        start_line_index (int, optional): The starting line to find searching for\n            the polygon. Defaults to 0.\n\n    Returns:\n        (Polygon): a Polygon object\n    \"\"\"\n    # pylint: disable=too-many-locals\n    # pylint: disable=too-many-positional-arguments, too-many-arguments\n    lines = np.asarray(lines)\n    assert_list_of_lines(lines=lines)\n\n    _lines = copy.deepcopy(lines)\n    list_build_cnt = []\n    is_polygon_found = False\n    idx_seg_closest = start_line_index\n    i = 0\n    while not is_polygon_found and i &lt; max_iterations:\n        curseg = Segment(_lines[idx_seg_closest])\n        curpoint = curseg.asarray[1]\n        list_build_cnt.append(curseg.asarray)\n        _lines = np.delete(_lines, idx_seg_closest, axis=0)\n\n        if len(_lines) == 0:\n            logging.debug(\"No more lines to be processed.\")\n\n        # find the closest point to the current one and associated line\n        lines2points = _lines.reshape(len(_lines) * 2, 2)\n        dist_from_curpoint = np.linalg.norm(lines2points - curpoint, axis=1)\n        idx_closest_points = np.nonzero(dist_from_curpoint &lt; max_dist_thresh)[0]\n\n        if len(idx_closest_points) &gt; 1:\n            # more than one point close to the current point - take the closest\n            idx_closest_points = np.array([np.argmin(dist_from_curpoint)])\n        if len(idx_closest_points) == 0:\n            # no point detected - can mean that the polygon is done or not\n            first_seg = Segment(list_build_cnt[0])\n            if np.linalg.norm(first_seg.asarray[0] - curpoint) &lt; max_dist_thresh:\n                intersect_point = curseg.intersection_line(first_seg)\n                list_build_cnt[-1][1] = intersect_point\n                list_build_cnt[0][0] = intersect_point\n                is_polygon_found = True\n                break\n            raise RuntimeError(\"No point detected close to the current point\")\n\n        # only one closest point - get indices of unique closest point on segment\n        idx_point_closest = int(idx_closest_points[0])\n        idx_seg_closest = int(np.floor(idx_point_closest / 2))\n\n        # arrange the line so that the closest point is in the first place\n        idx_point_in_line = 0 if (idx_point_closest / 2).is_integer() else 1\n        seg_closest = _lines[idx_seg_closest]\n        if idx_point_in_line == 1:  # flip points positions\n            seg_closest = np.flip(seg_closest, axis=0)\n        _lines[idx_seg_closest] = seg_closest\n\n        # find intersection point between the two lines\n        intersect_point = curseg.intersection_line(Segment(seg_closest))\n\n        # update arrays with the intersection point\n        _lines[idx_seg_closest][0] = intersect_point\n        list_build_cnt[i][1] = intersect_point\n\n        i += 1\n\n    cnt = Polygon.from_lines(np.array(list_build_cnt, dtype=np.int32))\n    return cnt\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.inter_area","title":"<code>inter_area(other)</code>","text":"<p>Inter area with another Polygon</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Polygon</code> <p>other Polygon</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>inter area value</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def inter_area(self, other: Polygon) -&gt; float:\n    \"\"\"Inter area with another Polygon\n\n    Args:\n        other (Polygon): other Polygon\n\n    Returns:\n        float: inter area value\n    \"\"\"\n    inter_pts = cv2.intersectConvexConvex(self.asarray, other.asarray)\n    if inter_pts[0] &gt; 0:\n        inter_area = cv2.contourArea(inter_pts[1])\n    else:\n        inter_area = 0.0\n    return inter_area\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.iou","title":"<code>iou(other)</code>","text":"<p>Intersection over union with another Polygon</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Polygon</code> <p>other Polygon</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>intersection over union value</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def iou(self, other: Polygon) -&gt; float:\n    \"\"\"Intersection over union with another Polygon\n\n    Args:\n        other (Polygon): other Polygon\n\n    Returns:\n        float: intersection over union value\n    \"\"\"\n    inter_area = self.inter_area(other)\n\n    # optimized not to compute twice the inter area\n    union_area = self.area + other.area - inter_area\n\n    if union_area == 0:\n        return 0.0\n    return inter_area / union_area\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.is_clockwise","title":"<code>is_clockwise(is_y_axis_down=False)</code>","text":"<p>Determine if a polygon points go clockwise using the Shoelace formula.</p> <p>True if polygon vertices order is clockwise in the \"y-axis points up\" referential.</p> <p>Parameters:</p> Name Type Description Default <code>is_y_axis_down</code> <code>bool</code> <p>If is_y_axis_down is True, then the image referential is used where y axis points down.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if clockwise, False if counter-clockwise</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def is_clockwise(self, is_y_axis_down: bool = False) -&gt; bool:\n    \"\"\"Determine if a polygon points go clockwise using the Shoelace formula.\n\n    True if polygon vertices order is clockwise in the \"y-axis points up\"\n    referential.\n\n    Args:\n        is_y_axis_down (bool, optional): If is_y_axis_down is True, then the image\n            referential is used where y axis points down.\n\n    Returns:\n        bool: True if clockwise, False if counter-clockwise\n    \"\"\"\n    x = self.asarray[:, 0]\n    y = self.asarray[:, 1]\n\n    x_next = np.roll(x, -1)\n    y_next = np.roll(y, -1)\n\n    s = np.sum((x_next - x) * (y_next + y))\n\n    is_clockwise = bool(s &gt; 0)  # Clockwise if positive (OpenCV's convention)\n\n    if is_y_axis_down:  # in referential where y axis points down\n        return not is_clockwise\n\n    return is_clockwise\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.is_equal","title":"<code>is_equal(polygon, dist_margin_error=5)</code>","text":"<p>Check whether two polygons objects are equal by considering a margin of error based on a distance between points.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Polygon object</p> required <code>dist_margin_error</code> <code>float</code> <p>distance margin of error. Defaults to 5.</p> <code>5</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the polygon are equal, False otherwise</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def is_equal(self, polygon: Polygon, dist_margin_error: float = 5) -&gt; bool:\n    \"\"\"Check whether two polygons objects are equal by considering a margin of\n    error based on a distance between points.\n\n    Args:\n        polygon (Polygon): Polygon object\n        dist_margin_error (float, optional): distance margin of error.\n            Defaults to 5.\n\n    Returns:\n        bool: True if the polygon are equal, False otherwise\n    \"\"\"\n    if self.n_points != polygon.n_points:\n        # if polygons do not have the same number of points they can not be similar\n        return False\n\n    # check if each points composing the polygons are close to each other\n    new_cnt = polygon.copy().rearrange_first_vertice_closest_to_point(\n        self.points[0]\n    )\n    points_diff = new_cnt.points - self.points\n    distances = np.linalg.norm(points_diff, axis=1)\n    max_distance = np.max(distances)\n    return max_distance &lt;= dist_margin_error\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.is_regular","title":"<code>is_regular(margin_dist_error_pct=0.01)</code>","text":"<p>Identifies whether the polygon is regular, this means is rectangular or is a square.</p> <p>Parameters:</p> Name Type Description Default <code>margin_dist_error_pct</code> <code>float</code> <p>margin for a distance error. The percentage is multiplied by the square root of the product of the diagonals. Defaults to 1e-2.</p> <code>0.01</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the polygon describes a rectangle or square.</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def is_regular(self, margin_dist_error_pct: float = 1e-2) -&gt; bool:\n    \"\"\"Identifies whether the polygon is regular, this means is rectangular or is\n    a square.\n\n    Args:\n        margin_dist_error_pct (float, optional): margin for a distance error.\n            The percentage is multiplied by the square root of the product of\n            the diagonals. Defaults to 1e-2.\n\n    Returns:\n        bool: True if the polygon describes a rectangle or square.\n    \"\"\"\n    # check we have four points\n    if len(self.asarray) != 4:\n        return False\n\n    # compute diagonal 1 = taking reference index as 1st point in list - index 0\n    refpoint = self.asarray[0]\n    idx_max_dist = self.find_vertice_ix_farthest_from(point=refpoint)\n    farther_point = self.asarray[idx_max_dist]\n    diag1 = Segment(points=[refpoint, farther_point])\n\n    # compute diagonal 2\n    diag2_idxs = [1, 2, 3]  # every index except 0\n    diag2_idxs.remove(idx_max_dist)  # delete index of point in first diag\n    diag2 = Segment(points=self.asarray[diag2_idxs])\n\n    # rectangular criteria = the diagonals have same lengths\n    normed_length = np.sqrt(diag1.length * diag2.length)\n    if np.abs(diag1.length - diag2.length) &gt; normed_length * margin_dist_error_pct:\n        return False\n\n    # there should exist only one intersection point\n    intersection_points = diag1.intersection(other=diag2)\n    if len(intersection_points) != 1:\n        return False\n\n    # diagonals bisect on the center of both diagonal\n    cross_point = intersection_points[0]\n    dist_mid_cross_diag1 = np.linalg.norm(cross_point - diag1.centroid)\n    dist_mid_cross_diag2 = np.linalg.norm(cross_point - diag2.centroid)\n    if (\n        np.abs(dist_mid_cross_diag1) &gt; normed_length * margin_dist_error_pct\n        or np.abs(dist_mid_cross_diag2) &gt; normed_length * margin_dist_error_pct\n    ):\n        return False\n\n    return True\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.normal_point","title":"<code>normal_point(start_index, end_index, dist_along_edge_pct, dist_from_edge, is_outward=True)</code>","text":"<p>Compute the outward normal point. This is a point that points toward the outside of the polygon</p> <p>Parameters:</p> Name Type Description Default <code>start_index</code> <code>int</code> <p>start index for the edge selection</p> required <code>end_index</code> <code>int</code> <p>end index for the edge selection</p> required <code>dist_along_edge_pct</code> <code>float</code> <p>distance along the edge to place the point</p> required <code>dist_from_edge</code> <code>float</code> <p>distance outward from the edge</p> required <code>is_outward</code> <code>bool</code> <p>True if the normal points to the outside of the polygon. False if the normal points to the inside of the polygon. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>2D point as array</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def normal_point(\n    self,\n    start_index: int,\n    end_index: int,\n    dist_along_edge_pct: float,\n    dist_from_edge: float,\n    is_outward: bool = True,\n) -&gt; NDArray:\n    \"\"\"Compute the outward normal point.\n    This is a point that points toward the outside of the polygon\n\n    Args:\n        start_index (int): start index for the edge selection\n        end_index (int): end index for the edge selection\n        dist_along_edge_pct (float): distance along the edge to place the point\n        dist_from_edge (float): distance outward from the edge\n        is_outward (bool, optional): True if the normal points to the outside of\n            the polygon. False if the normal points to the inside of the polygon.\n            Defaults to True.\n\n    Returns:\n        NDArray: 2D point as array\n    \"\"\"\n    # pylint: disable=too-many-locals\n    # pylint: disable=too-many-arguments, too-many-positional-arguments,\n    if not 0.0 &lt;= dist_along_edge_pct &lt;= 1.0:\n        raise ValueError(\"dist_along_edge_pct must be in [0, 1]\")\n\n    pt_interpolated, prev_ix = self.find_interpolated_point_and_prev_ix(\n        start_index=start_index, end_index=end_index, pct_dist=dist_along_edge_pct\n    )\n    next_ix = (prev_ix + 1) % len(self)\n\n    is_interpolated_pt_existing_edge = np.array_equal(\n        pt_interpolated, self.asarray[prev_ix]\n    ) or np.array_equal(pt_interpolated, self.asarray[next_ix])\n    if is_interpolated_pt_existing_edge:\n        raise ValueError(\n            \"Interpolated point for normal computation is an existing vertice \"\n            \"along polygon. Please choose another dist_along_edge_pct parameter.\"\n        )\n\n    edge = Vector(points=[self.asarray[prev_ix], self.asarray[next_ix]])\n\n    normal = edge.normal().normalized\n\n    pt_plus = pt_interpolated + dist_from_edge * normal\n    pt_minus = pt_interpolated - dist_from_edge * normal\n\n    dist_plus = np.linalg.norm(pt_plus - self.centroid)\n    dist_minus = np.linalg.norm(pt_minus - self.centroid)\n\n    # choose the point which distance to the center is greater\n    if dist_plus &gt; dist_minus:\n        if is_outward:\n            return pt_plus\n        return pt_minus\n\n    if is_outward:\n        return pt_minus\n    return pt_plus\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.rearrange_first_vertice_at_index","title":"<code>rearrange_first_vertice_at_index(index)</code>","text":"<p>Rearrange the list of points that defines the Polygon so that the first point in the list of points is the one at index given by the argument of this function.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>index value</p> required <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Self</code> <p>Polygon which is the exact same one but with a rearranged list of points.</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def rearrange_first_vertice_at_index(self, index: int) -&gt; Self:\n    \"\"\"Rearrange the list of points that defines the Polygon so that the first\n    point in the list of points is the one at index given by the argument of this\n    function.\n\n    Args:\n        index (int): index value\n\n    Returns:\n        Polygon: Polygon which is the exact same one but with a rearranged list\n            of points.\n    \"\"\"\n    size = len(self)\n    if index &gt;= size:\n        raise ValueError(\n            f\"The index value {index} is too big. \"\n            f\"The maximum possible index value is {size-1}.\"\n        )\n    if index &lt; 0:\n        if abs(index) &gt; size:\n            raise ValueError(\n                f\"The index value {index} is too small. \"\n                f\"The minimum possible index value is {-size}\"\n            )\n        index = size + index\n\n    self.points = np.concatenate([self.points[index:], self.points[:index]])\n    return self\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.rearrange_first_vertice_closest_to_point","title":"<code>rearrange_first_vertice_closest_to_point(point=np.zeros(shape=(2,)))</code>","text":"<p>Rearrange the list of vertices that defines the Polygon so that the first point in the list of vertices is the one that is the closest by distance to the reference point.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>point that is taken as a reference in the space to find the one in the Polygon list of points that is the closest to this reference point. Default to origin point [0, 0].</p> <code>zeros(shape=(2,))</code> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>Polygon which is the exact same one but with a rearranged list of points.</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def rearrange_first_vertice_closest_to_point(\n    self, point: NDArray = np.zeros(shape=(2,))\n) -&gt; Polygon:\n    \"\"\"Rearrange the list of vertices that defines the Polygon so that the first\n    point in the list of vertices is the one that is the closest by distance to\n    the reference point.\n\n    Args:\n        point (NDArray): point that is taken as a reference in the\n            space to find the one in the Polygon list of points that is the\n            closest to this reference point. Default to origin point [0, 0].\n\n    Returns:\n        Polygon: Polygon which is the exact same one but with a rearranged list\n            of points.\n    \"\"\"\n    idx_min_dist = self.find_vertice_ix_closest_from(point=point)\n    return self.rearrange_first_vertice_at_index(index=idx_min_dist)\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.reorder_clockwise","title":"<code>reorder_clockwise(is_y_axis_down=False)</code>","text":"<p>Reorder the vertices of the polygon in clockwise order where the first point stays the same.</p> <p>Parameters:</p> Name Type Description Default <code>is_y_axis_down</code> <code>bool</code> <p>True if cv2 is used. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>reordered polygon</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def reorder_clockwise(self, is_y_axis_down: bool = False) -&gt; Polygon:\n    \"\"\"Reorder the vertices of the polygon in clockwise order where the first point\n    stays the same.\n\n    Args:\n        is_y_axis_down (bool, optional): True if cv2 is used. Defaults to False.\n\n    Returns:\n        Polygon: reordered polygon\n    \"\"\"\n    if self.is_clockwise(is_y_axis_down=is_y_axis_down):\n        return self\n    self.asarray = np.roll(self.asarray[::-1], shift=1, axis=0)\n    return self\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.score_vertices_in_points","title":"<code>score_vertices_in_points(points, max_distance)</code>","text":"<p>Returns a score of 0 or 1 for each point in the polygon if it is close enough to any point in the input points.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>NDArray</code> <p>list of 2D points</p> required <code>max_distance</code> <code>float</code> <p>maximum distance to consider two points as close enough to be considered as the same points</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>a list of score for each point in the contour</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def score_vertices_in_points(self, points: NDArray, max_distance: float) -&gt; NDArray:\n    \"\"\"Returns a score of 0 or 1 for each point in the polygon if it is close\n    enough to any point in the input points.\n\n    Args:\n        points (NDArray): list of 2D points\n        max_distance (float): maximum distance to consider two points as\n            close enough to be considered as the same points\n\n    Returns:\n        NDArray: a list of score for each point in the contour\n    \"\"\"\n\n    indices = get_shared_point_indices(\n        points_to_check=self.asarray,\n        checkpoints=points,\n        margin_dist_error=max_distance,\n        method=\"close\",\n        cond=\"any\",\n    )\n    score = np.bincount(indices, minlength=len(self))\n    return score\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.shrink","title":"<code>shrink(scale)</code>","text":"<p>Contract or shrink a polygon</p> <p>Parameters:</p> Name Type Description Default <code>scale</code> <code>float</code> <p>scale shrinking factor. Must be greater than 1.</p> required <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>new bigger polygon</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def shrink(self, scale: float) -&gt; Polygon:\n    \"\"\"Contract or shrink a polygon\n\n    Args:\n        scale (float): scale shrinking factor. Must be greater than 1.\n\n    Returns:\n        Polygon: new bigger polygon\n    \"\"\"\n    if scale &lt; 1:\n        raise ValueError(\n            \"The scale value can not be less than 1 when shrinking a polygon. \"\n            f\"Found {scale}\"\n        )\n    return self.__rescale(scale=1 / scale)\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.to_image_crop_referential","title":"<code>to_image_crop_referential(other, crop, image_crop_shape=None)</code>","text":"<p>This function can be useful for a very specific need: In a single image you have two same polygons and their coordinates are defined in this image referential.</p> <p>You want to obtain the original polygon and all its vertices information in the image crop referential to match the other polygon within it.</p> <p>This method manipulates three referentials: 1. image referential (main referential) 2. crop referential 3. image crop referential. It is different from the crop referential     because the width and height of the crop referential may not be the same.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Polygon</code> <p>other Polygon in the image referential</p> required <code>crop</code> <code>Rectangle</code> <p>crop rectangle in the image referential</p> required <code>image_crop_shape</code> <code>(tuple[int, int], optionla)</code> <p>[width, height] of the crop image. If None, the shape is assumed to be directly the crop shape.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Polygon</code> <code>Polygon</code> <p>original polygon in the image crop referential</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def to_image_crop_referential(\n    self,\n    other: Polygon,\n    crop: Rectangle,\n    image_crop_shape: Optional[tuple[int, int]] = None,\n) -&gt; Polygon:\n    \"\"\"This function can be useful for a very specific need:\n    In a single image you have two same polygons and their coordinates are defined\n    in this image referential.\n\n    You want to obtain the original polygon and all its vertices information\n    in the image crop referential to match the other polygon within it.\n\n    This method manipulates three referentials:\n    1. image referential (main referential)\n    2. crop referential\n    3. image crop referential. It is different from the crop referential\n        because the width and height of the crop referential may not be the same.\n\n    Args:\n        other (Polygon): other Polygon in the image referential\n        crop (Rectangle): crop rectangle in the image referential\n        image_crop_shape (tuple[int, int], optionla): [width, height] of the crop\n            image. If None, the shape is assumed to be directly the crop shape.\n\n\n    Returns:\n        Polygon: original polygon in the image crop referential\n    \"\"\"\n    if not crop.contains(other=other):\n        raise ValueError(\n            f\"The crop rectangle {crop} does not contain the other polygon {other}\"\n        )\n    crop_width = int(crop.get_width_from_topleft(0))\n    crop_height = int(crop.get_height_from_topleft(0))\n\n    if image_crop_shape is None:\n        image_crop_shape = (crop_width, crop_height)\n\n    # self polygon in the original image shifted and normalized\n    aabb_main = self.enclosing_axis_aligned_bbox()\n    contour_main_shifted_normalized = self.copy().shift(\n        vector=-np.asarray([self.xmin, self.ymin])\n    ) / np.array([aabb_main.width, aabb_main.height])\n\n    # AABB of the polygon in the crop referential\n    aabb_crop = other.enclosing_axis_aligned_bbox()\n    aabb_crop_normalized = (\n        aabb_crop - np.asarray([crop.xmin, crop.ymin])\n    ) / np.array([crop_width, crop_height])\n\n    # obtain the self polygon in the image crop referential\n    aabb_crop2 = aabb_crop_normalized * np.array(image_crop_shape)\n    new_polygon = contour_main_shifted_normalized * np.array(\n        [\n            aabb_crop2.get_width_from_topleft(0),\n            aabb_crop2.get_height_from_topleft(0),\n        ]\n    ) + np.asarray([aabb_crop2.xmin, aabb_crop2.ymin])\n\n    return new_polygon\n</code></pre>"},{"location":"api/geometry/discrete/shape/polygon/#otary.geometry.discrete.shape.polygon.Polygon.union_area","title":"<code>union_area(other)</code>","text":"<p>Union area with another Polygon</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Polygon</code> <p>other Polygon</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>union area value</p> Source code in <code>otary/geometry/discrete/shape/polygon.py</code> <pre><code>def union_area(self, other: Polygon) -&gt; float:\n    \"\"\"Union area with another Polygon\n\n    Args:\n        other (Polygon): other Polygon\n\n    Returns:\n        float: union area value\n    \"\"\"\n    return self.area + other.area - self.inter_area(other)\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/","title":"Rectangle","text":"<p>Rectangle class. It will be particularly useful for the AITT project for describing bounding boxes.</p>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle","title":"<code>Rectangle</code>","text":"<p>               Bases: <code>Polygon</code></p> <p>Rectangle class to manipulate rectangle object</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>class Rectangle(Polygon):\n    \"\"\"Rectangle class to manipulate rectangle object\"\"\"\n\n    def __init__(\n        self,\n        points: NDArray | list,\n        is_cast_int: bool = False,\n        regularity_margin_error: float = 1e-2,\n        desintersect: bool = True,\n    ) -&gt; None:\n        \"\"\"Create a Rectangle object.\n\n        Args:\n            points (NDArray | list): 2D points that define the rectangle\n            is_cast_int (bool, optional): cast points to int. Defaults to False.\n            regularity_margin_error (float, optional): defines the allowed margin\n                distance error when checking if the points form a rectangle or not\n                on initialization.\n            desintersect (bool, optional): whether to desintersect the rectangle or not.\n                Can be useful if the input points are in a random order and\n                self-intersection is possible. In any case, if you try to instantiate\n                a self-intersected rectangle a ValueError will be raised.\n                Defaults to True.\n        \"\"\"\n        if len(points) != 4:\n            raise ValueError(\"Cannot create a Rectangle since it must have 4 points\")\n        super().__init__(points=points, is_cast_int=is_cast_int)\n\n        if desintersect:\n            self.desintersect()\n\n        if self.is_self_intersected:\n            raise ValueError(\n                \"The points form a self-intersected geometric object which is not \"\n                f\"allowed for a {self.__class__.__name__}\"\n            )\n\n        if not self.is_regular(margin_dist_error_pct=regularity_margin_error):\n            raise ValueError(\n                \"Try to create a Rectangle object but the coordinates \"\n                \"do not form a valid Rectangle. Please check your input coordinates, \"\n                \"the regularity_margin_error and the desintersect parameters.\"\n            )\n\n    @classmethod\n    def unit(cls) -&gt; Rectangle:\n        \"\"\"Create a unit Rectangle object\n\n        Returns:\n            Rectangle: new Rectangle object\n        \"\"\"\n        return cls(points=[[0, 0], [0, 1], [1, 1], [1, 0]])\n\n    @classmethod\n    def from_center(\n        cls,\n        center: NDArray,\n        width: float,\n        height: float,\n        is_cast_int: bool = False,\n    ) -&gt; Rectangle:\n        \"\"\"Create a Rectangle object using the center point, width, height.\n\n        Convention to create the rectangle is:\n            index 0: top left point\n            index 1: top right point\n            index 2: bottom right point\n            index 3: bottom left point\n\n        Args:\n            center (NDArray): center point of the rectangle\n            width (float): width of the rectangle\n            height (float): height of the rectangle\n            is_cast_int (bool, optional): cast the points coordinates to int\n\n        Returns:\n            Rectangle: Rectangle object\n        \"\"\"\n        # compute the halves lengths\n        half_width = width / 2\n        half_height = height / 2\n\n        # get center coordinates\n        center_x, center_y = center[0], center[1]\n\n        # get the rectangle coordinates\n        points = np.array(\n            [\n                [center_x - half_width, center_y - half_height],\n                [center_x + half_width, center_y - half_height],\n                [center_x + half_width, center_y + half_height],\n                [center_x - half_width, center_y + half_height],\n            ]\n        )\n\n        return Rectangle(points=points, is_cast_int=is_cast_int)\n\n    @classmethod\n    def from_topleft_bottomright(\n        cls,\n        topleft: NDArray,\n        bottomright: NDArray,\n        is_cast_int: bool = False,\n    ) -&gt; Self:\n        \"\"\"Create a Rectangle object using the top left and bottom right points.\n\n        Convention to create the rectangle is:\n            index 0: top left point\n            index 1: top right point\n            index 2: bottom right point\n            index 3: bottom left point\n\n        Args:\n            topleft (NDArray): top left point of the rectangle\n            bottomright (NDArray): bottom right point of the rectangle\n\n        Returns:\n            Rectangle: new Rectangle object\n        \"\"\"\n        topright_vertice = np.array([bottomright[0], topleft[1]])\n        bottomleft_vertice = np.array([topleft[0], bottomright[1]])\n        return cls(\n            np.asarray([topleft, topright_vertice, bottomright, bottomleft_vertice]),\n            is_cast_int=is_cast_int,\n        )\n\n    @classmethod\n    def from_topleft(\n        cls,\n        topleft: NDArray,\n        width: float,\n        height: float,\n        is_cast_int: bool = False,\n    ) -&gt; Self:\n        \"\"\"Create a Rectangle object using the top left point, width, height and angle.\n\n        Convention to create the rectangle is:\n            index 0: top left point\n            index 1: top right point\n            index 2: bottom right point\n            index 3: bottom left point\n\n        Args:\n            topleft (NDArray): top left point of the rectangle\n            width (float): width of the rectangle\n            height (float): height of the rectangle\n            is_cast_int (bool, optional): whether to cast int or not. Defaults to False.\n\n        Returns:\n            Rectangle: Rectangle object\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        bottomright_vertice = np.array([topleft[0] + width, topleft[1] + height])\n        return cls.from_topleft_bottomright(\n            topleft=topleft,\n            bottomright=bottomright_vertice,\n            is_cast_int=is_cast_int,\n        )\n\n    @property\n    def is_square(self) -&gt; bool:\n        \"\"\"Whether the rectangle is a square or not\n\n        Returns:\n            bool: True if the Rectangle is a Square\n        \"\"\"\n        if self.shortside_length == self.longside_length:\n            return True\n\n        return False\n\n    def is_axis_aligned_approx(self, precision: int = 3) -&gt; bool:\n        \"\"\"Check if the rectangle is axis-aligned\n\n        Args:\n            precision (int, optional): precision for the slope angle.\n                This define the number of decimals to consider for the angle\n                calculation of both the longside and shortside angle. Defaults to 3.\n\n        Returns:\n            bool: True if the rectangle is axis-aligned, False otherwise\n        \"\"\"\n\n        def is_mult_of_90_approx(x, precision: int) -&gt; bool:\n            return bool(round((x + 90 * 100), precision) % 90 == 0)\n\n        longside_cond = is_mult_of_90_approx(\n            self.longside_slope_angle(degree=True), precision=precision\n        )\n        shortside_cond = is_mult_of_90_approx(\n            self.shortside_slope_angle(degree=True), precision=precision\n        )\n        return longside_cond and shortside_cond\n\n    @property\n    def is_axis_aligned(self) -&gt; bool:\n        \"\"\"Check if the rectangle is exactly axis-aligned.\n        If you wish to check if a rectangle is only approximately axis-aligned,\n        use the `is_axis_aligned_approx` method.\n\n        Returns:\n            bool: True if the rectangle is exactly axis-aligned, False otherwise\n        \"\"\"\n        if self.points[0][1] != self.points[1][1]:  # top left y == top right y\n            return False\n        if self.points[1][0] != self.points[2][0]:  # top right x == bottom right x\n            return False\n        if self.points[2][1] != self.points[3][1]:  # bottom right y == bottom left y\n            return False\n        if self.points[3][0] != self.points[0][0]:  # bottom left x == top left x\n            return False\n        return True\n\n    @property\n    def longside_length(self) -&gt; float:\n        \"\"\"Compute the biggest side of the rectangle\n\n        Returns:\n            float: the biggest side length\n        \"\"\"\n        seg1 = self.segments[0]\n        seg2 = self.segments[1]\n        return seg1.length if seg1.length &gt; seg2.length else seg2.length\n\n    @property\n    def shortside_length(self) -&gt; float:\n        \"\"\"Compute the smallest side of the rectangle\n\n        Returns:\n            Segment: Longest side of the Rectangle as a Segment object\n        \"\"\"\n        seg1 = self.segments[0]\n        seg2 = self.segments[1]\n        return seg2.length if seg1.length &gt; seg2.length else seg1.length\n\n    def longside_slope_angle(\n        self, degree: bool = False, is_y_axis_down: bool = False\n    ) -&gt; float:\n        \"\"\"Compute the biggest slope of the rectangle\n\n        Returns:\n            float: the biggest slope\n        \"\"\"\n        seg1 = self.segments[0]\n        seg2 = self.segments[1]\n        seg_bigside = seg1 if seg1.length &gt; seg2.length else seg2\n        return seg_bigside.slope_angle(degree=degree, is_y_axis_down=is_y_axis_down)\n\n    def shortside_slope_angle(\n        self, degree: bool = False, is_y_axis_down: bool = False\n    ) -&gt; float:\n        \"\"\"Compute the smallest slope of the rectangle\n\n        Returns:\n            float: the smallest slope\n        \"\"\"\n        seg1 = self.segments[0]\n        seg2 = self.segments[1]\n        seg_smallside = seg2 if seg1.length &gt; seg2.length else seg1\n        return seg_smallside.slope_angle(degree=degree, is_y_axis_down=is_y_axis_down)\n\n    def desintersect(self) -&gt; Self:\n        \"\"\"Desintersect the rectangle if it is self-intersected.\n        If the rectangle is not self-intersected, returns the same rectangle.\n\n        Returns:\n            Rectangle: the desintersected Rectangle object\n        \"\"\"\n        if not self.is_self_intersected:\n            return self\n\n        # Sort points based on angle from centroid\n        def angle_from_center(pt):\n            return np.arctan2(pt[1] - self.centroid[1], pt[0] - self.centroid[0])\n\n        sorted_vertices = sorted(self.asarray, key=angle_from_center)\n        self.asarray = np.array(sorted_vertices)\n        return self\n\n    def join(\n        self, rect: Rectangle, margin_dist_error: float = 1e-5\n    ) -&gt; Optional[Rectangle]:\n        \"\"\"Join two rectangles into a single one.\n        If they share no point in common or only a single point returns None.\n        If they share two points, returns a new Rectangle that is the concatenation\n        of the two rectangles and that is not self-intersected.\n        If they share 3 or more points they represent the same rectangle, thus\n        returns this object.\n\n        Args:\n            rect (Rectangle): the other Rectangle object\n            margin_dist_error (float, optional): the threshold to consider whether the\n                rectangle share a common point. Defaults to 1e-5.\n\n        Returns:\n            Rectangle: the join new Rectangle object\n        \"\"\"\n        shared_points = self.find_shared_approx_vertices(rect, margin_dist_error)\n        n_shared_points = len(shared_points)\n\n        if n_shared_points in (0, 1):\n            return None\n        if n_shared_points == 2:\n            new_rect_points = np.concatenate(\n                (\n                    self.find_vertices_far_from(shared_points, margin_dist_error),\n                    rect.find_vertices_far_from(shared_points, margin_dist_error),\n                ),\n                axis=0,\n            )\n            return Rectangle(points=new_rect_points).desintersect()\n        # if 3 or more points in common it is the same rectangle\n        return self\n\n    def _topright_vertice_from_topleft(self, topleft_index: int) -&gt; NDArray:\n        \"\"\"Get the top-right vertice from the topleft vertice\n\n        Args:\n            topleft_index (int): index of the topleft vertice\n\n        Returns:\n            NDArray: topright vertice\n        \"\"\"\n        if self.is_clockwise(is_y_axis_down=True):\n            return self.asarray[(topleft_index + 1) % len(self)]\n        return self.asarray[topleft_index - 1]\n\n    def _bottomleft_vertice_from_topleft(self, topleft_index: int) -&gt; NDArray:\n        \"\"\"Get the bottom-left vertice from the topleft vertice\n\n        Args:\n            topleft_index (int): index of the topleft vertice\n\n        Returns:\n            NDArray: topright vertice\n        \"\"\"\n        if self.is_clockwise(is_y_axis_down=True):\n            return self.asarray[topleft_index - 1]\n        return self.asarray[(topleft_index + 1) % len(self)]\n\n    def _bottomright_vertice_from_topleft(self, topleft_index: int) -&gt; NDArray:\n        \"\"\"Get the bottom-right vertice from the topleft vertice\n\n        Args:\n            topleft_index (int): index of the topleft vertice\n\n        Returns:\n            NDArray: topright vertice\n        \"\"\"\n        return self.asarray[(topleft_index + 2) % len(self)]\n\n    def get_vertice_from_topleft(\n        self, topleft_index: int, vertice: str = \"topright\"\n    ) -&gt; NDArray:\n        \"\"\"Get vertice from the topleft vertice. You can use this method to\n        obtain the topright, bottomleft, bottomright vertice from the topleft vertice.\n\n        Returns:\n            NDArray: topright vertice\n        \"\"\"\n        if vertice not in (\"topright\", \"bottomleft\", \"bottomright\"):\n            raise ValueError(\n                \"Parameter vertice must be one of\"\n                \"'topright', 'bottomleft', 'bottomright'\"\n                f\"but got {vertice}\"\n            )\n        return getattr(self, f\"_{vertice}_vertice_from_topleft\")(topleft_index)\n\n    def get_width_from_topleft(self, topleft_index: int) -&gt; float:\n        \"\"\"Get the width from the topleft vertice\n\n        Args:\n            topleft_index (int): top-left vertice index\n\n        Returns:\n            float: width value\n        \"\"\"\n        return float(\n            np.linalg.norm(\n                self.asarray[topleft_index]\n                - self.get_vertice_from_topleft(topleft_index, \"topright\")\n            )\n        )\n\n    def get_height_from_topleft(self, topleft_index: int) -&gt; float:\n        \"\"\"Get the heigth from the topleft vertice\n\n        Args:\n            topleft_index (int): top-left vertice index\n\n        Returns:\n            float: height value\n        \"\"\"\n        return float(\n            np.linalg.norm(\n                self.asarray[topleft_index]\n                - self.get_vertice_from_topleft(topleft_index, \"bottomleft\")\n            )\n        )\n\n    def get_vector_up_from_topleft(self, topleft_index: int) -&gt; Vector:\n        \"\"\"Get the vector that goes from the bottomleft vertice to the topleft vertice\n\n        Args:\n            topleft_index (int): top-left vertice index\n\n        Returns:\n            Vector: Vector object descripting the vector\n        \"\"\"\n        bottomleft_vertice = self.get_vertice_from_topleft(\n            topleft_index=topleft_index, vertice=\"bottomleft\"\n        )\n        return Vector([bottomleft_vertice, self[topleft_index]])\n\n    def get_vector_left_from_topleft(self, topleft_index: int) -&gt; Vector:\n        \"\"\"Get the vector that goes from the topleft vertice to the topright vertice\n\n        Args:\n            topleft_index (int): top-left vertice index\n\n        Returns:\n            Vector: Vector object descripting the vector\n        \"\"\"\n        rect_topright_vertice = self.get_vertice_from_topleft(\n            topleft_index=topleft_index, vertice=\"topright\"\n        )\n        return Vector([self[topleft_index], rect_topright_vertice])\n\n    def __str__(self) -&gt; str:\n        return (  # pylint: disable=duplicate-code\n            self.__class__.__name__\n            + \"([\"\n            + self.asarray[0].tolist().__str__()\n            + \", \"\n            + self.asarray[1].tolist().__str__()\n            + \", \"\n            + self.asarray[2].tolist().__str__()\n            + \", \"\n            + self.asarray[3].tolist().__str__()\n            + \"])\"\n        )\n\n    def __repr__(self) -&gt; str:\n        return str(self)\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.is_axis_aligned","title":"<code>is_axis_aligned</code>  <code>property</code>","text":"<p>Check if the rectangle is exactly axis-aligned. If you wish to check if a rectangle is only approximately axis-aligned, use the <code>is_axis_aligned_approx</code> method.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the rectangle is exactly axis-aligned, False otherwise</p>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.is_square","title":"<code>is_square</code>  <code>property</code>","text":"<p>Whether the rectangle is a square or not</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the Rectangle is a Square</p>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.longside_length","title":"<code>longside_length</code>  <code>property</code>","text":"<p>Compute the biggest side of the rectangle</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>the biggest side length</p>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.shortside_length","title":"<code>shortside_length</code>  <code>property</code>","text":"<p>Compute the smallest side of the rectangle</p> <p>Returns:</p> Name Type Description <code>Segment</code> <code>float</code> <p>Longest side of the Rectangle as a Segment object</p>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.__init__","title":"<code>__init__(points, is_cast_int=False, regularity_margin_error=0.01, desintersect=True)</code>","text":"<p>Create a Rectangle object.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>NDArray | list</code> <p>2D points that define the rectangle</p> required <code>is_cast_int</code> <code>bool</code> <p>cast points to int. Defaults to False.</p> <code>False</code> <code>regularity_margin_error</code> <code>float</code> <p>defines the allowed margin distance error when checking if the points form a rectangle or not on initialization.</p> <code>0.01</code> <code>desintersect</code> <code>bool</code> <p>whether to desintersect the rectangle or not. Can be useful if the input points are in a random order and self-intersection is possible. In any case, if you try to instantiate a self-intersected rectangle a ValueError will be raised. Defaults to True.</p> <code>True</code> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def __init__(\n    self,\n    points: NDArray | list,\n    is_cast_int: bool = False,\n    regularity_margin_error: float = 1e-2,\n    desintersect: bool = True,\n) -&gt; None:\n    \"\"\"Create a Rectangle object.\n\n    Args:\n        points (NDArray | list): 2D points that define the rectangle\n        is_cast_int (bool, optional): cast points to int. Defaults to False.\n        regularity_margin_error (float, optional): defines the allowed margin\n            distance error when checking if the points form a rectangle or not\n            on initialization.\n        desintersect (bool, optional): whether to desintersect the rectangle or not.\n            Can be useful if the input points are in a random order and\n            self-intersection is possible. In any case, if you try to instantiate\n            a self-intersected rectangle a ValueError will be raised.\n            Defaults to True.\n    \"\"\"\n    if len(points) != 4:\n        raise ValueError(\"Cannot create a Rectangle since it must have 4 points\")\n    super().__init__(points=points, is_cast_int=is_cast_int)\n\n    if desintersect:\n        self.desintersect()\n\n    if self.is_self_intersected:\n        raise ValueError(\n            \"The points form a self-intersected geometric object which is not \"\n            f\"allowed for a {self.__class__.__name__}\"\n        )\n\n    if not self.is_regular(margin_dist_error_pct=regularity_margin_error):\n        raise ValueError(\n            \"Try to create a Rectangle object but the coordinates \"\n            \"do not form a valid Rectangle. Please check your input coordinates, \"\n            \"the regularity_margin_error and the desintersect parameters.\"\n        )\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.desintersect","title":"<code>desintersect()</code>","text":"<p>Desintersect the rectangle if it is self-intersected. If the rectangle is not self-intersected, returns the same rectangle.</p> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Self</code> <p>the desintersected Rectangle object</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def desintersect(self) -&gt; Self:\n    \"\"\"Desintersect the rectangle if it is self-intersected.\n    If the rectangle is not self-intersected, returns the same rectangle.\n\n    Returns:\n        Rectangle: the desintersected Rectangle object\n    \"\"\"\n    if not self.is_self_intersected:\n        return self\n\n    # Sort points based on angle from centroid\n    def angle_from_center(pt):\n        return np.arctan2(pt[1] - self.centroid[1], pt[0] - self.centroid[0])\n\n    sorted_vertices = sorted(self.asarray, key=angle_from_center)\n    self.asarray = np.array(sorted_vertices)\n    return self\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.from_center","title":"<code>from_center(center, width, height, is_cast_int=False)</code>  <code>classmethod</code>","text":"<p>Create a Rectangle object using the center point, width, height.</p> Convention to create the rectangle is <p>index 0: top left point index 1: top right point index 2: bottom right point index 3: bottom left point</p> <p>Parameters:</p> Name Type Description Default <code>center</code> <code>NDArray</code> <p>center point of the rectangle</p> required <code>width</code> <code>float</code> <p>width of the rectangle</p> required <code>height</code> <code>float</code> <p>height of the rectangle</p> required <code>is_cast_int</code> <code>bool</code> <p>cast the points coordinates to int</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Rectangle</code> <p>Rectangle object</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>@classmethod\ndef from_center(\n    cls,\n    center: NDArray,\n    width: float,\n    height: float,\n    is_cast_int: bool = False,\n) -&gt; Rectangle:\n    \"\"\"Create a Rectangle object using the center point, width, height.\n\n    Convention to create the rectangle is:\n        index 0: top left point\n        index 1: top right point\n        index 2: bottom right point\n        index 3: bottom left point\n\n    Args:\n        center (NDArray): center point of the rectangle\n        width (float): width of the rectangle\n        height (float): height of the rectangle\n        is_cast_int (bool, optional): cast the points coordinates to int\n\n    Returns:\n        Rectangle: Rectangle object\n    \"\"\"\n    # compute the halves lengths\n    half_width = width / 2\n    half_height = height / 2\n\n    # get center coordinates\n    center_x, center_y = center[0], center[1]\n\n    # get the rectangle coordinates\n    points = np.array(\n        [\n            [center_x - half_width, center_y - half_height],\n            [center_x + half_width, center_y - half_height],\n            [center_x + half_width, center_y + half_height],\n            [center_x - half_width, center_y + half_height],\n        ]\n    )\n\n    return Rectangle(points=points, is_cast_int=is_cast_int)\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.from_topleft","title":"<code>from_topleft(topleft, width, height, is_cast_int=False)</code>  <code>classmethod</code>","text":"<p>Create a Rectangle object using the top left point, width, height and angle.</p> Convention to create the rectangle is <p>index 0: top left point index 1: top right point index 2: bottom right point index 3: bottom left point</p> <p>Parameters:</p> Name Type Description Default <code>topleft</code> <code>NDArray</code> <p>top left point of the rectangle</p> required <code>width</code> <code>float</code> <p>width of the rectangle</p> required <code>height</code> <code>float</code> <p>height of the rectangle</p> required <code>is_cast_int</code> <code>bool</code> <p>whether to cast int or not. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Self</code> <p>Rectangle object</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>@classmethod\ndef from_topleft(\n    cls,\n    topleft: NDArray,\n    width: float,\n    height: float,\n    is_cast_int: bool = False,\n) -&gt; Self:\n    \"\"\"Create a Rectangle object using the top left point, width, height and angle.\n\n    Convention to create the rectangle is:\n        index 0: top left point\n        index 1: top right point\n        index 2: bottom right point\n        index 3: bottom left point\n\n    Args:\n        topleft (NDArray): top left point of the rectangle\n        width (float): width of the rectangle\n        height (float): height of the rectangle\n        is_cast_int (bool, optional): whether to cast int or not. Defaults to False.\n\n    Returns:\n        Rectangle: Rectangle object\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    bottomright_vertice = np.array([topleft[0] + width, topleft[1] + height])\n    return cls.from_topleft_bottomright(\n        topleft=topleft,\n        bottomright=bottomright_vertice,\n        is_cast_int=is_cast_int,\n    )\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.from_topleft_bottomright","title":"<code>from_topleft_bottomright(topleft, bottomright, is_cast_int=False)</code>  <code>classmethod</code>","text":"<p>Create a Rectangle object using the top left and bottom right points.</p> Convention to create the rectangle is <p>index 0: top left point index 1: top right point index 2: bottom right point index 3: bottom left point</p> <p>Parameters:</p> Name Type Description Default <code>topleft</code> <code>NDArray</code> <p>top left point of the rectangle</p> required <code>bottomright</code> <code>NDArray</code> <p>bottom right point of the rectangle</p> required <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Self</code> <p>new Rectangle object</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>@classmethod\ndef from_topleft_bottomright(\n    cls,\n    topleft: NDArray,\n    bottomright: NDArray,\n    is_cast_int: bool = False,\n) -&gt; Self:\n    \"\"\"Create a Rectangle object using the top left and bottom right points.\n\n    Convention to create the rectangle is:\n        index 0: top left point\n        index 1: top right point\n        index 2: bottom right point\n        index 3: bottom left point\n\n    Args:\n        topleft (NDArray): top left point of the rectangle\n        bottomright (NDArray): bottom right point of the rectangle\n\n    Returns:\n        Rectangle: new Rectangle object\n    \"\"\"\n    topright_vertice = np.array([bottomright[0], topleft[1]])\n    bottomleft_vertice = np.array([topleft[0], bottomright[1]])\n    return cls(\n        np.asarray([topleft, topright_vertice, bottomright, bottomleft_vertice]),\n        is_cast_int=is_cast_int,\n    )\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.get_height_from_topleft","title":"<code>get_height_from_topleft(topleft_index)</code>","text":"<p>Get the heigth from the topleft vertice</p> <p>Parameters:</p> Name Type Description Default <code>topleft_index</code> <code>int</code> <p>top-left vertice index</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>height value</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def get_height_from_topleft(self, topleft_index: int) -&gt; float:\n    \"\"\"Get the heigth from the topleft vertice\n\n    Args:\n        topleft_index (int): top-left vertice index\n\n    Returns:\n        float: height value\n    \"\"\"\n    return float(\n        np.linalg.norm(\n            self.asarray[topleft_index]\n            - self.get_vertice_from_topleft(topleft_index, \"bottomleft\")\n        )\n    )\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.get_vector_left_from_topleft","title":"<code>get_vector_left_from_topleft(topleft_index)</code>","text":"<p>Get the vector that goes from the topleft vertice to the topright vertice</p> <p>Parameters:</p> Name Type Description Default <code>topleft_index</code> <code>int</code> <p>top-left vertice index</p> required <p>Returns:</p> Name Type Description <code>Vector</code> <code>Vector</code> <p>Vector object descripting the vector</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def get_vector_left_from_topleft(self, topleft_index: int) -&gt; Vector:\n    \"\"\"Get the vector that goes from the topleft vertice to the topright vertice\n\n    Args:\n        topleft_index (int): top-left vertice index\n\n    Returns:\n        Vector: Vector object descripting the vector\n    \"\"\"\n    rect_topright_vertice = self.get_vertice_from_topleft(\n        topleft_index=topleft_index, vertice=\"topright\"\n    )\n    return Vector([self[topleft_index], rect_topright_vertice])\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.get_vector_up_from_topleft","title":"<code>get_vector_up_from_topleft(topleft_index)</code>","text":"<p>Get the vector that goes from the bottomleft vertice to the topleft vertice</p> <p>Parameters:</p> Name Type Description Default <code>topleft_index</code> <code>int</code> <p>top-left vertice index</p> required <p>Returns:</p> Name Type Description <code>Vector</code> <code>Vector</code> <p>Vector object descripting the vector</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def get_vector_up_from_topleft(self, topleft_index: int) -&gt; Vector:\n    \"\"\"Get the vector that goes from the bottomleft vertice to the topleft vertice\n\n    Args:\n        topleft_index (int): top-left vertice index\n\n    Returns:\n        Vector: Vector object descripting the vector\n    \"\"\"\n    bottomleft_vertice = self.get_vertice_from_topleft(\n        topleft_index=topleft_index, vertice=\"bottomleft\"\n    )\n    return Vector([bottomleft_vertice, self[topleft_index]])\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.get_vertice_from_topleft","title":"<code>get_vertice_from_topleft(topleft_index, vertice='topright')</code>","text":"<p>Get vertice from the topleft vertice. You can use this method to obtain the topright, bottomleft, bottomright vertice from the topleft vertice.</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>topright vertice</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def get_vertice_from_topleft(\n    self, topleft_index: int, vertice: str = \"topright\"\n) -&gt; NDArray:\n    \"\"\"Get vertice from the topleft vertice. You can use this method to\n    obtain the topright, bottomleft, bottomright vertice from the topleft vertice.\n\n    Returns:\n        NDArray: topright vertice\n    \"\"\"\n    if vertice not in (\"topright\", \"bottomleft\", \"bottomright\"):\n        raise ValueError(\n            \"Parameter vertice must be one of\"\n            \"'topright', 'bottomleft', 'bottomright'\"\n            f\"but got {vertice}\"\n        )\n    return getattr(self, f\"_{vertice}_vertice_from_topleft\")(topleft_index)\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.get_width_from_topleft","title":"<code>get_width_from_topleft(topleft_index)</code>","text":"<p>Get the width from the topleft vertice</p> <p>Parameters:</p> Name Type Description Default <code>topleft_index</code> <code>int</code> <p>top-left vertice index</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>width value</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def get_width_from_topleft(self, topleft_index: int) -&gt; float:\n    \"\"\"Get the width from the topleft vertice\n\n    Args:\n        topleft_index (int): top-left vertice index\n\n    Returns:\n        float: width value\n    \"\"\"\n    return float(\n        np.linalg.norm(\n            self.asarray[topleft_index]\n            - self.get_vertice_from_topleft(topleft_index, \"topright\")\n        )\n    )\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.is_axis_aligned_approx","title":"<code>is_axis_aligned_approx(precision=3)</code>","text":"<p>Check if the rectangle is axis-aligned</p> <p>Parameters:</p> Name Type Description Default <code>precision</code> <code>int</code> <p>precision for the slope angle. This define the number of decimals to consider for the angle calculation of both the longside and shortside angle. Defaults to 3.</p> <code>3</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the rectangle is axis-aligned, False otherwise</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def is_axis_aligned_approx(self, precision: int = 3) -&gt; bool:\n    \"\"\"Check if the rectangle is axis-aligned\n\n    Args:\n        precision (int, optional): precision for the slope angle.\n            This define the number of decimals to consider for the angle\n            calculation of both the longside and shortside angle. Defaults to 3.\n\n    Returns:\n        bool: True if the rectangle is axis-aligned, False otherwise\n    \"\"\"\n\n    def is_mult_of_90_approx(x, precision: int) -&gt; bool:\n        return bool(round((x + 90 * 100), precision) % 90 == 0)\n\n    longside_cond = is_mult_of_90_approx(\n        self.longside_slope_angle(degree=True), precision=precision\n    )\n    shortside_cond = is_mult_of_90_approx(\n        self.shortside_slope_angle(degree=True), precision=precision\n    )\n    return longside_cond and shortside_cond\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.join","title":"<code>join(rect, margin_dist_error=1e-05)</code>","text":"<p>Join two rectangles into a single one. If they share no point in common or only a single point returns None. If they share two points, returns a new Rectangle that is the concatenation of the two rectangles and that is not self-intersected. If they share 3 or more points they represent the same rectangle, thus returns this object.</p> <p>Parameters:</p> Name Type Description Default <code>rect</code> <code>Rectangle</code> <p>the other Rectangle object</p> required <code>margin_dist_error</code> <code>float</code> <p>the threshold to consider whether the rectangle share a common point. Defaults to 1e-5.</p> <code>1e-05</code> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Optional[Rectangle]</code> <p>the join new Rectangle object</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def join(\n    self, rect: Rectangle, margin_dist_error: float = 1e-5\n) -&gt; Optional[Rectangle]:\n    \"\"\"Join two rectangles into a single one.\n    If they share no point in common or only a single point returns None.\n    If they share two points, returns a new Rectangle that is the concatenation\n    of the two rectangles and that is not self-intersected.\n    If they share 3 or more points they represent the same rectangle, thus\n    returns this object.\n\n    Args:\n        rect (Rectangle): the other Rectangle object\n        margin_dist_error (float, optional): the threshold to consider whether the\n            rectangle share a common point. Defaults to 1e-5.\n\n    Returns:\n        Rectangle: the join new Rectangle object\n    \"\"\"\n    shared_points = self.find_shared_approx_vertices(rect, margin_dist_error)\n    n_shared_points = len(shared_points)\n\n    if n_shared_points in (0, 1):\n        return None\n    if n_shared_points == 2:\n        new_rect_points = np.concatenate(\n            (\n                self.find_vertices_far_from(shared_points, margin_dist_error),\n                rect.find_vertices_far_from(shared_points, margin_dist_error),\n            ),\n            axis=0,\n        )\n        return Rectangle(points=new_rect_points).desintersect()\n    # if 3 or more points in common it is the same rectangle\n    return self\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.longside_slope_angle","title":"<code>longside_slope_angle(degree=False, is_y_axis_down=False)</code>","text":"<p>Compute the biggest slope of the rectangle</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>the biggest slope</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def longside_slope_angle(\n    self, degree: bool = False, is_y_axis_down: bool = False\n) -&gt; float:\n    \"\"\"Compute the biggest slope of the rectangle\n\n    Returns:\n        float: the biggest slope\n    \"\"\"\n    seg1 = self.segments[0]\n    seg2 = self.segments[1]\n    seg_bigside = seg1 if seg1.length &gt; seg2.length else seg2\n    return seg_bigside.slope_angle(degree=degree, is_y_axis_down=is_y_axis_down)\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.shortside_slope_angle","title":"<code>shortside_slope_angle(degree=False, is_y_axis_down=False)</code>","text":"<p>Compute the smallest slope of the rectangle</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>the smallest slope</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>def shortside_slope_angle(\n    self, degree: bool = False, is_y_axis_down: bool = False\n) -&gt; float:\n    \"\"\"Compute the smallest slope of the rectangle\n\n    Returns:\n        float: the smallest slope\n    \"\"\"\n    seg1 = self.segments[0]\n    seg2 = self.segments[1]\n    seg_smallside = seg2 if seg1.length &gt; seg2.length else seg1\n    return seg_smallside.slope_angle(degree=degree, is_y_axis_down=is_y_axis_down)\n</code></pre>"},{"location":"api/geometry/discrete/shape/rectangle/#otary.geometry.discrete.shape.rectangle.Rectangle.unit","title":"<code>unit()</code>  <code>classmethod</code>","text":"<p>Create a unit Rectangle object</p> <p>Returns:</p> Name Type Description <code>Rectangle</code> <code>Rectangle</code> <p>new Rectangle object</p> Source code in <code>otary/geometry/discrete/shape/rectangle.py</code> <pre><code>@classmethod\ndef unit(cls) -&gt; Rectangle:\n    \"\"\"Create a unit Rectangle object\n\n    Returns:\n        Rectangle: new Rectangle object\n    \"\"\"\n    return cls(points=[[0, 0], [0, 1], [1, 1], [1, 0]])\n</code></pre>"},{"location":"api/geometry/discrete/shape/triangle/","title":"Triangle","text":"<p>Triangle class module</p>"},{"location":"api/geometry/discrete/shape/triangle/#otary.geometry.discrete.shape.triangle.Triangle","title":"<code>Triangle</code>","text":"<p>               Bases: <code>Polygon</code></p> <p>Triangle class</p> Source code in <code>otary/geometry/discrete/shape/triangle.py</code> <pre><code>class Triangle(Polygon):\n    \"\"\"Triangle class\"\"\"\n\n    def __init__(self, points: np.ndarray | list, is_cast_int: bool = False) -&gt; None:\n        if len(points) != 3:\n            raise ValueError(\"Cannot create a Triangle since it must have 3 points\")\n        super().__init__(points=points, is_cast_int=is_cast_int)\n\n    def __str__(self) -&gt; str:\n        return (  # pylint: disable=duplicate-code\n            self.__class__.__name__\n            + \"([\"\n            + self.asarray[0].tolist().__str__()\n            + \", \"\n            + self.asarray[1].tolist().__str__()\n            + \", \"\n            + self.asarray[2].tolist().__str__()\n            + \"])\"\n        )\n\n    def __repr__(self) -&gt; str:\n        return str(self)\n</code></pre>"},{"location":"api/image/","title":"Image","text":"<p>The <code>image</code> module provides a flexible and powerful way to work with images. Otary aims to make image processing easy and accessible to everyone.</p> <p>Here is a sample python code to show what Otary can do:</p> <pre><code>import otary as ot\n\nim = ot.Image.from_file(filepath=\"path/to/file/image\")\n\nim.crop(x0=50, y0=50, x1=450, y1=450)\nim.rotate(angle=90, is_degree=True)\n\nim.save(save_filepath=\"path/to/file/image\")\nim.show()\n</code></pre>"},{"location":"api/image/#components","title":"Components","text":"<p>The <code>image</code> module is built around the following components:</p> <ul> <li>I/O: Responsible for reading and writing image data.</li> <li>Analysis: Perform image analysis tasks</li> <li>Transformers: Allows you to apply various transformations to the image, such as resizing, cropping, and color adjustments</li> <li>Drawer: Provides methods for drawing shapes and text on the image.</li> </ul> <p>Behind the scene the components all use a base image class.</p>"},{"location":"api/image/conversion/","title":"Conversion Methods","text":"<p>Conversion is the process of converting an image to something else, which can be anything.</p> <p>For example, here is an example to convert an image to grayscale:</p> <pre><code>import otary as ot\n\nim = ot.Image.from_file(filepath=\"path/to/file/image\")\n\nim.as_grayscale()\n</code></pre> <p>Image core class. It groups all the methods available from composition from all the image classes.</p> Source code in <code>otary/image/image.py</code> <pre><code>class Image:\n    \"\"\"\n    Image core class. It groups all the methods available from composition\n    from all the image classes.\n    \"\"\"\n\n    # pylint: disable=too-many-public-methods\n\n    reader = ReaderImage()\n\n    def __init__(self, image: NDArray) -&gt; None:\n        self.base = BaseImage(image=image, parent=self)\n        self.drawer = DrawerImage(base=self.base)\n        self.writer = WriterImage(base=self.base)\n        self.transformer = TransformerImage(base=self.base)\n\n    # -------------------------------- CLASS METHODS ----------------------------------\n\n    @classmethod\n    def from_fillvalue(cls, value: int = 255, shape: tuple = (128, 128, 3)) -&gt; Image:\n        \"\"\"Class method to create an image from a single value\n\n        Args:\n            value (int, optional): value in [0, 255]. Defaults to 255.\n            shape (tuple, optional): image shape. If it has three elements then\n                the last one must be a 3 for a coloscale image.\n                Defaults to (128, 128, 3).\n\n        Returns:\n            Image: array with a single value\n        \"\"\"\n        return cls(image=cls.reader.from_fillvalue(value=value, shape=shape))\n\n    @classmethod\n    def from_file(\n        cls, filepath: str, as_grayscale: bool = False, resolution: Optional[int] = None\n    ) -&gt; Image:\n        \"\"\"Create a Image array from a file image path\n\n        Args:\n            filepath (str): path to the image file\n            as_grayscale (bool, optional): turn the image in grayscale.\n                Defaults to False.\n            resolution (Optional[int], optional): resolution of the image.\n\n        Returns:\n            Image: Image object with a single value\n        \"\"\"\n        return cls(\n            cls.reader.from_file(\n                filepath=filepath, as_grayscale=as_grayscale, resolution=resolution\n            )\n        )\n\n    @classmethod\n    def from_pdf(\n        cls,\n        filepath: str,\n        as_grayscale: bool = False,\n        page_nb: int = 0,\n        resolution: Optional[int] = None,\n        clip_pct: Optional[AxisAlignedRectangle] = None,\n    ) -&gt; Image:\n        \"\"\"Create an Image array from a pdf file.\n\n        Args:\n            filepath (str): path to the pdf file\n            as_grayscale (bool, optional): turn the image in grayscale.\n                Defaults to False.\n            page_nb (int, optional): page number to extract. Defaults to 0.\n            resolution (Optional[int], optional): resolution of the image.\n            clip_pct (Optional[AxisAlignedRectangle], optional): clip percentage of the\n                image to only load a small part of the image (crop) for faster loading\n                and less memory usage. Defaults to None.\n\n        Returns:\n            Image: Image object from pdf\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        return cls(\n            cls.reader.from_pdf(\n                filepath=filepath,\n                as_grayscale=as_grayscale,\n                page_nb=page_nb,\n                resolution=resolution,\n                clip_pct=clip_pct,\n            )\n        )\n\n    # ---------------------------------- PROPERTIES -----------------------------------\n\n    @property\n    def asarray(self) -&gt; NDArray:\n        \"\"\"Array representation of the image\"\"\"\n        return self.base.asarray\n\n    @asarray.setter\n    def asarray(self, value: NDArray) -&gt; None:\n        \"\"\"Setter for the asarray property\n\n        Args:\n            value (NDArray): value of the asarray to be changed\n        \"\"\"\n        self.base.asarray = value\n\n    @property\n    def asarray_binary(self) -&gt; NDArray:\n        \"\"\"Returns the representation of the image as a array with value not in\n        [0, 255] but in [0, 1].\n\n        Returns:\n            NDArray: an array with value in [0, 1]\n        \"\"\"\n        return self.base.asarray_binary\n\n    @property\n    def width(self) -&gt; int:\n        \"\"\"Width of the image.\n\n        Returns:\n            int: image width\n        \"\"\"\n        return self.base.width\n\n    @property\n    def height(self) -&gt; int:\n        \"\"\"Height of the image\n\n        Returns:\n            int: image height\n        \"\"\"\n        return self.base.height\n\n    @property\n    def channels(self) -&gt; int:\n        \"\"\"Number of channels in the image\n\n        Returns:\n            int: number of channels\n        \"\"\"\n        return self.base.channels\n\n    @property\n    def center(self) -&gt; NDArray[np.int16]:\n        \"\"\"Center point of the image.\n\n        Please note that it is returned as type int because the center is\n        represented as a X-Y coords of a pixel.\n\n        Returns:\n            NDArray: center point of the image\n        \"\"\"\n        return self.base.center\n\n    @property\n    def area(self) -&gt; int:\n        \"\"\"Area of the image\n\n        Returns:\n            int: image area\n        \"\"\"\n        return self.base.area\n\n    @property\n    def shape_array(self) -&gt; tuple[int, int, int]:\n        \"\"\"Returns the array shape value (height, width, channel)\n\n        Returns:\n            tuple[int]: image shape\n        \"\"\"\n        return self.base.shape_array\n\n    @property\n    def shape_xy(self) -&gt; tuple[int, int, int]:\n        \"\"\"Returns the array shape value (width, height, channel)\n\n        Returns:\n            tuple[int]: image shape\n        \"\"\"\n        return self.base.shape_xy\n\n    @property\n    def is_gray(self) -&gt; bool:\n        \"\"\"Whether the image is a grayscale image or not\n\n        Returns:\n            bool: True if image is in grayscale, 0 otherwise\n        \"\"\"\n        return self.base.is_gray\n\n    @property\n    def norm_side_length(self) -&gt; int:\n        \"\"\"Returns the normalized side length of the image.\n        This is the side length if the image had the same area but\n        the shape of a square (four sides of the same length).\n\n        Returns:\n            int: normalized side length\n        \"\"\"\n        return self.base.norm_side_length\n\n    @property\n    def corners(self) -&gt; NDArray:\n        \"\"\"Returns the corners in clockwise order:\n\n        0. top left corner\n        1. top right corner\n        2. bottom right corner\n        3. bottom left corner\n\n        Returns:\n            NDArray: array containing the corners\n        \"\"\"\n        return self.base.corners\n\n    # ---------------------------------- BASE METHODS ---------------------------------\n\n    def as_grayscale(self) -&gt; Self:\n        \"\"\"Generate the image in grayscale of shape (height, width)\n\n        Returns:\n            Self: original image in grayscale\n        \"\"\"\n        self.base.as_grayscale()\n        return self\n\n    def as_colorscale(self) -&gt; Self:\n        \"\"\"Generate the image in colorscale (height, width, 3).\n        This property can be useful when we wish to draw objects in a given color\n        on a grayscale image.\n\n        Returns:\n            Self: original image in color\n        \"\"\"\n        self.base.as_colorscale()\n        return self\n\n    def as_reversed_color_channel(self) -&gt; Self:\n        \"\"\"Generate the image with the color channels reversed.\n        This is useful when we want to convert an image from BGR to RGB or vice versa.\n\n        Returns:\n            Self: original image with reversed color channels\n        \"\"\"\n        self.base.as_reversed_color_channel()\n        return self\n\n    def as_filled(self, fill_value: int | NDArray = 255) -&gt; Self:\n        \"\"\"Returns an entirely white image of the same size as the original.\n        Can be useful to get an empty representation of the same image to paint\n        and draw things on an image of the same dimension.\n\n        Args:\n            fill_value (int | NDArray, optional): color to fill the new empty image.\n                Defaults to 255 which means that is returns a entirely white image.\n\n        Returns:\n            Self: new image with a single color of the same size as original.\n        \"\"\"\n        self.base.as_filled(fill_value=fill_value)\n        return self\n\n    def as_white(self) -&gt; Self:\n        \"\"\"Returns an entirely white image with the same dimension as the original.\n\n        Returns:\n            Self: new white image\n        \"\"\"\n        self.base.as_white()\n        return self\n\n    def as_black(self) -&gt; Self:\n        \"\"\"Returns an entirely black image with the same dimension as the original.\n\n        Returns:\n            Self: new black image\n        \"\"\"\n        self.base.as_black()\n        return self\n\n    def as_pil(self) -&gt; ImagePIL.Image:\n        \"\"\"Return the image as PIL Image\n\n        Returns:\n            ImagePIL: PIL Image\n        \"\"\"\n        return self.base.as_pil()\n\n    def as_api_file_input(\n        self, fmt: str = \"png\", filename: str = \"image\"\n    ) -&gt; dict[str, tuple[str, bytes, str]]:\n        \"\"\"Return the image as a file input for API requests.\n\n        Args:\n            fmt (str, optional): format of the image. Defaults to \"png\".\n            filename (str, optional): name of the file without the format.\n                Defaults to \"image\".\n\n        Returns:\n            dict[str, tuple[str, bytes, str]]: dictionary with file input\n                for API requests, where the key is \"file\" and the value is a tuple\n                containing the filename, image bytes, and content type.\n        \"\"\"\n        return self.base.as_api_file_input(fmt=fmt, filename=filename)\n\n    def rev(self) -&gt; Self:\n        \"\"\"Reverse the image colors. Each pixel color value V becomes |V - 255|.\n\n        Applied on a grayscale image the black pixel becomes white and the\n        white pixels become black.\n        \"\"\"\n        self.base.rev()\n        return self\n\n    def dist_pct(self, pct: float) -&gt; float:\n        \"\"\"Distance percentage that can be used an acceptable distance error margin.\n        It is calculated based on the normalized side length.\n\n        Args:\n            pct (float, optional): percentage of distance error. Defaults to 0.01,\n                which means 1% of the normalized side length as the\n                default margin distance error.\n\n        Returns:\n            float: margin distance error\n        \"\"\"\n        return self.base.dist_pct(pct=pct)\n\n    def is_equal_shape(self, other: Image, consider_channel: bool = True) -&gt; bool:\n        \"\"\"Check whether two images have the same shape\n\n        Args:\n            other (BaseImage): BaseImage object\n\n        Returns:\n            bool: True if the objects have the same shape, False otherwise\n        \"\"\"\n        return self.base.is_equal_shape(\n            other=other.base, consider_channel=consider_channel\n        )\n\n    # ---------------------------------- COPY METHOD ----------------------------------\n\n    def copy(self) -&gt; Image:\n        \"\"\"Copy of the image.\n\n        For NumPy arrays containing basic data types (e.g., int, float, bool),\n        using copy.deepcopy() is generally unnecessary.\n        The numpy.copy() method achieves the same result more efficiently.\n        numpy.copy() creates a new array in memory with a separate copy of the data,\n        ensuring that modifications to the copy do not affect the original array.\n\n        Returns:\n            Image: image copy\n        \"\"\"\n        return Image(image=self.asarray.copy())\n\n    # -------------------------------- WRITE METHODS ----------------------------------\n\n    def save(self, fp: str) -&gt; None:\n        \"\"\"Save the image in a local file\n\n        Args:\n            fp (str): fp stands for filepath which is the path to the file\n        \"\"\"\n        self.writer.save(fp=fp)\n\n    def show(\n        self,\n        figsize: tuple[float, float] = (-1, -1),\n        popup_window_display: bool = False,\n    ) -&gt; ImagePIL.Image:\n        \"\"\"Show the image\n\n        Args:\n            figsize (tuple[float, float], optional): size of the figure.\n                Defaults to (-1, -1), meaning the original size of the image.\n            popup_window_display (bool, optional): whether to display the image in a\n                popup window. Defaults to False.\n        \"\"\"\n        return self.writer.show(\n            figsize=figsize, popup_window_display=popup_window_display\n        )\n\n    # -------------------------------- DRAWER METHODS ---------------------------------\n\n    def draw_circles(\n        self, circles: Sequence[geo.Circle], render: CirclesRender = CirclesRender()\n    ) -&gt; Self:\n        \"\"\"Draw circles in the image\n\n        Args:\n            circles (list[Circle]): list of Circle geometry objects.\n            render (CirclesRender): circle renderer\n\n        Returns:\n            Image: new image with circles drawn\n        \"\"\"\n        self.drawer.draw_circles(circles=circles, render=render)\n        return self\n\n    def draw_ellipses(\n        self, ellipses: Sequence[geo.Ellipse], render: EllipsesRender = EllipsesRender()\n    ) -&gt; Self:\n        \"\"\"Draw ellipses in the image\n\n        Args:\n            ellipses (list[Ellipse]): list of Ellipse geometry objects.\n            render (EllipsesRender): ellipse renderer\n\n        Returns:\n            Image: new image with ellipses drawn\n        \"\"\"\n        self.drawer.draw_ellipses(ellipses=ellipses, render=render)\n        return self\n\n    def draw_points(\n        self,\n        points: list | NDArray | Sequence[geo.Point],\n        render: PointsRender = PointsRender(),\n    ) -&gt; Self:\n        \"\"\"Draw points in the image\n\n        Args:\n            points (NDArray): list of points. It must be of shape (n, 2). This\n                means n points of shape 2 (x and y coordinates).\n            render (PointsRender): point renderer\n\n        Returns:\n            Image: new image with points drawn\n        \"\"\"\n        self.drawer.draw_points(points=points, render=render)\n        return self\n\n    def draw_segments(\n        self,\n        segments: NDArray | Sequence[geo.Segment],\n        render: SegmentsRender = SegmentsRender(),\n    ) -&gt; Self:\n        \"\"\"Draw segments in the image. It can be arrowed segments (vectors) too.\n\n        Args:\n            segments (NDArray): list of segments. Can be a numpy array of shape\n                (n, 2, 2) which means n array of shape (2, 2) that define a segment\n                by two 2D points.\n            render (SegmentsRender): segment renderer\n\n        Returns:\n            Image: new image with segments drawn\n        \"\"\"\n        self.drawer.draw_segments(segments=segments, render=render)\n        return self\n\n    def draw_polygons(\n        self,\n        polygons: Sequence[geo.Polygon],\n        render: PolygonsRender = PolygonsRender(),\n    ) -&gt; Self:\n        \"\"\"Draw polygons in the image\n\n        Args:\n            polygons (Sequence[Polygon]): list of Polygon objects\n            render (PolygonsRender): PolygonRender object\n\n        Returns:\n            Image: new image with polygons drawn\n        \"\"\"\n        self.drawer.draw_polygons(polygons=polygons, render=render)\n        return self\n\n    def draw_splines(\n        self,\n        splines: Sequence[geo.LinearSpline],\n        render: LinearSplinesRender = LinearSplinesRender(),\n    ) -&gt; Self:\n        \"\"\"Draw linear splines in the image.\n\n        Args:\n            splines (Sequence[geo.LinearSpline]): linear splines to draw.\n            render (LinearSplinesRender, optional): linear splines render.\n                Defaults to LinearSplinesRender().\n\n        Returns:\n            Image: new image with splines drawn\n        \"\"\"\n        self.drawer.draw_splines(splines=splines, render=render)\n        return self\n\n    def draw_ocr_outputs(\n        self,\n        ocr_outputs: Sequence[OcrSingleOutput],\n        render: OcrSingleOutputRender = OcrSingleOutputRender(),\n    ) -&gt; Self:\n        \"\"\"Return the image with the bounding boxes displayed from a list of OCR\n        single output. It allows you to show bounding boxes that can have an angle,\n        not necessarily vertical or horizontal.\n\n        Args:\n            ocr_outputs (list[OcrSingleOutput]): list of OcrSingleOutput objects\n            render (OcrSingleOutputRender): OcrSingleOutputRender object\n\n        Returns:\n            Image: new image with ocr outputs drawn\n        \"\"\"\n        self.drawer.draw_ocr_outputs(ocr_outputs=ocr_outputs, render=render)\n        return self\n\n    # --------------------------------- BINARIZER -------------------------------------\n\n    def threshold_simple(self, thresh: int) -&gt; Self:\n        \"\"\"Compute the image thesholded by a single value T.\n        All pixels with value v &lt;= T are turned black and those with value v &gt; T are\n        turned white. This is a global thresholding method.\n\n        Args:\n            thresh (int): value to separate the black from the white pixels.\n\n        Returns:\n            (Self): output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_simple(thresh=thresh)\n        return self\n\n    def threshold_otsu(self) -&gt; Self:\n        \"\"\"Apply Otsu global thresholding.\n        This is a global thresholding method that automatically determines\n        an optimal threshold value from the image histogram.\n\n        Paper (1979):\n        https://ieeexplore.ieee.org/document/4310076\n\n        Consider applying a gaussian blur before for better thresholding results.\n        See why in https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html.\n\n        As the input image must be a grayscale before applying any thresholding\n        methods we convert the image to grayscale.\n\n        Returns:\n            (Self): output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_otsu()\n        return self\n\n    def threshold_adaptive(self, block_size: int = 11, constant: float = 2.0) -&gt; Self:\n        \"\"\"Apply adaptive local thresholding.\n        This is a local thresholding method that computes the threshold for a pixel\n        based on a small region around it.\n\n        A gaussian blur is applied before for better thresholding results.\n        See why in https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html.\n\n        As the input image must be a grayscale before applying any thresholding\n        methods we convert the image to grayscale.\n\n        Args:\n            block_size (int, optional): Size of a pixel neighborhood that is used to\n                calculate a threshold value for the pixel: 3, 5, 7, and so on.\n                Defaults to 11.\n            constant (int, optional): Constant subtracted from the mean or weighted\n                mean. Normally, it is positive but may be zero or negative as well.\n                Defaults to 2.\n\n        Returns:\n            (Self): output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_adaptive(\n            block_size=block_size, constant=constant\n        )\n        return self\n\n    def threshold_sauvola(\n        self, window_size: int = 15, k: float = 0.5, r: float = 128.0\n    ) -&gt; Self:\n        \"\"\"Apply Sauvola local thresholding.\n         This is a local thresholding method that computes the threshold for a pixel\n         based on a small region around it.\n\n         Paper (1997):\n         https://www.researchgate.net/publication/3710586\n\n         See https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_niblack_sauvola.html # pylint: disable=line-too-long\n\n         As the input image must be a grayscale before applying any thresholding\n         methods we convert the image to grayscale.\n\n         Args:\n             window_size (int, optional): sauvola window size to apply on the\n                 image. Defaults to 15.\n             k (float, optional): sauvola k factor to apply to regulate the impact\n                 of the std. Defaults to 0.5.\n             r (float, optional): sauvola r value. Defaults to 128.\n\n        Returns:\n             (Self): output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_sauvola(window_size=window_size, k=k, r=r)\n        return self\n\n    def threshold_bradley(self, window_size: int = 15, t: float = 0.15) -&gt; Self:\n        \"\"\"Implementation of the Bradley &amp; Roth thresholding method.\n\n        Paper (2007):\n        https://www.researchgate.net/publication/220494200_Adaptive_Thresholding_using_the_Integral_Image\n\n        Args:\n            window_size (int, optional): window size for local computations.\n                Defaults to 15.\n            t (float, optional): t value in [0, 1]. Defaults to 0.15.\n\n        Returns:\n            NDArray[np.uint8]: output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_bradley(window_size=window_size, t=t)\n        return self\n\n    def binary(self, method: BinarizationMethods = \"sauvola\") -&gt; NDArray:\n        \"\"\"Binary representation of the image with values that can be only 0 or 1.\n        The value 0 is now 0 and value of 255 are now 1. Black is 0 and white is 1.\n        We can also talk about the mask of the image to refer to the binary\n        representation of it.\n\n        The sauvola is generally the best binarization method however it is\n        way slower than the others methods. The adaptative or otsu method are the best\n        method in terms of speed and quality.\n\n        Args:\n            method (str, optional): the binarization method to apply.\n                Must be in [\"adaptative\", \"otsu\", \"sauvola\", \"niblack\", \"nick\", \"wolf\"].\n                Defaults to \"sauvola\".\n\n        Returns:\n            NDArray: array where its inner values are 0 or 1\n        \"\"\"\n        return self.transformer.binarizer.binary(method=method)\n\n    def binaryrev(self, method: BinarizationMethods = \"sauvola\") -&gt; NDArray:\n        \"\"\"Reversed binary representation of the image.\n        The value 0 is now 1 and value of 255 are now 0. Black is 1 and white is 0.\n        This is why it is called the \"binary rev\" or \"binary reversed\".\n\n        Args:\n            method (str, optional): the binarization method to apply.\n                Must be in [\"adaptative\", \"otsu\", \"sauvola\", \"niblack\", \"nick\", \"wolf\"].\n                Defaults to \"adaptative\".\n\n        Returns:\n            NDArray: array where its inner values are 0 or 1\n        \"\"\"\n        return self.transformer.binarizer.binaryrev(method=method)\n\n    # ---------------------------------- CROPPER --------------------------------------\n    # the copy arguments is special in the crop methods.\n    # this is important for performance reasons\n    # if you want to crop a small part of an image and conserve the original\n    # without doing image.copy().crop() which would copy the entire original image!\n    # this would be much more expensive if the image is large\n\n    def crop(\n        self, x0: int, y0: int, x1: int, y1: int, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop the image in a straight axis-aligned rectangle way given\n        by the top-left point [x0, y0] and the bottom-right point [x1, y1]\n\n        This function inputs represents the top-left and bottom-right points.\n        This method does not provide a way to extract a rotated rectangle or a\n        different shape from the image.\n\n        Remember that in this library the x coordinates represent the y coordinates of\n        the image array (horizontal axis of the image).\n        The array representation is always rows then columns.\n        In this library this is the contrary like in opencv.\n\n        Args:\n            x0 (int): top-left x coordinate\n            y0 (int): top-left y coordinate\n            x1 (int): bottom-right x coordinate\n            y1 (int): bottom-right y coordinate\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        out = self.transformer.cropper.crop(\n            x0=x0, y0=y0, x1=x1, y1=y1, copy=copy, **kwargs\n        )\n        return out if out is not None else self\n\n    def crop_from_topleft(\n        self, topleft: NDArray, width: int, height: int, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop the image from a rectangle defined by its top-left point, its width and\n        its height.\n\n        Args:\n            topleft (NDArray): (x, y) coordinates of the top-left point\n            width (int): width of the rectangle to crop\n            height (int): height of the rectangle to crop\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        out = self.transformer.cropper.crop_from_topleft(\n            topleft=topleft, width=width, height=height, copy=copy, **kwargs\n        )\n        return out if out is not None else self\n\n    def crop_from_center(\n        self, center: NDArray, width: int, height: int, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop the image from a rectangle defined by its center point, its width and\n        its height.\n\n        Args:\n            center (NDArray): (x, y) coordinates of the center point\n            width (int): width of the rectangle to crop\n            height (int): height of the rectangle to crop\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        out = self.transformer.cropper.crop_from_center(\n            center=center, width=width, height=height, copy=copy, **kwargs\n        )\n        return out if out is not None and copy else self\n\n    def crop_from_axis_aligned_bbox(\n        self, bbox: geo.AxisAlignedRectangle, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop the image from an Axis-Aligned Bounding Box (AABB).\n        Inclusive crops which means that the cropped image will have\n        width and height equal to the width and height of the AABB.\n\n        Args:\n            bbox (geo.AxisAlignedRectangle): axis-aligned rectangle bounding box\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        out = self.transformer.cropper.crop_from_axis_aligned_rectangle(\n            bbox=bbox, copy=copy, **kwargs\n        )\n        return out if out is not None and copy else self\n\n    def crop_hq_from_aabb_and_pdf(\n        self,\n        bbox: geo.AxisAlignedRectangle,\n        pdf_filepath: str,\n        page_nb: int = 0,\n        as_grayscale: bool = False,\n        resolution: int = 1000,\n    ) -&gt; Image:\n        \"\"\"Generate a new image from a pdf file by cropping a High Quality crop\n        from a given Axis-Aligned Bounding Box (AABB).\n\n        The crop is of high quality because we can load only the crop part of the image\n        from the original pdf.\n\n        Args:\n            bbox (geo.AxisAlignedRectangle): crop bounding box\n            pdf_filepath (str): PDF filepath\n            page_nb (int, optional): page to load in the PDF. The first page is 0.\n                Defaults to 0.\n            as_grayscale (bool, optional): whether to load the image as grayscale or\n                not. Defaults to False.\n            resolution (int, optional): resolution of the final crop image.\n                Defaults to 1000.\n\n        Returns:\n            Image: high quality crop image\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        # get the bbox normalized\n        clip_pct = bbox.copy().normalize(x=self.width, y=self.height)\n\n        # obtain the High Quality crop image by reading\n        im_crop = Image.from_pdf(\n            filepath=pdf_filepath,\n            page_nb=page_nb,\n            as_grayscale=as_grayscale,\n            resolution=resolution,\n            clip_pct=clip_pct,\n        )\n        return im_crop\n\n    def crop_from_polygon(\n        self, polygon: geo.Polygon, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop from a polygon using its Axis-Aligned Bounding Box (AABB)\n\n        Args:\n            polygon (geo.Polygon): polygon object to crop in the image\n            copy (bool, optional): whether to create a copy or not. Defaults to False.\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        out = self.transformer.cropper.crop_from_polygon(\n            polygon=polygon, copy=copy, **kwargs\n        )\n        return out if out is not None and copy else self\n\n    def crop_from_linear_spline(\n        self, spline: geo.LinearSpline, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop from a Linear Spline using its Axis-Aligned Bounding Box (AABB)\n\n        Args:\n            spline (geo.LinearSpline): linear spline object to crop in the image\n            copy (bool, optional): whether to create a copy or not. Defaults to False.\n                        clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        out = self.transformer.cropper.crop_from_linear_spline(\n            spline=spline, copy=copy, **kwargs\n        )\n        return out if out is not None and copy else self\n\n    def crop_segment(\n        self,\n        segment: NDArray,\n        dim_crop_rect: tuple[int, int] = (-1, 100),\n        added_width: int = 75,\n    ) -&gt; tuple[Image, NDArray, float, NDArray]:\n        \"\"\"Crop around a specific segment in the image. This is done in three\n        specific steps:\n        1) shift image so that the middle of the segment is in the middle of the image\n        2) rotate image by the angle of segment so that the segment becomes horizontal\n        3) crop the image\n\n        Args:\n            segment (NDArray): segment as numpy array of shape (2, 2).\n            dim_crop_rect (tuple, optional): represents (width, height).\n                Defaults to heigth of 100 and width of -1 which means\n                that the width is automatically computed based on the length of\n                the segment.\n            added_width (int, optional): additional width for cropping.\n                Half of the added_width is added to each side of the segment.\n                Defaults to 75.\n\n        Returns:\n            tuple[Self, NDArray, float, NDArray]: returns in the following order:\n                1) the cropped image\n                2) the translation vector used to center the image\n                3) the angle of rotation applied to the image\n                4) the translation vector used to crop the image\n        \"\"\"\n        width_crop_rect, height_crop_rect = dim_crop_rect\n        im = self.copy()  # the copy before makes this method slow\n\n        # center the image based on the middle of the line\n        geo_segment = geo.Segment(segment)\n        im, translation_vector = im.center_to_segment(segment=segment)\n\n        if width_crop_rect == -1:\n            # default the width for crop to be a bit more than line length\n            width_crop_rect = int(geo_segment.length)\n        width_crop_rect += added_width\n        assert width_crop_rect &gt; 0 and height_crop_rect &gt; 0\n\n        # rotate the image so that the line is horizontal\n        angle = geo_segment.slope_angle(is_y_axis_down=True)\n        im = im.rotate(angle=angle)\n\n        # cropping\n        im_crop = im.crop_from_center(\n            center=im.base.center,\n            width=width_crop_rect,\n            height=height_crop_rect,\n        )\n\n        crop_translation_vector = self.base.center - im_crop.base.center\n        return im_crop, translation_vector, angle, crop_translation_vector\n\n    def crop_segment_faster(\n        self,\n        segment: NDArray,\n        dim_crop_rect: tuple[int, int] = (-1, 100),\n        added_width: int = 75,\n        pad_value: int = 0,\n    ) -&gt; Image:\n        \"\"\"Crop around a specific segment in the image.\n        This method is faster especially for large images.\n\n        Here is a comparison of the total time taken for cropping with the two methods\n        with a loop over 1000 iterations:\n\n        | Image dimension | Crop v1 | Crop faster |\n        |-----------------|---------|-------------|\n        | 1224 x 946      | 2.0s    | 0.25s       |\n        | 2448 x 1892     | 4.51s   | 0.25s       |\n        | 4896 x 3784     | 23.2s   | 0.25s       |\n\n        Args:\n            segment (NDArray): segment as numpy array of shape (2, 2).\n            dim_crop_rect (tuple, optional): represents (width, height).\n                Defaults to heigth of 100 and width of -1 which means\n                that the width is automatically computed based on the length of\n                the segment.\n            added_width (int, optional): additional width for cropping.\n                Half of the added_width is added to each side of the segment.\n                Defaults to 75.\n\n        Returns:\n            Self: cropped image around the segment\n        \"\"\"\n        width_crop_rect, height_crop_rect = dim_crop_rect\n        geo_segment = geo.Segment(segment)\n        angle = geo_segment.slope_angle(is_y_axis_down=True)\n\n        if width_crop_rect == -1:\n            # default the width for crop to be a bit more than line length\n            width_crop_rect = int(geo_segment.length)\n        width_crop_rect += added_width\n        assert width_crop_rect &gt; 0 and height_crop_rect &gt; 0\n\n        x_extra = abs(added_width / 2 * np.cos(angle))\n        y_extra = abs(added_width / 2 * np.sin(angle))\n\n        # add extra width for crop in case segment is ~vertical\n        x_extra += int(width_crop_rect / 2) + 1\n        y_extra += int(height_crop_rect / 2) + 1\n\n        im: Image = self.crop(\n            x0=geo_segment.xmin - x_extra,\n            y0=geo_segment.ymin - y_extra,\n            x1=geo_segment.xmax + x_extra,\n            y1=geo_segment.ymax + y_extra,\n            pad=True,\n            clip=False,\n            copy=True,  # copy the image after cropping for very fast performance\n            pad_value=pad_value,\n        )\n\n        # rotate the image so that the line is horizontal\n        im.rotate(angle=angle)\n\n        # cropping around segment center\n        im.crop_from_center(\n            center=im.base.center,\n            width=width_crop_rect,\n            height=height_crop_rect,\n        )\n\n        return im\n\n    def crop_from_rectangle_referential(\n        self,\n        rect: geo.Rectangle,\n        rect_topleft_ix: int = 0,\n        crop_dim: tuple[float, float] = (-1, -1),\n        crop_shift: tuple[float, float] = (0, 0),\n    ) -&gt; Image:\n        \"\"\"Crop image in the referential of the rectangle.\n\n        Args:\n            rect (geo.Rectangle): rectangle for reference to crop.\n            rect_topleft_ix (int): top-left vertice index of the rectangle\n            crop_dim (tuple[float, float], optional): (width, height) crop dimension.\n                Defaults to (-1, -1).\n            crop_shift (tuple[float, float], optional): The shift is (x, y).\n                The crop_shift argument is applied from the rectangle center based on\n                the axis referential of the rectangle.\n                This means that the shift in the Y direction\n                is based on the normalized vector (bottom-left, top-left)\n                The shift in the X direction is based on the normalized vector\n                (top-left, top-right). Defaults to (0, 0) meaning no shift.\n\n        Returns:\n            Self: new image cropped\n        \"\"\"\n        # shift down and up vector calculated based on the top-left vertice\n        rect_shift_up = rect.get_vector_up_from_topleft(topleft_index=rect_topleft_ix)\n        rect_shift_left = rect.get_vector_left_from_topleft(\n            topleft_index=rect_topleft_ix\n        )\n\n        # crop dimension\n        rect_heigth = rect.get_height_from_topleft(topleft_index=rect_topleft_ix)\n        crop_width = rect_heigth if crop_dim[0] == -1 else crop_dim[0]\n        crop_height = rect_heigth if crop_dim[1] == -1 else crop_dim[1]\n        crop_width, crop_height = int(crop_width), int(crop_height)\n        assert crop_width &gt; 0 and crop_height &gt; 0\n\n        # compute the crop center\n        crop_center = rect.centroid\n        crop_center += crop_shift[0] * rect_shift_left.normalized  # shift left\n        crop_center += crop_shift[1] * rect_shift_up.normalized  # shift up\n\n        # get the crop segment\n        crop_segment = geo.Segment(\n            [\n                crop_center - crop_width / 2 * rect_shift_left.normalized,\n                crop_center + crop_width / 2 * rect_shift_left.normalized,\n            ]\n        )\n\n        return self.crop_segment_faster(\n            segment=crop_segment.asarray,\n            dim_crop_rect=(crop_width, crop_height),\n            added_width=0,\n        )\n\n    def crop_rectangle(self, rect: geo.Rectangle, rect_topleft_ix: int = 0) -&gt; Image:\n        \"\"\"Crop from a rectangle that can be rotated in any direction.\n        The crop is done using the information of the top-left vertice index to\n        determine the width and height of the crop.\n\n        Args:\n            rect (geo.Rectangle): rectangle to crop in the referential of the image\n            rect_topleft_ix (int, optional): top-left vertice index. Defaults to 0.\n\n        Returns:\n            Image: crop of the image\n        \"\"\"\n        crop_dim = (\n            rect.get_width_from_topleft(rect_topleft_ix),\n            rect.get_height_from_topleft(rect_topleft_ix),\n        )\n        return self.crop_from_rectangle_referential(\n            rect=rect, rect_topleft_ix=rect_topleft_ix, crop_dim=crop_dim\n        )\n\n    # ------------------------------- GEOMETRY METHODS --------------------------------\n\n    def shift(self, shift: NDArray, fill_value: Sequence[float] = (0.0,)) -&gt; Self:\n        \"\"\"Shift the image by performing a translation operation\n\n        Args:\n            shift (NDArray): Vector for translation\n            fill_value (int | tuple[int, int, int], optional): value to fill the\n                border of the image after the rotation in case reshape is True.\n                Can be a tuple of 3 integers for RGB image or a single integer for\n                grayscale image. Defaults to (0.0,) which is black.\n\n        Returns:\n            Self: shifted image\n        \"\"\"\n        self.transformer.geometrizer.shift(shift=shift, fill_value=fill_value)\n        return self\n\n    def rotate(\n        self,\n        angle: float,\n        is_degree: bool = False,\n        is_clockwise: bool = True,\n        reshape: bool = True,\n        fill_value: Sequence[float] = (0.0,),\n    ) -&gt; Self:\n        \"\"\"Rotate the image by a given angle.\n\n        For the rotation with reshape, meaning preserving the whole image,\n        we used the code from the imutils library:\n        https://github.com/PyImageSearch/imutils/blob/master/imutils/convenience.py#L41\n\n        Args:\n            angle (float): angle to rotate the image\n            is_degree (bool, optional): whether the angle is in degree or not.\n                If not it is considered to be in radians.\n                Defaults to False which means radians.\n            is_clockwise (bool, optional): whether the rotation is clockwise or\n                counter-clockwise. Defaults to True.\n            reshape (bool, optional): whether to preserve the original image or not.\n                If True, the complete image is preserved hence the width and height\n                of the rotated image are different than in the original image.\n                Defaults to True.\n            fill_value (Sequence[float], optional): value to\n                fill the border of the image after the rotation in case reshape is True.\n                Can be a tuple of 3 integers for RGB image or a single integer for\n                grayscale image. Defaults to (0.0,) which is black\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        self.transformer.geometrizer.rotate(\n            angle=angle,\n            is_degree=is_degree,\n            is_clockwise=is_clockwise,\n            reshape=reshape,\n            fill_value=fill_value,\n        )\n        return self\n\n    def center_to_point(self, point: NDArray) -&gt; tuple[Self, NDArray]:\n        \"\"\"Shift the image so that the input point ends up in the middle of the\n        new image\n\n        Args:\n            point (NDArray): point as (2,) shape numpy array\n\n        Returns:\n            (tuple[Self, NDArray]): Self, translation Vector\n        \"\"\"\n        shift_vector = self.transformer.geometrizer.center_to_point(point=point)\n        return self, shift_vector\n\n    def center_to_segment(self, segment: NDArray) -&gt; tuple[Self, NDArray]:\n        \"\"\"Shift the image so that the segment middle point ends up in the middle\n        of the new image\n\n        Args:\n            segment (NDArray): segment as numpy array of shape (2, 2)\n\n        Returns:\n            (tuple[Self, NDArray]): Self, vector_shift\n        \"\"\"\n        shift_vector = self.transformer.geometrizer.center_to_segment(segment=segment)\n        return self, shift_vector\n\n    def restrict_rect_in_frame(self, rectangle: geo.Rectangle) -&gt; geo.Rectangle:\n        \"\"\"Create a new rectangle that is contained within the image borders.\n        If the input rectangle is outside the image, the returned rectangle is a\n        image frame-fitted rectangle that preserve the same shape.\n\n        Args:\n            rectangle (geo.Rectangle): input rectangle\n\n        Returns:\n            geo.Rectangle: new rectangle\n        \"\"\"\n        return self.transformer.geometrizer.restrict_rect_in_frame(rectangle=rectangle)\n\n    # ----------------------------- MORPHOLOGICAL METHODS -----------------------------\n\n    def resize_fixed(\n        self,\n        dim: tuple[int, int],\n        interpolation: int = cv2.INTER_AREA,\n        copy: bool = False,\n    ) -&gt; Image | Self:\n        \"\"\"Resize the image using a fixed dimension well defined.\n        This function can result in a distorted image if the ratio between\n        width and height is different in the original and the new image.\n\n        If the dim argument has a negative value in height or width, then\n        a proportional ratio is applied based on the one of the two dimension given.\n\n        Args:\n            dim (tuple[int, int]): a tuple with two integers in the following order\n                (width, height).\n            interpolation (int, optional): resize interpolation.\n                Defaults to cv2.INTER_AREA.\n            copy (bool, optional): whether to return a new image or not.\n\n        Returns:\n            Image | Self: resized new image if copy=True else resized original image\n        \"\"\"\n        out = self.transformer.morphologyzer.resize_fixed(\n            dim=dim, interpolation=interpolation, copy=copy\n        )\n        return out if out is not None and copy else self\n\n    def resize(\n        self, factor: float, interpolation: int = cv2.INTER_AREA, copy: bool = False\n    ) -&gt; Image | Self:\n        \"\"\"Resize the image to a new size using a scaling factor value that\n        will be applied to all dimensions (width and height).\n\n        Applying this method can not result in a distorted image.\n\n        Args:\n            factor (float): factor in [0, 5] to resize the image.\n                A value of 1 does not change the image.\n                A value of 2 doubles the image size.\n                A maximum value of 5 is set to avoid accidentally producing a gigantic\n                image.\n            interpolation (int, optional): resize interpolation.\n                Defaults to cv2.INTER_AREA.\n            copy (bool, optional): whether to return a new image or not.\n\n        Returns:\n            Image | Self: resized new image if copy=True else resized original image\n        \"\"\"\n        out = self.transformer.morphologyzer.resize(\n            factor=factor, interpolation=interpolation, copy=copy\n        )\n        return out if out is not None and copy else self\n\n    def blur(\n        self,\n        kernel: tuple = (5, 5),\n        iterations: int = 1,\n        method: BlurMethods = \"average\",\n        sigmax: float = 0,\n    ) -&gt; Self:\n        \"\"\"Blur the image\n\n        Args:\n            kernel (tuple, optional): blur kernel size. Defaults to (5, 5).\n            iterations (int, optional): number of iterations. Defaults to 1.\n            method (str, optional): blur method.\n                Must be in [\"average\", \"median\", \"gaussian\", \"bilateral\"].\n                Defaults to \"average\".\n            sigmax (float, optional): sigmaX value for the gaussian blur.\n                Defaults to 0.\n\n        Returns:\n            Self: blurred image\n        \"\"\"\n        self.transformer.morphologyzer.blur(\n            kernel=kernel, iterations=iterations, method=method, sigmax=sigmax\n        )\n        return self\n\n    def dilate(\n        self,\n        kernel: tuple = (5, 5),\n        iterations: int = 1,\n        dilate_black_pixels: bool = True,\n    ) -&gt; Self:\n        \"\"\"Dilate the image by making the black pixels expand in the image.\n        The dilatation can be parametrize thanks to the kernel and iterations\n        arguments.\n\n        Args:\n            kernel (tuple, optional): kernel to dilate. Defaults to (5, 5).\n            iterations (int, optional): number of dilatation iterations. Defaults to 1.\n            dilate_black_pixels (bool, optional): whether to dilate black pixels or not\n\n        Returns:\n            Self: dilated image\n        \"\"\"\n        self.transformer.morphologyzer.dilate(\n            kernel=kernel,\n            iterations=iterations,\n            dilate_black_pixels=dilate_black_pixels,\n        )\n        return self\n\n    def erode(\n        self,\n        kernel: tuple = (5, 5),\n        iterations: int = 1,\n        erode_black_pixels: bool = True,\n    ) -&gt; Self:\n        \"\"\"Erode the image by making the black pixels shrink in the image.\n        The anti-dilatation can be parametrize thanks to the kernel and iterations\n        arguments.\n\n        Args:\n            kernel (tuple, optional): kernel to erode. Defaults to (5, 5).\n            iterations (int, optional): number of iterations. Defaults to 1.\n            erode_black_pixels (bool, optional): whether to erode black pixels or not\n\n        Returns:\n            Self: eroded image\n        \"\"\"\n        self.transformer.morphologyzer.erode(\n            kernel=kernel, iterations=iterations, erode_black_pixels=erode_black_pixels\n        )\n        return self\n\n    def add_border(self, size: int, fill_value: int = 0) -&gt; Self:\n        \"\"\"Add a border to the image.\n\n        Args:\n            thickness (int): border thickness.\n            color (int, optional): border color. Defaults to 0.\n        \"\"\"\n        self.transformer.morphologyzer.add_border(size=size, fill_value=fill_value)\n        return self\n\n    def add_noise_salt_and_pepper(self, amount: float = 0.05) -&gt; Self:\n        \"\"\"Add salt and pepper noise to the image.\n\n        Args:\n            amount (float, optional): Proportion of image pixels to alter.\n                Defaults to 0.05.\n        \"\"\"\n        self.transformer.morphologyzer.add_noise_salt_and_pepper(amount=amount)\n        return self\n\n    def add_noise_gaussian(self, mean: float = 0, std: float = 0.05) -&gt; Self:\n        \"\"\"Add Gaussian noise to the image.\n\n        Args:\n            amount (float, optional): Proportion of image pixels to alter.\n                Defaults to 0.05.\n        \"\"\"\n        self.transformer.morphologyzer.add_noise_gaussian(mean=mean, std=std)\n        return self\n\n    # -------------------------- ASSEMBLED COMPOSED METHODS ---------------------------\n    # methods that use multiple components\n    # ---------------------------------------------------------------------------------\n\n    def iou(\n        self, other: Image, binarization_method: BinarizationMethods = \"sauvola\"\n    ) -&gt; float:\n        \"\"\"Compute the intersection over union score\n\n        Args:\n            other (Image): another image\n            binarization_method (str, optional): binarization method to turn images\n                into 0 and 1 images. The black pixels will be 1 and the white pixels\n                will be 0. This is used to compute the score.\n                Defaults to \"sauvola\".\n\n        Returns:\n            float: a score from 0 to 1. The greater the score the greater the other\n                image is equal to the original image\n        \"\"\"\n        assert self.is_equal_shape(other)\n        mask0 = self.binaryrev(method=binarization_method)\n        mask1 = other.binaryrev(method=binarization_method)\n        return np.sum(mask0 * mask1) / np.count_nonzero(mask0 + mask1)\n\n    def score_contains_v2(\n        self, other: Image, binarization_method: BinarizationMethods = \"sauvola\"\n    ) -&gt; float:\n        \"\"\"Score contains version 2 which is more efficient and faster.\n\n        Args:\n            other (Image): other Image object\n            binarization_method (str, optional): binarization method to turn images\n                into 0 and 1 images. The black pixels will be 1 and the white pixels\n                will be 0. This is used to compute the score.\n                Defaults to \"sauvola\".\n\n        Returns:\n            float: a score from 0 to 1. The greater the score the greater the other\n                image is contained within the original image\n        \"\"\"\n        assert self.is_equal_shape(other, consider_channel=False)\n\n        cur_binaryrev = self.binaryrev(method=binarization_method)\n        other_binaryrev = other.binaryrev(method=binarization_method)\n\n        other_pixels = cur_binaryrev[other_binaryrev == 1]\n\n        coverage = np.sum(other_pixels) / np.sum(other_binaryrev)\n        return coverage\n\n    def score_contains(\n        self, other: Image, binarization_method: BinarizationMethods = \"sauvola\"\n    ) -&gt; float:\n        \"\"\"How much the other image is contained in the original image.\n\n        Args:\n            other (Image): other Image object\n            binarization_method (str, optional): binarization method to turn images\n                into 0 and 1 images. The black pixels will be 1 and the white pixels\n                will be 0. This is used to compute the score.\n                Defaults to \"sauvola\".\n\n        Returns:\n            float: a score from 0 to 1. The greater the score the greater the other\n                image is contained within the original image\n        \"\"\"\n        assert self.is_equal_shape(other, consider_channel=False)\n        other_binaryrev = other.binaryrev(method=binarization_method)\n        return np.sum(\n            self.binaryrev(method=binarization_method) * other_binaryrev\n        ) / np.sum(other_binaryrev)\n\n    def score_contains_segments(\n        self,\n        segments: Sequence[geo.Segment],\n        dilate_kernel: tuple = (5, 5),\n        dilate_iterations: int = 0,\n        binarization_method: BinarizationMethods = \"sauvola\",\n        resize_factor: float = 1.0,\n    ) -&gt; list[float]:\n        \"\"\"Compute the contains score in [0, 1] for each individual segment.\n        This method can be better than score_contains_polygons in some\n        cases.\n        It provides a score for each single segments. This way it is better to\n        identify which segments specifically are contained in the image or not.\n\n        Args:\n            segments (NDArray | list[geo.Segment]): a list of segments\n            dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n            dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n            binarization_method (str, optional): binarization method. Here\n                we can afford the sauvola method since we crop the image first\n                and the binarization occurs on a small image.\n                Defaults to \"sauvola\".\n            resize_factor (float, optional): resize factor that can be adjusted to\n                provide extra speed. A lower value will be faster but less accurate.\n                Typically 0.5 works well but less can have a negative impact on accuracy\n                Defaults to 1.0 which implies no resize.\n\n        Returns:\n            NDArray: list of score for each individual segment in the same order\n                as the list of segments\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        added_width = 10\n        height_crop = 30\n        mid_height_crop = int(height_crop / 2)\n        score_segments: list[float] = []\n\n        for segment in segments:\n\n            im = self.crop_segment_faster(\n                segment=segment.asarray,\n                dim_crop_rect=(-1, height_crop),\n                added_width=added_width,\n                pad_value=255,\n            )\n\n            im.dilate(kernel=dilate_kernel, iterations=dilate_iterations)\n\n            im.resize(factor=resize_factor)\n\n            # re-compute the segment in the crop referential\n            segment_crop = geo.Segment(\n                np.array(\n                    [\n                        [added_width, mid_height_crop],\n                        [segment.length + added_width, mid_height_crop],\n                    ]\n                )\n                * resize_factor\n            )\n\n            # create all-white image of same size as original with the segment drawn\n            other = (\n                im.copy()\n                .as_white()\n                .draw_segments(\n                    segments=[segment_crop],\n                    render=SegmentsRender(thickness=1, default_color=(0, 0, 0)),\n                )\n                .as_grayscale()\n            )\n\n            score = im.score_contains_v2(\n                other=other, binarization_method=binarization_method\n            )\n\n            score_segments.append(score)\n\n        return score_segments\n\n    def score_contains_polygons(\n        self,\n        polygons: Sequence[geo.Polygon],\n        dilate_kernel: tuple = (5, 5),\n        dilate_iterations: int = 0,\n        binarization_method: BinarizationMethods = \"sauvola\",\n        resize_factor: float = 1.0,\n    ) -&gt; list[float]:\n        \"\"\"Compute the contains score in [0, 1] for each individual polygon.\n\n        Beware: this method is different from the score_contains method because in\n        this case you can emphasize the base image by dilating its content.\n\n        Everything that is a 1 in the rmask will be dilated to give more chance for the\n        contour to be contained within the image in the calculation. This way you\n        can control the sensitivity of the score.\n\n        Args:\n            polygons (Sequence[Polygon]): Polygon object\n            dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n            dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n            binarization_method (str, optional): binarization method. Here\n                we can afford the sauvola method since we crop the image first\n                and the binarization occurs on a small image.\n                Defaults to \"sauvola\".\n            resize_factor (float, optional): resize factor that can be adjusted to\n                provide extra speed. A lower value will be faster but less accurate.\n                Typically 0.5 works well but less can have a negative impact on accuracy\n                Defaults to 1.0 which implies no resize.\n\n        Returns:\n            float: a score from 0 to 1. The greater the score the greater the contour\n                 is contained within the original image\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        extra_border_size = 10\n        scores: list[float] = []\n        for polygon in polygons:\n\n            im = self.crop_from_polygon(\n                polygon=polygon,\n                copy=True,\n                pad=True,\n                clip=False,\n                extra_border_size=extra_border_size,\n                pad_value=255,\n            )\n\n            im.dilate(kernel=dilate_kernel, iterations=dilate_iterations)\n\n            im.resize(factor=resize_factor)\n\n            # re-compute the polygon in the crop referential\n            polygon_crop = geo.Polygon(\n                (polygon.crop_coordinates + extra_border_size) * resize_factor\n            )\n\n            # create all-white image of same size as original with the geometry entity\n            other = (\n                im.copy()\n                .as_white()\n                .draw_polygons(\n                    polygons=[polygon_crop],\n                    render=PolygonsRender(thickness=1, default_color=(0, 0, 0)),\n                )\n                .as_grayscale()\n            )\n\n            cur_score = im.score_contains_v2(\n                other=other, binarization_method=binarization_method\n            )\n\n            scores.append(cur_score)\n\n        return scores\n\n    def score_contains_linear_splines(\n        self,\n        splines: Sequence[geo.LinearSpline],\n        dilate_kernel: tuple = (5, 5),\n        dilate_iterations: int = 0,\n        binarization_method: BinarizationMethods = \"sauvola\",\n        resize_factor: float = 1.0,\n    ) -&gt; list[float]:\n        \"\"\"Compute the contains score in [0, 1]for each individual LinearSpline.\n        It provides a score for each single linear spline.\n\n        Args:\n            splines (Sequence[LinearSpline]): a list of linear splines objects\n            dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n            dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n            binarization_method (str, optional): binarization method. Here\n                we can afford the sauvola method since we crop the image first\n                and the binarization occurs on a small image.\n                Defaults to \"sauvola\".\n            resize_factor (float, optional): resize factor that can be adjusted to\n                provide extra speed. A lower value will be faster but less accurate.\n                Typically 0.5 works well but less can have a negative impact on accuracy\n                Defaults to 1.0 which implies no resize.\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        extra_border_size = 10\n        scores: list[float] = []\n        for spline in splines:\n            im = self.crop_from_linear_spline(\n                spline=spline,\n                copy=True,\n                pad=True,\n                clip=False,\n                extra_border_size=extra_border_size,\n                pad_value=255,\n            )\n\n            im.dilate(kernel=dilate_kernel, iterations=dilate_iterations)\n\n            im.resize(factor=resize_factor)\n\n            spline_crop = geo.LinearSpline(\n                (spline.crop_coordinates + extra_border_size) * resize_factor\n            )\n\n            # create all-white image of same size as original with the geometry entity\n            other = (\n                im.copy()\n                .as_white()\n                .draw_splines(\n                    splines=[spline_crop],\n                    render=LinearSplinesRender(thickness=1, default_color=(0, 0, 0)),\n                )\n                .as_grayscale()\n            )\n\n            cur_score = im.score_contains_v2(\n                other=other, binarization_method=binarization_method\n            )\n\n            scores.append(cur_score)\n\n        return scores\n\n    def score_contains_linear_entities(\n        self,\n        entities: Sequence[LinearEntity],\n        dilate_kernel: tuple = (5, 5),\n        dilate_iterations: int = 0,\n        binarization_method: BinarizationMethods = \"sauvola\",\n        resize_factor: float = 1.0,\n    ) -&gt; list[float]:\n        \"\"\"Compute the contains score in [0, 1] for each individual linear entity\n        (either LinearSpline or Segment).\n\n        Args:\n            entities (list[geo.LinearEntity]): a list of linear entities\n                (splines or segments)\n            dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n            dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n            binarization_method (BinarizationMethods, optional): binarization method.\n                Defaults to \"sauvola\".\n            resize_factor (float, optional): resize factor for speed/accuracy tradeoff.\n                Defaults to 1.0.\n\n        Returns:\n            list[float]: list of scores for each individual entity\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        scores = []\n        for entity in entities:\n            if isinstance(entity, geo.LinearSpline):\n                score = self.score_contains_linear_splines(\n                    splines=[entity],\n                    dilate_kernel=dilate_kernel,\n                    dilate_iterations=dilate_iterations,\n                    binarization_method=binarization_method,\n                    resize_factor=resize_factor,\n                )[0]\n            elif isinstance(entity, geo.Segment):\n                score = self.score_contains_segments(\n                    segments=[entity],\n                    dilate_kernel=dilate_kernel,\n                    dilate_iterations=dilate_iterations,\n                    binarization_method=binarization_method,\n                    resize_factor=resize_factor,\n                )[0]\n            else:\n                raise TypeError(\n                    f\"Unsupported entity type: {type(entity)}. \"\n                    \"Expected LinearSpline or Segment.\"\n                )\n            scores.append(score)\n        return scores\n\n    def score_distance_from_center(\n        self, point: NDArray, method: ScoreDistanceFromCenterMethods = \"linear\"\n    ) -&gt; float:\n        \"\"\"Compute a score to evaluate how far a point is from the\n        image center point.\n\n        A score close to 0 means that the point and the image center are far away.\n        A score close to 1 means that the point and the image center are close.\n\n        It is particularly useful when calling it where the point argument is a\n        contour centroid. Then, a score equal to 1 means that the contour and image\n        centers coincide.\n\n        This method can be used to compute a score for a contour centroid:\n        - A small score should be taken into account and informs us that the contour\n        found is probably wrong.\n        - On the contrary, a high score does not ensure a high quality contour.\n\n        Args:\n            point (NDArray): 2D point\n            method (str): the method to be used to compute the score. Defaults to\n                \"linear\".\n\n        Returns:\n            float: a score from 0 to 1.\n        \"\"\"\n\n        def gaussian_2d(\n            x: float,\n            y: float,\n            x0: float = 0.0,\n            y0: float = 0.0,\n            amplitude: float = 1.0,\n            sigmax: float = 1.0,\n            sigmay: float = 1.0,\n        ) -&gt; float:\n            # pylint: disable=too-many-positional-arguments,too-many-arguments\n            return amplitude * np.exp(\n                -((x - x0) ** 2 / (2 * sigmax**2) + (y - y0) ** 2 / (2 * sigmay**2))\n            )\n\n        def cone_positive_2d(\n            x: float,\n            y: float,\n            x0: float = 0.0,\n            y0: float = 0.0,\n            amplitude: float = 1.0,\n            radius: float = 1.0,\n        ) -&gt; float:\n            # pylint: disable=too-many-positional-arguments,too-many-arguments\n            r = np.sqrt((x - x0) ** 2 + (y - y0) ** 2)\n            if r &gt;= radius:\n                return 0\n            return amplitude * (1 - r / radius)\n\n        if method == \"linear\":\n            return cone_positive_2d(\n                x=point[0],\n                y=point[1],\n                x0=self.center[0],\n                y0=self.center[1],\n                radius=self.norm_side_length / 2,\n            )\n        if method == \"gaussian\":\n            return gaussian_2d(\n                x=point[0],\n                y=point[1],\n                x0=self.center[0],\n                y0=self.center[1],\n                sigmax=self.dist_pct(0.1),\n                sigmay=self.dist_pct(0.1),\n            )\n\n        raise ValueError(f\"Unknown method {method}\")\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the image\n\n        Returns:\n            str: string\n        \"\"\"\n        return (\n            self.__class__.__name__\n            + \"(height=\"\n            + str(self.height)\n            + \", width=\"\n            + str(self.width)\n            + \", n_channels=\"\n            + str(self.channels)\n            + \")\"\n        )\n\n    def _repr_image(self, image_format: str, **kwargs: Any) -&gt; Optional[bytes]:\n        \"\"\"Helper function for iPython display hook.\n\n        Just reused the code from PIL library:\n        https://github.com/python-pillow/Pillow/blob/main/src/PIL/Image.py\n\n        Args:\n          image_format (str): Image format.\n\n        Returns:\n            (bytes, optional): image as bytes, saved into the given format.\n        \"\"\"\n        b = io.BytesIO()\n        try:\n            im = self.show()\n            im.save(b, image_format, **kwargs)\n        except Exception:  # pylint: disable=broad-except\n            return None\n        return b.getvalue()\n\n    def _repr_png_(self) -&gt; Optional[bytes]:\n        \"\"\"iPython display hook support for PNG format.\n\n        Returns:\n            (bytes, optional): PNG version of the image as bytes\n        \"\"\"\n        return self._repr_image(\"PNG\", compress_level=1)\n\n    def _repr_jpeg_(self) -&gt; Optional[bytes]:\n        \"\"\"iPython display hook support for JPEG format.\n\n        Returns:\n            (bytes, optional): JPEG version of the image as bytes\n        \"\"\"\n        return self._repr_image(\"JPEG\")\n</code></pre>"},{"location":"api/image/conversion/#otary.image.image.Image.as_grayscale","title":"<code>as_grayscale()</code>","text":"<p>Generate the image in grayscale of shape (height, width)</p> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>original image in grayscale</p> Source code in <code>otary/image/image.py</code> <pre><code>def as_grayscale(self) -&gt; Self:\n    \"\"\"Generate the image in grayscale of shape (height, width)\n\n    Returns:\n        Self: original image in grayscale\n    \"\"\"\n    self.base.as_grayscale()\n    return self\n</code></pre>"},{"location":"api/image/conversion/#otary.image.image.Image.as_colorscale","title":"<code>as_colorscale()</code>","text":"<p>Generate the image in colorscale (height, width, 3). This property can be useful when we wish to draw objects in a given color on a grayscale image.</p> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>original image in color</p> Source code in <code>otary/image/image.py</code> <pre><code>def as_colorscale(self) -&gt; Self:\n    \"\"\"Generate the image in colorscale (height, width, 3).\n    This property can be useful when we wish to draw objects in a given color\n    on a grayscale image.\n\n    Returns:\n        Self: original image in color\n    \"\"\"\n    self.base.as_colorscale()\n    return self\n</code></pre>"},{"location":"api/image/conversion/#otary.image.image.Image.as_filled","title":"<code>as_filled(fill_value=255)</code>","text":"<p>Returns an entirely white image of the same size as the original. Can be useful to get an empty representation of the same image to paint and draw things on an image of the same dimension.</p> <p>Parameters:</p> Name Type Description Default <code>fill_value</code> <code>int | NDArray</code> <p>color to fill the new empty image. Defaults to 255 which means that is returns a entirely white image.</p> <code>255</code> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>new image with a single color of the same size as original.</p> Source code in <code>otary/image/image.py</code> <pre><code>def as_filled(self, fill_value: int | NDArray = 255) -&gt; Self:\n    \"\"\"Returns an entirely white image of the same size as the original.\n    Can be useful to get an empty representation of the same image to paint\n    and draw things on an image of the same dimension.\n\n    Args:\n        fill_value (int | NDArray, optional): color to fill the new empty image.\n            Defaults to 255 which means that is returns a entirely white image.\n\n    Returns:\n        Self: new image with a single color of the same size as original.\n    \"\"\"\n    self.base.as_filled(fill_value=fill_value)\n    return self\n</code></pre>"},{"location":"api/image/conversion/#otary.image.image.Image.as_white","title":"<code>as_white()</code>","text":"<p>Returns an entirely white image with the same dimension as the original.</p> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>new white image</p> Source code in <code>otary/image/image.py</code> <pre><code>def as_white(self) -&gt; Self:\n    \"\"\"Returns an entirely white image with the same dimension as the original.\n\n    Returns:\n        Self: new white image\n    \"\"\"\n    self.base.as_white()\n    return self\n</code></pre>"},{"location":"api/image/conversion/#otary.image.image.Image.as_black","title":"<code>as_black()</code>","text":"<p>Returns an entirely black image with the same dimension as the original.</p> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>new black image</p> Source code in <code>otary/image/image.py</code> <pre><code>def as_black(self) -&gt; Self:\n    \"\"\"Returns an entirely black image with the same dimension as the original.\n\n    Returns:\n        Self: new black image\n    \"\"\"\n    self.base.as_black()\n    return self\n</code></pre>"},{"location":"api/image/conversion/#otary.image.image.Image.as_pil","title":"<code>as_pil()</code>","text":"<p>Return the image as PIL Image</p> <p>Returns:</p> Name Type Description <code>ImagePIL</code> <code>Image</code> <p>PIL Image</p> Source code in <code>otary/image/image.py</code> <pre><code>def as_pil(self) -&gt; ImagePIL.Image:\n    \"\"\"Return the image as PIL Image\n\n    Returns:\n        ImagePIL: PIL Image\n    \"\"\"\n    return self.base.as_pil()\n</code></pre>"},{"location":"api/image/conversion/#otary.image.image.Image.as_api_file_input","title":"<code>as_api_file_input(fmt='png', filename='image')</code>","text":"<p>Return the image as a file input for API requests.</p> <p>Parameters:</p> Name Type Description Default <code>fmt</code> <code>str</code> <p>format of the image. Defaults to \"png\".</p> <code>'png'</code> <code>filename</code> <code>str</code> <p>name of the file without the format. Defaults to \"image\".</p> <code>'image'</code> <p>Returns:</p> Type Description <code>dict[str, tuple[str, bytes, str]]</code> <p>dict[str, tuple[str, bytes, str]]: dictionary with file input for API requests, where the key is \"file\" and the value is a tuple containing the filename, image bytes, and content type.</p> Source code in <code>otary/image/image.py</code> <pre><code>def as_api_file_input(\n    self, fmt: str = \"png\", filename: str = \"image\"\n) -&gt; dict[str, tuple[str, bytes, str]]:\n    \"\"\"Return the image as a file input for API requests.\n\n    Args:\n        fmt (str, optional): format of the image. Defaults to \"png\".\n        filename (str, optional): name of the file without the format.\n            Defaults to \"image\".\n\n    Returns:\n        dict[str, tuple[str, bytes, str]]: dictionary with file input\n            for API requests, where the key is \"file\" and the value is a tuple\n            containing the filename, image bytes, and content type.\n    \"\"\"\n    return self.base.as_api_file_input(fmt=fmt, filename=filename)\n</code></pre>"},{"location":"api/image/properties/","title":"Properties","text":"<p>Properties are the essential attributes of an image. They provide basic information about the image, such as its dimensions, shape, etc.</p> <p>Here is for example a python sample code to get the width of the image:</p> <pre><code>import otary as ot\n\nim = ot.Image.from_fillvalue(shape=(256, 128, 3), value=255)\n\nprint(im.width) # 128\n</code></pre> <p>Image core class. It groups all the methods available from composition from all the image classes.</p> Source code in <code>otary/image/image.py</code> <pre><code>class Image:\n    \"\"\"\n    Image core class. It groups all the methods available from composition\n    from all the image classes.\n    \"\"\"\n\n    # pylint: disable=too-many-public-methods\n\n    reader = ReaderImage()\n\n    def __init__(self, image: NDArray) -&gt; None:\n        self.base = BaseImage(image=image, parent=self)\n        self.drawer = DrawerImage(base=self.base)\n        self.writer = WriterImage(base=self.base)\n        self.transformer = TransformerImage(base=self.base)\n\n    # -------------------------------- CLASS METHODS ----------------------------------\n\n    @classmethod\n    def from_fillvalue(cls, value: int = 255, shape: tuple = (128, 128, 3)) -&gt; Image:\n        \"\"\"Class method to create an image from a single value\n\n        Args:\n            value (int, optional): value in [0, 255]. Defaults to 255.\n            shape (tuple, optional): image shape. If it has three elements then\n                the last one must be a 3 for a coloscale image.\n                Defaults to (128, 128, 3).\n\n        Returns:\n            Image: array with a single value\n        \"\"\"\n        return cls(image=cls.reader.from_fillvalue(value=value, shape=shape))\n\n    @classmethod\n    def from_file(\n        cls, filepath: str, as_grayscale: bool = False, resolution: Optional[int] = None\n    ) -&gt; Image:\n        \"\"\"Create a Image array from a file image path\n\n        Args:\n            filepath (str): path to the image file\n            as_grayscale (bool, optional): turn the image in grayscale.\n                Defaults to False.\n            resolution (Optional[int], optional): resolution of the image.\n\n        Returns:\n            Image: Image object with a single value\n        \"\"\"\n        return cls(\n            cls.reader.from_file(\n                filepath=filepath, as_grayscale=as_grayscale, resolution=resolution\n            )\n        )\n\n    @classmethod\n    def from_pdf(\n        cls,\n        filepath: str,\n        as_grayscale: bool = False,\n        page_nb: int = 0,\n        resolution: Optional[int] = None,\n        clip_pct: Optional[AxisAlignedRectangle] = None,\n    ) -&gt; Image:\n        \"\"\"Create an Image array from a pdf file.\n\n        Args:\n            filepath (str): path to the pdf file\n            as_grayscale (bool, optional): turn the image in grayscale.\n                Defaults to False.\n            page_nb (int, optional): page number to extract. Defaults to 0.\n            resolution (Optional[int], optional): resolution of the image.\n            clip_pct (Optional[AxisAlignedRectangle], optional): clip percentage of the\n                image to only load a small part of the image (crop) for faster loading\n                and less memory usage. Defaults to None.\n\n        Returns:\n            Image: Image object from pdf\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        return cls(\n            cls.reader.from_pdf(\n                filepath=filepath,\n                as_grayscale=as_grayscale,\n                page_nb=page_nb,\n                resolution=resolution,\n                clip_pct=clip_pct,\n            )\n        )\n\n    # ---------------------------------- PROPERTIES -----------------------------------\n\n    @property\n    def asarray(self) -&gt; NDArray:\n        \"\"\"Array representation of the image\"\"\"\n        return self.base.asarray\n\n    @asarray.setter\n    def asarray(self, value: NDArray) -&gt; None:\n        \"\"\"Setter for the asarray property\n\n        Args:\n            value (NDArray): value of the asarray to be changed\n        \"\"\"\n        self.base.asarray = value\n\n    @property\n    def asarray_binary(self) -&gt; NDArray:\n        \"\"\"Returns the representation of the image as a array with value not in\n        [0, 255] but in [0, 1].\n\n        Returns:\n            NDArray: an array with value in [0, 1]\n        \"\"\"\n        return self.base.asarray_binary\n\n    @property\n    def width(self) -&gt; int:\n        \"\"\"Width of the image.\n\n        Returns:\n            int: image width\n        \"\"\"\n        return self.base.width\n\n    @property\n    def height(self) -&gt; int:\n        \"\"\"Height of the image\n\n        Returns:\n            int: image height\n        \"\"\"\n        return self.base.height\n\n    @property\n    def channels(self) -&gt; int:\n        \"\"\"Number of channels in the image\n\n        Returns:\n            int: number of channels\n        \"\"\"\n        return self.base.channels\n\n    @property\n    def center(self) -&gt; NDArray[np.int16]:\n        \"\"\"Center point of the image.\n\n        Please note that it is returned as type int because the center is\n        represented as a X-Y coords of a pixel.\n\n        Returns:\n            NDArray: center point of the image\n        \"\"\"\n        return self.base.center\n\n    @property\n    def area(self) -&gt; int:\n        \"\"\"Area of the image\n\n        Returns:\n            int: image area\n        \"\"\"\n        return self.base.area\n\n    @property\n    def shape_array(self) -&gt; tuple[int, int, int]:\n        \"\"\"Returns the array shape value (height, width, channel)\n\n        Returns:\n            tuple[int]: image shape\n        \"\"\"\n        return self.base.shape_array\n\n    @property\n    def shape_xy(self) -&gt; tuple[int, int, int]:\n        \"\"\"Returns the array shape value (width, height, channel)\n\n        Returns:\n            tuple[int]: image shape\n        \"\"\"\n        return self.base.shape_xy\n\n    @property\n    def is_gray(self) -&gt; bool:\n        \"\"\"Whether the image is a grayscale image or not\n\n        Returns:\n            bool: True if image is in grayscale, 0 otherwise\n        \"\"\"\n        return self.base.is_gray\n\n    @property\n    def norm_side_length(self) -&gt; int:\n        \"\"\"Returns the normalized side length of the image.\n        This is the side length if the image had the same area but\n        the shape of a square (four sides of the same length).\n\n        Returns:\n            int: normalized side length\n        \"\"\"\n        return self.base.norm_side_length\n\n    @property\n    def corners(self) -&gt; NDArray:\n        \"\"\"Returns the corners in clockwise order:\n\n        0. top left corner\n        1. top right corner\n        2. bottom right corner\n        3. bottom left corner\n\n        Returns:\n            NDArray: array containing the corners\n        \"\"\"\n        return self.base.corners\n\n    # ---------------------------------- BASE METHODS ---------------------------------\n\n    def as_grayscale(self) -&gt; Self:\n        \"\"\"Generate the image in grayscale of shape (height, width)\n\n        Returns:\n            Self: original image in grayscale\n        \"\"\"\n        self.base.as_grayscale()\n        return self\n\n    def as_colorscale(self) -&gt; Self:\n        \"\"\"Generate the image in colorscale (height, width, 3).\n        This property can be useful when we wish to draw objects in a given color\n        on a grayscale image.\n\n        Returns:\n            Self: original image in color\n        \"\"\"\n        self.base.as_colorscale()\n        return self\n\n    def as_reversed_color_channel(self) -&gt; Self:\n        \"\"\"Generate the image with the color channels reversed.\n        This is useful when we want to convert an image from BGR to RGB or vice versa.\n\n        Returns:\n            Self: original image with reversed color channels\n        \"\"\"\n        self.base.as_reversed_color_channel()\n        return self\n\n    def as_filled(self, fill_value: int | NDArray = 255) -&gt; Self:\n        \"\"\"Returns an entirely white image of the same size as the original.\n        Can be useful to get an empty representation of the same image to paint\n        and draw things on an image of the same dimension.\n\n        Args:\n            fill_value (int | NDArray, optional): color to fill the new empty image.\n                Defaults to 255 which means that is returns a entirely white image.\n\n        Returns:\n            Self: new image with a single color of the same size as original.\n        \"\"\"\n        self.base.as_filled(fill_value=fill_value)\n        return self\n\n    def as_white(self) -&gt; Self:\n        \"\"\"Returns an entirely white image with the same dimension as the original.\n\n        Returns:\n            Self: new white image\n        \"\"\"\n        self.base.as_white()\n        return self\n\n    def as_black(self) -&gt; Self:\n        \"\"\"Returns an entirely black image with the same dimension as the original.\n\n        Returns:\n            Self: new black image\n        \"\"\"\n        self.base.as_black()\n        return self\n\n    def as_pil(self) -&gt; ImagePIL.Image:\n        \"\"\"Return the image as PIL Image\n\n        Returns:\n            ImagePIL: PIL Image\n        \"\"\"\n        return self.base.as_pil()\n\n    def as_api_file_input(\n        self, fmt: str = \"png\", filename: str = \"image\"\n    ) -&gt; dict[str, tuple[str, bytes, str]]:\n        \"\"\"Return the image as a file input for API requests.\n\n        Args:\n            fmt (str, optional): format of the image. Defaults to \"png\".\n            filename (str, optional): name of the file without the format.\n                Defaults to \"image\".\n\n        Returns:\n            dict[str, tuple[str, bytes, str]]: dictionary with file input\n                for API requests, where the key is \"file\" and the value is a tuple\n                containing the filename, image bytes, and content type.\n        \"\"\"\n        return self.base.as_api_file_input(fmt=fmt, filename=filename)\n\n    def rev(self) -&gt; Self:\n        \"\"\"Reverse the image colors. Each pixel color value V becomes |V - 255|.\n\n        Applied on a grayscale image the black pixel becomes white and the\n        white pixels become black.\n        \"\"\"\n        self.base.rev()\n        return self\n\n    def dist_pct(self, pct: float) -&gt; float:\n        \"\"\"Distance percentage that can be used an acceptable distance error margin.\n        It is calculated based on the normalized side length.\n\n        Args:\n            pct (float, optional): percentage of distance error. Defaults to 0.01,\n                which means 1% of the normalized side length as the\n                default margin distance error.\n\n        Returns:\n            float: margin distance error\n        \"\"\"\n        return self.base.dist_pct(pct=pct)\n\n    def is_equal_shape(self, other: Image, consider_channel: bool = True) -&gt; bool:\n        \"\"\"Check whether two images have the same shape\n\n        Args:\n            other (BaseImage): BaseImage object\n\n        Returns:\n            bool: True if the objects have the same shape, False otherwise\n        \"\"\"\n        return self.base.is_equal_shape(\n            other=other.base, consider_channel=consider_channel\n        )\n\n    # ---------------------------------- COPY METHOD ----------------------------------\n\n    def copy(self) -&gt; Image:\n        \"\"\"Copy of the image.\n\n        For NumPy arrays containing basic data types (e.g., int, float, bool),\n        using copy.deepcopy() is generally unnecessary.\n        The numpy.copy() method achieves the same result more efficiently.\n        numpy.copy() creates a new array in memory with a separate copy of the data,\n        ensuring that modifications to the copy do not affect the original array.\n\n        Returns:\n            Image: image copy\n        \"\"\"\n        return Image(image=self.asarray.copy())\n\n    # -------------------------------- WRITE METHODS ----------------------------------\n\n    def save(self, fp: str) -&gt; None:\n        \"\"\"Save the image in a local file\n\n        Args:\n            fp (str): fp stands for filepath which is the path to the file\n        \"\"\"\n        self.writer.save(fp=fp)\n\n    def show(\n        self,\n        figsize: tuple[float, float] = (-1, -1),\n        popup_window_display: bool = False,\n    ) -&gt; ImagePIL.Image:\n        \"\"\"Show the image\n\n        Args:\n            figsize (tuple[float, float], optional): size of the figure.\n                Defaults to (-1, -1), meaning the original size of the image.\n            popup_window_display (bool, optional): whether to display the image in a\n                popup window. Defaults to False.\n        \"\"\"\n        return self.writer.show(\n            figsize=figsize, popup_window_display=popup_window_display\n        )\n\n    # -------------------------------- DRAWER METHODS ---------------------------------\n\n    def draw_circles(\n        self, circles: Sequence[geo.Circle], render: CirclesRender = CirclesRender()\n    ) -&gt; Self:\n        \"\"\"Draw circles in the image\n\n        Args:\n            circles (list[Circle]): list of Circle geometry objects.\n            render (CirclesRender): circle renderer\n\n        Returns:\n            Image: new image with circles drawn\n        \"\"\"\n        self.drawer.draw_circles(circles=circles, render=render)\n        return self\n\n    def draw_ellipses(\n        self, ellipses: Sequence[geo.Ellipse], render: EllipsesRender = EllipsesRender()\n    ) -&gt; Self:\n        \"\"\"Draw ellipses in the image\n\n        Args:\n            ellipses (list[Ellipse]): list of Ellipse geometry objects.\n            render (EllipsesRender): ellipse renderer\n\n        Returns:\n            Image: new image with ellipses drawn\n        \"\"\"\n        self.drawer.draw_ellipses(ellipses=ellipses, render=render)\n        return self\n\n    def draw_points(\n        self,\n        points: list | NDArray | Sequence[geo.Point],\n        render: PointsRender = PointsRender(),\n    ) -&gt; Self:\n        \"\"\"Draw points in the image\n\n        Args:\n            points (NDArray): list of points. It must be of shape (n, 2). This\n                means n points of shape 2 (x and y coordinates).\n            render (PointsRender): point renderer\n\n        Returns:\n            Image: new image with points drawn\n        \"\"\"\n        self.drawer.draw_points(points=points, render=render)\n        return self\n\n    def draw_segments(\n        self,\n        segments: NDArray | Sequence[geo.Segment],\n        render: SegmentsRender = SegmentsRender(),\n    ) -&gt; Self:\n        \"\"\"Draw segments in the image. It can be arrowed segments (vectors) too.\n\n        Args:\n            segments (NDArray): list of segments. Can be a numpy array of shape\n                (n, 2, 2) which means n array of shape (2, 2) that define a segment\n                by two 2D points.\n            render (SegmentsRender): segment renderer\n\n        Returns:\n            Image: new image with segments drawn\n        \"\"\"\n        self.drawer.draw_segments(segments=segments, render=render)\n        return self\n\n    def draw_polygons(\n        self,\n        polygons: Sequence[geo.Polygon],\n        render: PolygonsRender = PolygonsRender(),\n    ) -&gt; Self:\n        \"\"\"Draw polygons in the image\n\n        Args:\n            polygons (Sequence[Polygon]): list of Polygon objects\n            render (PolygonsRender): PolygonRender object\n\n        Returns:\n            Image: new image with polygons drawn\n        \"\"\"\n        self.drawer.draw_polygons(polygons=polygons, render=render)\n        return self\n\n    def draw_splines(\n        self,\n        splines: Sequence[geo.LinearSpline],\n        render: LinearSplinesRender = LinearSplinesRender(),\n    ) -&gt; Self:\n        \"\"\"Draw linear splines in the image.\n\n        Args:\n            splines (Sequence[geo.LinearSpline]): linear splines to draw.\n            render (LinearSplinesRender, optional): linear splines render.\n                Defaults to LinearSplinesRender().\n\n        Returns:\n            Image: new image with splines drawn\n        \"\"\"\n        self.drawer.draw_splines(splines=splines, render=render)\n        return self\n\n    def draw_ocr_outputs(\n        self,\n        ocr_outputs: Sequence[OcrSingleOutput],\n        render: OcrSingleOutputRender = OcrSingleOutputRender(),\n    ) -&gt; Self:\n        \"\"\"Return the image with the bounding boxes displayed from a list of OCR\n        single output. It allows you to show bounding boxes that can have an angle,\n        not necessarily vertical or horizontal.\n\n        Args:\n            ocr_outputs (list[OcrSingleOutput]): list of OcrSingleOutput objects\n            render (OcrSingleOutputRender): OcrSingleOutputRender object\n\n        Returns:\n            Image: new image with ocr outputs drawn\n        \"\"\"\n        self.drawer.draw_ocr_outputs(ocr_outputs=ocr_outputs, render=render)\n        return self\n\n    # --------------------------------- BINARIZER -------------------------------------\n\n    def threshold_simple(self, thresh: int) -&gt; Self:\n        \"\"\"Compute the image thesholded by a single value T.\n        All pixels with value v &lt;= T are turned black and those with value v &gt; T are\n        turned white. This is a global thresholding method.\n\n        Args:\n            thresh (int): value to separate the black from the white pixels.\n\n        Returns:\n            (Self): output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_simple(thresh=thresh)\n        return self\n\n    def threshold_otsu(self) -&gt; Self:\n        \"\"\"Apply Otsu global thresholding.\n        This is a global thresholding method that automatically determines\n        an optimal threshold value from the image histogram.\n\n        Paper (1979):\n        https://ieeexplore.ieee.org/document/4310076\n\n        Consider applying a gaussian blur before for better thresholding results.\n        See why in https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html.\n\n        As the input image must be a grayscale before applying any thresholding\n        methods we convert the image to grayscale.\n\n        Returns:\n            (Self): output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_otsu()\n        return self\n\n    def threshold_adaptive(self, block_size: int = 11, constant: float = 2.0) -&gt; Self:\n        \"\"\"Apply adaptive local thresholding.\n        This is a local thresholding method that computes the threshold for a pixel\n        based on a small region around it.\n\n        A gaussian blur is applied before for better thresholding results.\n        See why in https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html.\n\n        As the input image must be a grayscale before applying any thresholding\n        methods we convert the image to grayscale.\n\n        Args:\n            block_size (int, optional): Size of a pixel neighborhood that is used to\n                calculate a threshold value for the pixel: 3, 5, 7, and so on.\n                Defaults to 11.\n            constant (int, optional): Constant subtracted from the mean or weighted\n                mean. Normally, it is positive but may be zero or negative as well.\n                Defaults to 2.\n\n        Returns:\n            (Self): output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_adaptive(\n            block_size=block_size, constant=constant\n        )\n        return self\n\n    def threshold_sauvola(\n        self, window_size: int = 15, k: float = 0.5, r: float = 128.0\n    ) -&gt; Self:\n        \"\"\"Apply Sauvola local thresholding.\n         This is a local thresholding method that computes the threshold for a pixel\n         based on a small region around it.\n\n         Paper (1997):\n         https://www.researchgate.net/publication/3710586\n\n         See https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_niblack_sauvola.html # pylint: disable=line-too-long\n\n         As the input image must be a grayscale before applying any thresholding\n         methods we convert the image to grayscale.\n\n         Args:\n             window_size (int, optional): sauvola window size to apply on the\n                 image. Defaults to 15.\n             k (float, optional): sauvola k factor to apply to regulate the impact\n                 of the std. Defaults to 0.5.\n             r (float, optional): sauvola r value. Defaults to 128.\n\n        Returns:\n             (Self): output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_sauvola(window_size=window_size, k=k, r=r)\n        return self\n\n    def threshold_bradley(self, window_size: int = 15, t: float = 0.15) -&gt; Self:\n        \"\"\"Implementation of the Bradley &amp; Roth thresholding method.\n\n        Paper (2007):\n        https://www.researchgate.net/publication/220494200_Adaptive_Thresholding_using_the_Integral_Image\n\n        Args:\n            window_size (int, optional): window size for local computations.\n                Defaults to 15.\n            t (float, optional): t value in [0, 1]. Defaults to 0.15.\n\n        Returns:\n            NDArray[np.uint8]: output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_bradley(window_size=window_size, t=t)\n        return self\n\n    def binary(self, method: BinarizationMethods = \"sauvola\") -&gt; NDArray:\n        \"\"\"Binary representation of the image with values that can be only 0 or 1.\n        The value 0 is now 0 and value of 255 are now 1. Black is 0 and white is 1.\n        We can also talk about the mask of the image to refer to the binary\n        representation of it.\n\n        The sauvola is generally the best binarization method however it is\n        way slower than the others methods. The adaptative or otsu method are the best\n        method in terms of speed and quality.\n\n        Args:\n            method (str, optional): the binarization method to apply.\n                Must be in [\"adaptative\", \"otsu\", \"sauvola\", \"niblack\", \"nick\", \"wolf\"].\n                Defaults to \"sauvola\".\n\n        Returns:\n            NDArray: array where its inner values are 0 or 1\n        \"\"\"\n        return self.transformer.binarizer.binary(method=method)\n\n    def binaryrev(self, method: BinarizationMethods = \"sauvola\") -&gt; NDArray:\n        \"\"\"Reversed binary representation of the image.\n        The value 0 is now 1 and value of 255 are now 0. Black is 1 and white is 0.\n        This is why it is called the \"binary rev\" or \"binary reversed\".\n\n        Args:\n            method (str, optional): the binarization method to apply.\n                Must be in [\"adaptative\", \"otsu\", \"sauvola\", \"niblack\", \"nick\", \"wolf\"].\n                Defaults to \"adaptative\".\n\n        Returns:\n            NDArray: array where its inner values are 0 or 1\n        \"\"\"\n        return self.transformer.binarizer.binaryrev(method=method)\n\n    # ---------------------------------- CROPPER --------------------------------------\n    # the copy arguments is special in the crop methods.\n    # this is important for performance reasons\n    # if you want to crop a small part of an image and conserve the original\n    # without doing image.copy().crop() which would copy the entire original image!\n    # this would be much more expensive if the image is large\n\n    def crop(\n        self, x0: int, y0: int, x1: int, y1: int, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop the image in a straight axis-aligned rectangle way given\n        by the top-left point [x0, y0] and the bottom-right point [x1, y1]\n\n        This function inputs represents the top-left and bottom-right points.\n        This method does not provide a way to extract a rotated rectangle or a\n        different shape from the image.\n\n        Remember that in this library the x coordinates represent the y coordinates of\n        the image array (horizontal axis of the image).\n        The array representation is always rows then columns.\n        In this library this is the contrary like in opencv.\n\n        Args:\n            x0 (int): top-left x coordinate\n            y0 (int): top-left y coordinate\n            x1 (int): bottom-right x coordinate\n            y1 (int): bottom-right y coordinate\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        out = self.transformer.cropper.crop(\n            x0=x0, y0=y0, x1=x1, y1=y1, copy=copy, **kwargs\n        )\n        return out if out is not None else self\n\n    def crop_from_topleft(\n        self, topleft: NDArray, width: int, height: int, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop the image from a rectangle defined by its top-left point, its width and\n        its height.\n\n        Args:\n            topleft (NDArray): (x, y) coordinates of the top-left point\n            width (int): width of the rectangle to crop\n            height (int): height of the rectangle to crop\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        out = self.transformer.cropper.crop_from_topleft(\n            topleft=topleft, width=width, height=height, copy=copy, **kwargs\n        )\n        return out if out is not None else self\n\n    def crop_from_center(\n        self, center: NDArray, width: int, height: int, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop the image from a rectangle defined by its center point, its width and\n        its height.\n\n        Args:\n            center (NDArray): (x, y) coordinates of the center point\n            width (int): width of the rectangle to crop\n            height (int): height of the rectangle to crop\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        out = self.transformer.cropper.crop_from_center(\n            center=center, width=width, height=height, copy=copy, **kwargs\n        )\n        return out if out is not None and copy else self\n\n    def crop_from_axis_aligned_bbox(\n        self, bbox: geo.AxisAlignedRectangle, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop the image from an Axis-Aligned Bounding Box (AABB).\n        Inclusive crops which means that the cropped image will have\n        width and height equal to the width and height of the AABB.\n\n        Args:\n            bbox (geo.AxisAlignedRectangle): axis-aligned rectangle bounding box\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        out = self.transformer.cropper.crop_from_axis_aligned_rectangle(\n            bbox=bbox, copy=copy, **kwargs\n        )\n        return out if out is not None and copy else self\n\n    def crop_hq_from_aabb_and_pdf(\n        self,\n        bbox: geo.AxisAlignedRectangle,\n        pdf_filepath: str,\n        page_nb: int = 0,\n        as_grayscale: bool = False,\n        resolution: int = 1000,\n    ) -&gt; Image:\n        \"\"\"Generate a new image from a pdf file by cropping a High Quality crop\n        from a given Axis-Aligned Bounding Box (AABB).\n\n        The crop is of high quality because we can load only the crop part of the image\n        from the original pdf.\n\n        Args:\n            bbox (geo.AxisAlignedRectangle): crop bounding box\n            pdf_filepath (str): PDF filepath\n            page_nb (int, optional): page to load in the PDF. The first page is 0.\n                Defaults to 0.\n            as_grayscale (bool, optional): whether to load the image as grayscale or\n                not. Defaults to False.\n            resolution (int, optional): resolution of the final crop image.\n                Defaults to 1000.\n\n        Returns:\n            Image: high quality crop image\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        # get the bbox normalized\n        clip_pct = bbox.copy().normalize(x=self.width, y=self.height)\n\n        # obtain the High Quality crop image by reading\n        im_crop = Image.from_pdf(\n            filepath=pdf_filepath,\n            page_nb=page_nb,\n            as_grayscale=as_grayscale,\n            resolution=resolution,\n            clip_pct=clip_pct,\n        )\n        return im_crop\n\n    def crop_from_polygon(\n        self, polygon: geo.Polygon, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop from a polygon using its Axis-Aligned Bounding Box (AABB)\n\n        Args:\n            polygon (geo.Polygon): polygon object to crop in the image\n            copy (bool, optional): whether to create a copy or not. Defaults to False.\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        out = self.transformer.cropper.crop_from_polygon(\n            polygon=polygon, copy=copy, **kwargs\n        )\n        return out if out is not None and copy else self\n\n    def crop_from_linear_spline(\n        self, spline: geo.LinearSpline, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop from a Linear Spline using its Axis-Aligned Bounding Box (AABB)\n\n        Args:\n            spline (geo.LinearSpline): linear spline object to crop in the image\n            copy (bool, optional): whether to create a copy or not. Defaults to False.\n                        clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        out = self.transformer.cropper.crop_from_linear_spline(\n            spline=spline, copy=copy, **kwargs\n        )\n        return out if out is not None and copy else self\n\n    def crop_segment(\n        self,\n        segment: NDArray,\n        dim_crop_rect: tuple[int, int] = (-1, 100),\n        added_width: int = 75,\n    ) -&gt; tuple[Image, NDArray, float, NDArray]:\n        \"\"\"Crop around a specific segment in the image. This is done in three\n        specific steps:\n        1) shift image so that the middle of the segment is in the middle of the image\n        2) rotate image by the angle of segment so that the segment becomes horizontal\n        3) crop the image\n\n        Args:\n            segment (NDArray): segment as numpy array of shape (2, 2).\n            dim_crop_rect (tuple, optional): represents (width, height).\n                Defaults to heigth of 100 and width of -1 which means\n                that the width is automatically computed based on the length of\n                the segment.\n            added_width (int, optional): additional width for cropping.\n                Half of the added_width is added to each side of the segment.\n                Defaults to 75.\n\n        Returns:\n            tuple[Self, NDArray, float, NDArray]: returns in the following order:\n                1) the cropped image\n                2) the translation vector used to center the image\n                3) the angle of rotation applied to the image\n                4) the translation vector used to crop the image\n        \"\"\"\n        width_crop_rect, height_crop_rect = dim_crop_rect\n        im = self.copy()  # the copy before makes this method slow\n\n        # center the image based on the middle of the line\n        geo_segment = geo.Segment(segment)\n        im, translation_vector = im.center_to_segment(segment=segment)\n\n        if width_crop_rect == -1:\n            # default the width for crop to be a bit more than line length\n            width_crop_rect = int(geo_segment.length)\n        width_crop_rect += added_width\n        assert width_crop_rect &gt; 0 and height_crop_rect &gt; 0\n\n        # rotate the image so that the line is horizontal\n        angle = geo_segment.slope_angle(is_y_axis_down=True)\n        im = im.rotate(angle=angle)\n\n        # cropping\n        im_crop = im.crop_from_center(\n            center=im.base.center,\n            width=width_crop_rect,\n            height=height_crop_rect,\n        )\n\n        crop_translation_vector = self.base.center - im_crop.base.center\n        return im_crop, translation_vector, angle, crop_translation_vector\n\n    def crop_segment_faster(\n        self,\n        segment: NDArray,\n        dim_crop_rect: tuple[int, int] = (-1, 100),\n        added_width: int = 75,\n        pad_value: int = 0,\n    ) -&gt; Image:\n        \"\"\"Crop around a specific segment in the image.\n        This method is faster especially for large images.\n\n        Here is a comparison of the total time taken for cropping with the two methods\n        with a loop over 1000 iterations:\n\n        | Image dimension | Crop v1 | Crop faster |\n        |-----------------|---------|-------------|\n        | 1224 x 946      | 2.0s    | 0.25s       |\n        | 2448 x 1892     | 4.51s   | 0.25s       |\n        | 4896 x 3784     | 23.2s   | 0.25s       |\n\n        Args:\n            segment (NDArray): segment as numpy array of shape (2, 2).\n            dim_crop_rect (tuple, optional): represents (width, height).\n                Defaults to heigth of 100 and width of -1 which means\n                that the width is automatically computed based on the length of\n                the segment.\n            added_width (int, optional): additional width for cropping.\n                Half of the added_width is added to each side of the segment.\n                Defaults to 75.\n\n        Returns:\n            Self: cropped image around the segment\n        \"\"\"\n        width_crop_rect, height_crop_rect = dim_crop_rect\n        geo_segment = geo.Segment(segment)\n        angle = geo_segment.slope_angle(is_y_axis_down=True)\n\n        if width_crop_rect == -1:\n            # default the width for crop to be a bit more than line length\n            width_crop_rect = int(geo_segment.length)\n        width_crop_rect += added_width\n        assert width_crop_rect &gt; 0 and height_crop_rect &gt; 0\n\n        x_extra = abs(added_width / 2 * np.cos(angle))\n        y_extra = abs(added_width / 2 * np.sin(angle))\n\n        # add extra width for crop in case segment is ~vertical\n        x_extra += int(width_crop_rect / 2) + 1\n        y_extra += int(height_crop_rect / 2) + 1\n\n        im: Image = self.crop(\n            x0=geo_segment.xmin - x_extra,\n            y0=geo_segment.ymin - y_extra,\n            x1=geo_segment.xmax + x_extra,\n            y1=geo_segment.ymax + y_extra,\n            pad=True,\n            clip=False,\n            copy=True,  # copy the image after cropping for very fast performance\n            pad_value=pad_value,\n        )\n\n        # rotate the image so that the line is horizontal\n        im.rotate(angle=angle)\n\n        # cropping around segment center\n        im.crop_from_center(\n            center=im.base.center,\n            width=width_crop_rect,\n            height=height_crop_rect,\n        )\n\n        return im\n\n    def crop_from_rectangle_referential(\n        self,\n        rect: geo.Rectangle,\n        rect_topleft_ix: int = 0,\n        crop_dim: tuple[float, float] = (-1, -1),\n        crop_shift: tuple[float, float] = (0, 0),\n    ) -&gt; Image:\n        \"\"\"Crop image in the referential of the rectangle.\n\n        Args:\n            rect (geo.Rectangle): rectangle for reference to crop.\n            rect_topleft_ix (int): top-left vertice index of the rectangle\n            crop_dim (tuple[float, float], optional): (width, height) crop dimension.\n                Defaults to (-1, -1).\n            crop_shift (tuple[float, float], optional): The shift is (x, y).\n                The crop_shift argument is applied from the rectangle center based on\n                the axis referential of the rectangle.\n                This means that the shift in the Y direction\n                is based on the normalized vector (bottom-left, top-left)\n                The shift in the X direction is based on the normalized vector\n                (top-left, top-right). Defaults to (0, 0) meaning no shift.\n\n        Returns:\n            Self: new image cropped\n        \"\"\"\n        # shift down and up vector calculated based on the top-left vertice\n        rect_shift_up = rect.get_vector_up_from_topleft(topleft_index=rect_topleft_ix)\n        rect_shift_left = rect.get_vector_left_from_topleft(\n            topleft_index=rect_topleft_ix\n        )\n\n        # crop dimension\n        rect_heigth = rect.get_height_from_topleft(topleft_index=rect_topleft_ix)\n        crop_width = rect_heigth if crop_dim[0] == -1 else crop_dim[0]\n        crop_height = rect_heigth if crop_dim[1] == -1 else crop_dim[1]\n        crop_width, crop_height = int(crop_width), int(crop_height)\n        assert crop_width &gt; 0 and crop_height &gt; 0\n\n        # compute the crop center\n        crop_center = rect.centroid\n        crop_center += crop_shift[0] * rect_shift_left.normalized  # shift left\n        crop_center += crop_shift[1] * rect_shift_up.normalized  # shift up\n\n        # get the crop segment\n        crop_segment = geo.Segment(\n            [\n                crop_center - crop_width / 2 * rect_shift_left.normalized,\n                crop_center + crop_width / 2 * rect_shift_left.normalized,\n            ]\n        )\n\n        return self.crop_segment_faster(\n            segment=crop_segment.asarray,\n            dim_crop_rect=(crop_width, crop_height),\n            added_width=0,\n        )\n\n    def crop_rectangle(self, rect: geo.Rectangle, rect_topleft_ix: int = 0) -&gt; Image:\n        \"\"\"Crop from a rectangle that can be rotated in any direction.\n        The crop is done using the information of the top-left vertice index to\n        determine the width and height of the crop.\n\n        Args:\n            rect (geo.Rectangle): rectangle to crop in the referential of the image\n            rect_topleft_ix (int, optional): top-left vertice index. Defaults to 0.\n\n        Returns:\n            Image: crop of the image\n        \"\"\"\n        crop_dim = (\n            rect.get_width_from_topleft(rect_topleft_ix),\n            rect.get_height_from_topleft(rect_topleft_ix),\n        )\n        return self.crop_from_rectangle_referential(\n            rect=rect, rect_topleft_ix=rect_topleft_ix, crop_dim=crop_dim\n        )\n\n    # ------------------------------- GEOMETRY METHODS --------------------------------\n\n    def shift(self, shift: NDArray, fill_value: Sequence[float] = (0.0,)) -&gt; Self:\n        \"\"\"Shift the image by performing a translation operation\n\n        Args:\n            shift (NDArray): Vector for translation\n            fill_value (int | tuple[int, int, int], optional): value to fill the\n                border of the image after the rotation in case reshape is True.\n                Can be a tuple of 3 integers for RGB image or a single integer for\n                grayscale image. Defaults to (0.0,) which is black.\n\n        Returns:\n            Self: shifted image\n        \"\"\"\n        self.transformer.geometrizer.shift(shift=shift, fill_value=fill_value)\n        return self\n\n    def rotate(\n        self,\n        angle: float,\n        is_degree: bool = False,\n        is_clockwise: bool = True,\n        reshape: bool = True,\n        fill_value: Sequence[float] = (0.0,),\n    ) -&gt; Self:\n        \"\"\"Rotate the image by a given angle.\n\n        For the rotation with reshape, meaning preserving the whole image,\n        we used the code from the imutils library:\n        https://github.com/PyImageSearch/imutils/blob/master/imutils/convenience.py#L41\n\n        Args:\n            angle (float): angle to rotate the image\n            is_degree (bool, optional): whether the angle is in degree or not.\n                If not it is considered to be in radians.\n                Defaults to False which means radians.\n            is_clockwise (bool, optional): whether the rotation is clockwise or\n                counter-clockwise. Defaults to True.\n            reshape (bool, optional): whether to preserve the original image or not.\n                If True, the complete image is preserved hence the width and height\n                of the rotated image are different than in the original image.\n                Defaults to True.\n            fill_value (Sequence[float], optional): value to\n                fill the border of the image after the rotation in case reshape is True.\n                Can be a tuple of 3 integers for RGB image or a single integer for\n                grayscale image. Defaults to (0.0,) which is black\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        self.transformer.geometrizer.rotate(\n            angle=angle,\n            is_degree=is_degree,\n            is_clockwise=is_clockwise,\n            reshape=reshape,\n            fill_value=fill_value,\n        )\n        return self\n\n    def center_to_point(self, point: NDArray) -&gt; tuple[Self, NDArray]:\n        \"\"\"Shift the image so that the input point ends up in the middle of the\n        new image\n\n        Args:\n            point (NDArray): point as (2,) shape numpy array\n\n        Returns:\n            (tuple[Self, NDArray]): Self, translation Vector\n        \"\"\"\n        shift_vector = self.transformer.geometrizer.center_to_point(point=point)\n        return self, shift_vector\n\n    def center_to_segment(self, segment: NDArray) -&gt; tuple[Self, NDArray]:\n        \"\"\"Shift the image so that the segment middle point ends up in the middle\n        of the new image\n\n        Args:\n            segment (NDArray): segment as numpy array of shape (2, 2)\n\n        Returns:\n            (tuple[Self, NDArray]): Self, vector_shift\n        \"\"\"\n        shift_vector = self.transformer.geometrizer.center_to_segment(segment=segment)\n        return self, shift_vector\n\n    def restrict_rect_in_frame(self, rectangle: geo.Rectangle) -&gt; geo.Rectangle:\n        \"\"\"Create a new rectangle that is contained within the image borders.\n        If the input rectangle is outside the image, the returned rectangle is a\n        image frame-fitted rectangle that preserve the same shape.\n\n        Args:\n            rectangle (geo.Rectangle): input rectangle\n\n        Returns:\n            geo.Rectangle: new rectangle\n        \"\"\"\n        return self.transformer.geometrizer.restrict_rect_in_frame(rectangle=rectangle)\n\n    # ----------------------------- MORPHOLOGICAL METHODS -----------------------------\n\n    def resize_fixed(\n        self,\n        dim: tuple[int, int],\n        interpolation: int = cv2.INTER_AREA,\n        copy: bool = False,\n    ) -&gt; Image | Self:\n        \"\"\"Resize the image using a fixed dimension well defined.\n        This function can result in a distorted image if the ratio between\n        width and height is different in the original and the new image.\n\n        If the dim argument has a negative value in height or width, then\n        a proportional ratio is applied based on the one of the two dimension given.\n\n        Args:\n            dim (tuple[int, int]): a tuple with two integers in the following order\n                (width, height).\n            interpolation (int, optional): resize interpolation.\n                Defaults to cv2.INTER_AREA.\n            copy (bool, optional): whether to return a new image or not.\n\n        Returns:\n            Image | Self: resized new image if copy=True else resized original image\n        \"\"\"\n        out = self.transformer.morphologyzer.resize_fixed(\n            dim=dim, interpolation=interpolation, copy=copy\n        )\n        return out if out is not None and copy else self\n\n    def resize(\n        self, factor: float, interpolation: int = cv2.INTER_AREA, copy: bool = False\n    ) -&gt; Image | Self:\n        \"\"\"Resize the image to a new size using a scaling factor value that\n        will be applied to all dimensions (width and height).\n\n        Applying this method can not result in a distorted image.\n\n        Args:\n            factor (float): factor in [0, 5] to resize the image.\n                A value of 1 does not change the image.\n                A value of 2 doubles the image size.\n                A maximum value of 5 is set to avoid accidentally producing a gigantic\n                image.\n            interpolation (int, optional): resize interpolation.\n                Defaults to cv2.INTER_AREA.\n            copy (bool, optional): whether to return a new image or not.\n\n        Returns:\n            Image | Self: resized new image if copy=True else resized original image\n        \"\"\"\n        out = self.transformer.morphologyzer.resize(\n            factor=factor, interpolation=interpolation, copy=copy\n        )\n        return out if out is not None and copy else self\n\n    def blur(\n        self,\n        kernel: tuple = (5, 5),\n        iterations: int = 1,\n        method: BlurMethods = \"average\",\n        sigmax: float = 0,\n    ) -&gt; Self:\n        \"\"\"Blur the image\n\n        Args:\n            kernel (tuple, optional): blur kernel size. Defaults to (5, 5).\n            iterations (int, optional): number of iterations. Defaults to 1.\n            method (str, optional): blur method.\n                Must be in [\"average\", \"median\", \"gaussian\", \"bilateral\"].\n                Defaults to \"average\".\n            sigmax (float, optional): sigmaX value for the gaussian blur.\n                Defaults to 0.\n\n        Returns:\n            Self: blurred image\n        \"\"\"\n        self.transformer.morphologyzer.blur(\n            kernel=kernel, iterations=iterations, method=method, sigmax=sigmax\n        )\n        return self\n\n    def dilate(\n        self,\n        kernel: tuple = (5, 5),\n        iterations: int = 1,\n        dilate_black_pixels: bool = True,\n    ) -&gt; Self:\n        \"\"\"Dilate the image by making the black pixels expand in the image.\n        The dilatation can be parametrize thanks to the kernel and iterations\n        arguments.\n\n        Args:\n            kernel (tuple, optional): kernel to dilate. Defaults to (5, 5).\n            iterations (int, optional): number of dilatation iterations. Defaults to 1.\n            dilate_black_pixels (bool, optional): whether to dilate black pixels or not\n\n        Returns:\n            Self: dilated image\n        \"\"\"\n        self.transformer.morphologyzer.dilate(\n            kernel=kernel,\n            iterations=iterations,\n            dilate_black_pixels=dilate_black_pixels,\n        )\n        return self\n\n    def erode(\n        self,\n        kernel: tuple = (5, 5),\n        iterations: int = 1,\n        erode_black_pixels: bool = True,\n    ) -&gt; Self:\n        \"\"\"Erode the image by making the black pixels shrink in the image.\n        The anti-dilatation can be parametrize thanks to the kernel and iterations\n        arguments.\n\n        Args:\n            kernel (tuple, optional): kernel to erode. Defaults to (5, 5).\n            iterations (int, optional): number of iterations. Defaults to 1.\n            erode_black_pixels (bool, optional): whether to erode black pixels or not\n\n        Returns:\n            Self: eroded image\n        \"\"\"\n        self.transformer.morphologyzer.erode(\n            kernel=kernel, iterations=iterations, erode_black_pixels=erode_black_pixels\n        )\n        return self\n\n    def add_border(self, size: int, fill_value: int = 0) -&gt; Self:\n        \"\"\"Add a border to the image.\n\n        Args:\n            thickness (int): border thickness.\n            color (int, optional): border color. Defaults to 0.\n        \"\"\"\n        self.transformer.morphologyzer.add_border(size=size, fill_value=fill_value)\n        return self\n\n    def add_noise_salt_and_pepper(self, amount: float = 0.05) -&gt; Self:\n        \"\"\"Add salt and pepper noise to the image.\n\n        Args:\n            amount (float, optional): Proportion of image pixels to alter.\n                Defaults to 0.05.\n        \"\"\"\n        self.transformer.morphologyzer.add_noise_salt_and_pepper(amount=amount)\n        return self\n\n    def add_noise_gaussian(self, mean: float = 0, std: float = 0.05) -&gt; Self:\n        \"\"\"Add Gaussian noise to the image.\n\n        Args:\n            amount (float, optional): Proportion of image pixels to alter.\n                Defaults to 0.05.\n        \"\"\"\n        self.transformer.morphologyzer.add_noise_gaussian(mean=mean, std=std)\n        return self\n\n    # -------------------------- ASSEMBLED COMPOSED METHODS ---------------------------\n    # methods that use multiple components\n    # ---------------------------------------------------------------------------------\n\n    def iou(\n        self, other: Image, binarization_method: BinarizationMethods = \"sauvola\"\n    ) -&gt; float:\n        \"\"\"Compute the intersection over union score\n\n        Args:\n            other (Image): another image\n            binarization_method (str, optional): binarization method to turn images\n                into 0 and 1 images. The black pixels will be 1 and the white pixels\n                will be 0. This is used to compute the score.\n                Defaults to \"sauvola\".\n\n        Returns:\n            float: a score from 0 to 1. The greater the score the greater the other\n                image is equal to the original image\n        \"\"\"\n        assert self.is_equal_shape(other)\n        mask0 = self.binaryrev(method=binarization_method)\n        mask1 = other.binaryrev(method=binarization_method)\n        return np.sum(mask0 * mask1) / np.count_nonzero(mask0 + mask1)\n\n    def score_contains_v2(\n        self, other: Image, binarization_method: BinarizationMethods = \"sauvola\"\n    ) -&gt; float:\n        \"\"\"Score contains version 2 which is more efficient and faster.\n\n        Args:\n            other (Image): other Image object\n            binarization_method (str, optional): binarization method to turn images\n                into 0 and 1 images. The black pixels will be 1 and the white pixels\n                will be 0. This is used to compute the score.\n                Defaults to \"sauvola\".\n\n        Returns:\n            float: a score from 0 to 1. The greater the score the greater the other\n                image is contained within the original image\n        \"\"\"\n        assert self.is_equal_shape(other, consider_channel=False)\n\n        cur_binaryrev = self.binaryrev(method=binarization_method)\n        other_binaryrev = other.binaryrev(method=binarization_method)\n\n        other_pixels = cur_binaryrev[other_binaryrev == 1]\n\n        coverage = np.sum(other_pixels) / np.sum(other_binaryrev)\n        return coverage\n\n    def score_contains(\n        self, other: Image, binarization_method: BinarizationMethods = \"sauvola\"\n    ) -&gt; float:\n        \"\"\"How much the other image is contained in the original image.\n\n        Args:\n            other (Image): other Image object\n            binarization_method (str, optional): binarization method to turn images\n                into 0 and 1 images. The black pixels will be 1 and the white pixels\n                will be 0. This is used to compute the score.\n                Defaults to \"sauvola\".\n\n        Returns:\n            float: a score from 0 to 1. The greater the score the greater the other\n                image is contained within the original image\n        \"\"\"\n        assert self.is_equal_shape(other, consider_channel=False)\n        other_binaryrev = other.binaryrev(method=binarization_method)\n        return np.sum(\n            self.binaryrev(method=binarization_method) * other_binaryrev\n        ) / np.sum(other_binaryrev)\n\n    def score_contains_segments(\n        self,\n        segments: Sequence[geo.Segment],\n        dilate_kernel: tuple = (5, 5),\n        dilate_iterations: int = 0,\n        binarization_method: BinarizationMethods = \"sauvola\",\n        resize_factor: float = 1.0,\n    ) -&gt; list[float]:\n        \"\"\"Compute the contains score in [0, 1] for each individual segment.\n        This method can be better than score_contains_polygons in some\n        cases.\n        It provides a score for each single segments. This way it is better to\n        identify which segments specifically are contained in the image or not.\n\n        Args:\n            segments (NDArray | list[geo.Segment]): a list of segments\n            dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n            dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n            binarization_method (str, optional): binarization method. Here\n                we can afford the sauvola method since we crop the image first\n                and the binarization occurs on a small image.\n                Defaults to \"sauvola\".\n            resize_factor (float, optional): resize factor that can be adjusted to\n                provide extra speed. A lower value will be faster but less accurate.\n                Typically 0.5 works well but less can have a negative impact on accuracy\n                Defaults to 1.0 which implies no resize.\n\n        Returns:\n            NDArray: list of score for each individual segment in the same order\n                as the list of segments\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        added_width = 10\n        height_crop = 30\n        mid_height_crop = int(height_crop / 2)\n        score_segments: list[float] = []\n\n        for segment in segments:\n\n            im = self.crop_segment_faster(\n                segment=segment.asarray,\n                dim_crop_rect=(-1, height_crop),\n                added_width=added_width,\n                pad_value=255,\n            )\n\n            im.dilate(kernel=dilate_kernel, iterations=dilate_iterations)\n\n            im.resize(factor=resize_factor)\n\n            # re-compute the segment in the crop referential\n            segment_crop = geo.Segment(\n                np.array(\n                    [\n                        [added_width, mid_height_crop],\n                        [segment.length + added_width, mid_height_crop],\n                    ]\n                )\n                * resize_factor\n            )\n\n            # create all-white image of same size as original with the segment drawn\n            other = (\n                im.copy()\n                .as_white()\n                .draw_segments(\n                    segments=[segment_crop],\n                    render=SegmentsRender(thickness=1, default_color=(0, 0, 0)),\n                )\n                .as_grayscale()\n            )\n\n            score = im.score_contains_v2(\n                other=other, binarization_method=binarization_method\n            )\n\n            score_segments.append(score)\n\n        return score_segments\n\n    def score_contains_polygons(\n        self,\n        polygons: Sequence[geo.Polygon],\n        dilate_kernel: tuple = (5, 5),\n        dilate_iterations: int = 0,\n        binarization_method: BinarizationMethods = \"sauvola\",\n        resize_factor: float = 1.0,\n    ) -&gt; list[float]:\n        \"\"\"Compute the contains score in [0, 1] for each individual polygon.\n\n        Beware: this method is different from the score_contains method because in\n        this case you can emphasize the base image by dilating its content.\n\n        Everything that is a 1 in the rmask will be dilated to give more chance for the\n        contour to be contained within the image in the calculation. This way you\n        can control the sensitivity of the score.\n\n        Args:\n            polygons (Sequence[Polygon]): Polygon object\n            dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n            dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n            binarization_method (str, optional): binarization method. Here\n                we can afford the sauvola method since we crop the image first\n                and the binarization occurs on a small image.\n                Defaults to \"sauvola\".\n            resize_factor (float, optional): resize factor that can be adjusted to\n                provide extra speed. A lower value will be faster but less accurate.\n                Typically 0.5 works well but less can have a negative impact on accuracy\n                Defaults to 1.0 which implies no resize.\n\n        Returns:\n            float: a score from 0 to 1. The greater the score the greater the contour\n                 is contained within the original image\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        extra_border_size = 10\n        scores: list[float] = []\n        for polygon in polygons:\n\n            im = self.crop_from_polygon(\n                polygon=polygon,\n                copy=True,\n                pad=True,\n                clip=False,\n                extra_border_size=extra_border_size,\n                pad_value=255,\n            )\n\n            im.dilate(kernel=dilate_kernel, iterations=dilate_iterations)\n\n            im.resize(factor=resize_factor)\n\n            # re-compute the polygon in the crop referential\n            polygon_crop = geo.Polygon(\n                (polygon.crop_coordinates + extra_border_size) * resize_factor\n            )\n\n            # create all-white image of same size as original with the geometry entity\n            other = (\n                im.copy()\n                .as_white()\n                .draw_polygons(\n                    polygons=[polygon_crop],\n                    render=PolygonsRender(thickness=1, default_color=(0, 0, 0)),\n                )\n                .as_grayscale()\n            )\n\n            cur_score = im.score_contains_v2(\n                other=other, binarization_method=binarization_method\n            )\n\n            scores.append(cur_score)\n\n        return scores\n\n    def score_contains_linear_splines(\n        self,\n        splines: Sequence[geo.LinearSpline],\n        dilate_kernel: tuple = (5, 5),\n        dilate_iterations: int = 0,\n        binarization_method: BinarizationMethods = \"sauvola\",\n        resize_factor: float = 1.0,\n    ) -&gt; list[float]:\n        \"\"\"Compute the contains score in [0, 1]for each individual LinearSpline.\n        It provides a score for each single linear spline.\n\n        Args:\n            splines (Sequence[LinearSpline]): a list of linear splines objects\n            dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n            dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n            binarization_method (str, optional): binarization method. Here\n                we can afford the sauvola method since we crop the image first\n                and the binarization occurs on a small image.\n                Defaults to \"sauvola\".\n            resize_factor (float, optional): resize factor that can be adjusted to\n                provide extra speed. A lower value will be faster but less accurate.\n                Typically 0.5 works well but less can have a negative impact on accuracy\n                Defaults to 1.0 which implies no resize.\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        extra_border_size = 10\n        scores: list[float] = []\n        for spline in splines:\n            im = self.crop_from_linear_spline(\n                spline=spline,\n                copy=True,\n                pad=True,\n                clip=False,\n                extra_border_size=extra_border_size,\n                pad_value=255,\n            )\n\n            im.dilate(kernel=dilate_kernel, iterations=dilate_iterations)\n\n            im.resize(factor=resize_factor)\n\n            spline_crop = geo.LinearSpline(\n                (spline.crop_coordinates + extra_border_size) * resize_factor\n            )\n\n            # create all-white image of same size as original with the geometry entity\n            other = (\n                im.copy()\n                .as_white()\n                .draw_splines(\n                    splines=[spline_crop],\n                    render=LinearSplinesRender(thickness=1, default_color=(0, 0, 0)),\n                )\n                .as_grayscale()\n            )\n\n            cur_score = im.score_contains_v2(\n                other=other, binarization_method=binarization_method\n            )\n\n            scores.append(cur_score)\n\n        return scores\n\n    def score_contains_linear_entities(\n        self,\n        entities: Sequence[LinearEntity],\n        dilate_kernel: tuple = (5, 5),\n        dilate_iterations: int = 0,\n        binarization_method: BinarizationMethods = \"sauvola\",\n        resize_factor: float = 1.0,\n    ) -&gt; list[float]:\n        \"\"\"Compute the contains score in [0, 1] for each individual linear entity\n        (either LinearSpline or Segment).\n\n        Args:\n            entities (list[geo.LinearEntity]): a list of linear entities\n                (splines or segments)\n            dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n            dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n            binarization_method (BinarizationMethods, optional): binarization method.\n                Defaults to \"sauvola\".\n            resize_factor (float, optional): resize factor for speed/accuracy tradeoff.\n                Defaults to 1.0.\n\n        Returns:\n            list[float]: list of scores for each individual entity\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        scores = []\n        for entity in entities:\n            if isinstance(entity, geo.LinearSpline):\n                score = self.score_contains_linear_splines(\n                    splines=[entity],\n                    dilate_kernel=dilate_kernel,\n                    dilate_iterations=dilate_iterations,\n                    binarization_method=binarization_method,\n                    resize_factor=resize_factor,\n                )[0]\n            elif isinstance(entity, geo.Segment):\n                score = self.score_contains_segments(\n                    segments=[entity],\n                    dilate_kernel=dilate_kernel,\n                    dilate_iterations=dilate_iterations,\n                    binarization_method=binarization_method,\n                    resize_factor=resize_factor,\n                )[0]\n            else:\n                raise TypeError(\n                    f\"Unsupported entity type: {type(entity)}. \"\n                    \"Expected LinearSpline or Segment.\"\n                )\n            scores.append(score)\n        return scores\n\n    def score_distance_from_center(\n        self, point: NDArray, method: ScoreDistanceFromCenterMethods = \"linear\"\n    ) -&gt; float:\n        \"\"\"Compute a score to evaluate how far a point is from the\n        image center point.\n\n        A score close to 0 means that the point and the image center are far away.\n        A score close to 1 means that the point and the image center are close.\n\n        It is particularly useful when calling it where the point argument is a\n        contour centroid. Then, a score equal to 1 means that the contour and image\n        centers coincide.\n\n        This method can be used to compute a score for a contour centroid:\n        - A small score should be taken into account and informs us that the contour\n        found is probably wrong.\n        - On the contrary, a high score does not ensure a high quality contour.\n\n        Args:\n            point (NDArray): 2D point\n            method (str): the method to be used to compute the score. Defaults to\n                \"linear\".\n\n        Returns:\n            float: a score from 0 to 1.\n        \"\"\"\n\n        def gaussian_2d(\n            x: float,\n            y: float,\n            x0: float = 0.0,\n            y0: float = 0.0,\n            amplitude: float = 1.0,\n            sigmax: float = 1.0,\n            sigmay: float = 1.0,\n        ) -&gt; float:\n            # pylint: disable=too-many-positional-arguments,too-many-arguments\n            return amplitude * np.exp(\n                -((x - x0) ** 2 / (2 * sigmax**2) + (y - y0) ** 2 / (2 * sigmay**2))\n            )\n\n        def cone_positive_2d(\n            x: float,\n            y: float,\n            x0: float = 0.0,\n            y0: float = 0.0,\n            amplitude: float = 1.0,\n            radius: float = 1.0,\n        ) -&gt; float:\n            # pylint: disable=too-many-positional-arguments,too-many-arguments\n            r = np.sqrt((x - x0) ** 2 + (y - y0) ** 2)\n            if r &gt;= radius:\n                return 0\n            return amplitude * (1 - r / radius)\n\n        if method == \"linear\":\n            return cone_positive_2d(\n                x=point[0],\n                y=point[1],\n                x0=self.center[0],\n                y0=self.center[1],\n                radius=self.norm_side_length / 2,\n            )\n        if method == \"gaussian\":\n            return gaussian_2d(\n                x=point[0],\n                y=point[1],\n                x0=self.center[0],\n                y0=self.center[1],\n                sigmax=self.dist_pct(0.1),\n                sigmay=self.dist_pct(0.1),\n            )\n\n        raise ValueError(f\"Unknown method {method}\")\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the image\n\n        Returns:\n            str: string\n        \"\"\"\n        return (\n            self.__class__.__name__\n            + \"(height=\"\n            + str(self.height)\n            + \", width=\"\n            + str(self.width)\n            + \", n_channels=\"\n            + str(self.channels)\n            + \")\"\n        )\n\n    def _repr_image(self, image_format: str, **kwargs: Any) -&gt; Optional[bytes]:\n        \"\"\"Helper function for iPython display hook.\n\n        Just reused the code from PIL library:\n        https://github.com/python-pillow/Pillow/blob/main/src/PIL/Image.py\n\n        Args:\n          image_format (str): Image format.\n\n        Returns:\n            (bytes, optional): image as bytes, saved into the given format.\n        \"\"\"\n        b = io.BytesIO()\n        try:\n            im = self.show()\n            im.save(b, image_format, **kwargs)\n        except Exception:  # pylint: disable=broad-except\n            return None\n        return b.getvalue()\n\n    def _repr_png_(self) -&gt; Optional[bytes]:\n        \"\"\"iPython display hook support for PNG format.\n\n        Returns:\n            (bytes, optional): PNG version of the image as bytes\n        \"\"\"\n        return self._repr_image(\"PNG\", compress_level=1)\n\n    def _repr_jpeg_(self) -&gt; Optional[bytes]:\n        \"\"\"iPython display hook support for JPEG format.\n\n        Returns:\n            (bytes, optional): JPEG version of the image as bytes\n        \"\"\"\n        return self._repr_image(\"JPEG\")\n</code></pre>"},{"location":"api/image/properties/#otary.image.image.Image.asarray","title":"<code>asarray</code>  <code>property</code> <code>writable</code>","text":"<p>Array representation of the image</p>"},{"location":"api/image/properties/#otary.image.image.Image.asarray_binary","title":"<code>asarray_binary</code>  <code>property</code>","text":"<p>Returns the representation of the image as a array with value not in [0, 255] but in [0, 1].</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>an array with value in [0, 1]</p>"},{"location":"api/image/properties/#otary.image.image.Image.width","title":"<code>width</code>  <code>property</code>","text":"<p>Width of the image.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>image width</p>"},{"location":"api/image/properties/#otary.image.image.Image.height","title":"<code>height</code>  <code>property</code>","text":"<p>Height of the image</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>image height</p>"},{"location":"api/image/properties/#otary.image.image.Image.center","title":"<code>center</code>  <code>property</code>","text":"<p>Center point of the image.</p> <p>Please note that it is returned as type int because the center is represented as a X-Y coords of a pixel.</p> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray[int16]</code> <p>center point of the image</p>"},{"location":"api/image/properties/#otary.image.image.Image.area","title":"<code>area</code>  <code>property</code>","text":"<p>Area of the image</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>image area</p>"},{"location":"api/image/properties/#otary.image.image.Image.channels","title":"<code>channels</code>  <code>property</code>","text":"<p>Number of channels in the image</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of channels</p>"},{"location":"api/image/properties/#otary.image.image.Image.shape_array","title":"<code>shape_array</code>  <code>property</code>","text":"<p>Returns the array shape value (height, width, channel)</p> <p>Returns:</p> Type Description <code>tuple[int, int, int]</code> <p>tuple[int]: image shape</p>"},{"location":"api/image/properties/#otary.image.image.Image.is_gray","title":"<code>is_gray</code>  <code>property</code>","text":"<p>Whether the image is a grayscale image or not</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if image is in grayscale, 0 otherwise</p>"},{"location":"api/image/properties/#otary.image.image.Image.norm_side_length","title":"<code>norm_side_length</code>  <code>property</code>","text":"<p>Returns the normalized side length of the image. This is the side length if the image had the same area but the shape of a square (four sides of the same length).</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>normalized side length</p>"},{"location":"api/image/properties/#otary.image.image.Image.corners","title":"<code>corners</code>  <code>property</code>","text":"<p>Returns the corners in clockwise order:</p> <ol> <li>top left corner</li> <li>top right corner</li> <li>bottom right corner</li> <li>bottom left corner</li> </ol> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>array containing the corners</p>"},{"location":"api/image/analysis/","title":"Analyzer","text":"<p>The <code>analyzer</code> module provides a set of functions for analyzing images.</p> <p>For example, if you want to know whether a given segment is present in the image you can use the <code>score_contains_segments</code> function:</p> <pre><code>import otary as ot\n\nim = ot.Image.from_file(filepath=\"path/to/file/image\")\n\nsegment = ot.Segment([[100, 100], [200, 200]])\n\nscore = im.score_contains_segments(segments=[segment]) # score is between 0 and 1\n</code></pre>"},{"location":"api/image/analysis/#components","title":"Components","text":"<ul> <li>Scoring: scoring operations such as IoU (Intersection over Union).     Those score methods are special in the sense that the output is always a float     number between 0 and 1</li> </ul>"},{"location":"api/image/analysis/scoring/","title":"Scoring Methods","text":"<p>Image core class. It groups all the methods available from composition from all the image classes.</p> Source code in <code>otary/image/image.py</code> <pre><code>class Image:\n    \"\"\"\n    Image core class. It groups all the methods available from composition\n    from all the image classes.\n    \"\"\"\n\n    # pylint: disable=too-many-public-methods\n\n    reader = ReaderImage()\n\n    def __init__(self, image: NDArray) -&gt; None:\n        self.base = BaseImage(image=image, parent=self)\n        self.drawer = DrawerImage(base=self.base)\n        self.writer = WriterImage(base=self.base)\n        self.transformer = TransformerImage(base=self.base)\n\n    # -------------------------------- CLASS METHODS ----------------------------------\n\n    @classmethod\n    def from_fillvalue(cls, value: int = 255, shape: tuple = (128, 128, 3)) -&gt; Image:\n        \"\"\"Class method to create an image from a single value\n\n        Args:\n            value (int, optional): value in [0, 255]. Defaults to 255.\n            shape (tuple, optional): image shape. If it has three elements then\n                the last one must be a 3 for a coloscale image.\n                Defaults to (128, 128, 3).\n\n        Returns:\n            Image: array with a single value\n        \"\"\"\n        return cls(image=cls.reader.from_fillvalue(value=value, shape=shape))\n\n    @classmethod\n    def from_file(\n        cls, filepath: str, as_grayscale: bool = False, resolution: Optional[int] = None\n    ) -&gt; Image:\n        \"\"\"Create a Image array from a file image path\n\n        Args:\n            filepath (str): path to the image file\n            as_grayscale (bool, optional): turn the image in grayscale.\n                Defaults to False.\n            resolution (Optional[int], optional): resolution of the image.\n\n        Returns:\n            Image: Image object with a single value\n        \"\"\"\n        return cls(\n            cls.reader.from_file(\n                filepath=filepath, as_grayscale=as_grayscale, resolution=resolution\n            )\n        )\n\n    @classmethod\n    def from_pdf(\n        cls,\n        filepath: str,\n        as_grayscale: bool = False,\n        page_nb: int = 0,\n        resolution: Optional[int] = None,\n        clip_pct: Optional[AxisAlignedRectangle] = None,\n    ) -&gt; Image:\n        \"\"\"Create an Image array from a pdf file.\n\n        Args:\n            filepath (str): path to the pdf file\n            as_grayscale (bool, optional): turn the image in grayscale.\n                Defaults to False.\n            page_nb (int, optional): page number to extract. Defaults to 0.\n            resolution (Optional[int], optional): resolution of the image.\n            clip_pct (Optional[AxisAlignedRectangle], optional): clip percentage of the\n                image to only load a small part of the image (crop) for faster loading\n                and less memory usage. Defaults to None.\n\n        Returns:\n            Image: Image object from pdf\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        return cls(\n            cls.reader.from_pdf(\n                filepath=filepath,\n                as_grayscale=as_grayscale,\n                page_nb=page_nb,\n                resolution=resolution,\n                clip_pct=clip_pct,\n            )\n        )\n\n    # ---------------------------------- PROPERTIES -----------------------------------\n\n    @property\n    def asarray(self) -&gt; NDArray:\n        \"\"\"Array representation of the image\"\"\"\n        return self.base.asarray\n\n    @asarray.setter\n    def asarray(self, value: NDArray) -&gt; None:\n        \"\"\"Setter for the asarray property\n\n        Args:\n            value (NDArray): value of the asarray to be changed\n        \"\"\"\n        self.base.asarray = value\n\n    @property\n    def asarray_binary(self) -&gt; NDArray:\n        \"\"\"Returns the representation of the image as a array with value not in\n        [0, 255] but in [0, 1].\n\n        Returns:\n            NDArray: an array with value in [0, 1]\n        \"\"\"\n        return self.base.asarray_binary\n\n    @property\n    def width(self) -&gt; int:\n        \"\"\"Width of the image.\n\n        Returns:\n            int: image width\n        \"\"\"\n        return self.base.width\n\n    @property\n    def height(self) -&gt; int:\n        \"\"\"Height of the image\n\n        Returns:\n            int: image height\n        \"\"\"\n        return self.base.height\n\n    @property\n    def channels(self) -&gt; int:\n        \"\"\"Number of channels in the image\n\n        Returns:\n            int: number of channels\n        \"\"\"\n        return self.base.channels\n\n    @property\n    def center(self) -&gt; NDArray[np.int16]:\n        \"\"\"Center point of the image.\n\n        Please note that it is returned as type int because the center is\n        represented as a X-Y coords of a pixel.\n\n        Returns:\n            NDArray: center point of the image\n        \"\"\"\n        return self.base.center\n\n    @property\n    def area(self) -&gt; int:\n        \"\"\"Area of the image\n\n        Returns:\n            int: image area\n        \"\"\"\n        return self.base.area\n\n    @property\n    def shape_array(self) -&gt; tuple[int, int, int]:\n        \"\"\"Returns the array shape value (height, width, channel)\n\n        Returns:\n            tuple[int]: image shape\n        \"\"\"\n        return self.base.shape_array\n\n    @property\n    def shape_xy(self) -&gt; tuple[int, int, int]:\n        \"\"\"Returns the array shape value (width, height, channel)\n\n        Returns:\n            tuple[int]: image shape\n        \"\"\"\n        return self.base.shape_xy\n\n    @property\n    def is_gray(self) -&gt; bool:\n        \"\"\"Whether the image is a grayscale image or not\n\n        Returns:\n            bool: True if image is in grayscale, 0 otherwise\n        \"\"\"\n        return self.base.is_gray\n\n    @property\n    def norm_side_length(self) -&gt; int:\n        \"\"\"Returns the normalized side length of the image.\n        This is the side length if the image had the same area but\n        the shape of a square (four sides of the same length).\n\n        Returns:\n            int: normalized side length\n        \"\"\"\n        return self.base.norm_side_length\n\n    @property\n    def corners(self) -&gt; NDArray:\n        \"\"\"Returns the corners in clockwise order:\n\n        0. top left corner\n        1. top right corner\n        2. bottom right corner\n        3. bottom left corner\n\n        Returns:\n            NDArray: array containing the corners\n        \"\"\"\n        return self.base.corners\n\n    # ---------------------------------- BASE METHODS ---------------------------------\n\n    def as_grayscale(self) -&gt; Self:\n        \"\"\"Generate the image in grayscale of shape (height, width)\n\n        Returns:\n            Self: original image in grayscale\n        \"\"\"\n        self.base.as_grayscale()\n        return self\n\n    def as_colorscale(self) -&gt; Self:\n        \"\"\"Generate the image in colorscale (height, width, 3).\n        This property can be useful when we wish to draw objects in a given color\n        on a grayscale image.\n\n        Returns:\n            Self: original image in color\n        \"\"\"\n        self.base.as_colorscale()\n        return self\n\n    def as_reversed_color_channel(self) -&gt; Self:\n        \"\"\"Generate the image with the color channels reversed.\n        This is useful when we want to convert an image from BGR to RGB or vice versa.\n\n        Returns:\n            Self: original image with reversed color channels\n        \"\"\"\n        self.base.as_reversed_color_channel()\n        return self\n\n    def as_filled(self, fill_value: int | NDArray = 255) -&gt; Self:\n        \"\"\"Returns an entirely white image of the same size as the original.\n        Can be useful to get an empty representation of the same image to paint\n        and draw things on an image of the same dimension.\n\n        Args:\n            fill_value (int | NDArray, optional): color to fill the new empty image.\n                Defaults to 255 which means that is returns a entirely white image.\n\n        Returns:\n            Self: new image with a single color of the same size as original.\n        \"\"\"\n        self.base.as_filled(fill_value=fill_value)\n        return self\n\n    def as_white(self) -&gt; Self:\n        \"\"\"Returns an entirely white image with the same dimension as the original.\n\n        Returns:\n            Self: new white image\n        \"\"\"\n        self.base.as_white()\n        return self\n\n    def as_black(self) -&gt; Self:\n        \"\"\"Returns an entirely black image with the same dimension as the original.\n\n        Returns:\n            Self: new black image\n        \"\"\"\n        self.base.as_black()\n        return self\n\n    def as_pil(self) -&gt; ImagePIL.Image:\n        \"\"\"Return the image as PIL Image\n\n        Returns:\n            ImagePIL: PIL Image\n        \"\"\"\n        return self.base.as_pil()\n\n    def as_api_file_input(\n        self, fmt: str = \"png\", filename: str = \"image\"\n    ) -&gt; dict[str, tuple[str, bytes, str]]:\n        \"\"\"Return the image as a file input for API requests.\n\n        Args:\n            fmt (str, optional): format of the image. Defaults to \"png\".\n            filename (str, optional): name of the file without the format.\n                Defaults to \"image\".\n\n        Returns:\n            dict[str, tuple[str, bytes, str]]: dictionary with file input\n                for API requests, where the key is \"file\" and the value is a tuple\n                containing the filename, image bytes, and content type.\n        \"\"\"\n        return self.base.as_api_file_input(fmt=fmt, filename=filename)\n\n    def rev(self) -&gt; Self:\n        \"\"\"Reverse the image colors. Each pixel color value V becomes |V - 255|.\n\n        Applied on a grayscale image the black pixel becomes white and the\n        white pixels become black.\n        \"\"\"\n        self.base.rev()\n        return self\n\n    def dist_pct(self, pct: float) -&gt; float:\n        \"\"\"Distance percentage that can be used an acceptable distance error margin.\n        It is calculated based on the normalized side length.\n\n        Args:\n            pct (float, optional): percentage of distance error. Defaults to 0.01,\n                which means 1% of the normalized side length as the\n                default margin distance error.\n\n        Returns:\n            float: margin distance error\n        \"\"\"\n        return self.base.dist_pct(pct=pct)\n\n    def is_equal_shape(self, other: Image, consider_channel: bool = True) -&gt; bool:\n        \"\"\"Check whether two images have the same shape\n\n        Args:\n            other (BaseImage): BaseImage object\n\n        Returns:\n            bool: True if the objects have the same shape, False otherwise\n        \"\"\"\n        return self.base.is_equal_shape(\n            other=other.base, consider_channel=consider_channel\n        )\n\n    # ---------------------------------- COPY METHOD ----------------------------------\n\n    def copy(self) -&gt; Image:\n        \"\"\"Copy of the image.\n\n        For NumPy arrays containing basic data types (e.g., int, float, bool),\n        using copy.deepcopy() is generally unnecessary.\n        The numpy.copy() method achieves the same result more efficiently.\n        numpy.copy() creates a new array in memory with a separate copy of the data,\n        ensuring that modifications to the copy do not affect the original array.\n\n        Returns:\n            Image: image copy\n        \"\"\"\n        return Image(image=self.asarray.copy())\n\n    # -------------------------------- WRITE METHODS ----------------------------------\n\n    def save(self, fp: str) -&gt; None:\n        \"\"\"Save the image in a local file\n\n        Args:\n            fp (str): fp stands for filepath which is the path to the file\n        \"\"\"\n        self.writer.save(fp=fp)\n\n    def show(\n        self,\n        figsize: tuple[float, float] = (-1, -1),\n        popup_window_display: bool = False,\n    ) -&gt; ImagePIL.Image:\n        \"\"\"Show the image\n\n        Args:\n            figsize (tuple[float, float], optional): size of the figure.\n                Defaults to (-1, -1), meaning the original size of the image.\n            popup_window_display (bool, optional): whether to display the image in a\n                popup window. Defaults to False.\n        \"\"\"\n        return self.writer.show(\n            figsize=figsize, popup_window_display=popup_window_display\n        )\n\n    # -------------------------------- DRAWER METHODS ---------------------------------\n\n    def draw_circles(\n        self, circles: Sequence[geo.Circle], render: CirclesRender = CirclesRender()\n    ) -&gt; Self:\n        \"\"\"Draw circles in the image\n\n        Args:\n            circles (list[Circle]): list of Circle geometry objects.\n            render (CirclesRender): circle renderer\n\n        Returns:\n            Image: new image with circles drawn\n        \"\"\"\n        self.drawer.draw_circles(circles=circles, render=render)\n        return self\n\n    def draw_ellipses(\n        self, ellipses: Sequence[geo.Ellipse], render: EllipsesRender = EllipsesRender()\n    ) -&gt; Self:\n        \"\"\"Draw ellipses in the image\n\n        Args:\n            ellipses (list[Ellipse]): list of Ellipse geometry objects.\n            render (EllipsesRender): ellipse renderer\n\n        Returns:\n            Image: new image with ellipses drawn\n        \"\"\"\n        self.drawer.draw_ellipses(ellipses=ellipses, render=render)\n        return self\n\n    def draw_points(\n        self,\n        points: list | NDArray | Sequence[geo.Point],\n        render: PointsRender = PointsRender(),\n    ) -&gt; Self:\n        \"\"\"Draw points in the image\n\n        Args:\n            points (NDArray): list of points. It must be of shape (n, 2). This\n                means n points of shape 2 (x and y coordinates).\n            render (PointsRender): point renderer\n\n        Returns:\n            Image: new image with points drawn\n        \"\"\"\n        self.drawer.draw_points(points=points, render=render)\n        return self\n\n    def draw_segments(\n        self,\n        segments: NDArray | Sequence[geo.Segment],\n        render: SegmentsRender = SegmentsRender(),\n    ) -&gt; Self:\n        \"\"\"Draw segments in the image. It can be arrowed segments (vectors) too.\n\n        Args:\n            segments (NDArray): list of segments. Can be a numpy array of shape\n                (n, 2, 2) which means n array of shape (2, 2) that define a segment\n                by two 2D points.\n            render (SegmentsRender): segment renderer\n\n        Returns:\n            Image: new image with segments drawn\n        \"\"\"\n        self.drawer.draw_segments(segments=segments, render=render)\n        return self\n\n    def draw_polygons(\n        self,\n        polygons: Sequence[geo.Polygon],\n        render: PolygonsRender = PolygonsRender(),\n    ) -&gt; Self:\n        \"\"\"Draw polygons in the image\n\n        Args:\n            polygons (Sequence[Polygon]): list of Polygon objects\n            render (PolygonsRender): PolygonRender object\n\n        Returns:\n            Image: new image with polygons drawn\n        \"\"\"\n        self.drawer.draw_polygons(polygons=polygons, render=render)\n        return self\n\n    def draw_splines(\n        self,\n        splines: Sequence[geo.LinearSpline],\n        render: LinearSplinesRender = LinearSplinesRender(),\n    ) -&gt; Self:\n        \"\"\"Draw linear splines in the image.\n\n        Args:\n            splines (Sequence[geo.LinearSpline]): linear splines to draw.\n            render (LinearSplinesRender, optional): linear splines render.\n                Defaults to LinearSplinesRender().\n\n        Returns:\n            Image: new image with splines drawn\n        \"\"\"\n        self.drawer.draw_splines(splines=splines, render=render)\n        return self\n\n    def draw_ocr_outputs(\n        self,\n        ocr_outputs: Sequence[OcrSingleOutput],\n        render: OcrSingleOutputRender = OcrSingleOutputRender(),\n    ) -&gt; Self:\n        \"\"\"Return the image with the bounding boxes displayed from a list of OCR\n        single output. It allows you to show bounding boxes that can have an angle,\n        not necessarily vertical or horizontal.\n\n        Args:\n            ocr_outputs (list[OcrSingleOutput]): list of OcrSingleOutput objects\n            render (OcrSingleOutputRender): OcrSingleOutputRender object\n\n        Returns:\n            Image: new image with ocr outputs drawn\n        \"\"\"\n        self.drawer.draw_ocr_outputs(ocr_outputs=ocr_outputs, render=render)\n        return self\n\n    # --------------------------------- BINARIZER -------------------------------------\n\n    def threshold_simple(self, thresh: int) -&gt; Self:\n        \"\"\"Compute the image thesholded by a single value T.\n        All pixels with value v &lt;= T are turned black and those with value v &gt; T are\n        turned white. This is a global thresholding method.\n\n        Args:\n            thresh (int): value to separate the black from the white pixels.\n\n        Returns:\n            (Self): output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_simple(thresh=thresh)\n        return self\n\n    def threshold_otsu(self) -&gt; Self:\n        \"\"\"Apply Otsu global thresholding.\n        This is a global thresholding method that automatically determines\n        an optimal threshold value from the image histogram.\n\n        Paper (1979):\n        https://ieeexplore.ieee.org/document/4310076\n\n        Consider applying a gaussian blur before for better thresholding results.\n        See why in https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html.\n\n        As the input image must be a grayscale before applying any thresholding\n        methods we convert the image to grayscale.\n\n        Returns:\n            (Self): output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_otsu()\n        return self\n\n    def threshold_adaptive(self, block_size: int = 11, constant: float = 2.0) -&gt; Self:\n        \"\"\"Apply adaptive local thresholding.\n        This is a local thresholding method that computes the threshold for a pixel\n        based on a small region around it.\n\n        A gaussian blur is applied before for better thresholding results.\n        See why in https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html.\n\n        As the input image must be a grayscale before applying any thresholding\n        methods we convert the image to grayscale.\n\n        Args:\n            block_size (int, optional): Size of a pixel neighborhood that is used to\n                calculate a threshold value for the pixel: 3, 5, 7, and so on.\n                Defaults to 11.\n            constant (int, optional): Constant subtracted from the mean or weighted\n                mean. Normally, it is positive but may be zero or negative as well.\n                Defaults to 2.\n\n        Returns:\n            (Self): output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_adaptive(\n            block_size=block_size, constant=constant\n        )\n        return self\n\n    def threshold_sauvola(\n        self, window_size: int = 15, k: float = 0.5, r: float = 128.0\n    ) -&gt; Self:\n        \"\"\"Apply Sauvola local thresholding.\n         This is a local thresholding method that computes the threshold for a pixel\n         based on a small region around it.\n\n         Paper (1997):\n         https://www.researchgate.net/publication/3710586\n\n         See https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_niblack_sauvola.html # pylint: disable=line-too-long\n\n         As the input image must be a grayscale before applying any thresholding\n         methods we convert the image to grayscale.\n\n         Args:\n             window_size (int, optional): sauvola window size to apply on the\n                 image. Defaults to 15.\n             k (float, optional): sauvola k factor to apply to regulate the impact\n                 of the std. Defaults to 0.5.\n             r (float, optional): sauvola r value. Defaults to 128.\n\n        Returns:\n             (Self): output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_sauvola(window_size=window_size, k=k, r=r)\n        return self\n\n    def threshold_bradley(self, window_size: int = 15, t: float = 0.15) -&gt; Self:\n        \"\"\"Implementation of the Bradley &amp; Roth thresholding method.\n\n        Paper (2007):\n        https://www.researchgate.net/publication/220494200_Adaptive_Thresholding_using_the_Integral_Image\n\n        Args:\n            window_size (int, optional): window size for local computations.\n                Defaults to 15.\n            t (float, optional): t value in [0, 1]. Defaults to 0.15.\n\n        Returns:\n            NDArray[np.uint8]: output thresholded image\n        \"\"\"\n        self.transformer.binarizer.threshold_bradley(window_size=window_size, t=t)\n        return self\n\n    def binary(self, method: BinarizationMethods = \"sauvola\") -&gt; NDArray:\n        \"\"\"Binary representation of the image with values that can be only 0 or 1.\n        The value 0 is now 0 and value of 255 are now 1. Black is 0 and white is 1.\n        We can also talk about the mask of the image to refer to the binary\n        representation of it.\n\n        The sauvola is generally the best binarization method however it is\n        way slower than the others methods. The adaptative or otsu method are the best\n        method in terms of speed and quality.\n\n        Args:\n            method (str, optional): the binarization method to apply.\n                Must be in [\"adaptative\", \"otsu\", \"sauvola\", \"niblack\", \"nick\", \"wolf\"].\n                Defaults to \"sauvola\".\n\n        Returns:\n            NDArray: array where its inner values are 0 or 1\n        \"\"\"\n        return self.transformer.binarizer.binary(method=method)\n\n    def binaryrev(self, method: BinarizationMethods = \"sauvola\") -&gt; NDArray:\n        \"\"\"Reversed binary representation of the image.\n        The value 0 is now 1 and value of 255 are now 0. Black is 1 and white is 0.\n        This is why it is called the \"binary rev\" or \"binary reversed\".\n\n        Args:\n            method (str, optional): the binarization method to apply.\n                Must be in [\"adaptative\", \"otsu\", \"sauvola\", \"niblack\", \"nick\", \"wolf\"].\n                Defaults to \"adaptative\".\n\n        Returns:\n            NDArray: array where its inner values are 0 or 1\n        \"\"\"\n        return self.transformer.binarizer.binaryrev(method=method)\n\n    # ---------------------------------- CROPPER --------------------------------------\n    # the copy arguments is special in the crop methods.\n    # this is important for performance reasons\n    # if you want to crop a small part of an image and conserve the original\n    # without doing image.copy().crop() which would copy the entire original image!\n    # this would be much more expensive if the image is large\n\n    def crop(\n        self, x0: int, y0: int, x1: int, y1: int, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop the image in a straight axis-aligned rectangle way given\n        by the top-left point [x0, y0] and the bottom-right point [x1, y1]\n\n        This function inputs represents the top-left and bottom-right points.\n        This method does not provide a way to extract a rotated rectangle or a\n        different shape from the image.\n\n        Remember that in this library the x coordinates represent the y coordinates of\n        the image array (horizontal axis of the image).\n        The array representation is always rows then columns.\n        In this library this is the contrary like in opencv.\n\n        Args:\n            x0 (int): top-left x coordinate\n            y0 (int): top-left y coordinate\n            x1 (int): bottom-right x coordinate\n            y1 (int): bottom-right y coordinate\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        out = self.transformer.cropper.crop(\n            x0=x0, y0=y0, x1=x1, y1=y1, copy=copy, **kwargs\n        )\n        return out if out is not None else self\n\n    def crop_from_topleft(\n        self, topleft: NDArray, width: int, height: int, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop the image from a rectangle defined by its top-left point, its width and\n        its height.\n\n        Args:\n            topleft (NDArray): (x, y) coordinates of the top-left point\n            width (int): width of the rectangle to crop\n            height (int): height of the rectangle to crop\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        out = self.transformer.cropper.crop_from_topleft(\n            topleft=topleft, width=width, height=height, copy=copy, **kwargs\n        )\n        return out if out is not None else self\n\n    def crop_from_center(\n        self, center: NDArray, width: int, height: int, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop the image from a rectangle defined by its center point, its width and\n        its height.\n\n        Args:\n            center (NDArray): (x, y) coordinates of the center point\n            width (int): width of the rectangle to crop\n            height (int): height of the rectangle to crop\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        out = self.transformer.cropper.crop_from_center(\n            center=center, width=width, height=height, copy=copy, **kwargs\n        )\n        return out if out is not None and copy else self\n\n    def crop_from_axis_aligned_bbox(\n        self, bbox: geo.AxisAlignedRectangle, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop the image from an Axis-Aligned Bounding Box (AABB).\n        Inclusive crops which means that the cropped image will have\n        width and height equal to the width and height of the AABB.\n\n        Args:\n            bbox (geo.AxisAlignedRectangle): axis-aligned rectangle bounding box\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        out = self.transformer.cropper.crop_from_axis_aligned_rectangle(\n            bbox=bbox, copy=copy, **kwargs\n        )\n        return out if out is not None and copy else self\n\n    def crop_hq_from_aabb_and_pdf(\n        self,\n        bbox: geo.AxisAlignedRectangle,\n        pdf_filepath: str,\n        page_nb: int = 0,\n        as_grayscale: bool = False,\n        resolution: int = 1000,\n    ) -&gt; Image:\n        \"\"\"Generate a new image from a pdf file by cropping a High Quality crop\n        from a given Axis-Aligned Bounding Box (AABB).\n\n        The crop is of high quality because we can load only the crop part of the image\n        from the original pdf.\n\n        Args:\n            bbox (geo.AxisAlignedRectangle): crop bounding box\n            pdf_filepath (str): PDF filepath\n            page_nb (int, optional): page to load in the PDF. The first page is 0.\n                Defaults to 0.\n            as_grayscale (bool, optional): whether to load the image as grayscale or\n                not. Defaults to False.\n            resolution (int, optional): resolution of the final crop image.\n                Defaults to 1000.\n\n        Returns:\n            Image: high quality crop image\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        # get the bbox normalized\n        clip_pct = bbox.copy().normalize(x=self.width, y=self.height)\n\n        # obtain the High Quality crop image by reading\n        im_crop = Image.from_pdf(\n            filepath=pdf_filepath,\n            page_nb=page_nb,\n            as_grayscale=as_grayscale,\n            resolution=resolution,\n            clip_pct=clip_pct,\n        )\n        return im_crop\n\n    def crop_from_polygon(\n        self, polygon: geo.Polygon, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop from a polygon using its Axis-Aligned Bounding Box (AABB)\n\n        Args:\n            polygon (geo.Polygon): polygon object to crop in the image\n            copy (bool, optional): whether to create a copy or not. Defaults to False.\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        out = self.transformer.cropper.crop_from_polygon(\n            polygon=polygon, copy=copy, **kwargs\n        )\n        return out if out is not None and copy else self\n\n    def crop_from_linear_spline(\n        self, spline: geo.LinearSpline, copy: bool = False, **kwargs\n    ) -&gt; Image | Self:\n        \"\"\"Crop from a Linear Spline using its Axis-Aligned Bounding Box (AABB)\n\n        Args:\n            spline (geo.LinearSpline): linear spline object to crop in the image\n            copy (bool, optional): whether to create a copy or not. Defaults to False.\n                        clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Image | Self: new cropped image if copy=True else the current image cropped\n        \"\"\"\n        out = self.transformer.cropper.crop_from_linear_spline(\n            spline=spline, copy=copy, **kwargs\n        )\n        return out if out is not None and copy else self\n\n    def crop_segment(\n        self,\n        segment: NDArray,\n        dim_crop_rect: tuple[int, int] = (-1, 100),\n        added_width: int = 75,\n    ) -&gt; tuple[Image, NDArray, float, NDArray]:\n        \"\"\"Crop around a specific segment in the image. This is done in three\n        specific steps:\n        1) shift image so that the middle of the segment is in the middle of the image\n        2) rotate image by the angle of segment so that the segment becomes horizontal\n        3) crop the image\n\n        Args:\n            segment (NDArray): segment as numpy array of shape (2, 2).\n            dim_crop_rect (tuple, optional): represents (width, height).\n                Defaults to heigth of 100 and width of -1 which means\n                that the width is automatically computed based on the length of\n                the segment.\n            added_width (int, optional): additional width for cropping.\n                Half of the added_width is added to each side of the segment.\n                Defaults to 75.\n\n        Returns:\n            tuple[Self, NDArray, float, NDArray]: returns in the following order:\n                1) the cropped image\n                2) the translation vector used to center the image\n                3) the angle of rotation applied to the image\n                4) the translation vector used to crop the image\n        \"\"\"\n        width_crop_rect, height_crop_rect = dim_crop_rect\n        im = self.copy()  # the copy before makes this method slow\n\n        # center the image based on the middle of the line\n        geo_segment = geo.Segment(segment)\n        im, translation_vector = im.center_to_segment(segment=segment)\n\n        if width_crop_rect == -1:\n            # default the width for crop to be a bit more than line length\n            width_crop_rect = int(geo_segment.length)\n        width_crop_rect += added_width\n        assert width_crop_rect &gt; 0 and height_crop_rect &gt; 0\n\n        # rotate the image so that the line is horizontal\n        angle = geo_segment.slope_angle(is_y_axis_down=True)\n        im = im.rotate(angle=angle)\n\n        # cropping\n        im_crop = im.crop_from_center(\n            center=im.base.center,\n            width=width_crop_rect,\n            height=height_crop_rect,\n        )\n\n        crop_translation_vector = self.base.center - im_crop.base.center\n        return im_crop, translation_vector, angle, crop_translation_vector\n\n    def crop_segment_faster(\n        self,\n        segment: NDArray,\n        dim_crop_rect: tuple[int, int] = (-1, 100),\n        added_width: int = 75,\n        pad_value: int = 0,\n    ) -&gt; Image:\n        \"\"\"Crop around a specific segment in the image.\n        This method is faster especially for large images.\n\n        Here is a comparison of the total time taken for cropping with the two methods\n        with a loop over 1000 iterations:\n\n        | Image dimension | Crop v1 | Crop faster |\n        |-----------------|---------|-------------|\n        | 1224 x 946      | 2.0s    | 0.25s       |\n        | 2448 x 1892     | 4.51s   | 0.25s       |\n        | 4896 x 3784     | 23.2s   | 0.25s       |\n\n        Args:\n            segment (NDArray): segment as numpy array of shape (2, 2).\n            dim_crop_rect (tuple, optional): represents (width, height).\n                Defaults to heigth of 100 and width of -1 which means\n                that the width is automatically computed based on the length of\n                the segment.\n            added_width (int, optional): additional width for cropping.\n                Half of the added_width is added to each side of the segment.\n                Defaults to 75.\n\n        Returns:\n            Self: cropped image around the segment\n        \"\"\"\n        width_crop_rect, height_crop_rect = dim_crop_rect\n        geo_segment = geo.Segment(segment)\n        angle = geo_segment.slope_angle(is_y_axis_down=True)\n\n        if width_crop_rect == -1:\n            # default the width for crop to be a bit more than line length\n            width_crop_rect = int(geo_segment.length)\n        width_crop_rect += added_width\n        assert width_crop_rect &gt; 0 and height_crop_rect &gt; 0\n\n        x_extra = abs(added_width / 2 * np.cos(angle))\n        y_extra = abs(added_width / 2 * np.sin(angle))\n\n        # add extra width for crop in case segment is ~vertical\n        x_extra += int(width_crop_rect / 2) + 1\n        y_extra += int(height_crop_rect / 2) + 1\n\n        im: Image = self.crop(\n            x0=geo_segment.xmin - x_extra,\n            y0=geo_segment.ymin - y_extra,\n            x1=geo_segment.xmax + x_extra,\n            y1=geo_segment.ymax + y_extra,\n            pad=True,\n            clip=False,\n            copy=True,  # copy the image after cropping for very fast performance\n            pad_value=pad_value,\n        )\n\n        # rotate the image so that the line is horizontal\n        im.rotate(angle=angle)\n\n        # cropping around segment center\n        im.crop_from_center(\n            center=im.base.center,\n            width=width_crop_rect,\n            height=height_crop_rect,\n        )\n\n        return im\n\n    def crop_from_rectangle_referential(\n        self,\n        rect: geo.Rectangle,\n        rect_topleft_ix: int = 0,\n        crop_dim: tuple[float, float] = (-1, -1),\n        crop_shift: tuple[float, float] = (0, 0),\n    ) -&gt; Image:\n        \"\"\"Crop image in the referential of the rectangle.\n\n        Args:\n            rect (geo.Rectangle): rectangle for reference to crop.\n            rect_topleft_ix (int): top-left vertice index of the rectangle\n            crop_dim (tuple[float, float], optional): (width, height) crop dimension.\n                Defaults to (-1, -1).\n            crop_shift (tuple[float, float], optional): The shift is (x, y).\n                The crop_shift argument is applied from the rectangle center based on\n                the axis referential of the rectangle.\n                This means that the shift in the Y direction\n                is based on the normalized vector (bottom-left, top-left)\n                The shift in the X direction is based on the normalized vector\n                (top-left, top-right). Defaults to (0, 0) meaning no shift.\n\n        Returns:\n            Self: new image cropped\n        \"\"\"\n        # shift down and up vector calculated based on the top-left vertice\n        rect_shift_up = rect.get_vector_up_from_topleft(topleft_index=rect_topleft_ix)\n        rect_shift_left = rect.get_vector_left_from_topleft(\n            topleft_index=rect_topleft_ix\n        )\n\n        # crop dimension\n        rect_heigth = rect.get_height_from_topleft(topleft_index=rect_topleft_ix)\n        crop_width = rect_heigth if crop_dim[0] == -1 else crop_dim[0]\n        crop_height = rect_heigth if crop_dim[1] == -1 else crop_dim[1]\n        crop_width, crop_height = int(crop_width), int(crop_height)\n        assert crop_width &gt; 0 and crop_height &gt; 0\n\n        # compute the crop center\n        crop_center = rect.centroid\n        crop_center += crop_shift[0] * rect_shift_left.normalized  # shift left\n        crop_center += crop_shift[1] * rect_shift_up.normalized  # shift up\n\n        # get the crop segment\n        crop_segment = geo.Segment(\n            [\n                crop_center - crop_width / 2 * rect_shift_left.normalized,\n                crop_center + crop_width / 2 * rect_shift_left.normalized,\n            ]\n        )\n\n        return self.crop_segment_faster(\n            segment=crop_segment.asarray,\n            dim_crop_rect=(crop_width, crop_height),\n            added_width=0,\n        )\n\n    def crop_rectangle(self, rect: geo.Rectangle, rect_topleft_ix: int = 0) -&gt; Image:\n        \"\"\"Crop from a rectangle that can be rotated in any direction.\n        The crop is done using the information of the top-left vertice index to\n        determine the width and height of the crop.\n\n        Args:\n            rect (geo.Rectangle): rectangle to crop in the referential of the image\n            rect_topleft_ix (int, optional): top-left vertice index. Defaults to 0.\n\n        Returns:\n            Image: crop of the image\n        \"\"\"\n        crop_dim = (\n            rect.get_width_from_topleft(rect_topleft_ix),\n            rect.get_height_from_topleft(rect_topleft_ix),\n        )\n        return self.crop_from_rectangle_referential(\n            rect=rect, rect_topleft_ix=rect_topleft_ix, crop_dim=crop_dim\n        )\n\n    # ------------------------------- GEOMETRY METHODS --------------------------------\n\n    def shift(self, shift: NDArray, fill_value: Sequence[float] = (0.0,)) -&gt; Self:\n        \"\"\"Shift the image by performing a translation operation\n\n        Args:\n            shift (NDArray): Vector for translation\n            fill_value (int | tuple[int, int, int], optional): value to fill the\n                border of the image after the rotation in case reshape is True.\n                Can be a tuple of 3 integers for RGB image or a single integer for\n                grayscale image. Defaults to (0.0,) which is black.\n\n        Returns:\n            Self: shifted image\n        \"\"\"\n        self.transformer.geometrizer.shift(shift=shift, fill_value=fill_value)\n        return self\n\n    def rotate(\n        self,\n        angle: float,\n        is_degree: bool = False,\n        is_clockwise: bool = True,\n        reshape: bool = True,\n        fill_value: Sequence[float] = (0.0,),\n    ) -&gt; Self:\n        \"\"\"Rotate the image by a given angle.\n\n        For the rotation with reshape, meaning preserving the whole image,\n        we used the code from the imutils library:\n        https://github.com/PyImageSearch/imutils/blob/master/imutils/convenience.py#L41\n\n        Args:\n            angle (float): angle to rotate the image\n            is_degree (bool, optional): whether the angle is in degree or not.\n                If not it is considered to be in radians.\n                Defaults to False which means radians.\n            is_clockwise (bool, optional): whether the rotation is clockwise or\n                counter-clockwise. Defaults to True.\n            reshape (bool, optional): whether to preserve the original image or not.\n                If True, the complete image is preserved hence the width and height\n                of the rotated image are different than in the original image.\n                Defaults to True.\n            fill_value (Sequence[float], optional): value to\n                fill the border of the image after the rotation in case reshape is True.\n                Can be a tuple of 3 integers for RGB image or a single integer for\n                grayscale image. Defaults to (0.0,) which is black\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        self.transformer.geometrizer.rotate(\n            angle=angle,\n            is_degree=is_degree,\n            is_clockwise=is_clockwise,\n            reshape=reshape,\n            fill_value=fill_value,\n        )\n        return self\n\n    def center_to_point(self, point: NDArray) -&gt; tuple[Self, NDArray]:\n        \"\"\"Shift the image so that the input point ends up in the middle of the\n        new image\n\n        Args:\n            point (NDArray): point as (2,) shape numpy array\n\n        Returns:\n            (tuple[Self, NDArray]): Self, translation Vector\n        \"\"\"\n        shift_vector = self.transformer.geometrizer.center_to_point(point=point)\n        return self, shift_vector\n\n    def center_to_segment(self, segment: NDArray) -&gt; tuple[Self, NDArray]:\n        \"\"\"Shift the image so that the segment middle point ends up in the middle\n        of the new image\n\n        Args:\n            segment (NDArray): segment as numpy array of shape (2, 2)\n\n        Returns:\n            (tuple[Self, NDArray]): Self, vector_shift\n        \"\"\"\n        shift_vector = self.transformer.geometrizer.center_to_segment(segment=segment)\n        return self, shift_vector\n\n    def restrict_rect_in_frame(self, rectangle: geo.Rectangle) -&gt; geo.Rectangle:\n        \"\"\"Create a new rectangle that is contained within the image borders.\n        If the input rectangle is outside the image, the returned rectangle is a\n        image frame-fitted rectangle that preserve the same shape.\n\n        Args:\n            rectangle (geo.Rectangle): input rectangle\n\n        Returns:\n            geo.Rectangle: new rectangle\n        \"\"\"\n        return self.transformer.geometrizer.restrict_rect_in_frame(rectangle=rectangle)\n\n    # ----------------------------- MORPHOLOGICAL METHODS -----------------------------\n\n    def resize_fixed(\n        self,\n        dim: tuple[int, int],\n        interpolation: int = cv2.INTER_AREA,\n        copy: bool = False,\n    ) -&gt; Image | Self:\n        \"\"\"Resize the image using a fixed dimension well defined.\n        This function can result in a distorted image if the ratio between\n        width and height is different in the original and the new image.\n\n        If the dim argument has a negative value in height or width, then\n        a proportional ratio is applied based on the one of the two dimension given.\n\n        Args:\n            dim (tuple[int, int]): a tuple with two integers in the following order\n                (width, height).\n            interpolation (int, optional): resize interpolation.\n                Defaults to cv2.INTER_AREA.\n            copy (bool, optional): whether to return a new image or not.\n\n        Returns:\n            Image | Self: resized new image if copy=True else resized original image\n        \"\"\"\n        out = self.transformer.morphologyzer.resize_fixed(\n            dim=dim, interpolation=interpolation, copy=copy\n        )\n        return out if out is not None and copy else self\n\n    def resize(\n        self, factor: float, interpolation: int = cv2.INTER_AREA, copy: bool = False\n    ) -&gt; Image | Self:\n        \"\"\"Resize the image to a new size using a scaling factor value that\n        will be applied to all dimensions (width and height).\n\n        Applying this method can not result in a distorted image.\n\n        Args:\n            factor (float): factor in [0, 5] to resize the image.\n                A value of 1 does not change the image.\n                A value of 2 doubles the image size.\n                A maximum value of 5 is set to avoid accidentally producing a gigantic\n                image.\n            interpolation (int, optional): resize interpolation.\n                Defaults to cv2.INTER_AREA.\n            copy (bool, optional): whether to return a new image or not.\n\n        Returns:\n            Image | Self: resized new image if copy=True else resized original image\n        \"\"\"\n        out = self.transformer.morphologyzer.resize(\n            factor=factor, interpolation=interpolation, copy=copy\n        )\n        return out if out is not None and copy else self\n\n    def blur(\n        self,\n        kernel: tuple = (5, 5),\n        iterations: int = 1,\n        method: BlurMethods = \"average\",\n        sigmax: float = 0,\n    ) -&gt; Self:\n        \"\"\"Blur the image\n\n        Args:\n            kernel (tuple, optional): blur kernel size. Defaults to (5, 5).\n            iterations (int, optional): number of iterations. Defaults to 1.\n            method (str, optional): blur method.\n                Must be in [\"average\", \"median\", \"gaussian\", \"bilateral\"].\n                Defaults to \"average\".\n            sigmax (float, optional): sigmaX value for the gaussian blur.\n                Defaults to 0.\n\n        Returns:\n            Self: blurred image\n        \"\"\"\n        self.transformer.morphologyzer.blur(\n            kernel=kernel, iterations=iterations, method=method, sigmax=sigmax\n        )\n        return self\n\n    def dilate(\n        self,\n        kernel: tuple = (5, 5),\n        iterations: int = 1,\n        dilate_black_pixels: bool = True,\n    ) -&gt; Self:\n        \"\"\"Dilate the image by making the black pixels expand in the image.\n        The dilatation can be parametrize thanks to the kernel and iterations\n        arguments.\n\n        Args:\n            kernel (tuple, optional): kernel to dilate. Defaults to (5, 5).\n            iterations (int, optional): number of dilatation iterations. Defaults to 1.\n            dilate_black_pixels (bool, optional): whether to dilate black pixels or not\n\n        Returns:\n            Self: dilated image\n        \"\"\"\n        self.transformer.morphologyzer.dilate(\n            kernel=kernel,\n            iterations=iterations,\n            dilate_black_pixels=dilate_black_pixels,\n        )\n        return self\n\n    def erode(\n        self,\n        kernel: tuple = (5, 5),\n        iterations: int = 1,\n        erode_black_pixels: bool = True,\n    ) -&gt; Self:\n        \"\"\"Erode the image by making the black pixels shrink in the image.\n        The anti-dilatation can be parametrize thanks to the kernel and iterations\n        arguments.\n\n        Args:\n            kernel (tuple, optional): kernel to erode. Defaults to (5, 5).\n            iterations (int, optional): number of iterations. Defaults to 1.\n            erode_black_pixels (bool, optional): whether to erode black pixels or not\n\n        Returns:\n            Self: eroded image\n        \"\"\"\n        self.transformer.morphologyzer.erode(\n            kernel=kernel, iterations=iterations, erode_black_pixels=erode_black_pixels\n        )\n        return self\n\n    def add_border(self, size: int, fill_value: int = 0) -&gt; Self:\n        \"\"\"Add a border to the image.\n\n        Args:\n            thickness (int): border thickness.\n            color (int, optional): border color. Defaults to 0.\n        \"\"\"\n        self.transformer.morphologyzer.add_border(size=size, fill_value=fill_value)\n        return self\n\n    def add_noise_salt_and_pepper(self, amount: float = 0.05) -&gt; Self:\n        \"\"\"Add salt and pepper noise to the image.\n\n        Args:\n            amount (float, optional): Proportion of image pixels to alter.\n                Defaults to 0.05.\n        \"\"\"\n        self.transformer.morphologyzer.add_noise_salt_and_pepper(amount=amount)\n        return self\n\n    def add_noise_gaussian(self, mean: float = 0, std: float = 0.05) -&gt; Self:\n        \"\"\"Add Gaussian noise to the image.\n\n        Args:\n            amount (float, optional): Proportion of image pixels to alter.\n                Defaults to 0.05.\n        \"\"\"\n        self.transformer.morphologyzer.add_noise_gaussian(mean=mean, std=std)\n        return self\n\n    # -------------------------- ASSEMBLED COMPOSED METHODS ---------------------------\n    # methods that use multiple components\n    # ---------------------------------------------------------------------------------\n\n    def iou(\n        self, other: Image, binarization_method: BinarizationMethods = \"sauvola\"\n    ) -&gt; float:\n        \"\"\"Compute the intersection over union score\n\n        Args:\n            other (Image): another image\n            binarization_method (str, optional): binarization method to turn images\n                into 0 and 1 images. The black pixels will be 1 and the white pixels\n                will be 0. This is used to compute the score.\n                Defaults to \"sauvola\".\n\n        Returns:\n            float: a score from 0 to 1. The greater the score the greater the other\n                image is equal to the original image\n        \"\"\"\n        assert self.is_equal_shape(other)\n        mask0 = self.binaryrev(method=binarization_method)\n        mask1 = other.binaryrev(method=binarization_method)\n        return np.sum(mask0 * mask1) / np.count_nonzero(mask0 + mask1)\n\n    def score_contains_v2(\n        self, other: Image, binarization_method: BinarizationMethods = \"sauvola\"\n    ) -&gt; float:\n        \"\"\"Score contains version 2 which is more efficient and faster.\n\n        Args:\n            other (Image): other Image object\n            binarization_method (str, optional): binarization method to turn images\n                into 0 and 1 images. The black pixels will be 1 and the white pixels\n                will be 0. This is used to compute the score.\n                Defaults to \"sauvola\".\n\n        Returns:\n            float: a score from 0 to 1. The greater the score the greater the other\n                image is contained within the original image\n        \"\"\"\n        assert self.is_equal_shape(other, consider_channel=False)\n\n        cur_binaryrev = self.binaryrev(method=binarization_method)\n        other_binaryrev = other.binaryrev(method=binarization_method)\n\n        other_pixels = cur_binaryrev[other_binaryrev == 1]\n\n        coverage = np.sum(other_pixels) / np.sum(other_binaryrev)\n        return coverage\n\n    def score_contains(\n        self, other: Image, binarization_method: BinarizationMethods = \"sauvola\"\n    ) -&gt; float:\n        \"\"\"How much the other image is contained in the original image.\n\n        Args:\n            other (Image): other Image object\n            binarization_method (str, optional): binarization method to turn images\n                into 0 and 1 images. The black pixels will be 1 and the white pixels\n                will be 0. This is used to compute the score.\n                Defaults to \"sauvola\".\n\n        Returns:\n            float: a score from 0 to 1. The greater the score the greater the other\n                image is contained within the original image\n        \"\"\"\n        assert self.is_equal_shape(other, consider_channel=False)\n        other_binaryrev = other.binaryrev(method=binarization_method)\n        return np.sum(\n            self.binaryrev(method=binarization_method) * other_binaryrev\n        ) / np.sum(other_binaryrev)\n\n    def score_contains_segments(\n        self,\n        segments: Sequence[geo.Segment],\n        dilate_kernel: tuple = (5, 5),\n        dilate_iterations: int = 0,\n        binarization_method: BinarizationMethods = \"sauvola\",\n        resize_factor: float = 1.0,\n    ) -&gt; list[float]:\n        \"\"\"Compute the contains score in [0, 1] for each individual segment.\n        This method can be better than score_contains_polygons in some\n        cases.\n        It provides a score for each single segments. This way it is better to\n        identify which segments specifically are contained in the image or not.\n\n        Args:\n            segments (NDArray | list[geo.Segment]): a list of segments\n            dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n            dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n            binarization_method (str, optional): binarization method. Here\n                we can afford the sauvola method since we crop the image first\n                and the binarization occurs on a small image.\n                Defaults to \"sauvola\".\n            resize_factor (float, optional): resize factor that can be adjusted to\n                provide extra speed. A lower value will be faster but less accurate.\n                Typically 0.5 works well but less can have a negative impact on accuracy\n                Defaults to 1.0 which implies no resize.\n\n        Returns:\n            NDArray: list of score for each individual segment in the same order\n                as the list of segments\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        added_width = 10\n        height_crop = 30\n        mid_height_crop = int(height_crop / 2)\n        score_segments: list[float] = []\n\n        for segment in segments:\n\n            im = self.crop_segment_faster(\n                segment=segment.asarray,\n                dim_crop_rect=(-1, height_crop),\n                added_width=added_width,\n                pad_value=255,\n            )\n\n            im.dilate(kernel=dilate_kernel, iterations=dilate_iterations)\n\n            im.resize(factor=resize_factor)\n\n            # re-compute the segment in the crop referential\n            segment_crop = geo.Segment(\n                np.array(\n                    [\n                        [added_width, mid_height_crop],\n                        [segment.length + added_width, mid_height_crop],\n                    ]\n                )\n                * resize_factor\n            )\n\n            # create all-white image of same size as original with the segment drawn\n            other = (\n                im.copy()\n                .as_white()\n                .draw_segments(\n                    segments=[segment_crop],\n                    render=SegmentsRender(thickness=1, default_color=(0, 0, 0)),\n                )\n                .as_grayscale()\n            )\n\n            score = im.score_contains_v2(\n                other=other, binarization_method=binarization_method\n            )\n\n            score_segments.append(score)\n\n        return score_segments\n\n    def score_contains_polygons(\n        self,\n        polygons: Sequence[geo.Polygon],\n        dilate_kernel: tuple = (5, 5),\n        dilate_iterations: int = 0,\n        binarization_method: BinarizationMethods = \"sauvola\",\n        resize_factor: float = 1.0,\n    ) -&gt; list[float]:\n        \"\"\"Compute the contains score in [0, 1] for each individual polygon.\n\n        Beware: this method is different from the score_contains method because in\n        this case you can emphasize the base image by dilating its content.\n\n        Everything that is a 1 in the rmask will be dilated to give more chance for the\n        contour to be contained within the image in the calculation. This way you\n        can control the sensitivity of the score.\n\n        Args:\n            polygons (Sequence[Polygon]): Polygon object\n            dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n            dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n            binarization_method (str, optional): binarization method. Here\n                we can afford the sauvola method since we crop the image first\n                and the binarization occurs on a small image.\n                Defaults to \"sauvola\".\n            resize_factor (float, optional): resize factor that can be adjusted to\n                provide extra speed. A lower value will be faster but less accurate.\n                Typically 0.5 works well but less can have a negative impact on accuracy\n                Defaults to 1.0 which implies no resize.\n\n        Returns:\n            float: a score from 0 to 1. The greater the score the greater the contour\n                 is contained within the original image\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        extra_border_size = 10\n        scores: list[float] = []\n        for polygon in polygons:\n\n            im = self.crop_from_polygon(\n                polygon=polygon,\n                copy=True,\n                pad=True,\n                clip=False,\n                extra_border_size=extra_border_size,\n                pad_value=255,\n            )\n\n            im.dilate(kernel=dilate_kernel, iterations=dilate_iterations)\n\n            im.resize(factor=resize_factor)\n\n            # re-compute the polygon in the crop referential\n            polygon_crop = geo.Polygon(\n                (polygon.crop_coordinates + extra_border_size) * resize_factor\n            )\n\n            # create all-white image of same size as original with the geometry entity\n            other = (\n                im.copy()\n                .as_white()\n                .draw_polygons(\n                    polygons=[polygon_crop],\n                    render=PolygonsRender(thickness=1, default_color=(0, 0, 0)),\n                )\n                .as_grayscale()\n            )\n\n            cur_score = im.score_contains_v2(\n                other=other, binarization_method=binarization_method\n            )\n\n            scores.append(cur_score)\n\n        return scores\n\n    def score_contains_linear_splines(\n        self,\n        splines: Sequence[geo.LinearSpline],\n        dilate_kernel: tuple = (5, 5),\n        dilate_iterations: int = 0,\n        binarization_method: BinarizationMethods = \"sauvola\",\n        resize_factor: float = 1.0,\n    ) -&gt; list[float]:\n        \"\"\"Compute the contains score in [0, 1]for each individual LinearSpline.\n        It provides a score for each single linear spline.\n\n        Args:\n            splines (Sequence[LinearSpline]): a list of linear splines objects\n            dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n            dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n            binarization_method (str, optional): binarization method. Here\n                we can afford the sauvola method since we crop the image first\n                and the binarization occurs on a small image.\n                Defaults to \"sauvola\".\n            resize_factor (float, optional): resize factor that can be adjusted to\n                provide extra speed. A lower value will be faster but less accurate.\n                Typically 0.5 works well but less can have a negative impact on accuracy\n                Defaults to 1.0 which implies no resize.\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        extra_border_size = 10\n        scores: list[float] = []\n        for spline in splines:\n            im = self.crop_from_linear_spline(\n                spline=spline,\n                copy=True,\n                pad=True,\n                clip=False,\n                extra_border_size=extra_border_size,\n                pad_value=255,\n            )\n\n            im.dilate(kernel=dilate_kernel, iterations=dilate_iterations)\n\n            im.resize(factor=resize_factor)\n\n            spline_crop = geo.LinearSpline(\n                (spline.crop_coordinates + extra_border_size) * resize_factor\n            )\n\n            # create all-white image of same size as original with the geometry entity\n            other = (\n                im.copy()\n                .as_white()\n                .draw_splines(\n                    splines=[spline_crop],\n                    render=LinearSplinesRender(thickness=1, default_color=(0, 0, 0)),\n                )\n                .as_grayscale()\n            )\n\n            cur_score = im.score_contains_v2(\n                other=other, binarization_method=binarization_method\n            )\n\n            scores.append(cur_score)\n\n        return scores\n\n    def score_contains_linear_entities(\n        self,\n        entities: Sequence[LinearEntity],\n        dilate_kernel: tuple = (5, 5),\n        dilate_iterations: int = 0,\n        binarization_method: BinarizationMethods = \"sauvola\",\n        resize_factor: float = 1.0,\n    ) -&gt; list[float]:\n        \"\"\"Compute the contains score in [0, 1] for each individual linear entity\n        (either LinearSpline or Segment).\n\n        Args:\n            entities (list[geo.LinearEntity]): a list of linear entities\n                (splines or segments)\n            dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n            dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n            binarization_method (BinarizationMethods, optional): binarization method.\n                Defaults to \"sauvola\".\n            resize_factor (float, optional): resize factor for speed/accuracy tradeoff.\n                Defaults to 1.0.\n\n        Returns:\n            list[float]: list of scores for each individual entity\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        scores = []\n        for entity in entities:\n            if isinstance(entity, geo.LinearSpline):\n                score = self.score_contains_linear_splines(\n                    splines=[entity],\n                    dilate_kernel=dilate_kernel,\n                    dilate_iterations=dilate_iterations,\n                    binarization_method=binarization_method,\n                    resize_factor=resize_factor,\n                )[0]\n            elif isinstance(entity, geo.Segment):\n                score = self.score_contains_segments(\n                    segments=[entity],\n                    dilate_kernel=dilate_kernel,\n                    dilate_iterations=dilate_iterations,\n                    binarization_method=binarization_method,\n                    resize_factor=resize_factor,\n                )[0]\n            else:\n                raise TypeError(\n                    f\"Unsupported entity type: {type(entity)}. \"\n                    \"Expected LinearSpline or Segment.\"\n                )\n            scores.append(score)\n        return scores\n\n    def score_distance_from_center(\n        self, point: NDArray, method: ScoreDistanceFromCenterMethods = \"linear\"\n    ) -&gt; float:\n        \"\"\"Compute a score to evaluate how far a point is from the\n        image center point.\n\n        A score close to 0 means that the point and the image center are far away.\n        A score close to 1 means that the point and the image center are close.\n\n        It is particularly useful when calling it where the point argument is a\n        contour centroid. Then, a score equal to 1 means that the contour and image\n        centers coincide.\n\n        This method can be used to compute a score for a contour centroid:\n        - A small score should be taken into account and informs us that the contour\n        found is probably wrong.\n        - On the contrary, a high score does not ensure a high quality contour.\n\n        Args:\n            point (NDArray): 2D point\n            method (str): the method to be used to compute the score. Defaults to\n                \"linear\".\n\n        Returns:\n            float: a score from 0 to 1.\n        \"\"\"\n\n        def gaussian_2d(\n            x: float,\n            y: float,\n            x0: float = 0.0,\n            y0: float = 0.0,\n            amplitude: float = 1.0,\n            sigmax: float = 1.0,\n            sigmay: float = 1.0,\n        ) -&gt; float:\n            # pylint: disable=too-many-positional-arguments,too-many-arguments\n            return amplitude * np.exp(\n                -((x - x0) ** 2 / (2 * sigmax**2) + (y - y0) ** 2 / (2 * sigmay**2))\n            )\n\n        def cone_positive_2d(\n            x: float,\n            y: float,\n            x0: float = 0.0,\n            y0: float = 0.0,\n            amplitude: float = 1.0,\n            radius: float = 1.0,\n        ) -&gt; float:\n            # pylint: disable=too-many-positional-arguments,too-many-arguments\n            r = np.sqrt((x - x0) ** 2 + (y - y0) ** 2)\n            if r &gt;= radius:\n                return 0\n            return amplitude * (1 - r / radius)\n\n        if method == \"linear\":\n            return cone_positive_2d(\n                x=point[0],\n                y=point[1],\n                x0=self.center[0],\n                y0=self.center[1],\n                radius=self.norm_side_length / 2,\n            )\n        if method == \"gaussian\":\n            return gaussian_2d(\n                x=point[0],\n                y=point[1],\n                x0=self.center[0],\n                y0=self.center[1],\n                sigmax=self.dist_pct(0.1),\n                sigmay=self.dist_pct(0.1),\n            )\n\n        raise ValueError(f\"Unknown method {method}\")\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the image\n\n        Returns:\n            str: string\n        \"\"\"\n        return (\n            self.__class__.__name__\n            + \"(height=\"\n            + str(self.height)\n            + \", width=\"\n            + str(self.width)\n            + \", n_channels=\"\n            + str(self.channels)\n            + \")\"\n        )\n\n    def _repr_image(self, image_format: str, **kwargs: Any) -&gt; Optional[bytes]:\n        \"\"\"Helper function for iPython display hook.\n\n        Just reused the code from PIL library:\n        https://github.com/python-pillow/Pillow/blob/main/src/PIL/Image.py\n\n        Args:\n          image_format (str): Image format.\n\n        Returns:\n            (bytes, optional): image as bytes, saved into the given format.\n        \"\"\"\n        b = io.BytesIO()\n        try:\n            im = self.show()\n            im.save(b, image_format, **kwargs)\n        except Exception:  # pylint: disable=broad-except\n            return None\n        return b.getvalue()\n\n    def _repr_png_(self) -&gt; Optional[bytes]:\n        \"\"\"iPython display hook support for PNG format.\n\n        Returns:\n            (bytes, optional): PNG version of the image as bytes\n        \"\"\"\n        return self._repr_image(\"PNG\", compress_level=1)\n\n    def _repr_jpeg_(self) -&gt; Optional[bytes]:\n        \"\"\"iPython display hook support for JPEG format.\n\n        Returns:\n            (bytes, optional): JPEG version of the image as bytes\n        \"\"\"\n        return self._repr_image(\"JPEG\")\n</code></pre>"},{"location":"api/image/analysis/scoring/#otary.image.image.Image.iou","title":"<code>iou(other, binarization_method='sauvola')</code>","text":"<p>Compute the intersection over union score</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Image</code> <p>another image</p> required <code>binarization_method</code> <code>str</code> <p>binarization method to turn images into 0 and 1 images. The black pixels will be 1 and the white pixels will be 0. This is used to compute the score. Defaults to \"sauvola\".</p> <code>'sauvola'</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>a score from 0 to 1. The greater the score the greater the other image is equal to the original image</p> Source code in <code>otary/image/image.py</code> <pre><code>def iou(\n    self, other: Image, binarization_method: BinarizationMethods = \"sauvola\"\n) -&gt; float:\n    \"\"\"Compute the intersection over union score\n\n    Args:\n        other (Image): another image\n        binarization_method (str, optional): binarization method to turn images\n            into 0 and 1 images. The black pixels will be 1 and the white pixels\n            will be 0. This is used to compute the score.\n            Defaults to \"sauvola\".\n\n    Returns:\n        float: a score from 0 to 1. The greater the score the greater the other\n            image is equal to the original image\n    \"\"\"\n    assert self.is_equal_shape(other)\n    mask0 = self.binaryrev(method=binarization_method)\n    mask1 = other.binaryrev(method=binarization_method)\n    return np.sum(mask0 * mask1) / np.count_nonzero(mask0 + mask1)\n</code></pre>"},{"location":"api/image/analysis/scoring/#otary.image.image.Image.score_contains_v2","title":"<code>score_contains_v2(other, binarization_method='sauvola')</code>","text":"<p>Score contains version 2 which is more efficient and faster.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Image</code> <p>other Image object</p> required <code>binarization_method</code> <code>str</code> <p>binarization method to turn images into 0 and 1 images. The black pixels will be 1 and the white pixels will be 0. This is used to compute the score. Defaults to \"sauvola\".</p> <code>'sauvola'</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>a score from 0 to 1. The greater the score the greater the other image is contained within the original image</p> Source code in <code>otary/image/image.py</code> <pre><code>def score_contains_v2(\n    self, other: Image, binarization_method: BinarizationMethods = \"sauvola\"\n) -&gt; float:\n    \"\"\"Score contains version 2 which is more efficient and faster.\n\n    Args:\n        other (Image): other Image object\n        binarization_method (str, optional): binarization method to turn images\n            into 0 and 1 images. The black pixels will be 1 and the white pixels\n            will be 0. This is used to compute the score.\n            Defaults to \"sauvola\".\n\n    Returns:\n        float: a score from 0 to 1. The greater the score the greater the other\n            image is contained within the original image\n    \"\"\"\n    assert self.is_equal_shape(other, consider_channel=False)\n\n    cur_binaryrev = self.binaryrev(method=binarization_method)\n    other_binaryrev = other.binaryrev(method=binarization_method)\n\n    other_pixels = cur_binaryrev[other_binaryrev == 1]\n\n    coverage = np.sum(other_pixels) / np.sum(other_binaryrev)\n    return coverage\n</code></pre>"},{"location":"api/image/analysis/scoring/#otary.image.image.Image.score_contains","title":"<code>score_contains(other, binarization_method='sauvola')</code>","text":"<p>How much the other image is contained in the original image.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Image</code> <p>other Image object</p> required <code>binarization_method</code> <code>str</code> <p>binarization method to turn images into 0 and 1 images. The black pixels will be 1 and the white pixels will be 0. This is used to compute the score. Defaults to \"sauvola\".</p> <code>'sauvola'</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>a score from 0 to 1. The greater the score the greater the other image is contained within the original image</p> Source code in <code>otary/image/image.py</code> <pre><code>def score_contains(\n    self, other: Image, binarization_method: BinarizationMethods = \"sauvola\"\n) -&gt; float:\n    \"\"\"How much the other image is contained in the original image.\n\n    Args:\n        other (Image): other Image object\n        binarization_method (str, optional): binarization method to turn images\n            into 0 and 1 images. The black pixels will be 1 and the white pixels\n            will be 0. This is used to compute the score.\n            Defaults to \"sauvola\".\n\n    Returns:\n        float: a score from 0 to 1. The greater the score the greater the other\n            image is contained within the original image\n    \"\"\"\n    assert self.is_equal_shape(other, consider_channel=False)\n    other_binaryrev = other.binaryrev(method=binarization_method)\n    return np.sum(\n        self.binaryrev(method=binarization_method) * other_binaryrev\n    ) / np.sum(other_binaryrev)\n</code></pre>"},{"location":"api/image/analysis/scoring/#otary.image.image.Image.score_contains_segments","title":"<code>score_contains_segments(segments, dilate_kernel=(5, 5), dilate_iterations=0, binarization_method='sauvola', resize_factor=1.0)</code>","text":"<p>Compute the contains score in [0, 1] for each individual segment. This method can be better than score_contains_polygons in some cases. It provides a score for each single segments. This way it is better to identify which segments specifically are contained in the image or not.</p> <p>Parameters:</p> Name Type Description Default <code>segments</code> <code>NDArray | list[Segment]</code> <p>a list of segments</p> required <code>dilate_kernel</code> <code>tuple</code> <p>dilate kernel param. Defaults to (5, 5).</p> <code>(5, 5)</code> <code>dilate_iterations</code> <code>int</code> <p>dilate iterations param. Defaults to 0.</p> <code>0</code> <code>binarization_method</code> <code>str</code> <p>binarization method. Here we can afford the sauvola method since we crop the image first and the binarization occurs on a small image. Defaults to \"sauvola\".</p> <code>'sauvola'</code> <code>resize_factor</code> <code>float</code> <p>resize factor that can be adjusted to provide extra speed. A lower value will be faster but less accurate. Typically 0.5 works well but less can have a negative impact on accuracy Defaults to 1.0 which implies no resize.</p> <code>1.0</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>list[float]</code> <p>list of score for each individual segment in the same order as the list of segments</p> Source code in <code>otary/image/image.py</code> <pre><code>def score_contains_segments(\n    self,\n    segments: Sequence[geo.Segment],\n    dilate_kernel: tuple = (5, 5),\n    dilate_iterations: int = 0,\n    binarization_method: BinarizationMethods = \"sauvola\",\n    resize_factor: float = 1.0,\n) -&gt; list[float]:\n    \"\"\"Compute the contains score in [0, 1] for each individual segment.\n    This method can be better than score_contains_polygons in some\n    cases.\n    It provides a score for each single segments. This way it is better to\n    identify which segments specifically are contained in the image or not.\n\n    Args:\n        segments (NDArray | list[geo.Segment]): a list of segments\n        dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n        dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n        binarization_method (str, optional): binarization method. Here\n            we can afford the sauvola method since we crop the image first\n            and the binarization occurs on a small image.\n            Defaults to \"sauvola\".\n        resize_factor (float, optional): resize factor that can be adjusted to\n            provide extra speed. A lower value will be faster but less accurate.\n            Typically 0.5 works well but less can have a negative impact on accuracy\n            Defaults to 1.0 which implies no resize.\n\n    Returns:\n        NDArray: list of score for each individual segment in the same order\n            as the list of segments\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    added_width = 10\n    height_crop = 30\n    mid_height_crop = int(height_crop / 2)\n    score_segments: list[float] = []\n\n    for segment in segments:\n\n        im = self.crop_segment_faster(\n            segment=segment.asarray,\n            dim_crop_rect=(-1, height_crop),\n            added_width=added_width,\n            pad_value=255,\n        )\n\n        im.dilate(kernel=dilate_kernel, iterations=dilate_iterations)\n\n        im.resize(factor=resize_factor)\n\n        # re-compute the segment in the crop referential\n        segment_crop = geo.Segment(\n            np.array(\n                [\n                    [added_width, mid_height_crop],\n                    [segment.length + added_width, mid_height_crop],\n                ]\n            )\n            * resize_factor\n        )\n\n        # create all-white image of same size as original with the segment drawn\n        other = (\n            im.copy()\n            .as_white()\n            .draw_segments(\n                segments=[segment_crop],\n                render=SegmentsRender(thickness=1, default_color=(0, 0, 0)),\n            )\n            .as_grayscale()\n        )\n\n        score = im.score_contains_v2(\n            other=other, binarization_method=binarization_method\n        )\n\n        score_segments.append(score)\n\n    return score_segments\n</code></pre>"},{"location":"api/image/analysis/scoring/#otary.image.image.Image.score_contains_polygons","title":"<code>score_contains_polygons(polygons, dilate_kernel=(5, 5), dilate_iterations=0, binarization_method='sauvola', resize_factor=1.0)</code>","text":"<p>Compute the contains score in [0, 1] for each individual polygon.</p> <p>Beware: this method is different from the score_contains method because in this case you can emphasize the base image by dilating its content.</p> <p>Everything that is a 1 in the rmask will be dilated to give more chance for the contour to be contained within the image in the calculation. This way you can control the sensitivity of the score.</p> <p>Parameters:</p> Name Type Description Default <code>polygons</code> <code>Sequence[Polygon]</code> <p>Polygon object</p> required <code>dilate_kernel</code> <code>tuple</code> <p>dilate kernel param. Defaults to (5, 5).</p> <code>(5, 5)</code> <code>dilate_iterations</code> <code>int</code> <p>dilate iterations param. Defaults to 0.</p> <code>0</code> <code>binarization_method</code> <code>str</code> <p>binarization method. Here we can afford the sauvola method since we crop the image first and the binarization occurs on a small image. Defaults to \"sauvola\".</p> <code>'sauvola'</code> <code>resize_factor</code> <code>float</code> <p>resize factor that can be adjusted to provide extra speed. A lower value will be faster but less accurate. Typically 0.5 works well but less can have a negative impact on accuracy Defaults to 1.0 which implies no resize.</p> <code>1.0</code> <p>Returns:</p> Name Type Description <code>float</code> <code>list[float]</code> <p>a score from 0 to 1. The greater the score the greater the contour  is contained within the original image</p> Source code in <code>otary/image/image.py</code> <pre><code>def score_contains_polygons(\n    self,\n    polygons: Sequence[geo.Polygon],\n    dilate_kernel: tuple = (5, 5),\n    dilate_iterations: int = 0,\n    binarization_method: BinarizationMethods = \"sauvola\",\n    resize_factor: float = 1.0,\n) -&gt; list[float]:\n    \"\"\"Compute the contains score in [0, 1] for each individual polygon.\n\n    Beware: this method is different from the score_contains method because in\n    this case you can emphasize the base image by dilating its content.\n\n    Everything that is a 1 in the rmask will be dilated to give more chance for the\n    contour to be contained within the image in the calculation. This way you\n    can control the sensitivity of the score.\n\n    Args:\n        polygons (Sequence[Polygon]): Polygon object\n        dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n        dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n        binarization_method (str, optional): binarization method. Here\n            we can afford the sauvola method since we crop the image first\n            and the binarization occurs on a small image.\n            Defaults to \"sauvola\".\n        resize_factor (float, optional): resize factor that can be adjusted to\n            provide extra speed. A lower value will be faster but less accurate.\n            Typically 0.5 works well but less can have a negative impact on accuracy\n            Defaults to 1.0 which implies no resize.\n\n    Returns:\n        float: a score from 0 to 1. The greater the score the greater the contour\n             is contained within the original image\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    extra_border_size = 10\n    scores: list[float] = []\n    for polygon in polygons:\n\n        im = self.crop_from_polygon(\n            polygon=polygon,\n            copy=True,\n            pad=True,\n            clip=False,\n            extra_border_size=extra_border_size,\n            pad_value=255,\n        )\n\n        im.dilate(kernel=dilate_kernel, iterations=dilate_iterations)\n\n        im.resize(factor=resize_factor)\n\n        # re-compute the polygon in the crop referential\n        polygon_crop = geo.Polygon(\n            (polygon.crop_coordinates + extra_border_size) * resize_factor\n        )\n\n        # create all-white image of same size as original with the geometry entity\n        other = (\n            im.copy()\n            .as_white()\n            .draw_polygons(\n                polygons=[polygon_crop],\n                render=PolygonsRender(thickness=1, default_color=(0, 0, 0)),\n            )\n            .as_grayscale()\n        )\n\n        cur_score = im.score_contains_v2(\n            other=other, binarization_method=binarization_method\n        )\n\n        scores.append(cur_score)\n\n    return scores\n</code></pre>"},{"location":"api/image/analysis/scoring/#otary.image.image.Image.score_contains_linear_splines","title":"<code>score_contains_linear_splines(splines, dilate_kernel=(5, 5), dilate_iterations=0, binarization_method='sauvola', resize_factor=1.0)</code>","text":"<p>Compute the contains score in [0, 1]for each individual LinearSpline. It provides a score for each single linear spline.</p> <p>Parameters:</p> Name Type Description Default <code>splines</code> <code>Sequence[LinearSpline]</code> <p>a list of linear splines objects</p> required <code>dilate_kernel</code> <code>tuple</code> <p>dilate kernel param. Defaults to (5, 5).</p> <code>(5, 5)</code> <code>dilate_iterations</code> <code>int</code> <p>dilate iterations param. Defaults to 0.</p> <code>0</code> <code>binarization_method</code> <code>str</code> <p>binarization method. Here we can afford the sauvola method since we crop the image first and the binarization occurs on a small image. Defaults to \"sauvola\".</p> <code>'sauvola'</code> <code>resize_factor</code> <code>float</code> <p>resize factor that can be adjusted to provide extra speed. A lower value will be faster but less accurate. Typically 0.5 works well but less can have a negative impact on accuracy Defaults to 1.0 which implies no resize.</p> <code>1.0</code> Source code in <code>otary/image/image.py</code> <pre><code>def score_contains_linear_splines(\n    self,\n    splines: Sequence[geo.LinearSpline],\n    dilate_kernel: tuple = (5, 5),\n    dilate_iterations: int = 0,\n    binarization_method: BinarizationMethods = \"sauvola\",\n    resize_factor: float = 1.0,\n) -&gt; list[float]:\n    \"\"\"Compute the contains score in [0, 1]for each individual LinearSpline.\n    It provides a score for each single linear spline.\n\n    Args:\n        splines (Sequence[LinearSpline]): a list of linear splines objects\n        dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n        dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n        binarization_method (str, optional): binarization method. Here\n            we can afford the sauvola method since we crop the image first\n            and the binarization occurs on a small image.\n            Defaults to \"sauvola\".\n        resize_factor (float, optional): resize factor that can be adjusted to\n            provide extra speed. A lower value will be faster but less accurate.\n            Typically 0.5 works well but less can have a negative impact on accuracy\n            Defaults to 1.0 which implies no resize.\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    extra_border_size = 10\n    scores: list[float] = []\n    for spline in splines:\n        im = self.crop_from_linear_spline(\n            spline=spline,\n            copy=True,\n            pad=True,\n            clip=False,\n            extra_border_size=extra_border_size,\n            pad_value=255,\n        )\n\n        im.dilate(kernel=dilate_kernel, iterations=dilate_iterations)\n\n        im.resize(factor=resize_factor)\n\n        spline_crop = geo.LinearSpline(\n            (spline.crop_coordinates + extra_border_size) * resize_factor\n        )\n\n        # create all-white image of same size as original with the geometry entity\n        other = (\n            im.copy()\n            .as_white()\n            .draw_splines(\n                splines=[spline_crop],\n                render=LinearSplinesRender(thickness=1, default_color=(0, 0, 0)),\n            )\n            .as_grayscale()\n        )\n\n        cur_score = im.score_contains_v2(\n            other=other, binarization_method=binarization_method\n        )\n\n        scores.append(cur_score)\n\n    return scores\n</code></pre>"},{"location":"api/image/analysis/scoring/#otary.image.image.Image.score_contains_linear_entities","title":"<code>score_contains_linear_entities(entities, dilate_kernel=(5, 5), dilate_iterations=0, binarization_method='sauvola', resize_factor=1.0)</code>","text":"<p>Compute the contains score in [0, 1] for each individual linear entity (either LinearSpline or Segment).</p> <p>Parameters:</p> Name Type Description Default <code>entities</code> <code>list[LinearEntity]</code> <p>a list of linear entities (splines or segments)</p> required <code>dilate_kernel</code> <code>tuple</code> <p>dilate kernel param. Defaults to (5, 5).</p> <code>(5, 5)</code> <code>dilate_iterations</code> <code>int</code> <p>dilate iterations param. Defaults to 0.</p> <code>0</code> <code>binarization_method</code> <code>BinarizationMethods</code> <p>binarization method. Defaults to \"sauvola\".</p> <code>'sauvola'</code> <code>resize_factor</code> <code>float</code> <p>resize factor for speed/accuracy tradeoff. Defaults to 1.0.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>list[float]</code> <p>list[float]: list of scores for each individual entity</p> Source code in <code>otary/image/image.py</code> <pre><code>def score_contains_linear_entities(\n    self,\n    entities: Sequence[LinearEntity],\n    dilate_kernel: tuple = (5, 5),\n    dilate_iterations: int = 0,\n    binarization_method: BinarizationMethods = \"sauvola\",\n    resize_factor: float = 1.0,\n) -&gt; list[float]:\n    \"\"\"Compute the contains score in [0, 1] for each individual linear entity\n    (either LinearSpline or Segment).\n\n    Args:\n        entities (list[geo.LinearEntity]): a list of linear entities\n            (splines or segments)\n        dilate_kernel (tuple, optional): dilate kernel param. Defaults to (5, 5).\n        dilate_iterations (int, optional): dilate iterations param. Defaults to 0.\n        binarization_method (BinarizationMethods, optional): binarization method.\n            Defaults to \"sauvola\".\n        resize_factor (float, optional): resize factor for speed/accuracy tradeoff.\n            Defaults to 1.0.\n\n    Returns:\n        list[float]: list of scores for each individual entity\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    scores = []\n    for entity in entities:\n        if isinstance(entity, geo.LinearSpline):\n            score = self.score_contains_linear_splines(\n                splines=[entity],\n                dilate_kernel=dilate_kernel,\n                dilate_iterations=dilate_iterations,\n                binarization_method=binarization_method,\n                resize_factor=resize_factor,\n            )[0]\n        elif isinstance(entity, geo.Segment):\n            score = self.score_contains_segments(\n                segments=[entity],\n                dilate_kernel=dilate_kernel,\n                dilate_iterations=dilate_iterations,\n                binarization_method=binarization_method,\n                resize_factor=resize_factor,\n            )[0]\n        else:\n            raise TypeError(\n                f\"Unsupported entity type: {type(entity)}. \"\n                \"Expected LinearSpline or Segment.\"\n            )\n        scores.append(score)\n    return scores\n</code></pre>"},{"location":"api/image/analysis/scoring/#otary.image.image.Image.score_distance_from_center","title":"<code>score_distance_from_center(point, method='linear')</code>","text":"<p>Compute a score to evaluate how far a point is from the image center point.</p> <p>A score close to 0 means that the point and the image center are far away. A score close to 1 means that the point and the image center are close.</p> <p>It is particularly useful when calling it where the point argument is a contour centroid. Then, a score equal to 1 means that the contour and image centers coincide.</p> <p>This method can be used to compute a score for a contour centroid: - A small score should be taken into account and informs us that the contour found is probably wrong. - On the contrary, a high score does not ensure a high quality contour.</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>2D point</p> required <code>method</code> <code>str</code> <p>the method to be used to compute the score. Defaults to \"linear\".</p> <code>'linear'</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>a score from 0 to 1.</p> Source code in <code>otary/image/image.py</code> <pre><code>def score_distance_from_center(\n    self, point: NDArray, method: ScoreDistanceFromCenterMethods = \"linear\"\n) -&gt; float:\n    \"\"\"Compute a score to evaluate how far a point is from the\n    image center point.\n\n    A score close to 0 means that the point and the image center are far away.\n    A score close to 1 means that the point and the image center are close.\n\n    It is particularly useful when calling it where the point argument is a\n    contour centroid. Then, a score equal to 1 means that the contour and image\n    centers coincide.\n\n    This method can be used to compute a score for a contour centroid:\n    - A small score should be taken into account and informs us that the contour\n    found is probably wrong.\n    - On the contrary, a high score does not ensure a high quality contour.\n\n    Args:\n        point (NDArray): 2D point\n        method (str): the method to be used to compute the score. Defaults to\n            \"linear\".\n\n    Returns:\n        float: a score from 0 to 1.\n    \"\"\"\n\n    def gaussian_2d(\n        x: float,\n        y: float,\n        x0: float = 0.0,\n        y0: float = 0.0,\n        amplitude: float = 1.0,\n        sigmax: float = 1.0,\n        sigmay: float = 1.0,\n    ) -&gt; float:\n        # pylint: disable=too-many-positional-arguments,too-many-arguments\n        return amplitude * np.exp(\n            -((x - x0) ** 2 / (2 * sigmax**2) + (y - y0) ** 2 / (2 * sigmay**2))\n        )\n\n    def cone_positive_2d(\n        x: float,\n        y: float,\n        x0: float = 0.0,\n        y0: float = 0.0,\n        amplitude: float = 1.0,\n        radius: float = 1.0,\n    ) -&gt; float:\n        # pylint: disable=too-many-positional-arguments,too-many-arguments\n        r = np.sqrt((x - x0) ** 2 + (y - y0) ** 2)\n        if r &gt;= radius:\n            return 0\n        return amplitude * (1 - r / radius)\n\n    if method == \"linear\":\n        return cone_positive_2d(\n            x=point[0],\n            y=point[1],\n            x0=self.center[0],\n            y0=self.center[1],\n            radius=self.norm_side_length / 2,\n        )\n    if method == \"gaussian\":\n        return gaussian_2d(\n            x=point[0],\n            y=point[1],\n            x0=self.center[0],\n            y0=self.center[1],\n            sigmax=self.dist_pct(0.1),\n            sigmay=self.dist_pct(0.1),\n        )\n\n    raise ValueError(f\"Unknown method {method}\")\n</code></pre>"},{"location":"api/image/drawer/","title":"Drawer","text":"<p>Drawing methods can be accessed through the <code>drawer</code> attribute of the image object.</p> <p>However all the methods of the drawer are also available as direct methods of the image object to provide a more user friendly API. For example, drawing a circle in the image is as easy as:</p> <pre><code>import otary as ot\n\nim = ot.Image.from_file(filepath=\"path/to/file/image\")\n\ncircle = ot.Circle(center=[100, 100], radius=50)\n\nim.draw_circles(\n    circles=[circle],\n    render=ot.CirclesRender(thickness=5, default_color=\"red\")\n)\n</code></pre>"},{"location":"api/image/drawer/#components","title":"Components","text":"<p>The drawer module is divided into two parts:</p> <ul> <li>Drawing: provides methods to draw on images</li> <li>Renderers:  used to define the style of the objects to be drawn</li> </ul>"},{"location":"api/image/drawer/drawing/","title":"Drawing","text":""},{"location":"api/image/drawer/drawing/#drawing-methods","title":"Drawing Methods","text":"<p>Image Drawer module. It only contains methods to draw objects in images.</p>"},{"location":"api/image/drawer/drawing/#otary.image.components.drawer.drawer.DrawerImage","title":"<code>DrawerImage</code>","text":"<p>Image Drawer class to draw objects on a given image</p> Source code in <code>otary/image/components/drawer/drawer.py</code> <pre><code>class DrawerImage:\n    \"\"\"Image Drawer class to draw objects on a given image\"\"\"\n\n    def __init__(self, base: BaseImage):\n        self.base = base\n\n    def _pre_draw(self, n_objects: int, render: Render) -&gt; NDArray:\n        render.adjust_colors_length(n=n_objects)\n        return self.base.as_colorscale().asarray\n\n    def draw_circles(\n        self,\n        circles: Sequence[geo.Circle],\n        render: CirclesRender = CirclesRender(),\n    ) -&gt; None:\n        \"\"\"Draw circles in the image\n\n        Args:\n            circles (Sequence[Circle]): list of Circle geometry objects.\n            render (CirclesRender): circle renderer\n        \"\"\"\n        im_array = self._pre_draw(n_objects=len(circles), render=render)\n        for circle, color in zip(circles, render.colors_processed):\n            cv2.circle(  # type: ignore[call-overload]\n                img=im_array,\n                center=circle.center.astype(int),\n                radius=int(circle.radius),\n                color=color,\n                thickness=render.thickness if not render.is_filled else -1,\n                lineType=render.line_type,\n            )\n            if render.is_draw_center_point_enabled:\n                cv2.circle(  # type: ignore[call-overload]\n                    img=im_array,\n                    center=circle.center.astype(int),\n                    radius=1,\n                    color=color,\n                    thickness=render.thickness,\n                    lineType=render.line_type,\n                )\n        self.base.asarray = im_array\n\n    def draw_ellipses(\n        self,\n        ellipses: Sequence[geo.Ellipse],\n        render: EllipsesRender = EllipsesRender(),\n    ) -&gt; None:\n        \"\"\"Draw ellipses in the image\n\n        Args:\n            ellipses (Sequence[Ellipse]): list of Ellipse geometry objects.\n            render (EllipseRender): renderer (uses EllipseRender for color/thickness)\n        \"\"\"\n        im_array = self._pre_draw(n_objects=len(ellipses), render=render)\n        for ellipse, color in zip(ellipses, render.colors_processed):\n            axes = (int(ellipse.semi_major_axis), int(ellipse.semi_minor_axis))\n            cv2.ellipse(  # type: ignore[call-overload]\n                img=im_array,\n                center=ellipse.centroid.astype(int),\n                axes=axes,\n                angle=ellipse.angle(degree=True),\n                startAngle=0,\n                endAngle=360,\n                color=color,\n                thickness=render.thickness if not render.is_filled else -1,\n                lineType=render.line_type,\n            )\n            if render.is_draw_center_point_enabled:\n                cv2.circle(  # type: ignore[call-overload]\n                    img=im_array,\n                    center=ellipse.centroid.astype(int),\n                    radius=1,\n                    color=color,\n                    thickness=render.thickness,\n                    lineType=render.line_type,\n                )\n            if render.is_draw_focis_enabled:\n                for foci in [ellipse.foci1, ellipse.foci2]:\n                    cv2.circle(  # type: ignore[call-overload]\n                        img=im_array,\n                        center=foci.astype(int),\n                        radius=1,\n                        color=color,\n                        thickness=render.thickness,\n                        lineType=render.line_type,\n                    )\n        self.base.asarray = im_array\n\n    def draw_points(\n        self,\n        points: NDArray | Sequence[geo.Point],\n        render: PointsRender = PointsRender(),\n    ) -&gt; None:\n        \"\"\"Draw points in the image\n\n        Args:\n            points (NDArray): list of points. It must be of shape (n, 2). This\n                means n points of shape 2 (x and y coordinates).\n            render (PointsRender): point renderer\n        \"\"\"\n        _points = prep_obj_draw(objects=points, _type=geo.Point)\n        im_array = self._pre_draw(n_objects=len(_points), render=render)\n        for point, color in zip(_points, render.colors_processed):\n            cv2.circle(\n                img=im_array,\n                center=point,\n                radius=render.radius,\n                color=color,\n                thickness=render.thickness,\n                lineType=render.line_type,\n            )\n        self.base.asarray = im_array\n\n    def draw_segments(\n        self,\n        segments: NDArray | Sequence[geo.Segment],\n        render: SegmentsRender = SegmentsRender(),\n    ) -&gt; None:\n        \"\"\"Draw segments in the image. It can be arrowed segments (vectors) too.\n\n        Args:\n            segments (NDArray): list of segments. Can be a numpy array of shape\n                (n, 2, 2) which means n array of shape (2, 2) that define a segment\n                by two 2D points.\n            render (SegmentsRender): segment renderer\n        \"\"\"\n        _segments = prep_obj_draw(objects=segments, _type=geo.Segment)\n        im_array = self._pre_draw(n_objects=len(segments), render=render)\n        if render.as_vectors:\n            for segment, color in zip(_segments, render.colors_processed):\n                cv2.arrowedLine(\n                    img=im_array,\n                    pt1=segment[0],\n                    pt2=segment[1],\n                    color=color,\n                    thickness=render.thickness,\n                    line_type=render.line_type,\n                    tipLength=render.tip_length / geo.Segment(segment).length,\n                )\n        else:\n            for segment, color in zip(_segments, render.colors_processed):\n                cv2.line(\n                    img=im_array,\n                    pt1=segment[0],\n                    pt2=segment[1],\n                    color=color,\n                    thickness=render.thickness,\n                    lineType=render.line_type,\n                )\n        self.base.asarray = im_array\n\n    def draw_splines(\n        self,\n        splines: Sequence[geo.LinearSpline],\n        render: LinearSplinesRender = LinearSplinesRender(),\n    ) -&gt; None:\n        \"\"\"Draw linear splines in the image.\n\n        Args:\n            splines (Sequence[geo.LinearSpline]): linear splines to draw.\n            render (LinearSplinesRender, optional): linear splines render.\n                Defaults to LinearSplinesRender().\n        \"\"\"\n        _splines = prep_obj_draw(objects=splines, _type=geo.LinearSpline)\n        im_array = self._pre_draw(n_objects=len(_splines), render=render)\n        for spline, color in zip(_splines, render.colors_processed):\n\n            if render.as_vectors:\n                cv2.polylines(\n                    img=im_array,\n                    pts=[spline[:-1]],\n                    isClosed=False,\n                    color=color,\n                    thickness=render.thickness,\n                    lineType=render.line_type,\n                )\n\n                # Draw the last edge as a vector\n                ix = int(len(spline) * (1 - render.pct_ix_head))\n                ix = ix - 1 if ix == len(spline) - 1 else ix\n                segment = [spline[ix], spline[-1]]\n                cv2.arrowedLine(\n                    img=im_array,\n                    pt1=segment[0],\n                    pt2=segment[1],\n                    color=color,\n                    thickness=render.thickness,\n                    tipLength=render.tip_length / geo.Segment(segment).length,\n                )\n\n            else:\n                cv2.polylines(\n                    img=im_array,\n                    pts=[spline],\n                    isClosed=False,\n                    color=color,\n                    thickness=render.thickness,\n                    lineType=render.line_type,\n                )\n\n    def draw_polygons(\n        self, polygons: Sequence[geo.Polygon], render: PolygonsRender = PolygonsRender()\n    ) -&gt; None:\n        \"\"\"Draw polygons in the image\n\n        Args:\n            polygons (Sequence[Polygon]): list of Polygon objects\n            render (PolygonsRender): PolygonRender object\n        \"\"\"\n        _polygons = prep_obj_draw(objects=polygons, _type=geo.Polygon)\n        im_array = self._pre_draw(n_objects=len(_polygons), render=render)\n        for polygon, color in zip(_polygons, render.colors_processed):\n            if render.is_filled:\n                cv2.fillPoly(\n                    img=im_array,\n                    pts=[polygon],\n                    color=color,\n                    lineType=render.line_type,\n                )\n            else:\n                cv2.polylines(\n                    img=im_array,\n                    pts=[polygon],\n                    isClosed=True,\n                    color=color,\n                    thickness=render.thickness,\n                    lineType=render.line_type,\n                )\n        self.base.asarray = im_array\n\n    def draw_ocr_outputs(\n        self,\n        ocr_outputs: Sequence[OcrSingleOutput],\n        render: OcrSingleOutputRender = OcrSingleOutputRender(),\n    ) -&gt; None:\n        \"\"\"Return the image with the bounding boxes displayed from a list of OCR\n        single output. It allows you to show bounding boxes that can have an angle,\n        not necessarily vertical or horizontal.\n\n        Args:\n            ocr_outputs (Sequence[OcrSingleOutput]): list of OcrSingleOutput objects\n            render (OcrSingleOutputRender): OcrSingleOutputRender object\n        \"\"\"\n        im_array = self._pre_draw(n_objects=len(ocr_outputs), render=render)\n        for ocrso, color in zip(ocr_outputs, render.colors_processed):\n            if not isinstance(ocrso, OcrSingleOutput) or ocrso.bbox is None:\n                # warnings.warn(\n                #     f\"Object {ocrso} is not an OcrSingleOutput or has no bbox. \"\n                #     \"Skipping it.\"\n                # )\n                continue\n            cnt = [ocrso.bbox.asarray.reshape((-1, 1, 2)).astype(np.int32)]\n            im_array = cv2.drawContours(\n                image=im_array,\n                contours=cnt,\n                contourIdx=-1,\n                thickness=render.thickness,\n                color=color,\n                lineType=render.line_type,\n            )\n        self.base.asarray = im_array\n</code></pre>"},{"location":"api/image/drawer/drawing/#otary.image.components.drawer.drawer.DrawerImage.draw_circles","title":"<code>draw_circles(circles, render=CirclesRender())</code>","text":"<p>Draw circles in the image</p> <p>Parameters:</p> Name Type Description Default <code>circles</code> <code>Sequence[Circle]</code> <p>list of Circle geometry objects.</p> required <code>render</code> <code>CirclesRender</code> <p>circle renderer</p> <code>CirclesRender()</code> Source code in <code>otary/image/components/drawer/drawer.py</code> <pre><code>def draw_circles(\n    self,\n    circles: Sequence[geo.Circle],\n    render: CirclesRender = CirclesRender(),\n) -&gt; None:\n    \"\"\"Draw circles in the image\n\n    Args:\n        circles (Sequence[Circle]): list of Circle geometry objects.\n        render (CirclesRender): circle renderer\n    \"\"\"\n    im_array = self._pre_draw(n_objects=len(circles), render=render)\n    for circle, color in zip(circles, render.colors_processed):\n        cv2.circle(  # type: ignore[call-overload]\n            img=im_array,\n            center=circle.center.astype(int),\n            radius=int(circle.radius),\n            color=color,\n            thickness=render.thickness if not render.is_filled else -1,\n            lineType=render.line_type,\n        )\n        if render.is_draw_center_point_enabled:\n            cv2.circle(  # type: ignore[call-overload]\n                img=im_array,\n                center=circle.center.astype(int),\n                radius=1,\n                color=color,\n                thickness=render.thickness,\n                lineType=render.line_type,\n            )\n    self.base.asarray = im_array\n</code></pre>"},{"location":"api/image/drawer/drawing/#otary.image.components.drawer.drawer.DrawerImage.draw_ellipses","title":"<code>draw_ellipses(ellipses, render=EllipsesRender())</code>","text":"<p>Draw ellipses in the image</p> <p>Parameters:</p> Name Type Description Default <code>ellipses</code> <code>Sequence[Ellipse]</code> <p>list of Ellipse geometry objects.</p> required <code>render</code> <code>EllipseRender</code> <p>renderer (uses EllipseRender for color/thickness)</p> <code>EllipsesRender()</code> Source code in <code>otary/image/components/drawer/drawer.py</code> <pre><code>def draw_ellipses(\n    self,\n    ellipses: Sequence[geo.Ellipse],\n    render: EllipsesRender = EllipsesRender(),\n) -&gt; None:\n    \"\"\"Draw ellipses in the image\n\n    Args:\n        ellipses (Sequence[Ellipse]): list of Ellipse geometry objects.\n        render (EllipseRender): renderer (uses EllipseRender for color/thickness)\n    \"\"\"\n    im_array = self._pre_draw(n_objects=len(ellipses), render=render)\n    for ellipse, color in zip(ellipses, render.colors_processed):\n        axes = (int(ellipse.semi_major_axis), int(ellipse.semi_minor_axis))\n        cv2.ellipse(  # type: ignore[call-overload]\n            img=im_array,\n            center=ellipse.centroid.astype(int),\n            axes=axes,\n            angle=ellipse.angle(degree=True),\n            startAngle=0,\n            endAngle=360,\n            color=color,\n            thickness=render.thickness if not render.is_filled else -1,\n            lineType=render.line_type,\n        )\n        if render.is_draw_center_point_enabled:\n            cv2.circle(  # type: ignore[call-overload]\n                img=im_array,\n                center=ellipse.centroid.astype(int),\n                radius=1,\n                color=color,\n                thickness=render.thickness,\n                lineType=render.line_type,\n            )\n        if render.is_draw_focis_enabled:\n            for foci in [ellipse.foci1, ellipse.foci2]:\n                cv2.circle(  # type: ignore[call-overload]\n                    img=im_array,\n                    center=foci.astype(int),\n                    radius=1,\n                    color=color,\n                    thickness=render.thickness,\n                    lineType=render.line_type,\n                )\n    self.base.asarray = im_array\n</code></pre>"},{"location":"api/image/drawer/drawing/#otary.image.components.drawer.drawer.DrawerImage.draw_ocr_outputs","title":"<code>draw_ocr_outputs(ocr_outputs, render=OcrSingleOutputRender())</code>","text":"<p>Return the image with the bounding boxes displayed from a list of OCR single output. It allows you to show bounding boxes that can have an angle, not necessarily vertical or horizontal.</p> <p>Parameters:</p> Name Type Description Default <code>ocr_outputs</code> <code>Sequence[OcrSingleOutput]</code> <p>list of OcrSingleOutput objects</p> required <code>render</code> <code>OcrSingleOutputRender</code> <p>OcrSingleOutputRender object</p> <code>OcrSingleOutputRender()</code> Source code in <code>otary/image/components/drawer/drawer.py</code> <pre><code>def draw_ocr_outputs(\n    self,\n    ocr_outputs: Sequence[OcrSingleOutput],\n    render: OcrSingleOutputRender = OcrSingleOutputRender(),\n) -&gt; None:\n    \"\"\"Return the image with the bounding boxes displayed from a list of OCR\n    single output. It allows you to show bounding boxes that can have an angle,\n    not necessarily vertical or horizontal.\n\n    Args:\n        ocr_outputs (Sequence[OcrSingleOutput]): list of OcrSingleOutput objects\n        render (OcrSingleOutputRender): OcrSingleOutputRender object\n    \"\"\"\n    im_array = self._pre_draw(n_objects=len(ocr_outputs), render=render)\n    for ocrso, color in zip(ocr_outputs, render.colors_processed):\n        if not isinstance(ocrso, OcrSingleOutput) or ocrso.bbox is None:\n            # warnings.warn(\n            #     f\"Object {ocrso} is not an OcrSingleOutput or has no bbox. \"\n            #     \"Skipping it.\"\n            # )\n            continue\n        cnt = [ocrso.bbox.asarray.reshape((-1, 1, 2)).astype(np.int32)]\n        im_array = cv2.drawContours(\n            image=im_array,\n            contours=cnt,\n            contourIdx=-1,\n            thickness=render.thickness,\n            color=color,\n            lineType=render.line_type,\n        )\n    self.base.asarray = im_array\n</code></pre>"},{"location":"api/image/drawer/drawing/#otary.image.components.drawer.drawer.DrawerImage.draw_points","title":"<code>draw_points(points, render=PointsRender())</code>","text":"<p>Draw points in the image</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>NDArray</code> <p>list of points. It must be of shape (n, 2). This means n points of shape 2 (x and y coordinates).</p> required <code>render</code> <code>PointsRender</code> <p>point renderer</p> <code>PointsRender()</code> Source code in <code>otary/image/components/drawer/drawer.py</code> <pre><code>def draw_points(\n    self,\n    points: NDArray | Sequence[geo.Point],\n    render: PointsRender = PointsRender(),\n) -&gt; None:\n    \"\"\"Draw points in the image\n\n    Args:\n        points (NDArray): list of points. It must be of shape (n, 2). This\n            means n points of shape 2 (x and y coordinates).\n        render (PointsRender): point renderer\n    \"\"\"\n    _points = prep_obj_draw(objects=points, _type=geo.Point)\n    im_array = self._pre_draw(n_objects=len(_points), render=render)\n    for point, color in zip(_points, render.colors_processed):\n        cv2.circle(\n            img=im_array,\n            center=point,\n            radius=render.radius,\n            color=color,\n            thickness=render.thickness,\n            lineType=render.line_type,\n        )\n    self.base.asarray = im_array\n</code></pre>"},{"location":"api/image/drawer/drawing/#otary.image.components.drawer.drawer.DrawerImage.draw_polygons","title":"<code>draw_polygons(polygons, render=PolygonsRender())</code>","text":"<p>Draw polygons in the image</p> <p>Parameters:</p> Name Type Description Default <code>polygons</code> <code>Sequence[Polygon]</code> <p>list of Polygon objects</p> required <code>render</code> <code>PolygonsRender</code> <p>PolygonRender object</p> <code>PolygonsRender()</code> Source code in <code>otary/image/components/drawer/drawer.py</code> <pre><code>def draw_polygons(\n    self, polygons: Sequence[geo.Polygon], render: PolygonsRender = PolygonsRender()\n) -&gt; None:\n    \"\"\"Draw polygons in the image\n\n    Args:\n        polygons (Sequence[Polygon]): list of Polygon objects\n        render (PolygonsRender): PolygonRender object\n    \"\"\"\n    _polygons = prep_obj_draw(objects=polygons, _type=geo.Polygon)\n    im_array = self._pre_draw(n_objects=len(_polygons), render=render)\n    for polygon, color in zip(_polygons, render.colors_processed):\n        if render.is_filled:\n            cv2.fillPoly(\n                img=im_array,\n                pts=[polygon],\n                color=color,\n                lineType=render.line_type,\n            )\n        else:\n            cv2.polylines(\n                img=im_array,\n                pts=[polygon],\n                isClosed=True,\n                color=color,\n                thickness=render.thickness,\n                lineType=render.line_type,\n            )\n    self.base.asarray = im_array\n</code></pre>"},{"location":"api/image/drawer/drawing/#otary.image.components.drawer.drawer.DrawerImage.draw_segments","title":"<code>draw_segments(segments, render=SegmentsRender())</code>","text":"<p>Draw segments in the image. It can be arrowed segments (vectors) too.</p> <p>Parameters:</p> Name Type Description Default <code>segments</code> <code>NDArray</code> <p>list of segments. Can be a numpy array of shape (n, 2, 2) which means n array of shape (2, 2) that define a segment by two 2D points.</p> required <code>render</code> <code>SegmentsRender</code> <p>segment renderer</p> <code>SegmentsRender()</code> Source code in <code>otary/image/components/drawer/drawer.py</code> <pre><code>def draw_segments(\n    self,\n    segments: NDArray | Sequence[geo.Segment],\n    render: SegmentsRender = SegmentsRender(),\n) -&gt; None:\n    \"\"\"Draw segments in the image. It can be arrowed segments (vectors) too.\n\n    Args:\n        segments (NDArray): list of segments. Can be a numpy array of shape\n            (n, 2, 2) which means n array of shape (2, 2) that define a segment\n            by two 2D points.\n        render (SegmentsRender): segment renderer\n    \"\"\"\n    _segments = prep_obj_draw(objects=segments, _type=geo.Segment)\n    im_array = self._pre_draw(n_objects=len(segments), render=render)\n    if render.as_vectors:\n        for segment, color in zip(_segments, render.colors_processed):\n            cv2.arrowedLine(\n                img=im_array,\n                pt1=segment[0],\n                pt2=segment[1],\n                color=color,\n                thickness=render.thickness,\n                line_type=render.line_type,\n                tipLength=render.tip_length / geo.Segment(segment).length,\n            )\n    else:\n        for segment, color in zip(_segments, render.colors_processed):\n            cv2.line(\n                img=im_array,\n                pt1=segment[0],\n                pt2=segment[1],\n                color=color,\n                thickness=render.thickness,\n                lineType=render.line_type,\n            )\n    self.base.asarray = im_array\n</code></pre>"},{"location":"api/image/drawer/drawing/#otary.image.components.drawer.drawer.DrawerImage.draw_splines","title":"<code>draw_splines(splines, render=LinearSplinesRender())</code>","text":"<p>Draw linear splines in the image.</p> <p>Parameters:</p> Name Type Description Default <code>splines</code> <code>Sequence[LinearSpline]</code> <p>linear splines to draw.</p> required <code>render</code> <code>LinearSplinesRender</code> <p>linear splines render. Defaults to LinearSplinesRender().</p> <code>LinearSplinesRender()</code> Source code in <code>otary/image/components/drawer/drawer.py</code> <pre><code>def draw_splines(\n    self,\n    splines: Sequence[geo.LinearSpline],\n    render: LinearSplinesRender = LinearSplinesRender(),\n) -&gt; None:\n    \"\"\"Draw linear splines in the image.\n\n    Args:\n        splines (Sequence[geo.LinearSpline]): linear splines to draw.\n        render (LinearSplinesRender, optional): linear splines render.\n            Defaults to LinearSplinesRender().\n    \"\"\"\n    _splines = prep_obj_draw(objects=splines, _type=geo.LinearSpline)\n    im_array = self._pre_draw(n_objects=len(_splines), render=render)\n    for spline, color in zip(_splines, render.colors_processed):\n\n        if render.as_vectors:\n            cv2.polylines(\n                img=im_array,\n                pts=[spline[:-1]],\n                isClosed=False,\n                color=color,\n                thickness=render.thickness,\n                lineType=render.line_type,\n            )\n\n            # Draw the last edge as a vector\n            ix = int(len(spline) * (1 - render.pct_ix_head))\n            ix = ix - 1 if ix == len(spline) - 1 else ix\n            segment = [spline[ix], spline[-1]]\n            cv2.arrowedLine(\n                img=im_array,\n                pt1=segment[0],\n                pt2=segment[1],\n                color=color,\n                thickness=render.thickness,\n                tipLength=render.tip_length / geo.Segment(segment).length,\n            )\n\n        else:\n            cv2.polylines(\n                img=im_array,\n                pts=[spline],\n                isClosed=False,\n                color=color,\n                thickness=render.thickness,\n                lineType=render.line_type,\n            )\n</code></pre>"},{"location":"api/image/drawer/renderers/","title":"Renderers","text":"<p>Drawing Render used to makes easy drawings</p>"},{"location":"api/image/drawer/renderers/#otary.image.components.drawer.utils.render.CirclesRender","title":"<code>CirclesRender</code>  <code>dataclass</code>","text":"<p>               Bases: <code>EllipsesRender</code></p> <p>Render for Circle objects</p> Source code in <code>otary/image/components/drawer/utils/render.py</code> <pre><code>@dataclass\nclass CirclesRender(EllipsesRender):\n    \"\"\"Render for Circle objects\"\"\"\n</code></pre>"},{"location":"api/image/drawer/renderers/#otary.image.components.drawer.utils.render.EllipsesRender","title":"<code>EllipsesRender</code>  <code>dataclass</code>","text":"<p>               Bases: <code>GeometryRender</code></p> <p>Render for Ellipse objects</p> Source code in <code>otary/image/components/drawer/utils/render.py</code> <pre><code>@dataclass\nclass EllipsesRender(GeometryRender):\n    \"\"\"Render for Ellipse objects\"\"\"\n\n    is_filled: bool = False\n    is_draw_focis_enabled: bool = False\n    is_draw_center_point_enabled: bool = False\n</code></pre>"},{"location":"api/image/drawer/renderers/#otary.image.components.drawer.utils.render.GeometryRender","title":"<code>GeometryRender</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Render</code>, <code>ABC</code></p> <p>Base class for the rendering of GeometryEntity objects</p> Source code in <code>otary/image/components/drawer/utils/render.py</code> <pre><code>@dataclass\nclass GeometryRender(Render, ABC):\n    \"\"\"Base class for the rendering of GeometryEntity objects\"\"\"\n</code></pre>"},{"location":"api/image/drawer/renderers/#otary.image.components.drawer.utils.render.LinearSplinesRender","title":"<code>LinearSplinesRender</code>  <code>dataclass</code>","text":"<p>               Bases: <code>SegmentsRender</code></p> <p>Render for Linear Splines objects</p> Source code in <code>otary/image/components/drawer/utils/render.py</code> <pre><code>@dataclass\nclass LinearSplinesRender(SegmentsRender):\n    \"\"\"Render for Linear Splines objects\"\"\"\n\n    pct_ix_head: float = 0.25\n</code></pre>"},{"location":"api/image/drawer/renderers/#otary.image.components.drawer.utils.render.OcrSingleOutputRender","title":"<code>OcrSingleOutputRender</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Render</code></p> <p>Render for OcrSingleOutput objects</p> Source code in <code>otary/image/components/drawer/utils/render.py</code> <pre><code>@dataclass\nclass OcrSingleOutputRender(Render):\n    \"\"\"Render for OcrSingleOutput objects\"\"\"\n</code></pre>"},{"location":"api/image/drawer/renderers/#otary.image.components.drawer.utils.render.PointsRender","title":"<code>PointsRender</code>  <code>dataclass</code>","text":"<p>               Bases: <code>GeometryRender</code></p> <p>Render for Point objects</p> Source code in <code>otary/image/components/drawer/utils/render.py</code> <pre><code>@dataclass\nclass PointsRender(GeometryRender):\n    \"\"\"Render for Point objects\"\"\"\n\n    radius: int = 1\n</code></pre>"},{"location":"api/image/drawer/renderers/#otary.image.components.drawer.utils.render.PolygonsRender","title":"<code>PolygonsRender</code>  <code>dataclass</code>","text":"<p>               Bases: <code>SegmentsRender</code></p> <p>Render for Polygon objects. It inherits from SegmentsRender because Polygons are drawn as a succession of drawn segments.</p> Source code in <code>otary/image/components/drawer/utils/render.py</code> <pre><code>@dataclass\nclass PolygonsRender(SegmentsRender):\n    \"\"\"Render for Polygon objects. It inherits from SegmentsRender because\n    Polygons are drawn as a succession of drawn segments.\"\"\"\n\n    is_filled: bool = False\n</code></pre>"},{"location":"api/image/drawer/renderers/#otary.image.components.drawer.utils.render.Render","title":"<code>Render</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Render class used to facilitate the rendering of objects when drawing them</p> Source code in <code>otary/image/components/drawer/utils/render.py</code> <pre><code>@dataclass(kw_only=True)\nclass Render(ABC):\n    \"\"\"Render class used to facilitate the rendering of objects when drawing them\"\"\"\n\n    thickness: int = DEFAULT_RENDER_THICKNESS\n    line_type: int = cv2.LINE_AA\n    default_color: tuple[int, int, int] | str = DEFAULT_RENDER_COLOR\n    colors: list[tuple[int, int, int] | str] = field(default_factory=list)\n\n    def adjust_colors_length(self, n: int) -&gt; None:\n        \"\"\"Correct the color parameter in case the objects has not the same length\n\n        Args:\n            n (int): number of objects to expect\n        \"\"\"\n        if len(self.colors) &gt; n:\n            self.colors = self.colors[:n]\n        elif len(self.colors) &lt; n:\n            n_missing = n - len(self.colors)\n            self.colors = self.colors + [self.default_color for _ in range(n_missing)]\n\n    @property\n    def default_color_processed(self) -&gt; tuple[int, int, int]:\n        \"\"\"DrawingRender default_color property\"\"\"\n        if isinstance(self.default_color, str):\n            default_color = color_str_to_tuple(self.default_color)\n            if default_color is None:\n                return DEFAULT_RENDER_COLOR\n            return default_color\n\n        if is_color_tuple(self.default_color):\n            return self.default_color\n        return DEFAULT_RENDER_COLOR\n\n    @property\n    def colors_processed(self) -&gt; list[tuple[int, int, int]]:\n        \"\"\"DrawingRender colors_processed method\"\"\"\n        colors_processed: list[tuple[int, int, int]] = []\n        for color in self.colors:\n            if isinstance(color, str):\n                tmp_color = color_str_to_tuple(color)\n                if tmp_color is None:\n                    colors_processed.append(self.default_color_processed)\n                else:\n                    colors_processed.append(tmp_color)\n            elif is_color_tuple(color):\n                colors_processed.append(color)\n            else:\n                colors_processed.append(self.default_color_processed)\n        return colors_processed\n</code></pre>"},{"location":"api/image/drawer/renderers/#otary.image.components.drawer.utils.render.Render.colors_processed","title":"<code>colors_processed</code>  <code>property</code>","text":"<p>DrawingRender colors_processed method</p>"},{"location":"api/image/drawer/renderers/#otary.image.components.drawer.utils.render.Render.default_color_processed","title":"<code>default_color_processed</code>  <code>property</code>","text":"<p>DrawingRender default_color property</p>"},{"location":"api/image/drawer/renderers/#otary.image.components.drawer.utils.render.Render.adjust_colors_length","title":"<code>adjust_colors_length(n)</code>","text":"<p>Correct the color parameter in case the objects has not the same length</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>number of objects to expect</p> required Source code in <code>otary/image/components/drawer/utils/render.py</code> <pre><code>def adjust_colors_length(self, n: int) -&gt; None:\n    \"\"\"Correct the color parameter in case the objects has not the same length\n\n    Args:\n        n (int): number of objects to expect\n    \"\"\"\n    if len(self.colors) &gt; n:\n        self.colors = self.colors[:n]\n    elif len(self.colors) &lt; n:\n        n_missing = n - len(self.colors)\n        self.colors = self.colors + [self.default_color for _ in range(n_missing)]\n</code></pre>"},{"location":"api/image/drawer/renderers/#otary.image.components.drawer.utils.render.SegmentsRender","title":"<code>SegmentsRender</code>  <code>dataclass</code>","text":"<p>               Bases: <code>GeometryRender</code></p> <p>Render for Segment objects</p> Source code in <code>otary/image/components/drawer/utils/render.py</code> <pre><code>@dataclass\nclass SegmentsRender(GeometryRender):\n    \"\"\"Render for Segment objects\"\"\"\n\n    as_vectors: bool = False\n    tip_length: int = 20\n</code></pre>"},{"location":"api/image/io/","title":"I/O","text":"<p>The <code>io</code> module provides ways to read and write image data. Reading and writing in Otary is very simple:</p> <pre><code>import otary as ot\n\nim = ot.Image.from_file(filepath=\"path/to/file/image\")\n\n# any image manipulation you can think of\n# ...\n\nim.save(save_filepath=\"path/to/file/image\")\n</code></pre>"},{"location":"api/image/io/#components","title":"Components","text":"<ul> <li>Reader: Responsible for reading image data from various sources.</li> <li>Writer: Allows you to write image data to various destinations.</li> </ul>"},{"location":"api/image/io/reader/","title":"Reader","text":"<p>The <code>reader</code> module provides ways to read image data</p> <p>Image Reader module</p>"},{"location":"api/image/io/reader/#otary.image.components.io.reader.ReaderImage","title":"<code>ReaderImage</code>","text":"<p>ReaderImage class to facilitate the reading of images from different formats such as JPG, PNG, and PDF. It provides methods to load images from file paths.</p> Source code in <code>otary/image/components/io/reader.py</code> <pre><code>class ReaderImage:\n    \"\"\"ReaderImage class to facilitate the reading of images from different formats\n    such as JPG, PNG, and PDF. It provides methods to load images from file paths.\n    \"\"\"\n\n    @staticmethod\n    def from_fillvalue(value: int = 255, shape: tuple = (128, 128, 3)) -&gt; NDArray:\n        \"\"\"Create an array image from a single value\n\n        Args:\n            value (int, optional): value in [0, 255]. Defaults to 255.\n            shape (tuple, optional): image shape. If it has three elements then\n                the last one must be a 3 for a coloscale image.\n                Defaults to (128, 128, 3).\n\n        Returns:\n            NDArray: array with a single value\n        \"\"\"\n        if value &lt; 0 or value &gt; 255:\n            raise ValueError(f\"The value {value} must be in [0, 255]\")\n        if len(shape) &lt; 2 or len(shape) &gt;= 4:\n            raise ValueError(f\"The shape {shape} must be of length 2 or 3\")\n        if len(shape) == 3 and shape[-1] != 3:\n            raise ValueError(f\"The last value of {shape} must be 3\")\n        return np.full(shape=shape, fill_value=value, dtype=np.uint8)\n\n    @staticmethod\n    def from_jpg(\n        filepath: str, as_grayscale: bool = False, resolution: Optional[int] = None\n    ) -&gt; NDArray:\n        \"\"\"Create a Image object from a JPG or JPEG file path\n\n        Args:\n            filepath (str): path to the JPG image file\n            as_grayscale (bool, optional): turn the image in grayscale.\n                Defaults to False.\n\n        Returns:\n            NDArray: numpy array\n        \"\"\"\n        arr = np.asarray(cv2.imread(filepath, 1 - int(as_grayscale)))\n        original_height, original_width = arr.shape[:2]\n\n        if resolution is not None:\n            # Calculate the aspect ratio\n            aspect_ratio = original_width / original_height\n            new_width = int(resolution * aspect_ratio)\n            arr = cv2.resize(src=arr, dsize=(new_width, resolution))\n\n        return arr\n\n    @staticmethod\n    def from_png(\n        filepath: str, as_grayscale: bool = False, resolution: Optional[int] = None\n    ) -&gt; NDArray:\n        \"\"\"Create a Image array from a PNG file image path\n\n        Args:\n            filepath (str): path to the image file\n            as_grayscale (bool, optional): turn the image in grayscale.\n                Defaults to False.\n\n        Returns:\n            NDArray: Image as array\n        \"\"\"\n        return ReaderImage.from_jpg(\n            filepath=filepath, as_grayscale=as_grayscale, resolution=resolution\n        )\n\n    @staticmethod\n    def from_pdf(\n        filepath: str,\n        as_grayscale: bool = False,\n        page_nb: int = 0,\n        resolution: Optional[int] = None,\n        clip_pct: Optional[AxisAlignedRectangle] = None,\n    ) -&gt; NDArray:\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        \"\"\"Create an Image array from a pdf file.\n\n        Args:\n            filepath (str): path to the pdf file.\n            as_grayscale (bool, optional): whether to turn the image in grayscale.\n                Defaults to False.\n            page_nb (int, optional): as we load only one image we have to select the\n                page that will be turned into an image. Defaults to 0.\n            resolution (Optional[int], optional): resolution of the loaded image.\n                Defaults to 3508.\n            clip_pct (AxisAlignedRectangle, optional): optional zone to extract in the\n                image. This is particularly useful to load into memory only a small\n                part of the image without loading everything into memory.\n                This reduces considerably the image loading time especially combined\n                with a high resolution.\n\n        Returns:\n            NDArray: Image as array\n        \"\"\"\n        arr = read_pdf_to_images(\n            filepath_or_stream=filepath,\n            resolution=resolution,\n            page_nb=page_nb,\n            clip_pct=clip_pct,\n        )[0]\n\n        if as_grayscale:\n            arr = cv2.cvtColor(arr, cv2.COLOR_BGR2GRAY)\n\n        return arr\n\n    @staticmethod\n    def from_file(\n        filepath: str, as_grayscale: bool = False, resolution: Optional[int] = None\n    ) -&gt; NDArray:\n        \"\"\"Create a Image array from a file image path\n\n        Args:\n            filepath (str): path to the image file\n            as_grayscale (bool, optional): turn the image in grayscale.\n                Defaults to False.\n\n        Returns:\n            NDArray: Image as array\n        \"\"\"\n        valid_format = [\"png\", \"jpg\", \"jpeg\", \"pdf\"]\n\n        file_format = filepath.split(\".\")[-1]\n\n        if file_format in [\"png\"]:\n            return ReaderImage.from_png(\n                filepath=filepath, as_grayscale=as_grayscale, resolution=resolution\n            )\n        if file_format in [\"jpg\", \"jpeg\"]:\n            return ReaderImage.from_jpg(\n                filepath=filepath, as_grayscale=as_grayscale, resolution=resolution\n            )\n        if file_format in [\"pdf\"]:\n            return ReaderImage.from_pdf(\n                filepath=filepath, as_grayscale=as_grayscale, resolution=resolution\n            )\n\n        raise ValueError(f\"The filepath is not in any valid format {valid_format}\")\n</code></pre>"},{"location":"api/image/io/reader/#otary.image.components.io.reader.ReaderImage.from_file","title":"<code>from_file(filepath, as_grayscale=False, resolution=None)</code>  <code>staticmethod</code>","text":"<p>Create a Image array from a file image path</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>path to the image file</p> required <code>as_grayscale</code> <code>bool</code> <p>turn the image in grayscale. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>Image as array</p> Source code in <code>otary/image/components/io/reader.py</code> <pre><code>@staticmethod\ndef from_file(\n    filepath: str, as_grayscale: bool = False, resolution: Optional[int] = None\n) -&gt; NDArray:\n    \"\"\"Create a Image array from a file image path\n\n    Args:\n        filepath (str): path to the image file\n        as_grayscale (bool, optional): turn the image in grayscale.\n            Defaults to False.\n\n    Returns:\n        NDArray: Image as array\n    \"\"\"\n    valid_format = [\"png\", \"jpg\", \"jpeg\", \"pdf\"]\n\n    file_format = filepath.split(\".\")[-1]\n\n    if file_format in [\"png\"]:\n        return ReaderImage.from_png(\n            filepath=filepath, as_grayscale=as_grayscale, resolution=resolution\n        )\n    if file_format in [\"jpg\", \"jpeg\"]:\n        return ReaderImage.from_jpg(\n            filepath=filepath, as_grayscale=as_grayscale, resolution=resolution\n        )\n    if file_format in [\"pdf\"]:\n        return ReaderImage.from_pdf(\n            filepath=filepath, as_grayscale=as_grayscale, resolution=resolution\n        )\n\n    raise ValueError(f\"The filepath is not in any valid format {valid_format}\")\n</code></pre>"},{"location":"api/image/io/reader/#otary.image.components.io.reader.ReaderImage.from_fillvalue","title":"<code>from_fillvalue(value=255, shape=(128, 128, 3))</code>  <code>staticmethod</code>","text":"<p>Create an array image from a single value</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int</code> <p>value in [0, 255]. Defaults to 255.</p> <code>255</code> <code>shape</code> <code>tuple</code> <p>image shape. If it has three elements then the last one must be a 3 for a coloscale image. Defaults to (128, 128, 3).</p> <code>(128, 128, 3)</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>array with a single value</p> Source code in <code>otary/image/components/io/reader.py</code> <pre><code>@staticmethod\ndef from_fillvalue(value: int = 255, shape: tuple = (128, 128, 3)) -&gt; NDArray:\n    \"\"\"Create an array image from a single value\n\n    Args:\n        value (int, optional): value in [0, 255]. Defaults to 255.\n        shape (tuple, optional): image shape. If it has three elements then\n            the last one must be a 3 for a coloscale image.\n            Defaults to (128, 128, 3).\n\n    Returns:\n        NDArray: array with a single value\n    \"\"\"\n    if value &lt; 0 or value &gt; 255:\n        raise ValueError(f\"The value {value} must be in [0, 255]\")\n    if len(shape) &lt; 2 or len(shape) &gt;= 4:\n        raise ValueError(f\"The shape {shape} must be of length 2 or 3\")\n    if len(shape) == 3 and shape[-1] != 3:\n        raise ValueError(f\"The last value of {shape} must be 3\")\n    return np.full(shape=shape, fill_value=value, dtype=np.uint8)\n</code></pre>"},{"location":"api/image/io/reader/#otary.image.components.io.reader.ReaderImage.from_jpg","title":"<code>from_jpg(filepath, as_grayscale=False, resolution=None)</code>  <code>staticmethod</code>","text":"<p>Create a Image object from a JPG or JPEG file path</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>path to the JPG image file</p> required <code>as_grayscale</code> <code>bool</code> <p>turn the image in grayscale. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>numpy array</p> Source code in <code>otary/image/components/io/reader.py</code> <pre><code>@staticmethod\ndef from_jpg(\n    filepath: str, as_grayscale: bool = False, resolution: Optional[int] = None\n) -&gt; NDArray:\n    \"\"\"Create a Image object from a JPG or JPEG file path\n\n    Args:\n        filepath (str): path to the JPG image file\n        as_grayscale (bool, optional): turn the image in grayscale.\n            Defaults to False.\n\n    Returns:\n        NDArray: numpy array\n    \"\"\"\n    arr = np.asarray(cv2.imread(filepath, 1 - int(as_grayscale)))\n    original_height, original_width = arr.shape[:2]\n\n    if resolution is not None:\n        # Calculate the aspect ratio\n        aspect_ratio = original_width / original_height\n        new_width = int(resolution * aspect_ratio)\n        arr = cv2.resize(src=arr, dsize=(new_width, resolution))\n\n    return arr\n</code></pre>"},{"location":"api/image/io/reader/#otary.image.components.io.reader.ReaderImage.from_pdf","title":"<code>from_pdf(filepath, as_grayscale=False, page_nb=0, resolution=None, clip_pct=None)</code>  <code>staticmethod</code>","text":"<p>Create an Image array from a pdf file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>path to the pdf file.</p> required <code>as_grayscale</code> <code>bool</code> <p>whether to turn the image in grayscale. Defaults to False.</p> <code>False</code> <code>page_nb</code> <code>int</code> <p>as we load only one image we have to select the page that will be turned into an image. Defaults to 0.</p> <code>0</code> <code>resolution</code> <code>Optional[int]</code> <p>resolution of the loaded image. Defaults to 3508.</p> <code>None</code> <code>clip_pct</code> <code>AxisAlignedRectangle</code> <p>optional zone to extract in the image. This is particularly useful to load into memory only a small part of the image without loading everything into memory. This reduces considerably the image loading time especially combined with a high resolution.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>Image as array</p> Source code in <code>otary/image/components/io/reader.py</code> <pre><code>@staticmethod\ndef from_pdf(\n    filepath: str,\n    as_grayscale: bool = False,\n    page_nb: int = 0,\n    resolution: Optional[int] = None,\n    clip_pct: Optional[AxisAlignedRectangle] = None,\n) -&gt; NDArray:\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    \"\"\"Create an Image array from a pdf file.\n\n    Args:\n        filepath (str): path to the pdf file.\n        as_grayscale (bool, optional): whether to turn the image in grayscale.\n            Defaults to False.\n        page_nb (int, optional): as we load only one image we have to select the\n            page that will be turned into an image. Defaults to 0.\n        resolution (Optional[int], optional): resolution of the loaded image.\n            Defaults to 3508.\n        clip_pct (AxisAlignedRectangle, optional): optional zone to extract in the\n            image. This is particularly useful to load into memory only a small\n            part of the image without loading everything into memory.\n            This reduces considerably the image loading time especially combined\n            with a high resolution.\n\n    Returns:\n        NDArray: Image as array\n    \"\"\"\n    arr = read_pdf_to_images(\n        filepath_or_stream=filepath,\n        resolution=resolution,\n        page_nb=page_nb,\n        clip_pct=clip_pct,\n    )[0]\n\n    if as_grayscale:\n        arr = cv2.cvtColor(arr, cv2.COLOR_BGR2GRAY)\n\n    return arr\n</code></pre>"},{"location":"api/image/io/reader/#otary.image.components.io.reader.ReaderImage.from_png","title":"<code>from_png(filepath, as_grayscale=False, resolution=None)</code>  <code>staticmethod</code>","text":"<p>Create a Image array from a PNG file image path</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>path to the image file</p> required <code>as_grayscale</code> <code>bool</code> <p>turn the image in grayscale. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>Image as array</p> Source code in <code>otary/image/components/io/reader.py</code> <pre><code>@staticmethod\ndef from_png(\n    filepath: str, as_grayscale: bool = False, resolution: Optional[int] = None\n) -&gt; NDArray:\n    \"\"\"Create a Image array from a PNG file image path\n\n    Args:\n        filepath (str): path to the image file\n        as_grayscale (bool, optional): turn the image in grayscale.\n            Defaults to False.\n\n    Returns:\n        NDArray: Image as array\n    \"\"\"\n    return ReaderImage.from_jpg(\n        filepath=filepath, as_grayscale=as_grayscale, resolution=resolution\n    )\n</code></pre>"},{"location":"api/image/io/writer/","title":"Writer","text":"<p>The <code>writer</code> module provides ways to write image data.</p> <p>WriterImage module</p>"},{"location":"api/image/io/writer/#otary.image.components.io.writer.WriterImage","title":"<code>WriterImage</code>","text":"<p>WriterImage class that provide methods to save and show the image</p> Source code in <code>otary/image/components/io/writer.py</code> <pre><code>class WriterImage:\n    \"\"\"WriterImage class that provide methods to save and show the image\"\"\"\n\n    def __init__(self, base: BaseImage) -&gt; None:\n        self.base = base\n\n    def show(\n        self,\n        figsize: tuple[float, float] = (-1, -1),\n        popup_window_display: bool = False,\n    ) -&gt; ImagePIL.Image:\n        \"\"\"Show the image\n\n        Args:\n            figsize (tuple[float, float], optional): size of the figure.\n                Defaults to (-1, -1), meaning the original size of the image.\n            popup_window_display (bool, optional): whether to display the image in a\n                popup window. Defaults to False.\n        \"\"\"\n        if figsize[0] &lt;= 0 and figsize[1] &lt;= 0:\n            figsize = (self.base.width, self.base.height)\n        else:\n            if figsize[1] &lt;= 0:\n                aspect_ratio = self.base.height / self.base.width\n                figsize = (figsize[0], figsize[0] * aspect_ratio)\n\n            elif figsize[0] &lt;= 0:\n                aspect_ratio = self.base.width / self.base.height\n                figsize = (figsize[1] * aspect_ratio, figsize[1])\n\n        figsize = (int(figsize[0]), int(figsize[1]))\n\n        self.base.as_reversed_color_channel()\n        im = self.base.as_pil().resize(size=figsize)\n\n        if popup_window_display:\n            im.show()\n\n        return im\n\n    def save(self, fp: str) -&gt; None:\n        \"\"\"Save the image in a local file\n\n        Args:\n            fp (str): fp stands for filepath which is the path to the file\n        \"\"\"\n        self.base.as_reversed_color_channel().as_pil().save(fp)\n</code></pre>"},{"location":"api/image/io/writer/#otary.image.components.io.writer.WriterImage.save","title":"<code>save(fp)</code>","text":"<p>Save the image in a local file</p> <p>Parameters:</p> Name Type Description Default <code>fp</code> <code>str</code> <p>fp stands for filepath which is the path to the file</p> required Source code in <code>otary/image/components/io/writer.py</code> <pre><code>def save(self, fp: str) -&gt; None:\n    \"\"\"Save the image in a local file\n\n    Args:\n        fp (str): fp stands for filepath which is the path to the file\n    \"\"\"\n    self.base.as_reversed_color_channel().as_pil().save(fp)\n</code></pre>"},{"location":"api/image/io/writer/#otary.image.components.io.writer.WriterImage.show","title":"<code>show(figsize=(-1, -1), popup_window_display=False)</code>","text":"<p>Show the image</p> <p>Parameters:</p> Name Type Description Default <code>figsize</code> <code>tuple[float, float]</code> <p>size of the figure. Defaults to (-1, -1), meaning the original size of the image.</p> <code>(-1, -1)</code> <code>popup_window_display</code> <code>bool</code> <p>whether to display the image in a popup window. Defaults to False.</p> <code>False</code> Source code in <code>otary/image/components/io/writer.py</code> <pre><code>def show(\n    self,\n    figsize: tuple[float, float] = (-1, -1),\n    popup_window_display: bool = False,\n) -&gt; ImagePIL.Image:\n    \"\"\"Show the image\n\n    Args:\n        figsize (tuple[float, float], optional): size of the figure.\n            Defaults to (-1, -1), meaning the original size of the image.\n        popup_window_display (bool, optional): whether to display the image in a\n            popup window. Defaults to False.\n    \"\"\"\n    if figsize[0] &lt;= 0 and figsize[1] &lt;= 0:\n        figsize = (self.base.width, self.base.height)\n    else:\n        if figsize[1] &lt;= 0:\n            aspect_ratio = self.base.height / self.base.width\n            figsize = (figsize[0], figsize[0] * aspect_ratio)\n\n        elif figsize[0] &lt;= 0:\n            aspect_ratio = self.base.width / self.base.height\n            figsize = (figsize[1] * aspect_ratio, figsize[1])\n\n    figsize = (int(figsize[0]), int(figsize[1]))\n\n    self.base.as_reversed_color_channel()\n    im = self.base.as_pil().resize(size=figsize)\n\n    if popup_window_display:\n        im.show()\n\n    return im\n</code></pre>"},{"location":"api/image/transformers/","title":"Transformers","text":"<p>Transformers can be accessed using the <code>transformer</code> attribute of the image object. From here you can access all the specific transformer attributes: <code>cropper</code>, <code>geometrizer</code>, <code>morphologyzer</code>, <code>binarizer</code>.</p> <p>However to make the developer experience more user friendly, the transformers are also available as direct methods of the image object. For example, cropping an image is as easy as:</p> <pre><code>import otary as ot\n\nim = ot.Image.from_file(filepath=\"path/to/file/image\")\n\nim.crop(x0=50, y0=50, x1=450, y1=450)\n</code></pre> <p>Otary gives you the choice between being more explicit or more synthetic in your code.</p>"},{"location":"api/image/transformers/#components","title":"Components","text":"<p>Here are the different specialized components that can be used to transform images:</p> <ul> <li>Cropping: cropping methods</li> <li>Geometry: geometric operations</li> <li>Morphology: morphological operations</li> <li>Binarization &amp; Thresholding: binarization and thresholding</li> </ul>"},{"location":"api/image/transformers/#the-copy-parameter","title":"The <code>copy</code> parameter","text":"<p>Some methods (all the cropping methods, some morphology methods like resize, etc...) have a boolean <code>copy</code> parameter.</p> <p>By default, the <code>copy</code> parameter is set to <code>False</code> which means that the original image is modified and then returned. This is the default behaviour of all the methods in the Otary library.</p> <p>However, when <code>copy</code> is set to <code>True</code>, a new <code>Image</code> object is returned and the original image is not modified. This is useful when you want to create a new image after the transformation without modifying the original image.</p> <p>Consider an example where you want to crop an image:</p> <p>Wrong way of cropping and preserving the original image</p> <p>This approach works but can be considerably slower especially when the image is large because you first copy the image and then crop it.</p> <pre><code>import otary as ot\n\nim = ot.Image.from_file(filepath=\"path/to/file/image\")\n\nim_crop = im.copy().crop(x0=50, y0=50, x1=450, y1=450)\n</code></pre> <p>This would instead be the correct way to crop and preserve the original image:</p> <p>Good way of cropping and preserving the original image</p> <pre><code>import otary as ot\n\nim = ot.Image.from_file(filepath=\"path/to/file/image\")\n\nim_crop = im.crop(x0=50, y0=50, x1=450, y1=450, copy=True)\n</code></pre>"},{"location":"api/image/transformers/cropping/","title":"Cropping","text":"<p>Cropper Transformer component</p>"},{"location":"api/image/transformers/cropping/#otary.image.components.transformer.components.cropper.cropper.CropperImage","title":"<code>CropperImage</code>","text":"<p>CropperImage class</p> Source code in <code>otary/image/components/transformer/components/cropper/cropper.py</code> <pre><code>class CropperImage:\n    \"\"\"CropperImage class\"\"\"\n\n    def __init__(self, base: BaseImage) -&gt; None:\n        self.base = base\n\n    def __crop_with_padding(\n        self, x0: int, y0: int, x1: int, y1: int, pad_value: int = 0\n    ) -&gt; NDArray:\n        \"\"\"Crop the image in a straight axis-aligned rectangle way given\n        by the top-left point [x0, y0] and the bottom-right point [x1, y1].\n\n        This method is specific to crop with padding meaning that if the\n        coordinates are out of the image bounds, the padding is added to the\n        output cropped image with the pad value parameter, black by default.\n\n        Args:\n            x0 (int): x coordinate of the top-left point\n            y0 (int): y coordinate of the top-left point\n            x1 (int): x coordinate of the bottom-right point\n            y1 (int): y coordinate of the bottom-right point\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            NDArray: output cropped image\n        \"\"\"\n        # pylint: disable=too-many-locals\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n\n        # Output size\n        crop_width = x1 - x0\n        crop_height = y1 - y0\n\n        # Initialize output with black (zeros), same dtype and channel count\n        channels = 1 if self.base.is_gray else self.base.asarray.shape[2]\n        output_shape = (\n            (crop_height, crop_width)\n            if channels == 1\n            else (crop_height, crop_width, channels)\n        )\n        result = np.full(shape=output_shape, fill_value=pad_value, dtype=np.uint8)\n\n        # Compute the intersection of crop with image bounds\n        ix0 = max(x0, 0)\n        iy0 = max(y0, 0)\n        ix1 = min(x1, self.base.width)\n        iy1 = min(y1, self.base.height)\n\n        # Compute corresponding position in output\n        ox0 = ix0 - x0\n        oy0 = iy0 - y0\n        ox1 = ox0 + (ix1 - ix0)\n        oy1 = oy0 + (iy1 - iy0)\n\n        # Copy the valid region\n        result[oy0:oy1, ox0:ox1] = self.base.asarray[iy0:iy1, ix0:ix1]\n\n        return result\n\n    def __crop_with_clipping(self, x0: int, y0: int, x1: int, y1: int) -&gt; NDArray:\n        \"\"\"Crop the image in a straight axis-aligned rectangle way given\n        by the top-left point [x0, y0] and the bottom-right point [x1, y1].\n\n        Crop by clipping meaning that if the coordinates are out of the image\n        bounds the output is only the part of the image that is in the bounds.\n\n        Args:\n            x0 (int): x coordinate of the top-left point\n            y0 (int): y coordinate of the top-left point\n            x1 (int): x coordinate of the bottom-right point\n            y1 (int): y coordinate of the bottom-right point\n\n        Returns:\n            Self: image cropped\n        \"\"\"\n        x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n\n        if x0 &gt;= self.base.width or y0 &gt;= self.base.height or x1 &lt;= 0 or y1 &lt;= 0:\n            raise ValueError(\n                f\"The coordinates ({x0}, {y0}, {x1}, {y1}) are out of the image \"\n                f\"boundaries (width={self.base.width}, height={self.base.height}). \"\n                \"No crop is possible.\"\n            )\n\n        def clip(value: int, min_value: int, max_value: int) -&gt; int:\n            return int(max(min_value, min(value, max_value)))\n\n        x0 = clip(x0, 0, self.base.width)\n        y0 = clip(y0, 0, self.base.height)\n        x1 = clip(x1, 0, self.base.width)\n        y1 = clip(y1, 0, self.base.height)\n\n        result = self.base.asarray[y0:y1, x0:x1]\n        return result\n\n    def crop(\n        self,\n        x0: int,\n        y0: int,\n        x1: int,\n        y1: int,\n        clip: bool = True,\n        pad: bool = False,\n        copy: bool = False,\n        extra_border_size: int = 0,\n        pad_value: int = 0,\n    ) -&gt; Optional[Image]:\n        \"\"\"Crop the image in a straight axis-aligned rectangle way given\n        by the top-left point [x0, y0] and the bottom-right point [x1, y1]\n\n        This function inputs represents the top-left and bottom-right points.\n        This method does not provide a way to extract a rotated rectangle or a\n        different shape from the image.\n\n        Remember that in this library the x coordinates represent the y coordinates of\n        the image array (horizontal axis of the image).\n        The array representation is always rows then columns.\n        In this library this is the contrary like in opencv.\n\n        Args:\n            x0 (int): top-left x coordinate\n            y0 (int): top-left y coordinate\n            x1 (int): bottom-right x coordinate\n            y1 (int): bottom-right y coordinate\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Optional[Image]: cropped image if copy=True else None\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        if (clip and pad) or (not clip and not pad):\n            raise ValueError(f\"Parameters clip and pad cannot be both {clip}\")\n\n        if clip and not pad:\n            array_crop = self.__crop_with_clipping(\n                x0=x0 - extra_border_size,\n                y0=y0 - extra_border_size,\n                x1=x1 + extra_border_size,\n                y1=y1 + extra_border_size,\n            )\n        else:  # pad and not clip:\n            array_crop = self.__crop_with_padding(\n                x0=x0 - extra_border_size,\n                y0=y0 - extra_border_size,\n                x1=x1 + extra_border_size,\n                y1=y1 + extra_border_size,\n                pad_value=pad_value,\n            )\n\n        if copy:\n            # really important feature to allow new image from original\n            # without the user doing image.copy().crop()\n            # which would be much more expensive if the image is large\n            # this is why the output of the methods is Optional[Image] not None\n            # pylint: disable=import-outside-toplevel\n            from otary.image import Image\n\n            return Image(image=array_crop)\n\n        self.base.asarray = array_crop\n        return None\n\n    def crop_from_topleft(\n        self,\n        topleft: np.ndarray,\n        width: int,\n        height: int,\n        clip: bool = True,\n        pad: bool = False,\n        copy: bool = False,\n        extra_border_size: int = 0,\n        pad_value: int = 0,\n    ) -&gt; Optional[Image]:\n        \"\"\"Crop the image from a rectangle defined by its top-left point, its width and\n        its height.\n\n        Args:\n            topleft (np.ndarray): (x, y) coordinates of the top-left point\n            width (int): width of the rectangle to crop\n            height (int): height of the rectangle to crop\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Optional[Image]: image cropped if copy=True else None\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        return self.crop(\n            x0=topleft[0],\n            y0=topleft[1],\n            x1=topleft[0] + width,\n            y1=topleft[1] + height,\n            clip=clip,\n            pad=pad,\n            copy=copy,\n            extra_border_size=extra_border_size,\n            pad_value=pad_value,\n        )\n\n    def crop_from_center(\n        self,\n        center: NDArray,\n        width: int,\n        height: int,\n        clip: bool = True,\n        pad: bool = False,\n        copy: bool = False,\n        extra_border_size: int = 0,\n        pad_value: int = 0,\n    ) -&gt; Optional[Image]:\n        \"\"\"Crop the image from a rectangle defined by its center point, its width and\n        its height.\n\n        Args:\n            center (NDArray): (x, y) coordinates of the center point\n            width (int): width of the rectangle to crop\n            height (int): height of the rectangle to crop\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Optional[Image]: image cropped if copy=True else None\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        return self.crop_from_topleft(\n            topleft=center - np.array([width / 2, height / 2]),\n            width=width,\n            height=height,\n            clip=clip,\n            pad=pad,\n            copy=copy,\n            extra_border_size=extra_border_size,\n            pad_value=pad_value,\n        )\n\n    def crop_from_polygon(\n        self,\n        polygon: geo.Polygon,\n        copy: bool = False,\n        clip: bool = True,\n        pad: bool = False,\n        extra_border_size: int = 0,\n        pad_value: int = 0,\n    ) -&gt; Optional[Image]:\n        \"\"\"\n        Crops the image using the bounding box defined by a polygon.\n\n        Args:\n            polygon (geo.Polygon): The polygon whose bounding box will be used for\n                cropping.\n            copy (bool, optional): If True, returns a copy of the cropped image.\n                Defaults to False.\n            clip (bool, optional): If True, clips the crop region to the image\n                boundaries. Defaults to True.\n            pad (bool, optional): If True, pads the cropped region if it extends beyond\n                the image boundaries. Defaults to False.\n            extra_border_size (int, optional): Additional border size to add around the\n                cropped region. Defaults to 0.\n            pad_value (int, optional): Value to use for padding if pad is True.\n                Defaults to 0.\n\n        Returns:\n            Optional[Image]: The cropped image\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        return self.crop(\n            x0=int(polygon.xmin),\n            y0=int(polygon.ymin),\n            x1=int(polygon.xmax),\n            y1=int(polygon.ymax),\n            copy=copy,\n            clip=clip,\n            pad=pad,\n            extra_border_size=extra_border_size,\n            pad_value=pad_value,\n        )\n\n    def crop_from_linear_spline(\n        self,\n        spline: geo.LinearSpline,\n        copy: bool = False,\n        clip: bool = True,\n        pad: bool = False,\n        extra_border_size: int = 0,\n        pad_value: int = 0,\n    ) -&gt; Optional[Image]:\n        \"\"\"\n        Crops the image using the bounding box defined by a linear spline.\n\n        Args:\n            spline (geo.LinearSpline): The linear spline object defining the crop\n                region.\n            copy (bool, optional): If True, returns a copy of the cropped image.\n                Defaults to False.\n            clip (bool, optional): If True, clips the crop region to the image\n                boundaries. Defaults to True.\n            pad (bool, optional): If True, pads the cropped region if it extends beyond\n                the image boundaries. Defaults to False.\n            extra_border_size (int, optional): Additional border size to add around the\n                cropped region. Defaults to 0.\n            pad_value (int, optional): Value to use for padding if pad is True.\n                Defaults to 0.\n\n        Returns:\n            Optional[Image]: The cropped image\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        return self.crop(\n            x0=int(spline.xmin),\n            y0=int(spline.ymin),\n            x1=int(spline.xmax),\n            y1=int(spline.ymax),\n            copy=copy,\n            clip=clip,\n            pad=pad,\n            extra_border_size=extra_border_size,\n            pad_value=pad_value,\n        )\n\n    def crop_from_axis_aligned_rectangle(\n        self,\n        bbox: geo.AxisAlignedRectangle,\n        clip: bool = True,\n        pad: bool = False,\n        copy: bool = False,\n        extra_border_size: int = 0,\n        pad_value: int = 0,\n    ) -&gt; Optional[Image]:\n        \"\"\"Crop the image from an Axis-Aligned Bounding Box (AABB).\n        Inclusive crops which means that the cropped image will have\n        width and height equal to the width and height of the AABB.\n\n        Args:\n            bbox (geo.AxisAlignedRectangle): axis-aligned rectangle bounding box\n            clip (bool, optional): whether to clip or not. Defaults to True.\n            pad (bool, optional): whether to pad or not. Defaults to False.\n            copy (bool, optional): whether to copy or not. Defaults to False.\n            extra_border_size (int, optional): extra border size to add to the crop\n                in the x and y directions. Defaults to 0 which means no extra border.\n            pad_value (int, optional): pad fill value. Defaults to 0.\n\n        Returns:\n            Optional[Image]: cropped image if copy=True else None\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        topleft = np.asarray([bbox.xmin, bbox.ymin])\n        height = int(bbox.ymax - bbox.ymin + 1)\n        width = int(bbox.xmax - bbox.xmin + 1)\n        return self.crop_from_topleft(\n            topleft=topleft,\n            width=width,\n            height=height,\n            clip=clip,\n            pad=pad,\n            copy=copy,\n            extra_border_size=extra_border_size,\n            pad_value=pad_value,\n        )\n</code></pre>"},{"location":"api/image/transformers/cropping/#otary.image.components.transformer.components.cropper.cropper.CropperImage.__crop_with_clipping","title":"<code>__crop_with_clipping(x0, y0, x1, y1)</code>","text":"<p>Crop the image in a straight axis-aligned rectangle way given by the top-left point [x0, y0] and the bottom-right point [x1, y1].</p> <p>Crop by clipping meaning that if the coordinates are out of the image bounds the output is only the part of the image that is in the bounds.</p> <p>Parameters:</p> Name Type Description Default <code>x0</code> <code>int</code> <p>x coordinate of the top-left point</p> required <code>y0</code> <code>int</code> <p>y coordinate of the top-left point</p> required <code>x1</code> <code>int</code> <p>x coordinate of the bottom-right point</p> required <code>y1</code> <code>int</code> <p>y coordinate of the bottom-right point</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>NDArray</code> <p>image cropped</p> Source code in <code>otary/image/components/transformer/components/cropper/cropper.py</code> <pre><code>def __crop_with_clipping(self, x0: int, y0: int, x1: int, y1: int) -&gt; NDArray:\n    \"\"\"Crop the image in a straight axis-aligned rectangle way given\n    by the top-left point [x0, y0] and the bottom-right point [x1, y1].\n\n    Crop by clipping meaning that if the coordinates are out of the image\n    bounds the output is only the part of the image that is in the bounds.\n\n    Args:\n        x0 (int): x coordinate of the top-left point\n        y0 (int): y coordinate of the top-left point\n        x1 (int): x coordinate of the bottom-right point\n        y1 (int): y coordinate of the bottom-right point\n\n    Returns:\n        Self: image cropped\n    \"\"\"\n    x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n\n    if x0 &gt;= self.base.width or y0 &gt;= self.base.height or x1 &lt;= 0 or y1 &lt;= 0:\n        raise ValueError(\n            f\"The coordinates ({x0}, {y0}, {x1}, {y1}) are out of the image \"\n            f\"boundaries (width={self.base.width}, height={self.base.height}). \"\n            \"No crop is possible.\"\n        )\n\n    def clip(value: int, min_value: int, max_value: int) -&gt; int:\n        return int(max(min_value, min(value, max_value)))\n\n    x0 = clip(x0, 0, self.base.width)\n    y0 = clip(y0, 0, self.base.height)\n    x1 = clip(x1, 0, self.base.width)\n    y1 = clip(y1, 0, self.base.height)\n\n    result = self.base.asarray[y0:y1, x0:x1]\n    return result\n</code></pre>"},{"location":"api/image/transformers/cropping/#otary.image.components.transformer.components.cropper.cropper.CropperImage.__crop_with_padding","title":"<code>__crop_with_padding(x0, y0, x1, y1, pad_value=0)</code>","text":"<p>Crop the image in a straight axis-aligned rectangle way given by the top-left point [x0, y0] and the bottom-right point [x1, y1].</p> <p>This method is specific to crop with padding meaning that if the coordinates are out of the image bounds, the padding is added to the output cropped image with the pad value parameter, black by default.</p> <p>Parameters:</p> Name Type Description Default <code>x0</code> <code>int</code> <p>x coordinate of the top-left point</p> required <code>y0</code> <code>int</code> <p>y coordinate of the top-left point</p> required <code>x1</code> <code>int</code> <p>x coordinate of the bottom-right point</p> required <code>y1</code> <code>int</code> <p>y coordinate of the bottom-right point</p> required <code>pad_value</code> <code>int</code> <p>pad fill value. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>output cropped image</p> Source code in <code>otary/image/components/transformer/components/cropper/cropper.py</code> <pre><code>def __crop_with_padding(\n    self, x0: int, y0: int, x1: int, y1: int, pad_value: int = 0\n) -&gt; NDArray:\n    \"\"\"Crop the image in a straight axis-aligned rectangle way given\n    by the top-left point [x0, y0] and the bottom-right point [x1, y1].\n\n    This method is specific to crop with padding meaning that if the\n    coordinates are out of the image bounds, the padding is added to the\n    output cropped image with the pad value parameter, black by default.\n\n    Args:\n        x0 (int): x coordinate of the top-left point\n        y0 (int): y coordinate of the top-left point\n        x1 (int): x coordinate of the bottom-right point\n        y1 (int): y coordinate of the bottom-right point\n        pad_value (int, optional): pad fill value. Defaults to 0.\n\n    Returns:\n        NDArray: output cropped image\n    \"\"\"\n    # pylint: disable=too-many-locals\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n\n    # Output size\n    crop_width = x1 - x0\n    crop_height = y1 - y0\n\n    # Initialize output with black (zeros), same dtype and channel count\n    channels = 1 if self.base.is_gray else self.base.asarray.shape[2]\n    output_shape = (\n        (crop_height, crop_width)\n        if channels == 1\n        else (crop_height, crop_width, channels)\n    )\n    result = np.full(shape=output_shape, fill_value=pad_value, dtype=np.uint8)\n\n    # Compute the intersection of crop with image bounds\n    ix0 = max(x0, 0)\n    iy0 = max(y0, 0)\n    ix1 = min(x1, self.base.width)\n    iy1 = min(y1, self.base.height)\n\n    # Compute corresponding position in output\n    ox0 = ix0 - x0\n    oy0 = iy0 - y0\n    ox1 = ox0 + (ix1 - ix0)\n    oy1 = oy0 + (iy1 - iy0)\n\n    # Copy the valid region\n    result[oy0:oy1, ox0:ox1] = self.base.asarray[iy0:iy1, ix0:ix1]\n\n    return result\n</code></pre>"},{"location":"api/image/transformers/cropping/#otary.image.components.transformer.components.cropper.cropper.CropperImage.crop","title":"<code>crop(x0, y0, x1, y1, clip=True, pad=False, copy=False, extra_border_size=0, pad_value=0)</code>","text":"<p>Crop the image in a straight axis-aligned rectangle way given by the top-left point [x0, y0] and the bottom-right point [x1, y1]</p> <p>This function inputs represents the top-left and bottom-right points. This method does not provide a way to extract a rotated rectangle or a different shape from the image.</p> <p>Remember that in this library the x coordinates represent the y coordinates of the image array (horizontal axis of the image). The array representation is always rows then columns. In this library this is the contrary like in opencv.</p> <p>Parameters:</p> Name Type Description Default <code>x0</code> <code>int</code> <p>top-left x coordinate</p> required <code>y0</code> <code>int</code> <p>top-left y coordinate</p> required <code>x1</code> <code>int</code> <p>bottom-right x coordinate</p> required <code>y1</code> <code>int</code> <p>bottom-right y coordinate</p> required <code>clip</code> <code>bool</code> <p>whether to clip or not. Defaults to True.</p> <code>True</code> <code>pad</code> <code>bool</code> <p>whether to pad or not. Defaults to False.</p> <code>False</code> <code>copy</code> <code>bool</code> <p>whether to copy or not. Defaults to False.</p> <code>False</code> <code>extra_border_size</code> <code>int</code> <p>extra border size to add to the crop in the x and y directions. Defaults to 0 which means no extra border.</p> <code>0</code> <code>pad_value</code> <code>int</code> <p>pad fill value. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>Optional[Image]</code> <p>Optional[Image]: cropped image if copy=True else None</p> Source code in <code>otary/image/components/transformer/components/cropper/cropper.py</code> <pre><code>def crop(\n    self,\n    x0: int,\n    y0: int,\n    x1: int,\n    y1: int,\n    clip: bool = True,\n    pad: bool = False,\n    copy: bool = False,\n    extra_border_size: int = 0,\n    pad_value: int = 0,\n) -&gt; Optional[Image]:\n    \"\"\"Crop the image in a straight axis-aligned rectangle way given\n    by the top-left point [x0, y0] and the bottom-right point [x1, y1]\n\n    This function inputs represents the top-left and bottom-right points.\n    This method does not provide a way to extract a rotated rectangle or a\n    different shape from the image.\n\n    Remember that in this library the x coordinates represent the y coordinates of\n    the image array (horizontal axis of the image).\n    The array representation is always rows then columns.\n    In this library this is the contrary like in opencv.\n\n    Args:\n        x0 (int): top-left x coordinate\n        y0 (int): top-left y coordinate\n        x1 (int): bottom-right x coordinate\n        y1 (int): bottom-right y coordinate\n        clip (bool, optional): whether to clip or not. Defaults to True.\n        pad (bool, optional): whether to pad or not. Defaults to False.\n        copy (bool, optional): whether to copy or not. Defaults to False.\n        extra_border_size (int, optional): extra border size to add to the crop\n            in the x and y directions. Defaults to 0 which means no extra border.\n        pad_value (int, optional): pad fill value. Defaults to 0.\n\n    Returns:\n        Optional[Image]: cropped image if copy=True else None\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    if (clip and pad) or (not clip and not pad):\n        raise ValueError(f\"Parameters clip and pad cannot be both {clip}\")\n\n    if clip and not pad:\n        array_crop = self.__crop_with_clipping(\n            x0=x0 - extra_border_size,\n            y0=y0 - extra_border_size,\n            x1=x1 + extra_border_size,\n            y1=y1 + extra_border_size,\n        )\n    else:  # pad and not clip:\n        array_crop = self.__crop_with_padding(\n            x0=x0 - extra_border_size,\n            y0=y0 - extra_border_size,\n            x1=x1 + extra_border_size,\n            y1=y1 + extra_border_size,\n            pad_value=pad_value,\n        )\n\n    if copy:\n        # really important feature to allow new image from original\n        # without the user doing image.copy().crop()\n        # which would be much more expensive if the image is large\n        # this is why the output of the methods is Optional[Image] not None\n        # pylint: disable=import-outside-toplevel\n        from otary.image import Image\n\n        return Image(image=array_crop)\n\n    self.base.asarray = array_crop\n    return None\n</code></pre>"},{"location":"api/image/transformers/cropping/#otary.image.components.transformer.components.cropper.cropper.CropperImage.crop_from_axis_aligned_rectangle","title":"<code>crop_from_axis_aligned_rectangle(bbox, clip=True, pad=False, copy=False, extra_border_size=0, pad_value=0)</code>","text":"<p>Crop the image from an Axis-Aligned Bounding Box (AABB). Inclusive crops which means that the cropped image will have width and height equal to the width and height of the AABB.</p> <p>Parameters:</p> Name Type Description Default <code>bbox</code> <code>AxisAlignedRectangle</code> <p>axis-aligned rectangle bounding box</p> required <code>clip</code> <code>bool</code> <p>whether to clip or not. Defaults to True.</p> <code>True</code> <code>pad</code> <code>bool</code> <p>whether to pad or not. Defaults to False.</p> <code>False</code> <code>copy</code> <code>bool</code> <p>whether to copy or not. Defaults to False.</p> <code>False</code> <code>extra_border_size</code> <code>int</code> <p>extra border size to add to the crop in the x and y directions. Defaults to 0 which means no extra border.</p> <code>0</code> <code>pad_value</code> <code>int</code> <p>pad fill value. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>Optional[Image]</code> <p>Optional[Image]: cropped image if copy=True else None</p> Source code in <code>otary/image/components/transformer/components/cropper/cropper.py</code> <pre><code>def crop_from_axis_aligned_rectangle(\n    self,\n    bbox: geo.AxisAlignedRectangle,\n    clip: bool = True,\n    pad: bool = False,\n    copy: bool = False,\n    extra_border_size: int = 0,\n    pad_value: int = 0,\n) -&gt; Optional[Image]:\n    \"\"\"Crop the image from an Axis-Aligned Bounding Box (AABB).\n    Inclusive crops which means that the cropped image will have\n    width and height equal to the width and height of the AABB.\n\n    Args:\n        bbox (geo.AxisAlignedRectangle): axis-aligned rectangle bounding box\n        clip (bool, optional): whether to clip or not. Defaults to True.\n        pad (bool, optional): whether to pad or not. Defaults to False.\n        copy (bool, optional): whether to copy or not. Defaults to False.\n        extra_border_size (int, optional): extra border size to add to the crop\n            in the x and y directions. Defaults to 0 which means no extra border.\n        pad_value (int, optional): pad fill value. Defaults to 0.\n\n    Returns:\n        Optional[Image]: cropped image if copy=True else None\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    topleft = np.asarray([bbox.xmin, bbox.ymin])\n    height = int(bbox.ymax - bbox.ymin + 1)\n    width = int(bbox.xmax - bbox.xmin + 1)\n    return self.crop_from_topleft(\n        topleft=topleft,\n        width=width,\n        height=height,\n        clip=clip,\n        pad=pad,\n        copy=copy,\n        extra_border_size=extra_border_size,\n        pad_value=pad_value,\n    )\n</code></pre>"},{"location":"api/image/transformers/cropping/#otary.image.components.transformer.components.cropper.cropper.CropperImage.crop_from_center","title":"<code>crop_from_center(center, width, height, clip=True, pad=False, copy=False, extra_border_size=0, pad_value=0)</code>","text":"<p>Crop the image from a rectangle defined by its center point, its width and its height.</p> <p>Parameters:</p> Name Type Description Default <code>center</code> <code>NDArray</code> <p>(x, y) coordinates of the center point</p> required <code>width</code> <code>int</code> <p>width of the rectangle to crop</p> required <code>height</code> <code>int</code> <p>height of the rectangle to crop</p> required <code>clip</code> <code>bool</code> <p>whether to clip or not. Defaults to True.</p> <code>True</code> <code>pad</code> <code>bool</code> <p>whether to pad or not. Defaults to False.</p> <code>False</code> <code>copy</code> <code>bool</code> <p>whether to copy or not. Defaults to False.</p> <code>False</code> <code>extra_border_size</code> <code>int</code> <p>extra border size to add to the crop in the x and y directions. Defaults to 0 which means no extra border.</p> <code>0</code> <code>pad_value</code> <code>int</code> <p>pad fill value. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>Optional[Image]</code> <p>Optional[Image]: image cropped if copy=True else None</p> Source code in <code>otary/image/components/transformer/components/cropper/cropper.py</code> <pre><code>def crop_from_center(\n    self,\n    center: NDArray,\n    width: int,\n    height: int,\n    clip: bool = True,\n    pad: bool = False,\n    copy: bool = False,\n    extra_border_size: int = 0,\n    pad_value: int = 0,\n) -&gt; Optional[Image]:\n    \"\"\"Crop the image from a rectangle defined by its center point, its width and\n    its height.\n\n    Args:\n        center (NDArray): (x, y) coordinates of the center point\n        width (int): width of the rectangle to crop\n        height (int): height of the rectangle to crop\n        clip (bool, optional): whether to clip or not. Defaults to True.\n        pad (bool, optional): whether to pad or not. Defaults to False.\n        copy (bool, optional): whether to copy or not. Defaults to False.\n        extra_border_size (int, optional): extra border size to add to the crop\n            in the x and y directions. Defaults to 0 which means no extra border.\n        pad_value (int, optional): pad fill value. Defaults to 0.\n\n    Returns:\n        Optional[Image]: image cropped if copy=True else None\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    return self.crop_from_topleft(\n        topleft=center - np.array([width / 2, height / 2]),\n        width=width,\n        height=height,\n        clip=clip,\n        pad=pad,\n        copy=copy,\n        extra_border_size=extra_border_size,\n        pad_value=pad_value,\n    )\n</code></pre>"},{"location":"api/image/transformers/cropping/#otary.image.components.transformer.components.cropper.cropper.CropperImage.crop_from_linear_spline","title":"<code>crop_from_linear_spline(spline, copy=False, clip=True, pad=False, extra_border_size=0, pad_value=0)</code>","text":"<p>Crops the image using the bounding box defined by a linear spline.</p> <p>Parameters:</p> Name Type Description Default <code>spline</code> <code>LinearSpline</code> <p>The linear spline object defining the crop region.</p> required <code>copy</code> <code>bool</code> <p>If True, returns a copy of the cropped image. Defaults to False.</p> <code>False</code> <code>clip</code> <code>bool</code> <p>If True, clips the crop region to the image boundaries. Defaults to True.</p> <code>True</code> <code>pad</code> <code>bool</code> <p>If True, pads the cropped region if it extends beyond the image boundaries. Defaults to False.</p> <code>False</code> <code>extra_border_size</code> <code>int</code> <p>Additional border size to add around the cropped region. Defaults to 0.</p> <code>0</code> <code>pad_value</code> <code>int</code> <p>Value to use for padding if pad is True. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>Optional[Image]</code> <p>Optional[Image]: The cropped image</p> Source code in <code>otary/image/components/transformer/components/cropper/cropper.py</code> <pre><code>def crop_from_linear_spline(\n    self,\n    spline: geo.LinearSpline,\n    copy: bool = False,\n    clip: bool = True,\n    pad: bool = False,\n    extra_border_size: int = 0,\n    pad_value: int = 0,\n) -&gt; Optional[Image]:\n    \"\"\"\n    Crops the image using the bounding box defined by a linear spline.\n\n    Args:\n        spline (geo.LinearSpline): The linear spline object defining the crop\n            region.\n        copy (bool, optional): If True, returns a copy of the cropped image.\n            Defaults to False.\n        clip (bool, optional): If True, clips the crop region to the image\n            boundaries. Defaults to True.\n        pad (bool, optional): If True, pads the cropped region if it extends beyond\n            the image boundaries. Defaults to False.\n        extra_border_size (int, optional): Additional border size to add around the\n            cropped region. Defaults to 0.\n        pad_value (int, optional): Value to use for padding if pad is True.\n            Defaults to 0.\n\n    Returns:\n        Optional[Image]: The cropped image\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    return self.crop(\n        x0=int(spline.xmin),\n        y0=int(spline.ymin),\n        x1=int(spline.xmax),\n        y1=int(spline.ymax),\n        copy=copy,\n        clip=clip,\n        pad=pad,\n        extra_border_size=extra_border_size,\n        pad_value=pad_value,\n    )\n</code></pre>"},{"location":"api/image/transformers/cropping/#otary.image.components.transformer.components.cropper.cropper.CropperImage.crop_from_polygon","title":"<code>crop_from_polygon(polygon, copy=False, clip=True, pad=False, extra_border_size=0, pad_value=0)</code>","text":"<p>Crops the image using the bounding box defined by a polygon.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>The polygon whose bounding box will be used for cropping.</p> required <code>copy</code> <code>bool</code> <p>If True, returns a copy of the cropped image. Defaults to False.</p> <code>False</code> <code>clip</code> <code>bool</code> <p>If True, clips the crop region to the image boundaries. Defaults to True.</p> <code>True</code> <code>pad</code> <code>bool</code> <p>If True, pads the cropped region if it extends beyond the image boundaries. Defaults to False.</p> <code>False</code> <code>extra_border_size</code> <code>int</code> <p>Additional border size to add around the cropped region. Defaults to 0.</p> <code>0</code> <code>pad_value</code> <code>int</code> <p>Value to use for padding if pad is True. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>Optional[Image]</code> <p>Optional[Image]: The cropped image</p> Source code in <code>otary/image/components/transformer/components/cropper/cropper.py</code> <pre><code>def crop_from_polygon(\n    self,\n    polygon: geo.Polygon,\n    copy: bool = False,\n    clip: bool = True,\n    pad: bool = False,\n    extra_border_size: int = 0,\n    pad_value: int = 0,\n) -&gt; Optional[Image]:\n    \"\"\"\n    Crops the image using the bounding box defined by a polygon.\n\n    Args:\n        polygon (geo.Polygon): The polygon whose bounding box will be used for\n            cropping.\n        copy (bool, optional): If True, returns a copy of the cropped image.\n            Defaults to False.\n        clip (bool, optional): If True, clips the crop region to the image\n            boundaries. Defaults to True.\n        pad (bool, optional): If True, pads the cropped region if it extends beyond\n            the image boundaries. Defaults to False.\n        extra_border_size (int, optional): Additional border size to add around the\n            cropped region. Defaults to 0.\n        pad_value (int, optional): Value to use for padding if pad is True.\n            Defaults to 0.\n\n    Returns:\n        Optional[Image]: The cropped image\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    return self.crop(\n        x0=int(polygon.xmin),\n        y0=int(polygon.ymin),\n        x1=int(polygon.xmax),\n        y1=int(polygon.ymax),\n        copy=copy,\n        clip=clip,\n        pad=pad,\n        extra_border_size=extra_border_size,\n        pad_value=pad_value,\n    )\n</code></pre>"},{"location":"api/image/transformers/cropping/#otary.image.components.transformer.components.cropper.cropper.CropperImage.crop_from_topleft","title":"<code>crop_from_topleft(topleft, width, height, clip=True, pad=False, copy=False, extra_border_size=0, pad_value=0)</code>","text":"<p>Crop the image from a rectangle defined by its top-left point, its width and its height.</p> <p>Parameters:</p> Name Type Description Default <code>topleft</code> <code>ndarray</code> <p>(x, y) coordinates of the top-left point</p> required <code>width</code> <code>int</code> <p>width of the rectangle to crop</p> required <code>height</code> <code>int</code> <p>height of the rectangle to crop</p> required <code>clip</code> <code>bool</code> <p>whether to clip or not. Defaults to True.</p> <code>True</code> <code>pad</code> <code>bool</code> <p>whether to pad or not. Defaults to False.</p> <code>False</code> <code>copy</code> <code>bool</code> <p>whether to copy or not. Defaults to False.</p> <code>False</code> <code>extra_border_size</code> <code>int</code> <p>extra border size to add to the crop in the x and y directions. Defaults to 0 which means no extra border.</p> <code>0</code> <code>pad_value</code> <code>int</code> <p>pad fill value. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>Optional[Image]</code> <p>Optional[Image]: image cropped if copy=True else None</p> Source code in <code>otary/image/components/transformer/components/cropper/cropper.py</code> <pre><code>def crop_from_topleft(\n    self,\n    topleft: np.ndarray,\n    width: int,\n    height: int,\n    clip: bool = True,\n    pad: bool = False,\n    copy: bool = False,\n    extra_border_size: int = 0,\n    pad_value: int = 0,\n) -&gt; Optional[Image]:\n    \"\"\"Crop the image from a rectangle defined by its top-left point, its width and\n    its height.\n\n    Args:\n        topleft (np.ndarray): (x, y) coordinates of the top-left point\n        width (int): width of the rectangle to crop\n        height (int): height of the rectangle to crop\n        clip (bool, optional): whether to clip or not. Defaults to True.\n        pad (bool, optional): whether to pad or not. Defaults to False.\n        copy (bool, optional): whether to copy or not. Defaults to False.\n        extra_border_size (int, optional): extra border size to add to the crop\n            in the x and y directions. Defaults to 0 which means no extra border.\n        pad_value (int, optional): pad fill value. Defaults to 0.\n\n    Returns:\n        Optional[Image]: image cropped if copy=True else None\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    return self.crop(\n        x0=topleft[0],\n        y0=topleft[1],\n        x1=topleft[0] + width,\n        y1=topleft[1] + height,\n        clip=clip,\n        pad=pad,\n        copy=copy,\n        extra_border_size=extra_border_size,\n        pad_value=pad_value,\n    )\n</code></pre>"},{"location":"api/image/transformers/geometry/","title":"Geometric","text":"<p>Geometry Transformer component</p>"},{"location":"api/image/transformers/geometry/#otary.image.components.transformer.components.geometrizer.geometrizer.GeometrizerImage","title":"<code>GeometrizerImage</code>","text":"<p>GeometrizerImage class</p> Source code in <code>otary/image/components/transformer/components/geometrizer/geometrizer.py</code> <pre><code>class GeometrizerImage:\n    \"\"\"GeometrizerImage class\"\"\"\n\n    def __init__(self, base: BaseImage) -&gt; None:\n        self.base = base\n\n    def shift(self, shift: NDArray, fill_value: Sequence[float] = (0.0,)) -&gt; None:\n        \"\"\"Shift the image by performing a translation operation\n\n        Args:\n            shift (NDArray): Vector for translation\n            fill_value (int | tuple[int, int, int], optional): value to fill the\n                border of the image after the rotation in case reshape is True.\n                Can be a tuple of 3 integers for RGB image or a single integer for\n                grayscale image. Defaults to (0.0,) which is black.\n        \"\"\"\n        vector_shift = assert_transform_shift_vector(vector=shift)\n        shift_matrix = np.asarray(\n            [[1.0, 0.0, vector_shift[0]], [0.0, 1.0, vector_shift[1]]],\n            dtype=np.float32,\n        )\n\n        self.base.asarray = cv2.warpAffine(\n            src=self.base.asarray,\n            M=shift_matrix,\n            dsize=(self.base.width, self.base.height),\n            flags=cv2.INTER_LINEAR,\n            borderMode=cv2.BORDER_CONSTANT,\n            borderValue=fill_value,\n        )  # type: ignore[call-overload]\n\n    def rotate(\n        self,\n        angle: float,\n        is_degree: bool = False,\n        is_clockwise: bool = True,\n        reshape: bool = True,\n        fill_value: Sequence[float] = (0.0,),\n    ) -&gt; None:\n        \"\"\"Rotate the image by a given angle.\n\n        For the rotation with reshape, meaning preserving the whole image,\n        we used the code from the imutils library:\n        https://github.com/PyImageSearch/imutils/blob/master/imutils/convenience.py#L41\n\n        Args:\n            angle (float): angle to rotate the image\n            is_degree (bool, optional): whether the angle is in degree or not.\n                If not it is considered to be in radians.\n                Defaults to False which means radians.\n            is_clockwise (bool, optional): whether the rotation is clockwise or\n                counter-clockwise. Defaults to True.\n            reshape (bool, optional): whether to preserve the original image or not.\n                If True, the complete image is preserved hence the width and height\n                of the rotated image are different than in the original image.\n                Defaults to True.\n            fill_value (Sequence[float], optional): value to\n                fill the border of the image after the rotation in case reshape is True.\n                Can be a tuple of 3 integers for RGB image or a single integer for\n                grayscale image. Defaults to (0.0,) which is black.\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        # pylint: disable=too-many-locals\n        if not is_degree:\n            angle = np.rad2deg(angle)\n        if is_clockwise:\n            angle = -angle\n\n        h, w = self.base.asarray.shape[:2]\n        center = (w / 2, h / 2)\n\n        # Compute rotation matrix\n        rotmat = cv2.getRotationMatrix2D(center, angle, 1.0)  # param angle in degree\n\n        if reshape:\n            # Compute new bounding dimensions\n            cos_a = np.abs(rotmat[0, 0])\n            sin_a = np.abs(rotmat[0, 1])\n            new_w = int((h * sin_a) + (w * cos_a))\n            new_h = int((h * cos_a) + (w * sin_a))\n            w, h = new_w, new_h\n\n            # Adjust the rotation matrix to shift the image center\n            rotmat[0, 2] += (w / 2) - center[0]\n            rotmat[1, 2] += (h / 2) - center[1]\n\n        self.base.asarray = cv2.warpAffine(\n            src=self.base.asarray,\n            M=rotmat,\n            dsize=(w, h),\n            flags=cv2.INTER_LINEAR,\n            borderMode=cv2.BORDER_CONSTANT,\n            borderValue=fill_value,\n        )  # type: ignore[call-overload]\n\n    def center_to_point(self, point: NDArray) -&gt; NDArray:\n        \"\"\"Shift the image so that the input point ends up in the middle of the\n        new image\n\n        Args:\n            point (NDArray): point as (2,) shape numpy array\n\n        Returns:\n            NDArray: translation Vector\n        \"\"\"\n        shift_vector = self.base.center - point\n        self.shift(shift=shift_vector)\n        return shift_vector\n\n    def center_to_segment(self, segment: NDArray) -&gt; NDArray:\n        \"\"\"Shift the image so that the segment middle point ends up in the middle\n        of the new image\n\n        Args:\n            segment (NDArray): segment as numpy array of shape (2, 2)\n\n        Returns:\n            NDArray: vector_shift\n        \"\"\"\n        return self.center_to_point(point=geo.Segment(segment).centroid)\n\n    def restrict_rect_in_frame(self, rectangle: geo.Rectangle) -&gt; geo.Rectangle:\n        \"\"\"Create a new rectangle that is contained within the image borders.\n        If the input rectangle is outside the image, the returned rectangle is a\n        image frame-fitted rectangle that preserve the same shape.\n\n        Args:\n            rectangle (geo.Rectangle): input rectangle\n\n        Returns:\n            geo.Rectangle: new rectangle\n        \"\"\"\n        # rectangle boundaries\n        xmin, xmax = rectangle.xmin, rectangle.xmax\n        ymin, ymax = rectangle.ymin, rectangle.ymax\n\n        # recalculate boundaries based on image shape\n        xmin = max(0, xmin)\n        ymin = max(0, ymin)\n        xmax = min(self.base.width, xmax)\n        ymax = min(self.base.height, ymax)\n\n        # recreate a rectangle with new coordinates\n        rect_restricted = geo.Rectangle.from_topleft_bottomright(\n            topleft=np.asarray([xmin, ymin]),\n            bottomright=np.asarray([xmax, ymax]),\n            is_cast_int=True,\n        )\n        return rect_restricted\n</code></pre>"},{"location":"api/image/transformers/geometry/#otary.image.components.transformer.components.geometrizer.geometrizer.GeometrizerImage.center_to_point","title":"<code>center_to_point(point)</code>","text":"<p>Shift the image so that the input point ends up in the middle of the new image</p> <p>Parameters:</p> Name Type Description Default <code>point</code> <code>NDArray</code> <p>point as (2,) shape numpy array</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>translation Vector</p> Source code in <code>otary/image/components/transformer/components/geometrizer/geometrizer.py</code> <pre><code>def center_to_point(self, point: NDArray) -&gt; NDArray:\n    \"\"\"Shift the image so that the input point ends up in the middle of the\n    new image\n\n    Args:\n        point (NDArray): point as (2,) shape numpy array\n\n    Returns:\n        NDArray: translation Vector\n    \"\"\"\n    shift_vector = self.base.center - point\n    self.shift(shift=shift_vector)\n    return shift_vector\n</code></pre>"},{"location":"api/image/transformers/geometry/#otary.image.components.transformer.components.geometrizer.geometrizer.GeometrizerImage.center_to_segment","title":"<code>center_to_segment(segment)</code>","text":"<p>Shift the image so that the segment middle point ends up in the middle of the new image</p> <p>Parameters:</p> Name Type Description Default <code>segment</code> <code>NDArray</code> <p>segment as numpy array of shape (2, 2)</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>vector_shift</p> Source code in <code>otary/image/components/transformer/components/geometrizer/geometrizer.py</code> <pre><code>def center_to_segment(self, segment: NDArray) -&gt; NDArray:\n    \"\"\"Shift the image so that the segment middle point ends up in the middle\n    of the new image\n\n    Args:\n        segment (NDArray): segment as numpy array of shape (2, 2)\n\n    Returns:\n        NDArray: vector_shift\n    \"\"\"\n    return self.center_to_point(point=geo.Segment(segment).centroid)\n</code></pre>"},{"location":"api/image/transformers/geometry/#otary.image.components.transformer.components.geometrizer.geometrizer.GeometrizerImage.restrict_rect_in_frame","title":"<code>restrict_rect_in_frame(rectangle)</code>","text":"<p>Create a new rectangle that is contained within the image borders. If the input rectangle is outside the image, the returned rectangle is a image frame-fitted rectangle that preserve the same shape.</p> <p>Parameters:</p> Name Type Description Default <code>rectangle</code> <code>Rectangle</code> <p>input rectangle</p> required <p>Returns:</p> Type Description <code>Rectangle</code> <p>geo.Rectangle: new rectangle</p> Source code in <code>otary/image/components/transformer/components/geometrizer/geometrizer.py</code> <pre><code>def restrict_rect_in_frame(self, rectangle: geo.Rectangle) -&gt; geo.Rectangle:\n    \"\"\"Create a new rectangle that is contained within the image borders.\n    If the input rectangle is outside the image, the returned rectangle is a\n    image frame-fitted rectangle that preserve the same shape.\n\n    Args:\n        rectangle (geo.Rectangle): input rectangle\n\n    Returns:\n        geo.Rectangle: new rectangle\n    \"\"\"\n    # rectangle boundaries\n    xmin, xmax = rectangle.xmin, rectangle.xmax\n    ymin, ymax = rectangle.ymin, rectangle.ymax\n\n    # recalculate boundaries based on image shape\n    xmin = max(0, xmin)\n    ymin = max(0, ymin)\n    xmax = min(self.base.width, xmax)\n    ymax = min(self.base.height, ymax)\n\n    # recreate a rectangle with new coordinates\n    rect_restricted = geo.Rectangle.from_topleft_bottomright(\n        topleft=np.asarray([xmin, ymin]),\n        bottomright=np.asarray([xmax, ymax]),\n        is_cast_int=True,\n    )\n    return rect_restricted\n</code></pre>"},{"location":"api/image/transformers/geometry/#otary.image.components.transformer.components.geometrizer.geometrizer.GeometrizerImage.rotate","title":"<code>rotate(angle, is_degree=False, is_clockwise=True, reshape=True, fill_value=(0.0,))</code>","text":"<p>Rotate the image by a given angle.</p> <p>For the rotation with reshape, meaning preserving the whole image, we used the code from the imutils library: https://github.com/PyImageSearch/imutils/blob/master/imutils/convenience.py#L41</p> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>float</code> <p>angle to rotate the image</p> required <code>is_degree</code> <code>bool</code> <p>whether the angle is in degree or not. If not it is considered to be in radians. Defaults to False which means radians.</p> <code>False</code> <code>is_clockwise</code> <code>bool</code> <p>whether the rotation is clockwise or counter-clockwise. Defaults to True.</p> <code>True</code> <code>reshape</code> <code>bool</code> <p>whether to preserve the original image or not. If True, the complete image is preserved hence the width and height of the rotated image are different than in the original image. Defaults to True.</p> <code>True</code> <code>fill_value</code> <code>Sequence[float]</code> <p>value to fill the border of the image after the rotation in case reshape is True. Can be a tuple of 3 integers for RGB image or a single integer for grayscale image. Defaults to (0.0,) which is black.</p> <code>(0.0,)</code> Source code in <code>otary/image/components/transformer/components/geometrizer/geometrizer.py</code> <pre><code>def rotate(\n    self,\n    angle: float,\n    is_degree: bool = False,\n    is_clockwise: bool = True,\n    reshape: bool = True,\n    fill_value: Sequence[float] = (0.0,),\n) -&gt; None:\n    \"\"\"Rotate the image by a given angle.\n\n    For the rotation with reshape, meaning preserving the whole image,\n    we used the code from the imutils library:\n    https://github.com/PyImageSearch/imutils/blob/master/imutils/convenience.py#L41\n\n    Args:\n        angle (float): angle to rotate the image\n        is_degree (bool, optional): whether the angle is in degree or not.\n            If not it is considered to be in radians.\n            Defaults to False which means radians.\n        is_clockwise (bool, optional): whether the rotation is clockwise or\n            counter-clockwise. Defaults to True.\n        reshape (bool, optional): whether to preserve the original image or not.\n            If True, the complete image is preserved hence the width and height\n            of the rotated image are different than in the original image.\n            Defaults to True.\n        fill_value (Sequence[float], optional): value to\n            fill the border of the image after the rotation in case reshape is True.\n            Can be a tuple of 3 integers for RGB image or a single integer for\n            grayscale image. Defaults to (0.0,) which is black.\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    # pylint: disable=too-many-locals\n    if not is_degree:\n        angle = np.rad2deg(angle)\n    if is_clockwise:\n        angle = -angle\n\n    h, w = self.base.asarray.shape[:2]\n    center = (w / 2, h / 2)\n\n    # Compute rotation matrix\n    rotmat = cv2.getRotationMatrix2D(center, angle, 1.0)  # param angle in degree\n\n    if reshape:\n        # Compute new bounding dimensions\n        cos_a = np.abs(rotmat[0, 0])\n        sin_a = np.abs(rotmat[0, 1])\n        new_w = int((h * sin_a) + (w * cos_a))\n        new_h = int((h * cos_a) + (w * sin_a))\n        w, h = new_w, new_h\n\n        # Adjust the rotation matrix to shift the image center\n        rotmat[0, 2] += (w / 2) - center[0]\n        rotmat[1, 2] += (h / 2) - center[1]\n\n    self.base.asarray = cv2.warpAffine(\n        src=self.base.asarray,\n        M=rotmat,\n        dsize=(w, h),\n        flags=cv2.INTER_LINEAR,\n        borderMode=cv2.BORDER_CONSTANT,\n        borderValue=fill_value,\n    )  # type: ignore[call-overload]\n</code></pre>"},{"location":"api/image/transformers/geometry/#otary.image.components.transformer.components.geometrizer.geometrizer.GeometrizerImage.shift","title":"<code>shift(shift, fill_value=(0.0,))</code>","text":"<p>Shift the image by performing a translation operation</p> <p>Parameters:</p> Name Type Description Default <code>shift</code> <code>NDArray</code> <p>Vector for translation</p> required <code>fill_value</code> <code>int | tuple[int, int, int]</code> <p>value to fill the border of the image after the rotation in case reshape is True. Can be a tuple of 3 integers for RGB image or a single integer for grayscale image. Defaults to (0.0,) which is black.</p> <code>(0.0,)</code> Source code in <code>otary/image/components/transformer/components/geometrizer/geometrizer.py</code> <pre><code>def shift(self, shift: NDArray, fill_value: Sequence[float] = (0.0,)) -&gt; None:\n    \"\"\"Shift the image by performing a translation operation\n\n    Args:\n        shift (NDArray): Vector for translation\n        fill_value (int | tuple[int, int, int], optional): value to fill the\n            border of the image after the rotation in case reshape is True.\n            Can be a tuple of 3 integers for RGB image or a single integer for\n            grayscale image. Defaults to (0.0,) which is black.\n    \"\"\"\n    vector_shift = assert_transform_shift_vector(vector=shift)\n    shift_matrix = np.asarray(\n        [[1.0, 0.0, vector_shift[0]], [0.0, 1.0, vector_shift[1]]],\n        dtype=np.float32,\n    )\n\n    self.base.asarray = cv2.warpAffine(\n        src=self.base.asarray,\n        M=shift_matrix,\n        dsize=(self.base.width, self.base.height),\n        flags=cv2.INTER_LINEAR,\n        borderMode=cv2.BORDER_CONSTANT,\n        borderValue=fill_value,\n    )  # type: ignore[call-overload]\n</code></pre>"},{"location":"api/image/transformers/morphology/","title":"Morphological","text":"<p>Morphologyzer Transformer component</p>"},{"location":"api/image/transformers/morphology/#otary.image.components.transformer.components.morphologyzer.morphologyzer.MorphologyzerImage","title":"<code>MorphologyzerImage</code>","text":"<p>MorphologyzerImage.</p> Source code in <code>otary/image/components/transformer/components/morphologyzer/morphologyzer.py</code> <pre><code>class MorphologyzerImage:\n    \"\"\"MorphologyzerImage.\"\"\"\n\n    def __init__(self, base: BaseImage) -&gt; None:\n        self.base = base\n\n    def resize_fixed(\n        self,\n        dim: tuple[int, int],\n        interpolation: int = cv2.INTER_AREA,\n        copy: bool = False,\n    ) -&gt; Optional[Image]:\n        \"\"\"Resize the image using a fixed dimension well defined.\n        This function can result in a distorted image if the ratio between\n        width and height is different in the original and the new image.\n\n        If the dim argument has a negative value in height or width, then\n        a proportional ratio is applied based on the one of the two dimension given.\n\n        Args:\n            dim (tuple[int, int]): a tuple with two integers in the following order\n                (width, height).\n            interpolation (int, optional): resize interpolation.\n                Defaults to cv2.INTER_AREA.\n            copy (bool, optional): whether to return a new image or not.\n        \"\"\"\n        if dim[0] &lt; 0 and dim[1] &lt; 0:  # check that the dim is positive\n            raise ValueError(f\"The dim argument {dim} has two negative values.\")\n\n        _dim = list(dim)\n\n        # compute width or height if needed\n        if _dim[1] &lt;= 0:\n            _dim[1] = int(self.base.height * (_dim[0] / self.base.width))\n        if dim[0] &lt;= 0:\n            _dim[0] = int(self.base.width * (_dim[1] / self.base.height))\n\n        result = cv2.resize(\n            src=self.base.asarray, dsize=_dim, interpolation=interpolation\n        )\n\n        if copy:\n            # pylint: disable=import-outside-toplevel\n            from otary.image import Image\n\n            return Image(image=result)\n\n        self.base.asarray = result\n        return None\n\n    def resize(\n        self, factor: float, interpolation: int = cv2.INTER_AREA, copy: bool = False\n    ) -&gt; Optional[Image]:\n        \"\"\"Resize the image to a new size using a scaling factor value that\n        will be applied to all dimensions (width and height).\n\n        Applying this method can not result in a distorted image.\n\n        Args:\n            factor (float): factor in [0, 5] to resize the image.\n                A value of 1 does not change the image.\n                A value of 2 doubles the image size.\n                A maximum value of 5 is set to avoid accidentally producing a gigantic\n                image.\n            interpolation (int, optional): resize interpolation.\n                Defaults to cv2.INTER_AREA.\n            copy (bool, optional): whether to return a new image or not.\n        \"\"\"\n        if factor == 1:\n            return None\n\n        if factor &lt; 0:\n            raise ValueError(\n                f\"The resize factor value {factor} must be stricly positive\"\n            )\n\n        max_scale_pct = 5\n        if factor &gt; max_scale_pct:\n            raise ValueError(f\"The resize factor value {factor} is probably too big\")\n\n        width = int(self.base.width * factor)\n        height = int(self.base.height * factor)\n        dim = (width, height)\n\n        return self.resize_fixed(dim=dim, interpolation=interpolation, copy=copy)\n\n    def blur(\n        self,\n        kernel: tuple = (5, 5),\n        iterations: int = 1,\n        method: BlurMethods = \"average\",\n        sigmax: float = 0,\n    ) -&gt; None:\n        \"\"\"Blur the image\n\n        Args:\n            kernel (tuple, optional): blur kernel size. Defaults to (5, 5).\n            iterations (int, optional): number of iterations. Defaults to 1.\n            method (str, optional): blur method.\n                Must be in [\"average\", \"median\", \"gaussian\", \"bilateral\"].\n                Defaults to \"average\".\n            sigmax (float, optional): sigmaX value for the gaussian blur.\n                Defaults to 0.\n        \"\"\"\n        if method not in list(get_args(BlurMethods)):\n            raise ValueError(f\"Invalid blur method {method}. Must be in {BlurMethods}\")\n\n        for _ in range(iterations):\n            if method == \"average\":\n                self.base.asarray = cv2.blur(src=self.base.asarray, ksize=kernel)\n            elif method == \"median\":\n                self.base.asarray = cv2.medianBlur(\n                    src=self.base.asarray, ksize=kernel[0]\n                )\n            elif method == \"gaussian\":\n                self.base.asarray = cv2.GaussianBlur(\n                    src=self.base.asarray, ksize=kernel, sigmaX=sigmax\n                )\n            elif method == \"bilateral\":\n                self.base.asarray = cv2.bilateralFilter(\n                    src=self.base.asarray, d=kernel[0], sigmaColor=75, sigmaSpace=75\n                )\n\n    def dilate(\n        self,\n        kernel: tuple = (5, 5),\n        iterations: int = 1,\n        dilate_black_pixels: bool = True,\n    ) -&gt; None:\n        \"\"\"Dilate the image by making the black pixels expand in the image.\n        The dilatation can be parametrize thanks to the kernel and iterations\n        arguments.\n\n        Args:\n            kernel (tuple, optional): kernel to dilate. Defaults to (5, 5).\n            iterations (int, optional): number of dilatation iterations. Defaults to 1.\n            dilate_black_pixels (bool, optional): whether to dilate black pixels or not\n        \"\"\"\n        if iterations == 0:\n            return None\n\n        if dilate_black_pixels:\n            self.base.asarray = 255 - np.asarray(\n                cv2.dilate(\n                    self.base.rev().asarray,\n                    kernel=np.ones(kernel, np.uint8),\n                    iterations=iterations,\n                ),\n                dtype=np.uint8,\n            )\n        else:  # dilate white pixels by default\n            self.base.asarray = np.asarray(\n                cv2.dilate(\n                    self.base.asarray,\n                    kernel=np.ones(kernel, np.uint8),\n                    iterations=iterations,\n                ),\n                dtype=np.uint8,\n            )\n\n        return None\n\n    def erode(\n        self,\n        kernel: tuple = (5, 5),\n        iterations: int = 1,\n        erode_black_pixels: bool = True,\n    ) -&gt; None:\n        \"\"\"Erode the image by making the black pixels shrink in the image.\n        The anti-dilatation can be parametrize thanks to the kernel and iterations\n        arguments.\n\n        Args:\n            kernel (tuple, optional): kernel to erode. Defaults to (5, 5).\n            iterations (int, optional): number of iterations. Defaults to 1.\n            erode_black_pixels (bool, optional): whether to erode black pixels or not\n        \"\"\"\n        if iterations == 0:\n            pass\n\n        if erode_black_pixels:\n            self.base.asarray = 255 - np.asarray(\n                cv2.erode(\n                    self.base.rev().asarray,\n                    kernel=np.ones(kernel, np.uint8),\n                    iterations=iterations,\n                ),\n                dtype=np.uint8,\n            )\n        else:\n            self.base.asarray = np.asarray(\n                cv2.erode(\n                    self.base.asarray,\n                    kernel=np.ones(kernel, np.uint8),\n                    iterations=iterations,\n                ),\n                dtype=np.uint8,\n            )\n\n    def add_border(self, size: int, fill_value: int = 0) -&gt; None:\n        \"\"\"Add a border to the image.\n\n        Args:\n            size (int): border thickness in all directions (top, bottom, left, right).\n            fill_value (int, optional): border color as filled value. Defaults to 0.\n        \"\"\"\n        size = int(size)\n        self.base.asarray = cv2.copyMakeBorder(\n            src=self.base.asarray,\n            top=size,\n            bottom=size,\n            left=size,\n            right=size,\n            borderType=cv2.BORDER_CONSTANT,\n            value=fill_value,\n        )  # type: ignore[call-overload]\n\n    def add_noise_salt_and_pepper(self, amount: float = 0.05) -&gt; None:\n        \"\"\"Add salt and pepper noise to the image.\n\n        Args:\n            amount (float, optional): Proportion of image pixels to alter.\n                Defaults to 0.05.\n        \"\"\"\n        if not 0 &lt;= amount &lt;= 1:\n            raise ValueError(\n                \"Parameter amount must be between 0 and 1 when adding salt and pepper \"\n                f\"noise. Current value is {amount}.\"\n            )\n\n        img = self.base.asarray\n        row, col = img.shape[:2]\n        n_pixels_to_alter = int(amount * row * col)\n\n        # Generate random unique indices for salt and pepper\n        indices = np.random.choice(row * col, size=n_pixels_to_alter, replace=False)\n        salt_indices = indices[: n_pixels_to_alter // 2]\n        pepper_indices = indices[n_pixels_to_alter // 2 :]\n\n        salt_coords = np.unravel_index(salt_indices, (row, col))\n        pepper_coords = np.unravel_index(pepper_indices, (row, col))\n\n        img[salt_coords] = 255  # broadcast even if n channels &gt; 1\n        img[pepper_coords] = 0\n\n        self.base.asarray = img\n\n    def add_noise_gaussian(self, mean: float = 0, std: float = 0.05) -&gt; None:\n        \"\"\"Add Gaussian noise to the image.\n\n        Args:\n            mean (float, optional): mean of the noise. Defaults to 0.\n            std (float, optional): standard deviation of the noise. Defaults to 0.05.\n        \"\"\"\n        self.base.asarray = np.clip(\n            self.base.asarray + np.random.normal(mean, std, self.base.asarray.shape),\n            0,\n            255,\n        ).astype(np.uint8)\n</code></pre>"},{"location":"api/image/transformers/morphology/#otary.image.components.transformer.components.morphologyzer.morphologyzer.MorphologyzerImage.add_border","title":"<code>add_border(size, fill_value=0)</code>","text":"<p>Add a border to the image.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>border thickness in all directions (top, bottom, left, right).</p> required <code>fill_value</code> <code>int</code> <p>border color as filled value. Defaults to 0.</p> <code>0</code> Source code in <code>otary/image/components/transformer/components/morphologyzer/morphologyzer.py</code> <pre><code>def add_border(self, size: int, fill_value: int = 0) -&gt; None:\n    \"\"\"Add a border to the image.\n\n    Args:\n        size (int): border thickness in all directions (top, bottom, left, right).\n        fill_value (int, optional): border color as filled value. Defaults to 0.\n    \"\"\"\n    size = int(size)\n    self.base.asarray = cv2.copyMakeBorder(\n        src=self.base.asarray,\n        top=size,\n        bottom=size,\n        left=size,\n        right=size,\n        borderType=cv2.BORDER_CONSTANT,\n        value=fill_value,\n    )  # type: ignore[call-overload]\n</code></pre>"},{"location":"api/image/transformers/morphology/#otary.image.components.transformer.components.morphologyzer.morphologyzer.MorphologyzerImage.add_noise_gaussian","title":"<code>add_noise_gaussian(mean=0, std=0.05)</code>","text":"<p>Add Gaussian noise to the image.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>mean of the noise. Defaults to 0.</p> <code>0</code> <code>std</code> <code>float</code> <p>standard deviation of the noise. Defaults to 0.05.</p> <code>0.05</code> Source code in <code>otary/image/components/transformer/components/morphologyzer/morphologyzer.py</code> <pre><code>def add_noise_gaussian(self, mean: float = 0, std: float = 0.05) -&gt; None:\n    \"\"\"Add Gaussian noise to the image.\n\n    Args:\n        mean (float, optional): mean of the noise. Defaults to 0.\n        std (float, optional): standard deviation of the noise. Defaults to 0.05.\n    \"\"\"\n    self.base.asarray = np.clip(\n        self.base.asarray + np.random.normal(mean, std, self.base.asarray.shape),\n        0,\n        255,\n    ).astype(np.uint8)\n</code></pre>"},{"location":"api/image/transformers/morphology/#otary.image.components.transformer.components.morphologyzer.morphologyzer.MorphologyzerImage.add_noise_salt_and_pepper","title":"<code>add_noise_salt_and_pepper(amount=0.05)</code>","text":"<p>Add salt and pepper noise to the image.</p> <p>Parameters:</p> Name Type Description Default <code>amount</code> <code>float</code> <p>Proportion of image pixels to alter. Defaults to 0.05.</p> <code>0.05</code> Source code in <code>otary/image/components/transformer/components/morphologyzer/morphologyzer.py</code> <pre><code>def add_noise_salt_and_pepper(self, amount: float = 0.05) -&gt; None:\n    \"\"\"Add salt and pepper noise to the image.\n\n    Args:\n        amount (float, optional): Proportion of image pixels to alter.\n            Defaults to 0.05.\n    \"\"\"\n    if not 0 &lt;= amount &lt;= 1:\n        raise ValueError(\n            \"Parameter amount must be between 0 and 1 when adding salt and pepper \"\n            f\"noise. Current value is {amount}.\"\n        )\n\n    img = self.base.asarray\n    row, col = img.shape[:2]\n    n_pixels_to_alter = int(amount * row * col)\n\n    # Generate random unique indices for salt and pepper\n    indices = np.random.choice(row * col, size=n_pixels_to_alter, replace=False)\n    salt_indices = indices[: n_pixels_to_alter // 2]\n    pepper_indices = indices[n_pixels_to_alter // 2 :]\n\n    salt_coords = np.unravel_index(salt_indices, (row, col))\n    pepper_coords = np.unravel_index(pepper_indices, (row, col))\n\n    img[salt_coords] = 255  # broadcast even if n channels &gt; 1\n    img[pepper_coords] = 0\n\n    self.base.asarray = img\n</code></pre>"},{"location":"api/image/transformers/morphology/#otary.image.components.transformer.components.morphologyzer.morphologyzer.MorphologyzerImage.blur","title":"<code>blur(kernel=(5, 5), iterations=1, method='average', sigmax=0)</code>","text":"<p>Blur the image</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>tuple</code> <p>blur kernel size. Defaults to (5, 5).</p> <code>(5, 5)</code> <code>iterations</code> <code>int</code> <p>number of iterations. Defaults to 1.</p> <code>1</code> <code>method</code> <code>str</code> <p>blur method. Must be in [\"average\", \"median\", \"gaussian\", \"bilateral\"]. Defaults to \"average\".</p> <code>'average'</code> <code>sigmax</code> <code>float</code> <p>sigmaX value for the gaussian blur. Defaults to 0.</p> <code>0</code> Source code in <code>otary/image/components/transformer/components/morphologyzer/morphologyzer.py</code> <pre><code>def blur(\n    self,\n    kernel: tuple = (5, 5),\n    iterations: int = 1,\n    method: BlurMethods = \"average\",\n    sigmax: float = 0,\n) -&gt; None:\n    \"\"\"Blur the image\n\n    Args:\n        kernel (tuple, optional): blur kernel size. Defaults to (5, 5).\n        iterations (int, optional): number of iterations. Defaults to 1.\n        method (str, optional): blur method.\n            Must be in [\"average\", \"median\", \"gaussian\", \"bilateral\"].\n            Defaults to \"average\".\n        sigmax (float, optional): sigmaX value for the gaussian blur.\n            Defaults to 0.\n    \"\"\"\n    if method not in list(get_args(BlurMethods)):\n        raise ValueError(f\"Invalid blur method {method}. Must be in {BlurMethods}\")\n\n    for _ in range(iterations):\n        if method == \"average\":\n            self.base.asarray = cv2.blur(src=self.base.asarray, ksize=kernel)\n        elif method == \"median\":\n            self.base.asarray = cv2.medianBlur(\n                src=self.base.asarray, ksize=kernel[0]\n            )\n        elif method == \"gaussian\":\n            self.base.asarray = cv2.GaussianBlur(\n                src=self.base.asarray, ksize=kernel, sigmaX=sigmax\n            )\n        elif method == \"bilateral\":\n            self.base.asarray = cv2.bilateralFilter(\n                src=self.base.asarray, d=kernel[0], sigmaColor=75, sigmaSpace=75\n            )\n</code></pre>"},{"location":"api/image/transformers/morphology/#otary.image.components.transformer.components.morphologyzer.morphologyzer.MorphologyzerImage.dilate","title":"<code>dilate(kernel=(5, 5), iterations=1, dilate_black_pixels=True)</code>","text":"<p>Dilate the image by making the black pixels expand in the image. The dilatation can be parametrize thanks to the kernel and iterations arguments.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>tuple</code> <p>kernel to dilate. Defaults to (5, 5).</p> <code>(5, 5)</code> <code>iterations</code> <code>int</code> <p>number of dilatation iterations. Defaults to 1.</p> <code>1</code> <code>dilate_black_pixels</code> <code>bool</code> <p>whether to dilate black pixels or not</p> <code>True</code> Source code in <code>otary/image/components/transformer/components/morphologyzer/morphologyzer.py</code> <pre><code>def dilate(\n    self,\n    kernel: tuple = (5, 5),\n    iterations: int = 1,\n    dilate_black_pixels: bool = True,\n) -&gt; None:\n    \"\"\"Dilate the image by making the black pixels expand in the image.\n    The dilatation can be parametrize thanks to the kernel and iterations\n    arguments.\n\n    Args:\n        kernel (tuple, optional): kernel to dilate. Defaults to (5, 5).\n        iterations (int, optional): number of dilatation iterations. Defaults to 1.\n        dilate_black_pixels (bool, optional): whether to dilate black pixels or not\n    \"\"\"\n    if iterations == 0:\n        return None\n\n    if dilate_black_pixels:\n        self.base.asarray = 255 - np.asarray(\n            cv2.dilate(\n                self.base.rev().asarray,\n                kernel=np.ones(kernel, np.uint8),\n                iterations=iterations,\n            ),\n            dtype=np.uint8,\n        )\n    else:  # dilate white pixels by default\n        self.base.asarray = np.asarray(\n            cv2.dilate(\n                self.base.asarray,\n                kernel=np.ones(kernel, np.uint8),\n                iterations=iterations,\n            ),\n            dtype=np.uint8,\n        )\n\n    return None\n</code></pre>"},{"location":"api/image/transformers/morphology/#otary.image.components.transformer.components.morphologyzer.morphologyzer.MorphologyzerImage.erode","title":"<code>erode(kernel=(5, 5), iterations=1, erode_black_pixels=True)</code>","text":"<p>Erode the image by making the black pixels shrink in the image. The anti-dilatation can be parametrize thanks to the kernel and iterations arguments.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>tuple</code> <p>kernel to erode. Defaults to (5, 5).</p> <code>(5, 5)</code> <code>iterations</code> <code>int</code> <p>number of iterations. Defaults to 1.</p> <code>1</code> <code>erode_black_pixels</code> <code>bool</code> <p>whether to erode black pixels or not</p> <code>True</code> Source code in <code>otary/image/components/transformer/components/morphologyzer/morphologyzer.py</code> <pre><code>def erode(\n    self,\n    kernel: tuple = (5, 5),\n    iterations: int = 1,\n    erode_black_pixels: bool = True,\n) -&gt; None:\n    \"\"\"Erode the image by making the black pixels shrink in the image.\n    The anti-dilatation can be parametrize thanks to the kernel and iterations\n    arguments.\n\n    Args:\n        kernel (tuple, optional): kernel to erode. Defaults to (5, 5).\n        iterations (int, optional): number of iterations. Defaults to 1.\n        erode_black_pixels (bool, optional): whether to erode black pixels or not\n    \"\"\"\n    if iterations == 0:\n        pass\n\n    if erode_black_pixels:\n        self.base.asarray = 255 - np.asarray(\n            cv2.erode(\n                self.base.rev().asarray,\n                kernel=np.ones(kernel, np.uint8),\n                iterations=iterations,\n            ),\n            dtype=np.uint8,\n        )\n    else:\n        self.base.asarray = np.asarray(\n            cv2.erode(\n                self.base.asarray,\n                kernel=np.ones(kernel, np.uint8),\n                iterations=iterations,\n            ),\n            dtype=np.uint8,\n        )\n</code></pre>"},{"location":"api/image/transformers/morphology/#otary.image.components.transformer.components.morphologyzer.morphologyzer.MorphologyzerImage.resize","title":"<code>resize(factor, interpolation=cv2.INTER_AREA, copy=False)</code>","text":"<p>Resize the image to a new size using a scaling factor value that will be applied to all dimensions (width and height).</p> <p>Applying this method can not result in a distorted image.</p> <p>Parameters:</p> Name Type Description Default <code>factor</code> <code>float</code> <p>factor in [0, 5] to resize the image. A value of 1 does not change the image. A value of 2 doubles the image size. A maximum value of 5 is set to avoid accidentally producing a gigantic image.</p> required <code>interpolation</code> <code>int</code> <p>resize interpolation. Defaults to cv2.INTER_AREA.</p> <code>INTER_AREA</code> <code>copy</code> <code>bool</code> <p>whether to return a new image or not.</p> <code>False</code> Source code in <code>otary/image/components/transformer/components/morphologyzer/morphologyzer.py</code> <pre><code>def resize(\n    self, factor: float, interpolation: int = cv2.INTER_AREA, copy: bool = False\n) -&gt; Optional[Image]:\n    \"\"\"Resize the image to a new size using a scaling factor value that\n    will be applied to all dimensions (width and height).\n\n    Applying this method can not result in a distorted image.\n\n    Args:\n        factor (float): factor in [0, 5] to resize the image.\n            A value of 1 does not change the image.\n            A value of 2 doubles the image size.\n            A maximum value of 5 is set to avoid accidentally producing a gigantic\n            image.\n        interpolation (int, optional): resize interpolation.\n            Defaults to cv2.INTER_AREA.\n        copy (bool, optional): whether to return a new image or not.\n    \"\"\"\n    if factor == 1:\n        return None\n\n    if factor &lt; 0:\n        raise ValueError(\n            f\"The resize factor value {factor} must be stricly positive\"\n        )\n\n    max_scale_pct = 5\n    if factor &gt; max_scale_pct:\n        raise ValueError(f\"The resize factor value {factor} is probably too big\")\n\n    width = int(self.base.width * factor)\n    height = int(self.base.height * factor)\n    dim = (width, height)\n\n    return self.resize_fixed(dim=dim, interpolation=interpolation, copy=copy)\n</code></pre>"},{"location":"api/image/transformers/morphology/#otary.image.components.transformer.components.morphologyzer.morphologyzer.MorphologyzerImage.resize_fixed","title":"<code>resize_fixed(dim, interpolation=cv2.INTER_AREA, copy=False)</code>","text":"<p>Resize the image using a fixed dimension well defined. This function can result in a distorted image if the ratio between width and height is different in the original and the new image.</p> <p>If the dim argument has a negative value in height or width, then a proportional ratio is applied based on the one of the two dimension given.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>tuple[int, int]</code> <p>a tuple with two integers in the following order (width, height).</p> required <code>interpolation</code> <code>int</code> <p>resize interpolation. Defaults to cv2.INTER_AREA.</p> <code>INTER_AREA</code> <code>copy</code> <code>bool</code> <p>whether to return a new image or not.</p> <code>False</code> Source code in <code>otary/image/components/transformer/components/morphologyzer/morphologyzer.py</code> <pre><code>def resize_fixed(\n    self,\n    dim: tuple[int, int],\n    interpolation: int = cv2.INTER_AREA,\n    copy: bool = False,\n) -&gt; Optional[Image]:\n    \"\"\"Resize the image using a fixed dimension well defined.\n    This function can result in a distorted image if the ratio between\n    width and height is different in the original and the new image.\n\n    If the dim argument has a negative value in height or width, then\n    a proportional ratio is applied based on the one of the two dimension given.\n\n    Args:\n        dim (tuple[int, int]): a tuple with two integers in the following order\n            (width, height).\n        interpolation (int, optional): resize interpolation.\n            Defaults to cv2.INTER_AREA.\n        copy (bool, optional): whether to return a new image or not.\n    \"\"\"\n    if dim[0] &lt; 0 and dim[1] &lt; 0:  # check that the dim is positive\n        raise ValueError(f\"The dim argument {dim} has two negative values.\")\n\n    _dim = list(dim)\n\n    # compute width or height if needed\n    if _dim[1] &lt;= 0:\n        _dim[1] = int(self.base.height * (_dim[0] / self.base.width))\n    if dim[0] &lt;= 0:\n        _dim[0] = int(self.base.width * (_dim[1] / self.base.height))\n\n    result = cv2.resize(\n        src=self.base.asarray, dsize=_dim, interpolation=interpolation\n    )\n\n    if copy:\n        # pylint: disable=import-outside-toplevel\n        from otary.image import Image\n\n        return Image(image=result)\n\n    self.base.asarray = result\n    return None\n</code></pre>"},{"location":"api/image/transformers/thresholding/","title":"Binarization &amp; Thresholding Methods","text":"<p><code>BinarizerImage</code> component is a subpart of the Image Transformer component.</p> <p>Binarization converts an image to black and white, making every pixel either 0 or 255. Any color or grayscale image can be binarized. Methods fall into two types:</p> <ul> <li>Global: applies a single threshold to all pixels.</li> <li>Local: applies varying thresholds per pixel, usually performing better on images with uneven lighting.</li> </ul> <p>Otary offers 5 basic and 12 advanced binarization methods.</p> <p>Basic methods: simple, otsu, adaptive, bradley, and sauvola are available directly from the Image object:</p> <pre><code>import otary as ot\n\nim = ot.Image.from_file(filepath=\"path/to/file/image\")\nim.threshold_sauvola()\n</code></pre> <p>Advanced methods are accessible via the transformer.binarizer attribute:</p> <pre><code>im.transformer.binarizer.threshold_isauvola()\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage","title":"<code>BinarizerImage</code>","text":"<p>BinarizerImage class contains all the binarization methods.</p> <p>It includes only two global thresholding methods: <code>threshold_simple</code> and <code>threshold_otsu</code>. The other methods are local thresholding methods.</p> <p>It includes the following binarization methods, sorted by year of publication:</p> Name Year Reference Adaptive - OpenCV Adaptive Thresholding Documentation Otsu 1979 A Threshold Selection Method from Gray-Level Histograms Bernsen 1986 \"Dynamic thresholding of grey-level images\" by Bernsen Niblack 1986 \"An Introduction to Digital Image Processing\" by Wayne Niblack Sauvola 1997 Adaptive Document Binarization Wolf 2003 Extraction and Recognition of Artificial Text in Multimedia Documents Feng 2004 Contrast adaptive binarization of low quality document images Gatos 2005 Adaptive degraded document image binarization Bradley &amp; Roth 2007 Adaptive Thresholding using the Integral Image Nick 2009 Comparison of Niblack inspired Binarization Methods for Ancient Documents Su 2010 Binarization of historical document images using the local maximum and minimum Phansalkar 2011 Adaptive Local Thresholding for Detection of Nuclei in Diversely Stained Cytology Images Adotsu 2011 AdOtsu: An adaptive and parameterless generalization of Otsu\u2019s method for document image binarization Singh 2012 A New Local Adaptive Thresholding Technique in Binarization FAIR 2013 FAIR: A Fast Algorithm for document Image Restoration ISauvola 2016 ISauvola: Improved Sauvola\u2019s Algorithm for Document Image Binarization WAN 2018 Binarization of Document Image Using Optimum Threshold Modification Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>class BinarizerImage:\n    # pylint: disable=line-too-long\n    \"\"\"BinarizerImage class contains all the binarization methods.\n\n    It includes only two global thresholding methods: `threshold_simple` and `threshold_otsu`. The other methods are local thresholding methods.\n\n    It includes the following binarization methods, sorted by year of publication:\n\n    | Name           | Year | Reference                                                                                                                        |\n    |----------------|------|------------------------------------------------------------------------------------------------------------------------------------------|\n    | Adaptive       |  -   | [OpenCV Adaptive Thresholding Documentation](https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html)                           |\n    | Otsu           | 1979 | [A Threshold Selection Method from Gray-Level Histograms](https://ieeexplore.ieee.org/document/4310076)                                  |\n    | Bernsen        | 1986 | \"Dynamic thresholding of grey-level images\" by Bernsen                                                                                   |\n    | Niblack        | 1986 | \"An Introduction to Digital Image Processing\" by Wayne Niblack                                                                           |\n    | Sauvola        | 1997 | [Adaptive Document Binarization](https://www.researchgate.net/publication/3710586_Adaptive_Document_Binarization)                        |\n    | Wolf           | 2003 | [Extraction and Recognition of Artificial Text in Multimedia Documents](https://hal.science/hal-01504401v1)                              |\n    | Feng           | 2004 | [Contrast adaptive binarization of low quality document images](https://www.jstage.jst.go.jp/article/elex/1/16/1_16_501/_pdf)            |\n    | Gatos          | 2005 | [Adaptive degraded document image binarization](https://users.iit.demokritos.gr/~bgat/PatRec2006.pdf)                                    |\n    | Bradley &amp; Roth | 2007 | [Adaptive Thresholding using the Integral Image](https://www.researchgate.net/publication/220494200_Adaptive_Thresholding_using_the_Integral_Image) |\n    | Nick           | 2009 | [Comparison of Niblack inspired Binarization Methods for Ancient Documents](https://www.researchgate.net/publication/221253803)           |\n    | Su             | 2010 | [Binarization of historical document images using the local maximum and minimum](https://www.researchgate.net/publication/220933012)                                                             |\n    | Phansalkar     | 2011 | [Adaptive Local Thresholding for Detection of Nuclei in Diversely Stained Cytology Images](https://www.researchgate.net/publication/224226466) |\n    | Adotsu         | 2011 | [AdOtsu: An adaptive and parameterless generalization of Otsu\u2019s method for document image binarization](https://www.researchgate.net/publication/220602345) |\n    | Singh          | 2012 | [A New Local Adaptive Thresholding Technique in Binarization](https://www.researchgate.net/publication/220485031)                        |\n    | FAIR           | 2013 | [FAIR: A Fast Algorithm for document Image Restoration](https://amu.hal.science/hal-01479805/document)                                   |\n    | ISauvola       | 2016 | [ISauvola: Improved Sauvola\u2019s Algorithm for Document Image Binarization](https://www.researchgate.net/publication/304621554_ISauvola_Improved_Sauvola) |\n    | WAN            | 2018 | [Binarization of Document Image Using Optimum Threshold Modification](https://www.researchgate.net/publication/326026836)                 |\n    \"\"\"\n\n    def __init__(self, base: BaseImage) -&gt; None:\n        self.base = base\n\n    # ----------------------------- GLOBAL THRESHOLDING -------------------------------\n\n    def threshold_simple(self, thresh: int) -&gt; \"Image\":\n        \"\"\"Compute the image thresholded by a single value T.\n        All pixels with value v &lt;= T are turned black and those with value v &gt; T are\n        turned white. This is a global thresholding method.\n\n        Args:\n            thresh (int): value to separate the black from the white pixels.\n        \"\"\"\n        self.base.as_grayscale()\n        self.base.asarray = np.array((self.base.asarray &gt; thresh) * 255, dtype=np.uint8)\n        return self.base.parent\n\n    def threshold_otsu(self) -&gt; \"Image\":\n        \"\"\"Apply Otsu global thresholding.\n        This is a global thresholding method that automatically determines\n        an optimal threshold value from the image histogram.\n\n        Paper (1979):\n        [A Threshold Selection Method from Gray-Level Histograms](https://ieeexplore.ieee.org/document/4310076)\n\n        Consider applying a gaussian blur before for better thresholding results.\n        See why in the [OpenCV documentation](https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html).\n        \"\"\"\n        self.base.as_grayscale()\n        _, img_thresholded = cv2.threshold(\n            self.base.asarray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n        )\n        self.base.asarray = img_thresholded\n        return self.base.parent\n\n    # ------------------------------ LOCAL THRESHOLDING -------------------------------\n\n    def threshold_adaptive(\n        self, block_size: int = 11, constant: float = 2.0\n    ) -&gt; \"Image\":\n        \"\"\"Apply adaptive local thresholding.\n        This is a local thresholding method that computes the threshold for a pixel\n        based on a small region around it.\n\n        Consider applying a gaussian blur before for better thresholding results.\n        See why in the [OpenCV documentation](https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html).\n\n        Args:\n            block_size (int, optional): Size of a pixel neighborhood that is used to\n                calculate a threshold value for the pixel: 3, 5, 7, and so on.\n                Defaults to 11.\n            constant (int, optional): Constant subtracted from the mean or weighted\n                mean. Normally, it is positive but may be zero or negative as well.\n                Defaults to 2.\n        \"\"\"\n        self.base.as_grayscale()\n        self.base.asarray = cv2.adaptiveThreshold(\n            src=self.base.asarray,\n            maxValue=255,\n            adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n            thresholdType=cv2.THRESH_BINARY,\n            blockSize=block_size,\n            C=constant,\n        )\n        return self.base.parent\n\n    def threshold_bernsen(\n        self,\n        window_size: int = 75,\n        contrast_limit: float = 25,\n        threshold_global: int = 100,\n    ) -&gt; \"Image\":\n        \"\"\"Apply Bernsen local thresholding.\n\n        Paper (1986):\n        \"Dynamic thresholding of grey-level images\" by Bernsen.\n\n        Args:\n            window_size (int, optional): window size for local computations.\n                Defaults to 75.\n            contrast_limit (float, optional): contrast limit. If the\n                contrast is higher than this value, the pixel is thresholded by the\n                bernsen threshold otherwise the global threshold is used.\n                Defaults to 25.\n            threshold_global (int, optional): global threshold. Defaults to 100.\n        \"\"\"\n        self.base.as_grayscale()\n        self.base.asarray = threshold_bernsen(\n            img=self.base.asarray,\n            window_size=window_size,\n            contrast_limit=contrast_limit,\n            threshold_global=threshold_global,\n        )\n        return self.base.parent\n\n    def threshold_niblack(self, window_size: int = 15, k: float = -0.2) -&gt; \"Image\":\n        \"\"\"Apply Niblack local thresholding.\n\n        Book (1986):\n        \"An Introduction to Digital Image Processing\" by Wayne Niblack.\n\n        Args:\n            window_size (int, optional): apply on the\n                image. Defaults to 15.\n            k (float, optional): factor to apply to regulate the impact\n                of the std. Defaults to -0.2.\n        \"\"\"\n        self.base.as_grayscale()\n        self.base.asarray = threshold_niblack_like(\n            img=self.base.asarray, method=\"niblack\", window_size=window_size, k=k\n        )[1]\n        return self.base.parent\n\n    def threshold_sauvola(\n        self, window_size: int = 15, k: float = 0.5, r: float = 128.0\n    ) -&gt; \"Image\":\n        \"\"\"Apply Sauvola local thresholding.\n        This is a local thresholding method that computes the threshold for a pixel\n        based on a small region around it.\n\n        Paper (1997):\n        [Adaptive Document Binarization](https://www.researchgate.net/publication/3710586_Adaptive_Document_Binarization)\n\n        Args:\n            window_size (int, optional): sauvola window size to apply on the\n                image. Defaults to 15.\n            k (float, optional): sauvola k factor to apply to regulate the impact\n                of the std. Defaults to 0.5.\n            r (float, optional): sauvola r value. Defaults to 128.\n        \"\"\"\n        self.base.as_grayscale()\n        self.base.asarray = threshold_niblack_like(\n            img=self.base.asarray, method=\"sauvola\", window_size=window_size, k=k, r=r\n        )[1]\n        return self.base.parent\n\n    def threshold_wolf(self, window_size: int = 15, k: float = 0.5) -&gt; \"Image\":\n        \"\"\"Apply Wolf local thresholding.\n\n        Paper (2003):\n        [Extraction and Recognition of Artificial Text in Multimedia Documents](https://hal.science/hal-01504401v1)\n\n        Args:\n            window_size (int, optional): apply on the\n                image. Defaults to 15.\n            k (float, optional): factor to apply to regulate the impact\n                of the std. Defaults to 0.5.\n        \"\"\"\n        self.base.as_grayscale()\n        self.base.asarray = threshold_niblack_like(\n            img=self.base.asarray, method=\"wolf\", window_size=window_size, k=k\n        )[1]\n        return self.base.parent\n\n    def threshold_feng(\n        self,\n        w1: int = 19,\n        w2: int = 33,\n        alpha1: float = 0.12,\n        k1: float = 0.25,\n        k2: float = 0.04,\n        gamma: float = 2.0,\n    ) -&gt; \"Image\":\n        \"\"\"Implementation of the Feng thresholding method.\n\n        Paper (2004):\n        [Contrast adaptive binarization of low quality document images](https://www.jstage.jst.go.jp/article/elex/1/16/1_16_501/_pdf)\n\n        Args:\n            w1 (int, optional): primary window size. Defaults to 19.\n            w2 (int, optional): secondary window value. Defaults to 33.\n            alpha1 (float, optional): alpha1 value. Defaults to 0.12.\n            k1 (float, optional): k1 value. Defaults to 0.25.\n            k2 (float, optional): k2 value. Defaults to 0.04.\n            gamma (float, optional): gamma value. Defaults to 2.0.\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        self.base.as_grayscale()\n        self.base.asarray = threshold_feng(\n            img=self.base.asarray,\n            w1=w1,\n            w2=w2,\n            alpha1=alpha1,\n            k1=k1,\n            k2=k2,\n            gamma=gamma,\n        )\n        return self.base.parent\n\n    def threshold_gatos(\n        self,\n        q: float = 0.6,\n        p1: float = 0.5,\n        p2: float = 0.8,\n        lh: Optional[float] = None,\n        upsampling: bool = False,\n        upsampling_factor: int = 2,\n    ) -&gt; \"Image\":\n        \"\"\"Apply Gatos local thresholding.\n\n        Paper (2005):\n        [Adaptive degraded document image binarization](https://users.iit.demokritos.gr/~bgat/PatRec2006.pdf)\n\n        Args:\n            q (float, optional): q gatos factor. Defaults to 0.6.\n            p1 (float, optional): p1 gatos factor. Defaults to 0.5.\n            p2 (float, optional): p2 gatos factor. Defaults to 0.8.\n            lh (Optional[float], optional): height of character.\n                Defaults to None, meaning it is computed automatically to be\n                a fraction of the image size.\n            upsampling (bool, optional): whether to apply gatos upsampling definition.\n                Defaults to False.\n            upsampling_factor (int, optional): gatos upsampling factor. Defaults to 2.\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        # pylint: disable=duplicate-code\n        self.base.as_grayscale()\n        self.base.asarray = threshold_gatos(\n            img=self.base.asarray,\n            q=q,\n            p1=p1,\n            p2=p2,\n            lh=lh,\n            upsampling=upsampling,\n            upsampling_factor=upsampling_factor,\n        )\n        return self.base.parent\n\n    def threshold_bradley(self, window_size: int = 15, t: float = 0.15) -&gt; \"Image\":\n        \"\"\"Implementation of the Bradley &amp; Roth thresholding method.\n\n        Paper (2007):\n        [Adaptive Thresholding using the Integral Image](https://www.researchgate.net/publication/220494200_Adaptive_Thresholding_using_the_Integral_Image)\n\n        Args:\n            window_size (int, optional): window size for local computations.\n                Defaults to 15.\n            t (float, optional): t value in [0, 1]. Defaults to 0.15.\n\n        Returns:\n            NDArray[np.uint8]: output thresholded image\n        \"\"\"\n        self.base.as_grayscale()\n        self.base.asarray = threshold_bradley(\n            img=self.base.asarray, window_size=window_size, t=t\n        )\n        return self.base.parent\n\n    def threshold_nick(self, window_size: int = 19, k: float = -0.1) -&gt; \"Image\":\n        \"\"\"Apply Nick local thresholding.\n\n        Paper (2009):\n        [Comparison of Niblack inspired Binarization Methods for Ancient Documents](https://www.researchgate.net/publication/221253803)\n\n        The paper suggests to use a window size of 19 and a k factor in [-0.2, -0.1].\n\n        Args:\n            window_size (int, optional): apply on the\n                image. Defaults to 15.\n            k (float, optional): factor to apply to regulate the impact\n                of the std. Defaults to -0.1.\n        \"\"\"\n        self.base.as_grayscale()\n        self.base.asarray = threshold_niblack_like(\n            img=self.base.asarray, method=\"nick\", window_size=window_size, k=k\n        )[1]\n        return self.base.parent\n\n    def threshold_su(\n        self,\n        window_size: int = 3,\n        n_min: int = -1,\n    ) -&gt; \"Image\":\n        \"\"\"Compute the Su local thresholding.\n\n        Paper (2010):\n        [Binarization of historical document images using the local maximum and minimum](https://www.researchgate.net/publication/220933012)\n\n        Args:\n            window_size (int, optional): window size for high contrast image\n                computation. Defaults to 3.\n            n_min (int, optional): minimum number of high contrast pixels within the\n                neighborhood window. Defaults to -1 meaning that n_min = window_size.\n        \"\"\"\n        self.base.as_grayscale()\n        self.base.asarray = threshold_su(\n            img=self.base.asarray, window_size=window_size, n_min=n_min\n        )\n        return self.base.parent\n\n    def threshold_phansalkar(\n        self, window_size: int = 40, k: float = 0.25, p: float = 3.0, q: float = 10.0\n    ) -&gt; \"Image\":\n        \"\"\"Apply Phansalkar et al. local thresholding.\n\n        Paper (2011):\n        [Adaptive Local Thresholding for Detection of Nuclei in Diversely Stained Cytology Images](https://www.researchgate.net/publication/224226466)\n\n        Args:\n            window_size (int, optional): apply on the\n                image. Defaults to 40.\n            k (float, optional): factor to apply to regulate the impact\n                of the std. Defaults to 0.25.\n            p (float, optional): Phansalkar parameter to regulate low contrast zones.\n                Defaults to 3.0.\n            q (float, optional): Phansalkar parameter to regulate low contrast zones.\n                Defaults to 10.0.\n        \"\"\"\n        self.base.as_grayscale()\n        self.base.asarray = threshold_niblack_like(\n            img=self.base.asarray,\n            method=\"phansalkar\",\n            window_size=window_size,\n            k=k,\n            p=p,\n            q=q,\n        )[1]\n        return self.base.parent\n\n    def threshold_adotsu(\n        self, grid_size: int = 50, k_sigma: float = 1.6, n_steps: int = 2\n    ) -&gt; \"Image\":\n        \"\"\"Apply Adotsu local thresholding.\n\n        Paper (2011):\n        [AdOtsu: An adaptive and parameterless generalization of Otsu\u2019s method for document image binarization](https://www.researchgate.net/publication/220602345)\n\n        Args:\n            grid_size (int, optional): window size for local computations.\n                Defaults to 15.\n            k_sigma (float, optional): k_sigma value in [1, 2]. Defaults to 1.6.\n            n_steps (int, optional): number of iterations to update the binarization by\n                estimating a new background surface. Defaults to 2.\n        \"\"\"\n        self.base.as_grayscale()\n        self.base.asarray = threshold_adotsu(\n            img=self.base.asarray, grid_size=grid_size, k_sigma=k_sigma, n_steps=n_steps\n        )\n        return self.base.parent\n\n    def threshold_singh(self, window_size: int = 15, k: float = 0.06) -&gt; \"Image\":\n        \"\"\"Apply Singh local thresholding.\n\n        Paper (2012):\n        [A New Local Adaptive Thresholding Technique in Binarization](https://www.researchgate.net/publication/220485031)\n\n        Args:\n            window_size (int, optional): apply on the\n                image. Defaults to 15.\n            k (float, optional): factor to apply to regulate the impact\n                of the std. Defaults to 0.06.\n        \"\"\"\n        self.base.as_grayscale()\n        self.base.asarray = threshold_niblack_like(\n            img=self.base.asarray, method=\"singh\", window_size=window_size, k=k\n        )[1]\n        return self.base.parent\n\n    def threshold_fair(\n        self,\n        sfair_window_size: int = 33,\n        sfair_clustering_algo: str = \"otsu\",\n        sfair_clustering_max_iter: int = 20,\n        sfair_thining: float = 1.0,\n        sfair_alpha: float = 0.38,\n        post_stain_max_pixels: int = 25,\n        post_misclass_txt: bool = True,\n        post_clustering_algo: str = \"otsu\",\n        post_clustering_max_iter: int = 10,\n        post_max_iter: int = 15,\n        post_window_size: int = 75,\n        post_beta: float = 1.0,\n    ) -&gt; \"Image\":\n        \"\"\"Apply FAIR local thresholding.\n\n        Paper (2013):\n        [FAIR: A Fast Algorithm for document Image Restoration](https://amu.hal.science/hal-01479805/document)\n\n        Args:\n            sfair_window_size (int, optional): window size in preprocess\n                to cluster background and foreground pixels around edge pixels.\n                This parameter is important as a higher value will make the method\n                more robust to noise but also more computationally expensive and slow.\n                Defaults to 5.\n            sfair_clustering_algo (str, optional): clustering algorithm for the S-FAIR\n                step. Defaults to \"otsu\".\n            sfair_clustering_max_iter (int, optional): maximum number of iterations for\n                the clustering algorithm within the S-FAIR step. Defaults to 20.\n            sfair_thining (float, optional): thining factor in [0, 1]. 0 means no\n                thinning which means that all edge pixels are processed.\n                1 means that only every\n                sfair_window_size // 2 edge pixels are processed which signicantly\n                speeds up the computation. Defaults to 1.0.\n            sfair_alpha (float, optional): It defines the ratio to compute the lower\n                threshold in the 1st step of the S-FAIR step.\n                It is generally in [0.3, 0.5].\n                Defaults to 0.38.\n            post_stain_max_pixels (int, optional): maximum number of pixels for a stain\n                to be considered as an unknown connected component. Defaults to 25.\n            post_misclass_txt (bool, optional): whether to perform the\n                post-processing correct_misclassified_text_pixels step.\n                Defaults to True.\n            post_clustering_algo (str, optional): clustering algorithm for the\n                post-processing step. Defaults to \"otsu\".\n            post_clustering_max_iter (int, optional): maximum number of iterations for\n                the clustering algorithm within the post-processing step.\n                Defaults to 10.\n            post_max_iter (int, optional): maximum number of iterations for the\n                correct_misclassified_text_pixels step within the post-processing step.\n                Defaults to 15.\n            post_window_size (int, optional): window size in postprocess\n                to cluster background and foreground pixels around edge pixels.\n                This parameter is important as a higher value will make the method\n                more robust to noise but also more computationally expensive and slow.\n                Defaults to 75.\n            post_beta (float, optional): factor to define if the unkown pixels\n                should be set as text or background. If beta is 1 then\n                unknown pixels are set to text if the number of surrounding text pixels\n                (N_t) is higher than the number of surrounding background pixels (N_b).\n                Simply N_t &gt; N_b. Beta is the value to put more flexibility on the rule\n                and thus set unknown pixels to text if N_t &gt; beta * N_b\n                Defaults to 1.0.\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        # pylint: disable=duplicate-code\n        self.base.as_grayscale()\n        self.base.asarray = threshold_fair(\n            img=self.base.asarray,\n            sfair_window_size=sfair_window_size,\n            sfair_clustering_algo=sfair_clustering_algo,\n            sfair_clustering_max_iter=sfair_clustering_max_iter,\n            sfair_thining=sfair_thining,\n            sfair_alpha=sfair_alpha,\n            post_stain_max_pixels=post_stain_max_pixels,\n            post_misclass_txt=post_misclass_txt,\n            post_clustering_algo=post_clustering_algo,\n            post_max_iter=post_max_iter,\n            post_clustering_max_iter=post_clustering_max_iter,\n            post_window_size=post_window_size,\n            post_beta=post_beta,\n        )\n        return self.base.parent\n\n    def threshold_isauvola(\n        self,\n        window_size: int = 15,\n        k: float = 0.01,\n        r: float = 128.0,\n        connectivity: int = 8,\n        contrast_window_size: int = 3,\n        opening_n_min_pixels: int = 0,\n        opening_connectivity: int = 8,\n    ) -&gt; \"Image\":\n        \"\"\"Apply ISauvola local thresholding.\n\n        Paper (2016):\n        [ISauvola: Improved Sauvola\u2019s Algorithm for Document Image Binarization](https://www.researchgate.net/publication/304621554_ISauvola_Improved_Sauvola)\n\n        Args:\n            window_size (int, optional): apply on the\n                image. Defaults to 15.\n            k (float, optional): factor to apply to regulate the impact\n                of the std. Defaults to 0.01.\n            r (float, optional): factor to apply to regulate the impact\n                of the std. Defaults to 128.\n            connectivity (int, optional): connectivity to apply on the\n                image. Defaults to 8.\n            contrast_window_size (int, optional): contrast window size to apply on the\n                image. Defaults to 3.\n            opening_n_min_pixels (int, optional): opening n min pixels to apply on the\n                image. Defaults to 0.\n            opening_connectivity (int, optional): opening connectivity to apply on the\n                image. Defaults to 8.\n        \"\"\"\n        # pylint: disable=too-many-arguments, too-many-positional-arguments\n        self.base.as_grayscale()\n        self.base.asarray = threshold_isauvola(\n            img=self.base.asarray,\n            window_size=window_size,\n            k=k,\n            r=r,\n            connectivity=connectivity,\n            contrast_window_size=contrast_window_size,\n            opening_n_min_pixels=opening_n_min_pixels,\n            opening_connectivity=opening_connectivity,\n        )\n        return self.base.parent\n\n    def threshold_wan(\n        self, window_size: int = 15, k: float = 0.5, r: float = 128.0\n    ) -&gt; \"Image\":\n        \"\"\"Apply Wan local thresholding.\n\n        Paper (2018):\n        [Binarization of Document Image Using Optimum Threshold Modification](https://www.researchgate.net/publication/326026836)\n\n        Args:\n            window_size (int, optional): apply on the\n                image. Defaults to 15.\n            k (float, optional): factor to apply to regulate the impact\n                of the std. Defaults to 0.5.\n        \"\"\"\n        self.base.as_grayscale()\n        self.base.asarray = threshold_niblack_like(\n            img=self.base.asarray, method=\"wan\", window_size=window_size, k=k, r=r\n        )[1]\n        return self.base.parent\n\n    # ---------------------------- BINARY REPRESENTATION ------------------------------\n\n    def binary(self, method: BinarizationMethods = \"sauvola\") -&gt; NDArray:\n        \"\"\"Binary representation of the image with values that can be only 0 or 1.\n        The value 0 is now 0 and value of 255 are now 1. Black is 0 and white is 1.\n        We can also talk about the mask of the image to refer to the binary\n        representation of it.\n\n        The sauvola is generally the best binarization method however it is\n        way slower than the others methods. The adaptative or otsu method are the best\n        method in terms of speed and quality.\n\n        Args:\n            method (str, optional): the binarization method to apply.\n                Look at the BinarizationMethods to see all the available methods.\n                Defaults to \"sauvola\".\n\n        Returns:\n            NDArray: array where its inner values are 0 or 1\n        \"\"\"\n        if method not in list(get_args(BinarizationMethods)):\n            raise ValueError(\n                f\"Invalid binarization method {method}. \"\n                f\"Must be in {BinarizationMethods}\"\n            )\n        getattr(self, f\"threshold_{method}\")()\n        return self.base.asarray_binary\n\n    def binaryrev(self, method: BinarizationMethods = \"sauvola\") -&gt; NDArray:\n        \"\"\"Reversed binary representation of the image.\n        The value 0 is now 1 and value of 255 are now 0. Black is 1 and white is 0.\n        This is why it is called the \"binary rev\" or \"binary reversed\".\n\n        Args:\n            method (str, optional): the binarization method to apply.\n                Defaults to \"adaptative\".\n\n        Returns:\n            NDArray: array where its inner values are 0 or 1\n        \"\"\"\n        return 1 - self.binary(method=method)\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.binary","title":"<code>binary(method='sauvola')</code>","text":"<p>Binary representation of the image with values that can be only 0 or 1. The value 0 is now 0 and value of 255 are now 1. Black is 0 and white is 1. We can also talk about the mask of the image to refer to the binary representation of it.</p> <p>The sauvola is generally the best binarization method however it is way slower than the others methods. The adaptative or otsu method are the best method in terms of speed and quality.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>the binarization method to apply. Look at the BinarizationMethods to see all the available methods. Defaults to \"sauvola\".</p> <code>'sauvola'</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>array where its inner values are 0 or 1</p> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def binary(self, method: BinarizationMethods = \"sauvola\") -&gt; NDArray:\n    \"\"\"Binary representation of the image with values that can be only 0 or 1.\n    The value 0 is now 0 and value of 255 are now 1. Black is 0 and white is 1.\n    We can also talk about the mask of the image to refer to the binary\n    representation of it.\n\n    The sauvola is generally the best binarization method however it is\n    way slower than the others methods. The adaptative or otsu method are the best\n    method in terms of speed and quality.\n\n    Args:\n        method (str, optional): the binarization method to apply.\n            Look at the BinarizationMethods to see all the available methods.\n            Defaults to \"sauvola\".\n\n    Returns:\n        NDArray: array where its inner values are 0 or 1\n    \"\"\"\n    if method not in list(get_args(BinarizationMethods)):\n        raise ValueError(\n            f\"Invalid binarization method {method}. \"\n            f\"Must be in {BinarizationMethods}\"\n        )\n    getattr(self, f\"threshold_{method}\")()\n    return self.base.asarray_binary\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.binaryrev","title":"<code>binaryrev(method='sauvola')</code>","text":"<p>Reversed binary representation of the image. The value 0 is now 1 and value of 255 are now 0. Black is 1 and white is 0. This is why it is called the \"binary rev\" or \"binary reversed\".</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>the binarization method to apply. Defaults to \"adaptative\".</p> <code>'sauvola'</code> <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>array where its inner values are 0 or 1</p> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def binaryrev(self, method: BinarizationMethods = \"sauvola\") -&gt; NDArray:\n    \"\"\"Reversed binary representation of the image.\n    The value 0 is now 1 and value of 255 are now 0. Black is 1 and white is 0.\n    This is why it is called the \"binary rev\" or \"binary reversed\".\n\n    Args:\n        method (str, optional): the binarization method to apply.\n            Defaults to \"adaptative\".\n\n    Returns:\n        NDArray: array where its inner values are 0 or 1\n    \"\"\"\n    return 1 - self.binary(method=method)\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_adaptive","title":"<code>threshold_adaptive(block_size=11, constant=2.0)</code>","text":"<p>Apply adaptive local thresholding. This is a local thresholding method that computes the threshold for a pixel based on a small region around it.</p> <p>Consider applying a gaussian blur before for better thresholding results. See why in the OpenCV documentation.</p> <p>Parameters:</p> Name Type Description Default <code>block_size</code> <code>int</code> <p>Size of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7, and so on. Defaults to 11.</p> <code>11</code> <code>constant</code> <code>int</code> <p>Constant subtracted from the mean or weighted mean. Normally, it is positive but may be zero or negative as well. Defaults to 2.</p> <code>2.0</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_adaptive(\n    self, block_size: int = 11, constant: float = 2.0\n) -&gt; \"Image\":\n    \"\"\"Apply adaptive local thresholding.\n    This is a local thresholding method that computes the threshold for a pixel\n    based on a small region around it.\n\n    Consider applying a gaussian blur before for better thresholding results.\n    See why in the [OpenCV documentation](https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html).\n\n    Args:\n        block_size (int, optional): Size of a pixel neighborhood that is used to\n            calculate a threshold value for the pixel: 3, 5, 7, and so on.\n            Defaults to 11.\n        constant (int, optional): Constant subtracted from the mean or weighted\n            mean. Normally, it is positive but may be zero or negative as well.\n            Defaults to 2.\n    \"\"\"\n    self.base.as_grayscale()\n    self.base.asarray = cv2.adaptiveThreshold(\n        src=self.base.asarray,\n        maxValue=255,\n        adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n        thresholdType=cv2.THRESH_BINARY,\n        blockSize=block_size,\n        C=constant,\n    )\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_adotsu","title":"<code>threshold_adotsu(grid_size=50, k_sigma=1.6, n_steps=2)</code>","text":"<p>Apply Adotsu local thresholding.</p> <p>Paper (2011): AdOtsu: An adaptive and parameterless generalization of Otsu\u2019s method for document image binarization</p> <p>Parameters:</p> Name Type Description Default <code>grid_size</code> <code>int</code> <p>window size for local computations. Defaults to 15.</p> <code>50</code> <code>k_sigma</code> <code>float</code> <p>k_sigma value in [1, 2]. Defaults to 1.6.</p> <code>1.6</code> <code>n_steps</code> <code>int</code> <p>number of iterations to update the binarization by estimating a new background surface. Defaults to 2.</p> <code>2</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_adotsu(\n    self, grid_size: int = 50, k_sigma: float = 1.6, n_steps: int = 2\n) -&gt; \"Image\":\n    \"\"\"Apply Adotsu local thresholding.\n\n    Paper (2011):\n    [AdOtsu: An adaptive and parameterless generalization of Otsu\u2019s method for document image binarization](https://www.researchgate.net/publication/220602345)\n\n    Args:\n        grid_size (int, optional): window size for local computations.\n            Defaults to 15.\n        k_sigma (float, optional): k_sigma value in [1, 2]. Defaults to 1.6.\n        n_steps (int, optional): number of iterations to update the binarization by\n            estimating a new background surface. Defaults to 2.\n    \"\"\"\n    self.base.as_grayscale()\n    self.base.asarray = threshold_adotsu(\n        img=self.base.asarray, grid_size=grid_size, k_sigma=k_sigma, n_steps=n_steps\n    )\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_bernsen","title":"<code>threshold_bernsen(window_size=75, contrast_limit=25, threshold_global=100)</code>","text":"<p>Apply Bernsen local thresholding.</p> <p>Paper (1986): \"Dynamic thresholding of grey-level images\" by Bernsen.</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>window size for local computations. Defaults to 75.</p> <code>75</code> <code>contrast_limit</code> <code>float</code> <p>contrast limit. If the contrast is higher than this value, the pixel is thresholded by the bernsen threshold otherwise the global threshold is used. Defaults to 25.</p> <code>25</code> <code>threshold_global</code> <code>int</code> <p>global threshold. Defaults to 100.</p> <code>100</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_bernsen(\n    self,\n    window_size: int = 75,\n    contrast_limit: float = 25,\n    threshold_global: int = 100,\n) -&gt; \"Image\":\n    \"\"\"Apply Bernsen local thresholding.\n\n    Paper (1986):\n    \"Dynamic thresholding of grey-level images\" by Bernsen.\n\n    Args:\n        window_size (int, optional): window size for local computations.\n            Defaults to 75.\n        contrast_limit (float, optional): contrast limit. If the\n            contrast is higher than this value, the pixel is thresholded by the\n            bernsen threshold otherwise the global threshold is used.\n            Defaults to 25.\n        threshold_global (int, optional): global threshold. Defaults to 100.\n    \"\"\"\n    self.base.as_grayscale()\n    self.base.asarray = threshold_bernsen(\n        img=self.base.asarray,\n        window_size=window_size,\n        contrast_limit=contrast_limit,\n        threshold_global=threshold_global,\n    )\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_bradley","title":"<code>threshold_bradley(window_size=15, t=0.15)</code>","text":"<p>Implementation of the Bradley &amp; Roth thresholding method.</p> <p>Paper (2007): Adaptive Thresholding using the Integral Image</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>window size for local computations. Defaults to 15.</p> <code>15</code> <code>t</code> <code>float</code> <p>t value in [0, 1]. Defaults to 0.15.</p> <code>0.15</code> <p>Returns:</p> Type Description <code>Image</code> <p>NDArray[np.uint8]: output thresholded image</p> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_bradley(self, window_size: int = 15, t: float = 0.15) -&gt; \"Image\":\n    \"\"\"Implementation of the Bradley &amp; Roth thresholding method.\n\n    Paper (2007):\n    [Adaptive Thresholding using the Integral Image](https://www.researchgate.net/publication/220494200_Adaptive_Thresholding_using_the_Integral_Image)\n\n    Args:\n        window_size (int, optional): window size for local computations.\n            Defaults to 15.\n        t (float, optional): t value in [0, 1]. Defaults to 0.15.\n\n    Returns:\n        NDArray[np.uint8]: output thresholded image\n    \"\"\"\n    self.base.as_grayscale()\n    self.base.asarray = threshold_bradley(\n        img=self.base.asarray, window_size=window_size, t=t\n    )\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_fair","title":"<code>threshold_fair(sfair_window_size=33, sfair_clustering_algo='otsu', sfair_clustering_max_iter=20, sfair_thining=1.0, sfair_alpha=0.38, post_stain_max_pixels=25, post_misclass_txt=True, post_clustering_algo='otsu', post_clustering_max_iter=10, post_max_iter=15, post_window_size=75, post_beta=1.0)</code>","text":"<p>Apply FAIR local thresholding.</p> <p>Paper (2013): FAIR: A Fast Algorithm for document Image Restoration</p> <p>Parameters:</p> Name Type Description Default <code>sfair_window_size</code> <code>int</code> <p>window size in preprocess to cluster background and foreground pixels around edge pixels. This parameter is important as a higher value will make the method more robust to noise but also more computationally expensive and slow. Defaults to 5.</p> <code>33</code> <code>sfair_clustering_algo</code> <code>str</code> <p>clustering algorithm for the S-FAIR step. Defaults to \"otsu\".</p> <code>'otsu'</code> <code>sfair_clustering_max_iter</code> <code>int</code> <p>maximum number of iterations for the clustering algorithm within the S-FAIR step. Defaults to 20.</p> <code>20</code> <code>sfair_thining</code> <code>float</code> <p>thining factor in [0, 1]. 0 means no thinning which means that all edge pixels are processed. 1 means that only every sfair_window_size // 2 edge pixels are processed which signicantly speeds up the computation. Defaults to 1.0.</p> <code>1.0</code> <code>sfair_alpha</code> <code>float</code> <p>It defines the ratio to compute the lower threshold in the 1st step of the S-FAIR step. It is generally in [0.3, 0.5]. Defaults to 0.38.</p> <code>0.38</code> <code>post_stain_max_pixels</code> <code>int</code> <p>maximum number of pixels for a stain to be considered as an unknown connected component. Defaults to 25.</p> <code>25</code> <code>post_misclass_txt</code> <code>bool</code> <p>whether to perform the post-processing correct_misclassified_text_pixels step. Defaults to True.</p> <code>True</code> <code>post_clustering_algo</code> <code>str</code> <p>clustering algorithm for the post-processing step. Defaults to \"otsu\".</p> <code>'otsu'</code> <code>post_clustering_max_iter</code> <code>int</code> <p>maximum number of iterations for the clustering algorithm within the post-processing step. Defaults to 10.</p> <code>10</code> <code>post_max_iter</code> <code>int</code> <p>maximum number of iterations for the correct_misclassified_text_pixels step within the post-processing step. Defaults to 15.</p> <code>15</code> <code>post_window_size</code> <code>int</code> <p>window size in postprocess to cluster background and foreground pixels around edge pixels. This parameter is important as a higher value will make the method more robust to noise but also more computationally expensive and slow. Defaults to 75.</p> <code>75</code> <code>post_beta</code> <code>float</code> <p>factor to define if the unkown pixels should be set as text or background. If beta is 1 then unknown pixels are set to text if the number of surrounding text pixels (N_t) is higher than the number of surrounding background pixels (N_b). Simply N_t &gt; N_b. Beta is the value to put more flexibility on the rule and thus set unknown pixels to text if N_t &gt; beta * N_b Defaults to 1.0.</p> <code>1.0</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_fair(\n    self,\n    sfair_window_size: int = 33,\n    sfair_clustering_algo: str = \"otsu\",\n    sfair_clustering_max_iter: int = 20,\n    sfair_thining: float = 1.0,\n    sfair_alpha: float = 0.38,\n    post_stain_max_pixels: int = 25,\n    post_misclass_txt: bool = True,\n    post_clustering_algo: str = \"otsu\",\n    post_clustering_max_iter: int = 10,\n    post_max_iter: int = 15,\n    post_window_size: int = 75,\n    post_beta: float = 1.0,\n) -&gt; \"Image\":\n    \"\"\"Apply FAIR local thresholding.\n\n    Paper (2013):\n    [FAIR: A Fast Algorithm for document Image Restoration](https://amu.hal.science/hal-01479805/document)\n\n    Args:\n        sfair_window_size (int, optional): window size in preprocess\n            to cluster background and foreground pixels around edge pixels.\n            This parameter is important as a higher value will make the method\n            more robust to noise but also more computationally expensive and slow.\n            Defaults to 5.\n        sfair_clustering_algo (str, optional): clustering algorithm for the S-FAIR\n            step. Defaults to \"otsu\".\n        sfair_clustering_max_iter (int, optional): maximum number of iterations for\n            the clustering algorithm within the S-FAIR step. Defaults to 20.\n        sfair_thining (float, optional): thining factor in [0, 1]. 0 means no\n            thinning which means that all edge pixels are processed.\n            1 means that only every\n            sfair_window_size // 2 edge pixels are processed which signicantly\n            speeds up the computation. Defaults to 1.0.\n        sfair_alpha (float, optional): It defines the ratio to compute the lower\n            threshold in the 1st step of the S-FAIR step.\n            It is generally in [0.3, 0.5].\n            Defaults to 0.38.\n        post_stain_max_pixels (int, optional): maximum number of pixels for a stain\n            to be considered as an unknown connected component. Defaults to 25.\n        post_misclass_txt (bool, optional): whether to perform the\n            post-processing correct_misclassified_text_pixels step.\n            Defaults to True.\n        post_clustering_algo (str, optional): clustering algorithm for the\n            post-processing step. Defaults to \"otsu\".\n        post_clustering_max_iter (int, optional): maximum number of iterations for\n            the clustering algorithm within the post-processing step.\n            Defaults to 10.\n        post_max_iter (int, optional): maximum number of iterations for the\n            correct_misclassified_text_pixels step within the post-processing step.\n            Defaults to 15.\n        post_window_size (int, optional): window size in postprocess\n            to cluster background and foreground pixels around edge pixels.\n            This parameter is important as a higher value will make the method\n            more robust to noise but also more computationally expensive and slow.\n            Defaults to 75.\n        post_beta (float, optional): factor to define if the unkown pixels\n            should be set as text or background. If beta is 1 then\n            unknown pixels are set to text if the number of surrounding text pixels\n            (N_t) is higher than the number of surrounding background pixels (N_b).\n            Simply N_t &gt; N_b. Beta is the value to put more flexibility on the rule\n            and thus set unknown pixels to text if N_t &gt; beta * N_b\n            Defaults to 1.0.\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    # pylint: disable=duplicate-code\n    self.base.as_grayscale()\n    self.base.asarray = threshold_fair(\n        img=self.base.asarray,\n        sfair_window_size=sfair_window_size,\n        sfair_clustering_algo=sfair_clustering_algo,\n        sfair_clustering_max_iter=sfair_clustering_max_iter,\n        sfair_thining=sfair_thining,\n        sfair_alpha=sfair_alpha,\n        post_stain_max_pixels=post_stain_max_pixels,\n        post_misclass_txt=post_misclass_txt,\n        post_clustering_algo=post_clustering_algo,\n        post_max_iter=post_max_iter,\n        post_clustering_max_iter=post_clustering_max_iter,\n        post_window_size=post_window_size,\n        post_beta=post_beta,\n    )\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_feng","title":"<code>threshold_feng(w1=19, w2=33, alpha1=0.12, k1=0.25, k2=0.04, gamma=2.0)</code>","text":"<p>Implementation of the Feng thresholding method.</p> <p>Paper (2004): Contrast adaptive binarization of low quality document images</p> <p>Parameters:</p> Name Type Description Default <code>w1</code> <code>int</code> <p>primary window size. Defaults to 19.</p> <code>19</code> <code>w2</code> <code>int</code> <p>secondary window value. Defaults to 33.</p> <code>33</code> <code>alpha1</code> <code>float</code> <p>alpha1 value. Defaults to 0.12.</p> <code>0.12</code> <code>k1</code> <code>float</code> <p>k1 value. Defaults to 0.25.</p> <code>0.25</code> <code>k2</code> <code>float</code> <p>k2 value. Defaults to 0.04.</p> <code>0.04</code> <code>gamma</code> <code>float</code> <p>gamma value. Defaults to 2.0.</p> <code>2.0</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_feng(\n    self,\n    w1: int = 19,\n    w2: int = 33,\n    alpha1: float = 0.12,\n    k1: float = 0.25,\n    k2: float = 0.04,\n    gamma: float = 2.0,\n) -&gt; \"Image\":\n    \"\"\"Implementation of the Feng thresholding method.\n\n    Paper (2004):\n    [Contrast adaptive binarization of low quality document images](https://www.jstage.jst.go.jp/article/elex/1/16/1_16_501/_pdf)\n\n    Args:\n        w1 (int, optional): primary window size. Defaults to 19.\n        w2 (int, optional): secondary window value. Defaults to 33.\n        alpha1 (float, optional): alpha1 value. Defaults to 0.12.\n        k1 (float, optional): k1 value. Defaults to 0.25.\n        k2 (float, optional): k2 value. Defaults to 0.04.\n        gamma (float, optional): gamma value. Defaults to 2.0.\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    self.base.as_grayscale()\n    self.base.asarray = threshold_feng(\n        img=self.base.asarray,\n        w1=w1,\n        w2=w2,\n        alpha1=alpha1,\n        k1=k1,\n        k2=k2,\n        gamma=gamma,\n    )\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_gatos","title":"<code>threshold_gatos(q=0.6, p1=0.5, p2=0.8, lh=None, upsampling=False, upsampling_factor=2)</code>","text":"<p>Apply Gatos local thresholding.</p> <p>Paper (2005): Adaptive degraded document image binarization</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>float</code> <p>q gatos factor. Defaults to 0.6.</p> <code>0.6</code> <code>p1</code> <code>float</code> <p>p1 gatos factor. Defaults to 0.5.</p> <code>0.5</code> <code>p2</code> <code>float</code> <p>p2 gatos factor. Defaults to 0.8.</p> <code>0.8</code> <code>lh</code> <code>Optional[float]</code> <p>height of character. Defaults to None, meaning it is computed automatically to be a fraction of the image size.</p> <code>None</code> <code>upsampling</code> <code>bool</code> <p>whether to apply gatos upsampling definition. Defaults to False.</p> <code>False</code> <code>upsampling_factor</code> <code>int</code> <p>gatos upsampling factor. Defaults to 2.</p> <code>2</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_gatos(\n    self,\n    q: float = 0.6,\n    p1: float = 0.5,\n    p2: float = 0.8,\n    lh: Optional[float] = None,\n    upsampling: bool = False,\n    upsampling_factor: int = 2,\n) -&gt; \"Image\":\n    \"\"\"Apply Gatos local thresholding.\n\n    Paper (2005):\n    [Adaptive degraded document image binarization](https://users.iit.demokritos.gr/~bgat/PatRec2006.pdf)\n\n    Args:\n        q (float, optional): q gatos factor. Defaults to 0.6.\n        p1 (float, optional): p1 gatos factor. Defaults to 0.5.\n        p2 (float, optional): p2 gatos factor. Defaults to 0.8.\n        lh (Optional[float], optional): height of character.\n            Defaults to None, meaning it is computed automatically to be\n            a fraction of the image size.\n        upsampling (bool, optional): whether to apply gatos upsampling definition.\n            Defaults to False.\n        upsampling_factor (int, optional): gatos upsampling factor. Defaults to 2.\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    # pylint: disable=duplicate-code\n    self.base.as_grayscale()\n    self.base.asarray = threshold_gatos(\n        img=self.base.asarray,\n        q=q,\n        p1=p1,\n        p2=p2,\n        lh=lh,\n        upsampling=upsampling,\n        upsampling_factor=upsampling_factor,\n    )\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_isauvola","title":"<code>threshold_isauvola(window_size=15, k=0.01, r=128.0, connectivity=8, contrast_window_size=3, opening_n_min_pixels=0, opening_connectivity=8)</code>","text":"<p>Apply ISauvola local thresholding.</p> <p>Paper (2016): ISauvola: Improved Sauvola\u2019s Algorithm for Document Image Binarization</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>apply on the image. Defaults to 15.</p> <code>15</code> <code>k</code> <code>float</code> <p>factor to apply to regulate the impact of the std. Defaults to 0.01.</p> <code>0.01</code> <code>r</code> <code>float</code> <p>factor to apply to regulate the impact of the std. Defaults to 128.</p> <code>128.0</code> <code>connectivity</code> <code>int</code> <p>connectivity to apply on the image. Defaults to 8.</p> <code>8</code> <code>contrast_window_size</code> <code>int</code> <p>contrast window size to apply on the image. Defaults to 3.</p> <code>3</code> <code>opening_n_min_pixels</code> <code>int</code> <p>opening n min pixels to apply on the image. Defaults to 0.</p> <code>0</code> <code>opening_connectivity</code> <code>int</code> <p>opening connectivity to apply on the image. Defaults to 8.</p> <code>8</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_isauvola(\n    self,\n    window_size: int = 15,\n    k: float = 0.01,\n    r: float = 128.0,\n    connectivity: int = 8,\n    contrast_window_size: int = 3,\n    opening_n_min_pixels: int = 0,\n    opening_connectivity: int = 8,\n) -&gt; \"Image\":\n    \"\"\"Apply ISauvola local thresholding.\n\n    Paper (2016):\n    [ISauvola: Improved Sauvola\u2019s Algorithm for Document Image Binarization](https://www.researchgate.net/publication/304621554_ISauvola_Improved_Sauvola)\n\n    Args:\n        window_size (int, optional): apply on the\n            image. Defaults to 15.\n        k (float, optional): factor to apply to regulate the impact\n            of the std. Defaults to 0.01.\n        r (float, optional): factor to apply to regulate the impact\n            of the std. Defaults to 128.\n        connectivity (int, optional): connectivity to apply on the\n            image. Defaults to 8.\n        contrast_window_size (int, optional): contrast window size to apply on the\n            image. Defaults to 3.\n        opening_n_min_pixels (int, optional): opening n min pixels to apply on the\n            image. Defaults to 0.\n        opening_connectivity (int, optional): opening connectivity to apply on the\n            image. Defaults to 8.\n    \"\"\"\n    # pylint: disable=too-many-arguments, too-many-positional-arguments\n    self.base.as_grayscale()\n    self.base.asarray = threshold_isauvola(\n        img=self.base.asarray,\n        window_size=window_size,\n        k=k,\n        r=r,\n        connectivity=connectivity,\n        contrast_window_size=contrast_window_size,\n        opening_n_min_pixels=opening_n_min_pixels,\n        opening_connectivity=opening_connectivity,\n    )\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_niblack","title":"<code>threshold_niblack(window_size=15, k=-0.2)</code>","text":"<p>Apply Niblack local thresholding.</p> <p>Book (1986): \"An Introduction to Digital Image Processing\" by Wayne Niblack.</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>apply on the image. Defaults to 15.</p> <code>15</code> <code>k</code> <code>float</code> <p>factor to apply to regulate the impact of the std. Defaults to -0.2.</p> <code>-0.2</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_niblack(self, window_size: int = 15, k: float = -0.2) -&gt; \"Image\":\n    \"\"\"Apply Niblack local thresholding.\n\n    Book (1986):\n    \"An Introduction to Digital Image Processing\" by Wayne Niblack.\n\n    Args:\n        window_size (int, optional): apply on the\n            image. Defaults to 15.\n        k (float, optional): factor to apply to regulate the impact\n            of the std. Defaults to -0.2.\n    \"\"\"\n    self.base.as_grayscale()\n    self.base.asarray = threshold_niblack_like(\n        img=self.base.asarray, method=\"niblack\", window_size=window_size, k=k\n    )[1]\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_nick","title":"<code>threshold_nick(window_size=19, k=-0.1)</code>","text":"<p>Apply Nick local thresholding.</p> <p>Paper (2009): Comparison of Niblack inspired Binarization Methods for Ancient Documents</p> <p>The paper suggests to use a window size of 19 and a k factor in [-0.2, -0.1].</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>apply on the image. Defaults to 15.</p> <code>19</code> <code>k</code> <code>float</code> <p>factor to apply to regulate the impact of the std. Defaults to -0.1.</p> <code>-0.1</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_nick(self, window_size: int = 19, k: float = -0.1) -&gt; \"Image\":\n    \"\"\"Apply Nick local thresholding.\n\n    Paper (2009):\n    [Comparison of Niblack inspired Binarization Methods for Ancient Documents](https://www.researchgate.net/publication/221253803)\n\n    The paper suggests to use a window size of 19 and a k factor in [-0.2, -0.1].\n\n    Args:\n        window_size (int, optional): apply on the\n            image. Defaults to 15.\n        k (float, optional): factor to apply to regulate the impact\n            of the std. Defaults to -0.1.\n    \"\"\"\n    self.base.as_grayscale()\n    self.base.asarray = threshold_niblack_like(\n        img=self.base.asarray, method=\"nick\", window_size=window_size, k=k\n    )[1]\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_otsu","title":"<code>threshold_otsu()</code>","text":"<p>Apply Otsu global thresholding. This is a global thresholding method that automatically determines an optimal threshold value from the image histogram.</p> <p>Paper (1979): A Threshold Selection Method from Gray-Level Histograms</p> <p>Consider applying a gaussian blur before for better thresholding results. See why in the OpenCV documentation.</p> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_otsu(self) -&gt; \"Image\":\n    \"\"\"Apply Otsu global thresholding.\n    This is a global thresholding method that automatically determines\n    an optimal threshold value from the image histogram.\n\n    Paper (1979):\n    [A Threshold Selection Method from Gray-Level Histograms](https://ieeexplore.ieee.org/document/4310076)\n\n    Consider applying a gaussian blur before for better thresholding results.\n    See why in the [OpenCV documentation](https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html).\n    \"\"\"\n    self.base.as_grayscale()\n    _, img_thresholded = cv2.threshold(\n        self.base.asarray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n    )\n    self.base.asarray = img_thresholded\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_phansalkar","title":"<code>threshold_phansalkar(window_size=40, k=0.25, p=3.0, q=10.0)</code>","text":"<p>Apply Phansalkar et al. local thresholding.</p> <p>Paper (2011): Adaptive Local Thresholding for Detection of Nuclei in Diversely Stained Cytology Images</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>apply on the image. Defaults to 40.</p> <code>40</code> <code>k</code> <code>float</code> <p>factor to apply to regulate the impact of the std. Defaults to 0.25.</p> <code>0.25</code> <code>p</code> <code>float</code> <p>Phansalkar parameter to regulate low contrast zones. Defaults to 3.0.</p> <code>3.0</code> <code>q</code> <code>float</code> <p>Phansalkar parameter to regulate low contrast zones. Defaults to 10.0.</p> <code>10.0</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_phansalkar(\n    self, window_size: int = 40, k: float = 0.25, p: float = 3.0, q: float = 10.0\n) -&gt; \"Image\":\n    \"\"\"Apply Phansalkar et al. local thresholding.\n\n    Paper (2011):\n    [Adaptive Local Thresholding for Detection of Nuclei in Diversely Stained Cytology Images](https://www.researchgate.net/publication/224226466)\n\n    Args:\n        window_size (int, optional): apply on the\n            image. Defaults to 40.\n        k (float, optional): factor to apply to regulate the impact\n            of the std. Defaults to 0.25.\n        p (float, optional): Phansalkar parameter to regulate low contrast zones.\n            Defaults to 3.0.\n        q (float, optional): Phansalkar parameter to regulate low contrast zones.\n            Defaults to 10.0.\n    \"\"\"\n    self.base.as_grayscale()\n    self.base.asarray = threshold_niblack_like(\n        img=self.base.asarray,\n        method=\"phansalkar\",\n        window_size=window_size,\n        k=k,\n        p=p,\n        q=q,\n    )[1]\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_sauvola","title":"<code>threshold_sauvola(window_size=15, k=0.5, r=128.0)</code>","text":"<p>Apply Sauvola local thresholding. This is a local thresholding method that computes the threshold for a pixel based on a small region around it.</p> <p>Paper (1997): Adaptive Document Binarization</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>sauvola window size to apply on the image. Defaults to 15.</p> <code>15</code> <code>k</code> <code>float</code> <p>sauvola k factor to apply to regulate the impact of the std. Defaults to 0.5.</p> <code>0.5</code> <code>r</code> <code>float</code> <p>sauvola r value. Defaults to 128.</p> <code>128.0</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_sauvola(\n    self, window_size: int = 15, k: float = 0.5, r: float = 128.0\n) -&gt; \"Image\":\n    \"\"\"Apply Sauvola local thresholding.\n    This is a local thresholding method that computes the threshold for a pixel\n    based on a small region around it.\n\n    Paper (1997):\n    [Adaptive Document Binarization](https://www.researchgate.net/publication/3710586_Adaptive_Document_Binarization)\n\n    Args:\n        window_size (int, optional): sauvola window size to apply on the\n            image. Defaults to 15.\n        k (float, optional): sauvola k factor to apply to regulate the impact\n            of the std. Defaults to 0.5.\n        r (float, optional): sauvola r value. Defaults to 128.\n    \"\"\"\n    self.base.as_grayscale()\n    self.base.asarray = threshold_niblack_like(\n        img=self.base.asarray, method=\"sauvola\", window_size=window_size, k=k, r=r\n    )[1]\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_simple","title":"<code>threshold_simple(thresh)</code>","text":"<p>Compute the image thresholded by a single value T. All pixels with value v &lt;= T are turned black and those with value v &gt; T are turned white. This is a global thresholding method.</p> <p>Parameters:</p> Name Type Description Default <code>thresh</code> <code>int</code> <p>value to separate the black from the white pixels.</p> required Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_simple(self, thresh: int) -&gt; \"Image\":\n    \"\"\"Compute the image thresholded by a single value T.\n    All pixels with value v &lt;= T are turned black and those with value v &gt; T are\n    turned white. This is a global thresholding method.\n\n    Args:\n        thresh (int): value to separate the black from the white pixels.\n    \"\"\"\n    self.base.as_grayscale()\n    self.base.asarray = np.array((self.base.asarray &gt; thresh) * 255, dtype=np.uint8)\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_singh","title":"<code>threshold_singh(window_size=15, k=0.06)</code>","text":"<p>Apply Singh local thresholding.</p> <p>Paper (2012): A New Local Adaptive Thresholding Technique in Binarization</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>apply on the image. Defaults to 15.</p> <code>15</code> <code>k</code> <code>float</code> <p>factor to apply to regulate the impact of the std. Defaults to 0.06.</p> <code>0.06</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_singh(self, window_size: int = 15, k: float = 0.06) -&gt; \"Image\":\n    \"\"\"Apply Singh local thresholding.\n\n    Paper (2012):\n    [A New Local Adaptive Thresholding Technique in Binarization](https://www.researchgate.net/publication/220485031)\n\n    Args:\n        window_size (int, optional): apply on the\n            image. Defaults to 15.\n        k (float, optional): factor to apply to regulate the impact\n            of the std. Defaults to 0.06.\n    \"\"\"\n    self.base.as_grayscale()\n    self.base.asarray = threshold_niblack_like(\n        img=self.base.asarray, method=\"singh\", window_size=window_size, k=k\n    )[1]\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_su","title":"<code>threshold_su(window_size=3, n_min=-1)</code>","text":"<p>Compute the Su local thresholding.</p> <p>Paper (2010): Binarization of historical document images using the local maximum and minimum</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>window size for high contrast image computation. Defaults to 3.</p> <code>3</code> <code>n_min</code> <code>int</code> <p>minimum number of high contrast pixels within the neighborhood window. Defaults to -1 meaning that n_min = window_size.</p> <code>-1</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_su(\n    self,\n    window_size: int = 3,\n    n_min: int = -1,\n) -&gt; \"Image\":\n    \"\"\"Compute the Su local thresholding.\n\n    Paper (2010):\n    [Binarization of historical document images using the local maximum and minimum](https://www.researchgate.net/publication/220933012)\n\n    Args:\n        window_size (int, optional): window size for high contrast image\n            computation. Defaults to 3.\n        n_min (int, optional): minimum number of high contrast pixels within the\n            neighborhood window. Defaults to -1 meaning that n_min = window_size.\n    \"\"\"\n    self.base.as_grayscale()\n    self.base.asarray = threshold_su(\n        img=self.base.asarray, window_size=window_size, n_min=n_min\n    )\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_wan","title":"<code>threshold_wan(window_size=15, k=0.5, r=128.0)</code>","text":"<p>Apply Wan local thresholding.</p> <p>Paper (2018): Binarization of Document Image Using Optimum Threshold Modification</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>apply on the image. Defaults to 15.</p> <code>15</code> <code>k</code> <code>float</code> <p>factor to apply to regulate the impact of the std. Defaults to 0.5.</p> <code>0.5</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_wan(\n    self, window_size: int = 15, k: float = 0.5, r: float = 128.0\n) -&gt; \"Image\":\n    \"\"\"Apply Wan local thresholding.\n\n    Paper (2018):\n    [Binarization of Document Image Using Optimum Threshold Modification](https://www.researchgate.net/publication/326026836)\n\n    Args:\n        window_size (int, optional): apply on the\n            image. Defaults to 15.\n        k (float, optional): factor to apply to regulate the impact\n            of the std. Defaults to 0.5.\n    \"\"\"\n    self.base.as_grayscale()\n    self.base.asarray = threshold_niblack_like(\n        img=self.base.asarray, method=\"wan\", window_size=window_size, k=k, r=r\n    )[1]\n    return self.base.parent\n</code></pre>"},{"location":"api/image/transformers/thresholding/#otary.image.components.transformer.components.binarizer.binarizer.BinarizerImage.threshold_wolf","title":"<code>threshold_wolf(window_size=15, k=0.5)</code>","text":"<p>Apply Wolf local thresholding.</p> <p>Paper (2003): Extraction and Recognition of Artificial Text in Multimedia Documents</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>apply on the image. Defaults to 15.</p> <code>15</code> <code>k</code> <code>float</code> <p>factor to apply to regulate the impact of the std. Defaults to 0.5.</p> <code>0.5</code> Source code in <code>otary/image/components/transformer/components/binarizer/binarizer.py</code> <pre><code>def threshold_wolf(self, window_size: int = 15, k: float = 0.5) -&gt; \"Image\":\n    \"\"\"Apply Wolf local thresholding.\n\n    Paper (2003):\n    [Extraction and Recognition of Artificial Text in Multimedia Documents](https://hal.science/hal-01504401v1)\n\n    Args:\n        window_size (int, optional): apply on the\n            image. Defaults to 15.\n        k (float, optional): factor to apply to regulate the impact\n            of the std. Defaults to 0.5.\n    \"\"\"\n    self.base.as_grayscale()\n    self.base.asarray = threshold_niblack_like(\n        img=self.base.asarray, method=\"wolf\", window_size=window_size, k=k\n    )[1]\n    return self.base.parent\n</code></pre>"},{"location":"learn/","title":"Learn","text":"<p>Tutorials coming soon !</p>"}]}